{"prompt": "What are the different levels at which access control can be added to the platform? \n\n###\n\n", "completion": " uuid: 12044422040 Access control can be added at the cluster level, workspace level, and individual service level.\n"}
{"prompt": "Can access control be added at the deployment level? \n\n###\n\n", "completion": " uuid: 12044422040 Yes, access control can be added at the deployment level.\n"}
{"prompt": "What APIs are exposed for logging metrics and data? \n\n###\n\n", "completion": " uuid: 12044422040 APIs for logging parameters, data, and metrics are exposed.\n"}
{"prompt": "What is the Model Registry? \n\n###\n\n", "completion": " uuid: 12044422040 The Model Registry is a feature that allows for easy logging and deployment of models in different versions.\n"}
{"prompt": "Where can models be stored? \n\n###\n\n", "completion": " uuid: 12044422040 Models can be stored either on the cluster's cloud or on the user's cloud.\n"}
{"prompt": "What is the pricing structure for the platform? \n\n###\n\n", "completion": " uuid: 12044422040 The platform charges by the number of users, with a minimum of ten users at $150 per user per month. Pricing can be discussed and adjusted based on individual requirements.\n"}
{"prompt": "What is the next step after the call? \n\n###\n\n", "completion": " uuid: 12044422040 The next step is an internal discussion on Friday, followed by a larger team demo and setting up trial accounts after defining objectives and a start and end date for the trial.\n"}
{"prompt": "Who is speaking in the context? \n\n###\n\n", "completion": " uuid: 11189924245 Niquinh.\n"}
{"prompt": "Who is Yogesh? \n\n###\n\n", "completion": " uuid: 11189924245 The person being spoken to.\n"}
{"prompt": "What is Niquinh asking Yogesh in the beginning? \n\n###\n\n", "completion": " uuid: 11189924245 If he should call back later or if Yogesh can wait for ten minutes.\n"}
{"prompt": "What does Yogesh say in response to Niquinh's request to wait for ten minutes? \n\n###\n\n", "completion": " uuid: 11189924245 They can join the Google call together in ten minutes.\n"}
{"prompt": "What type of companies is Yogesh referring to when he says 'companies like CVS'? \n\n###\n\n", "completion": " uuid: 11189924245 Corporate American companies.\n"}
{"prompt": "Who is Yogesh targeting for his business? \n\n###\n\n", "completion": " uuid: 11189924245 Large companies that do not have much machine learning expertise.\n"}
{"prompt": "What is the goal for Yogesh's startup? \n\n###\n\n", "completion": " uuid: 11189924245 To work closely with five large companies to solve their initial use cases and prove value.\n"}
{"prompt": "What does Yogesh say is the most important aspect for the startup to be cautious about? \n\n###\n\n", "completion": " uuid: 11189924245 Constantly being in touch with the executives at the top level and having a spokesperson to generate revenue and long term business.\n"}
{"prompt": "What is True Foundry and what problem are they trying to solve? \n\n###\n\n", "completion": " uuid: 11564066567 True Foundry is a startup in the machine learning domain, helping companies build out ML platforms. They are solving the problem of making machine learning developers more productive by providing internal tools for frequent updates and cutting edge technology.\n"}
{"prompt": "What is the main challenge with deploying ML in the fintech industry? \n\n###\n\n", "completion": " uuid: 11564066567 The main challenge with deploying ML in the fintech industry is explainability. Fintech companies need to have a clear explanation of their ML models to regulators in order to use personal information in decision making.\n"}
{"prompt": "How is the team structured at Lending Club for building and deploying models? \n\n###\n\n", "completion": " uuid: 11564066567 There are separate teams for building and deploying models at Lending Club. Data scientists build the models and pass on requirements to data engineers who deploy, test, launch, and maintain the models in production.\n"}
{"prompt": "What is the focus of ML models at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 The focus of ML models at Lending Club is primarily on risk. Alternative data is a nascent area they are currently exploring for underwriting models.\n"}
{"prompt": "What is an example of alternative data at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 An example of alternative data at Lending Club is bank transaction data, which is currently being explored for underwriting models. However, the challenge is generating signals quickly enough, as runtime needs to be in milliseconds rather than seconds.\n"}
{"prompt": "What is the broad objective of the call? \n\n###\n\n", "completion": " uuid: 10881905922 To understand the ML process and pain points and get to know each other.\n"}
{"prompt": "Where is Vivek based now? \n\n###\n\n", "completion": " uuid: 10881905922 He is based in Bangalore.\n"}
{"prompt": "What is True Foundry and what are they building? \n\n###\n\n", "completion": " uuid: 10881905922 True Foundry is a startup building a platform for machine learning teams. They focus on model deployment and are working with design partners.\n"}
{"prompt": "How is Freshworks' ML team structured? \n\n###\n\n", "completion": " uuid: 10881905922 Freshworks has a monolithic code base with a separate team maintaining infrastructure. Their ML team operates with a layer that abstracts the application from the ML service, and ML services are specific to each account.\n"}
{"prompt": "Where are the models stored for inference? \n\n###\n\n", "completion": " uuid: 10881905922 Models are stored in an S3 model registry for inference.\n"}
{"prompt": "What is the main focus of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 10881905922 The main focus is on model deployment, enabling teams to deploy and monitor their machine learning models quickly.\n"}
{"prompt": "How does Freshworks guarantee performance for as many models as possible? \n\n###\n\n", "completion": " uuid: 10881905922 They have a custom-designed app with caching built in that ensures calls for a particular inference from a particular account meet certain SLA parameters.\n"}
{"prompt": "What is the problem with losing clients and how do they want to approach it? \n\n###\n\n", "completion": " uuid: 10323043378 They want to understand the problem and how it is hurting the clients, and also know how the clients have attempted to solve the problem prior to showcasing the capabilities of their product. They will try to have a personalized demo based on the client's specific use case.\n"}
{"prompt": "What is the plan for the demo and what will be sent beforehand? \n\n###\n\n", "completion": " uuid: 10323043378 Before the demo, they will send a document for the client to agree to the setup. During the demo, they will showcase how their platform can add value to the client's existing tools and solve the specific problems they are facing.\n"}
{"prompt": "What are some key questions they want to ask the client during the call? \n\n###\n\n", "completion": " uuid: 10323043378 They want to understand if deployment time is a problem, if the client is using ML Flow and if not, why, how much time batch inference takes, what existing tools the client is using, what business problems they are trying to solve, if they are being crunched on time, and if they are looking to hire more data scientists.\n"}
{"prompt": "What are some comparisons they can make to differentiate their platform from others? \n\n###\n\n", "completion": " uuid: 10323043378 They can discuss their expertise in Kubernetes and how it offers more flexibility for deployment over Sage Maker, as well as the potential cost savings compared to other platforms. They can also focus on specific areas where they excel, such as feature store management and data-driven monitoring.\n"}
{"prompt": "What is the plan for follow-up after the call? \n\n###\n\n", "completion": " uuid: 10323043378 They will keep the client in the loop by sending updates and seeking feedback. They also want to build a community of data scientists for feedback and suggestions on how to improve their platform.\n"}
{"prompt": "What is the context of the conversation? \n\n###\n\n", "completion": " uuid: 11189840489 A conversation between two people, Amar and Nicole, discussing Amar's platform and if it fits the use case for Dozee, including running hyper parameter tuning jobs and running models on the cloud.\n"}
{"prompt": "What are some of the issues with the current model training at Dozee? \n\n###\n\n", "completion": " uuid: 11189840489 The current process of running and training models is done on local machines, some jobs take a long time to run, and there is a desire to save and organize results remotely.\n"}
{"prompt": "What is the purpose of the Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189840489 The purpose of the Truefoundry platform is to provide a cloud-based solution for machine learning tasks, including running and training models, and organizing and visualizing results.\n"}
{"prompt": "What is the deployment process of a model on the Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189840489 The deployment process of a model on the Truefoundry platform involves writing a script to deploy the model, specifying dependencies, and setting up a job to run the script on a remote machine.\n"}
{"prompt": "What can be tracked and visualized on the Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189840489 Metrics and outputs from multiple runs and models can be tracked and visualized over time on the Truefoundry platform.\n"}
{"prompt": "Who is the CTO of you.com and what is his background? \n\n###\n\n", "completion": " uuid: 10784174762 The CTO of you.com is Brent and he co-founded it with Richard a few years ago. He worked with Richard at salesforce for about four years, doing research in AI, transfer learning, multitraining, and large language models. He has experience with chainer PyTorch alpha testing and GPUs.\n"}
{"prompt": "Who is involved with Builders Fund and how do they relate to you.com? \n\n###\n\n", "completion": " uuid: 10784174762 Pete from Builders Fund met Richard when they were both at salesforce and they worked on different projects together. He is now an advisor for you.com.\n"}
{"prompt": "What is Truefoundry and how does it work? \n\n###\n\n", "completion": " uuid: 10784174762 Truefoundry is a platform built on top of Kubernetes that supports machine learning developers to help them deploy their models to production. It supports real-time and batch model deployment, and provides service monitoring, logs, and basic monitoring for deployed models. The platform sits on top of either public or private clusters and allows easy provisioning and management of resources across different teams. It enforces best practices and supports CI/CD. The platform makes complicated things like traffic splitting and shadow traffic easier as well.\n"}
{"prompt": "What is the background of the founders of Truefoundry? \n\n###\n\n", "completion": " uuid: 10784174762 The founders of Truefoundry are Karen, Mia, and Nikhunj. Karen graduated from the Indian Institute of Technology, Pin, India and spent six years working in hedge funds. Mia and Nikhunj have backgrounds in machine learning, with Nikhunj building the platform for Reflection and becoming the lead ML engineer for Facebook's Portal team. They all left their jobs in 2020 to start Truefoundry.\n"}
{"prompt": "What is the platform used by you.com and what kind of work is done? \n\n###\n\n", "completion": " uuid: 10784174762 You.com is built on Azure and uses data bricks, ML flow, and Kubernetes for deploying services or models. The models are mainly built using PyTorch, and there are pipelines that use TerraForm. Engineers and the ML Ops/DevOps team deploy the models, while the data scientists are mostly responsible for data analytics work.\n"}
{"prompt": "What aspect of ML Flow did the speaker use in model building and tracking? \n\n###\n\n", "completion": " uuid: 11354404149 experiment tracking piece\n"}
{"prompt": "Was the experiment tracking aspect of ML Flow effective? \n\n###\n\n", "completion": " uuid: 11354404149 Yes, it worked pretty well.\n"}
{"prompt": "Why did the speaker and their team move away from using ML Flow? \n\n###\n\n", "completion": " uuid: 11354404149 To reduce maintenance overhead and free up time.\n"}
{"prompt": "What was the reason for wanting to move towards a managed service like SageMaker? \n\n###\n\n", "completion": " uuid: 11354404149 To further reduce overhead.\n"}
{"prompt": "Did SageMaker provide an adequate experiment tracking interface? \n\n###\n\n", "completion": " uuid: 11354404149 It was a little clunky and the team is still figuring out how to fully replace ML Flow.\n"}
{"prompt": "What practices important to SRE does the speaker's team implement, and how do they do it? \n\n###\n\n", "completion": " uuid: 11354404149 The speaker mentions CI/CD, authentication, and secrets management, which are implemented through GitLab, SageMaker, and other systems.\n"}
{"prompt": "What is the speaker's company building? \n\n###\n\n", "completion": " uuid: 11354404149 They are building a deployment platform for ML models.\n"}
{"prompt": "What is the core feature of the speaker's deployment platform? \n\n###\n\n", "completion": " uuid: 11354404149 The ability to quickly and easily deploy models while also following SRE best practices and running on the same infrastructure as software.\n"}
{"prompt": "How does the platform ensure reproducibility of models? \n\n###\n\n", "completion": " uuid: 11354404149 The platform provides a model registry for versioning, but users can also track versions in the deployed tab.\n"}
{"prompt": "What is the purpose of workspaces in the speaker's platform? \n\n###\n\n", "completion": " uuid: 11354404149 Workspaces are smaller groups for developer teams to work on, each with resource limits and proper access control.\n"}
{"prompt": "What did Cinema do before joining Found? \n\n###\n\n", "completion": " uuid: 12361625352 Cinema worked as a management consultant at McKenzie for IT.\n"}
{"prompt": "What is Pritika Groal's role at Medtronic? \n\n###\n\n", "completion": " uuid: 12361625352 Pritika Groal is leading data sciences and digital innovation at Medtronic, part of diabetes organization.\n"}
{"prompt": "What challenges are faced regarding unifying the workflows? \n\n###\n\n", "completion": " uuid: 12361625352 Challenges include misalignment of the process, differences in the integration to the development cycle, and differences in tool sets.\n"}
{"prompt": "What are the challenges faced for scaling and deployment of models? \n\n###\n\n", "completion": " uuid: 12361625352 Challenges include ensuring that resources are not wasted, and a pipeline is set up to follow FDA guidelines strictly.\n"}
{"prompt": "What is data identification and why is it necessary? \n\n###\n\n", "completion": " uuid: 12361625352 Data identification is separating personal identifiable information (PII) from the rest of the data to prevent researchers and analysts from accessing PII. It is necessary to follow privacy regulations.\n"}
{"prompt": "Who does explainability for models currently? \n\n###\n\n", "completion": " uuid: 12361625352 Currently, most models rely on SHAP values. They are still exploring a good system for explainability.\n"}
{"prompt": "What happens when a model needs to be retrained after going beyond set limits? \n\n###\n\n", "completion": " uuid: 12361625352 The model falls back to the previous version.\n"}
{"prompt": "Are the models for direct customer facing on the hardware or on the cloud? \n\n###\n\n", "completion": " uuid: 12361625352 Currently, they are on the cloud. They are exploring edge computing to get on mobile devices.\n"}
{"prompt": "How is the monitoring done for models when they are on devices and there is no connectivity? \n\n###\n\n", "completion": " uuid: 12361625352 One approach is to run some part of the feature on the device and use cloud for learning and optimizing parameters. Heuristic-based algorithms can also be used to detect patterns on the devices.\n"}
{"prompt": "How are you doing? \n\n###\n\n", "completion": " uuid: 11942347136 I'm good, how are you?\n"}
{"prompt": "Who is Lucky and when will he join? \n\n###\n\n", "completion": " uuid: 11942347136 Lucky is someone who will be joining the conversation and the speaker is texting him to join in a few minutes.\n"}
{"prompt": "What is Anrag's background? \n\n###\n\n", "completion": " uuid: 11942347136 Anrag is one of the co-founders at IIFL Truefoundry. He graduated from IAT Karakura in 2013 and spent seven years working with a hedge fund called World Fund.\n"}
{"prompt": "What is the goal of True Foundry? \n\n###\n\n", "completion": " uuid: 11942347136 The goal of True Foundry is to make it easier for data teams to get access to a better platform for testing out and deploying models in a scalable way to production with the right security, with the right authentication and with monitoring in building.\n"}
{"prompt": "What is the size of the Data Science team currently at IIFL? \n\n###\n\n", "completion": " uuid: 11942347136 The team has 4 members currently.\n"}
{"prompt": "What is the current workflow for data to modeling to batch computing to prediction? \n\n###\n\n", "completion": " uuid: 11942347136 The current workflow is to perform extensive exploration data analysis around the data, build models that can be posting and bagging models, and dump the scores in their old database. Prediction is done on the saved models.\n"}
{"prompt": "What kind of API traffic do they expect to see once the models are deployed? \n\n###\n\n", "completion": " uuid: 11942347136 They expect around 10-15 API hits per minute.\n"}
{"prompt": "What are some of the necessities from a deployment platform? \n\n###\n\n", "completion": " uuid: 11942347136 The deployment part should be taken care of, there should be a dashboard for tracking performance and failures in API calls, metrics for tracking population stability index, AUC k or characteristic stability index, and intelligence around retraining the model.\n"}
{"prompt": "Is there a timeline for deployment or solutioning? \n\n###\n\n", "completion": " uuid: 11942347136 There is currently no timeline, but they are exploring possible ways to work towards a solution.\n"}
{"prompt": "Can you provide a demo of how True Foundry works? \n\n###\n\n", "completion": " uuid: 11942347136 Yes, a simple recorded demo can be shown, and a more detailed demo can be scheduled for a hands-on experience with code repositories and deployment processes.\n"}
{"prompt": "What is the goal of the platform? \n\n###\n\n", "completion": " uuid: 12361625352 To help companies make their ML very simple and manage the entire workflow, from training to deployment and monitoring.\n"}
{"prompt": "What tools does the platform integrate with? \n\n###\n\n", "completion": " uuid: 12361625352 It integrates with Docker registry, GitHub, and Bitbucket, and can also integrate with Gitlab.\n"}
{"prompt": "What are workspaces in the platform? \n\n###\n\n", "completion": " uuid: 12361625352 Workspaces are environments within a cluster that set limits on the maximum amount of resources that a team can use, and can also have different access controls and service accounts attached for data access.\n"}
{"prompt": "Is the platform built on Kubernetes? \n\n###\n\n", "completion": " uuid: 12361625352 Yes, the entire platform is built on top of Kubernetes.\n"}
{"prompt": "What is the benefit of using the platform's access control feature? \n\n###\n\n", "completion": " uuid: 12361625352 It allows for setting different roles for different users in different clusters, ensuring that resources are used efficiently and securely, and also enables allocation of workspaces and service accounts for different teams and projects.\n"}
{"prompt": "What is the punditry focused on? \n\n###\n\n", "completion": " uuid: 12339295384 The punditry is focused on enabler solution providers and their migration to the cloud.\n"}
{"prompt": "What is the challenge in convincing customers to move to the cloud? \n\n###\n\n", "completion": " uuid: 12339295384 The challenge in convincing customers to move to the cloud is not just technical, but also involves individual perspectives and beliefs.\n"}
{"prompt": "What kind of interaction model influences the exposure of Ml Ops to clients? \n\n###\n\n", "completion": " uuid: 12339295384 If Ml Ops is going to be exposed to data scientists in the client's company, then the assumption is that the people building the models are also data scientists in the client's company through an automl kind of interface.\n"}
{"prompt": "What is the main challenge with Ml Ops? \n\n###\n\n", "completion": " uuid: 12339295384 The main challenge with Ml Ops is that very little is understood about it.\n"}
{"prompt": "What problem is the speaker interested in solving? \n\n###\n\n", "completion": " uuid: 12339295384 The speaker is interested in solving an Ml Ops problem involving building a pipeline for create, deploy, monitor, explain, the whole CI/CDCT, and scaffolding to sell services to other contact center service companies.\n"}
{"prompt": "Where is the speaker based out of? \n\n###\n\n", "completion": " uuid: 12339295384 The speaker is based out of San Francisco, but is currently visiting Pancroad.\n"}
{"prompt": "What did Ansul say when asked how he was doing? \n\n###\n\n", "completion": " uuid: 11354404149 Ansul said he was good and doing well.\n"}
{"prompt": "What was the name of Ansul's co-founder based in the SF area? \n\n###\n\n", "completion": " uuid: 11354404149 The name of Ansul's co-founder based in the SF area was Nikkunji.\n"}
{"prompt": "What is the goal of True Foundry according to Ansul? \n\n###\n\n", "completion": " uuid: 11354404149 The goal of True Foundry is to bring what they saw at Facebook in terms of the ML platform there to every company around the globe.\n"}
{"prompt": "Who is the primary user of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11354404149 The primary user of True Foundry's platform is the ML developers who are building the models.\n"}
{"prompt": "What is the secondary user of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11354404149 The secondary user is the intra engineer or the DevOps team or the platform teams in companies who would want to have a full view of what is going on in the resources, in the infrastructure that they have allocated.\n"}
{"prompt": "What kind of models is Prove building according to the conversation? \n\n###\n\n", "completion": " uuid: 11354404149 Prove is building models for identity authentication work that relies on signals from the device to help determine the level of risk and other factors related to behavioral biometrics.\n"}
{"prompt": "What is the main problem Prove is trying to solve? \n\n###\n\n", "completion": " uuid: 11354404149 The main problem Prove is trying to solve is how to become more efficient in their ML development process.\n"}
{"prompt": "What tools does Prove use for ML development? \n\n###\n\n", "completion": " uuid: 11354404149 Prove uses Sage Maker and AWS for ML development, with the ML team owning the infrastructure and using hosted notebooks in Sage Maker for easy prototyping.\n"}
{"prompt": "What challenges do projects face when deploying ML models on device according to the conversation? \n\n###\n\n", "completion": " uuid: 11354404149 Projects face challenges related to model size and privacy, as well as figuring out how to optimize the model for on-device performance and determining the right deployment framework such as TensorFlow Lite.\n"}
{"prompt": "Where in India are you based? \n\n###\n\n", "completion": " uuid: 12044331076 My home is in Lucknow, so right now I'm in Lucknow.\n"}
{"prompt": "What type of place is Charity, where you live? \n\n###\n\n", "completion": " uuid: 12044331076 Charity is a very fancy neighborhood, with a lot of good buildings and concrete walls.\n"}
{"prompt": "How long have you been living in Dubai? \n\n###\n\n", "completion": " uuid: 12044331076 I have been living in Dubai for almost 4 and a half years.\n"}
{"prompt": "How does the Dubai tech salary compare to other regions like India, Europe, and the US? \n\n###\n\n", "completion": " uuid: 12044331076 The Dubai tech salary is comparable to the US because there is no tax, and maybe a little bit less than the US.\n"}
{"prompt": "What cloud platform do you use to build your ML platform? \n\n###\n\n", "completion": " uuid: 12044331076 We use AWS and EKS to build our ML platform.\n"}
{"prompt": "How many people are in the platform team? \n\n###\n\n", "completion": " uuid: 12044331076 There are around 8-9 people in the platform team who work on different parts of the platform including machine learning, experimentation, feature store, and injection platform.\n"}
{"prompt": "What is your definition of experiment tracking? \n\n###\n\n", "completion": " uuid: 12044331076 Experiment tracking is basically tracking the version and parameters of models during experimentation.\n"}
{"prompt": "What tool do you use for experiment tracking? \n\n###\n\n", "completion": " uuid: 12044331076 We use ML Flow for experiment tracking, with a custom layer on top of it.\n"}
{"prompt": "What did the speaker share about their team? \n\n###\n\n", "completion": " uuid: 11655736677 As a team, they are comprised of Vishik, Nikko, and the speaker who were all batchmates at IIT Kharagpur, and they left their jobs to build something in the talent space to help companies hire better talent. They later sold that company to Info Edge and started working on building tools to reduce the time for ROI on machine learning, artificial intelligence, and analytics initiatives.\n"}
{"prompt": "What does the speaker want to know about Kotak's initiatives? \n\n###\n\n", "completion": " uuid: 11655736677 The speaker wants to know about Kotak's different digital initiatives, how AI and ML has been shaping those initiatives, and whether there are any opportunities for improvement when compared to other companies.\n"}
{"prompt": "Is there a central data team at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 Yes, there is a central team that works with different business units.\n"}
{"prompt": "Is there any challenge on the data side at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 No, there are significant opportunities for them to scale up and become better, but they do not face any challenges presently.\n"}
{"prompt": "What is the central data team responsible for at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 The central data team's main responsibility is to ensure that data is available in a manner in which it can be consumed on the fly, but not necessarily focusing on building all use cases coming out of it.\n"}
{"prompt": "What are the tasks involved in the data science process described? \n\n###\n\n", "completion": " uuid: 10346094649 Tasks involve cleaning data, doing feature engineering, building model, testing model, deploying model, and batch inferences and monitoring for data leakage or performance degradation.\n"}
{"prompt": "What challenges is the team facing in building neural network models? \n\n###\n\n", "completion": " uuid: 10346094649 The volume of work involved in building 400 multi-level, multi-classification models with neural networks is a challenge.\n"}
{"prompt": "What format is used to hand over Keras models to the engineering team? \n\n###\n\n", "completion": " uuid: 10346094649 Keras models are saved in the saved model format of TensorFlow.\n"}
{"prompt": "What is the process of updating features in the model and deploying them? \n\n###\n\n", "completion": " uuid: 10346094649 The data scientists add the feature, retrain the model, update the scripts in GitHub, and then the process flows through the production automatically.\n"}
{"prompt": "What tool is used for monitoring the models built? \n\n###\n\n", "completion": " uuid: 10346094649 It is assumed that Sage Maker is used for monitoring since everything is done in the environment.\n"}
{"prompt": "What is the game of operationalizing models, according to the speaker? \n\n###\n\n", "completion": " uuid: 11354404209 To monitor the models for drip data response and different monitoring activities and trigger a new AutoML bill if needed\n"}
{"prompt": "Why did the speaker ask about the stack built around Sage Maker? \n\n###\n\n", "completion": " uuid: 11354404209 To understand why Sage Maker was chosen and if building the ML deployment layer over Kubernetes was considered\n"}
{"prompt": "Where are the models that the speaker is referring to typically built? \n\n###\n\n", "completion": " uuid: 11354404209 Internally, but for Fortune 500 customers, the models can also be built by the customers using tools like Sage Maker and GCP\n"}
{"prompt": "What is the purpose of the platform built by the speaker's company? \n\n###\n\n", "completion": " uuid: 11354404209 To reduce time to value for ML models and provide scalability to allow quick ML model deployments with the flexibility for developers to build on top of it while ensuring right security and other requirements for the industry\n"}
{"prompt": "Which companies does the speaker suggest to target for their platform? \n\n###\n\n", "completion": " uuid: 11354404209 Chip or health manufacturers who are not hardcore IT companies and not at the level of Salesforce or ServiceNow\n"}
{"prompt": "What suggestion does the speaker give to improve the growth story of the platform? \n\n###\n\n", "completion": " uuid: 11354404209 To get data scientists out of it and enable business users to run AutoML pipeline parallel to the experimentation pipeline\n"}
{"prompt": "What does the speaker plan to do after scheduling the demo of the platform? \n\n###\n\n", "completion": " uuid: 11354404209 Take feedback and learn about challenges and use cases, but partnership with companies like Pega is not possible at the present stage of growth\n"}
{"prompt": "What is the speaker's opinion on hiring and managing a data science team? \n\n###\n\n", "completion": " uuid: 11354404209 It is a long and difficult process, and enabling business users to run AutoML pipeline parallel to the experimentation pipeline can offset the cost of maintaining a data science team on the company's side\n"}
{"prompt": "What is Richard's role at Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 Richard is responsible for all tooling around ML ops at Wayve.\n"}
{"prompt": "How did Richard learn about Pro Foundry? \n\n###\n\n", "completion": " uuid: 10441289250 Richard learned about Pro Foundry through an email newsletter alert.\n"}
{"prompt": "What kind of models does Wayve work with? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve works with models that deal with image and video data.\n"}
{"prompt": "What is Richard's biggest time sink in the pipeline? \n\n###\n\n", "completion": " uuid: 10441289250 Richard's biggest time sink is having a tight feedback loop of bugs occurring on road deployment and fixing them effectively.\n"}
{"prompt": "Does Wayve use open source tools for building their pipeline? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve mostly develops their tools internally due to the lack of off the shelf products for the autonomous driving industry.\n"}
{"prompt": "How many people are on Wayve's ML engineering team? \n\n###\n\n", "completion": " uuid: 10441289250 Around 60-70 people on Wayve's ML engineering team, which comprises around a third of the company's employees.\n"}
{"prompt": "What is Wayve's approach for building autonomous vehicles? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve's approach is focused on entering machine learning for this problem area, developing off internal fleets and retrofitting vehicles with their technology.\n"}
{"prompt": "What kind of data monitoring does Wayve do? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve mostly monitors for major data distribution shifts, data drift in the model and major bugs that occur on road deployments.\n"}
{"prompt": "Does Wayve export data out from the vehicles for further analysis? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve ingests offline data from the vehicles for analysis on further retraining.\n"}
{"prompt": "Is there a live update from the models in Wayve's pipeline? \n\n###\n\n", "completion": " uuid: 10441289250 No, there are no live updates from the models for Wayve's pipeline as the model is directly deployed on the vehicle itself.\n"}
{"prompt": "What kind of problems are you working on and what are the challenges that you are currently trying to solve? \n\n###\n\n", "completion": " uuid: 11354403948 The current focus is on building the tools for data scientists to efficiently process data for machine learning tasks. The challenge lies in building an efficient data pipeline from the database to the analytic machine to allow for sampling and feature engineering. We also need to consider distributed training and parallel computing for scalability.\n"}
{"prompt": "Who are your target customers and what is the application of machine learning? \n\n###\n\n", "completion": " uuid: 11354403948 Our target customers are data scientists who have knowledge of machine learning and encoding. We provide a Python library to import and then they can train and deploy their own models on their own infrastructure. Our next phase is to provide a cloud infrastructure to train the models and provide verticalized solutions for specific use cases like fraud detection and recommender systems.\n"}
{"prompt": "Are you planning to be cloud-agnostic or focused on one specific cloud provider? \n\n###\n\n", "completion": " uuid: 11354403948 We are planning to be cloud-agnostic and have already deployed our database on the big three cloud providers. We will prioritize which provider to integrate with first, most likely GCP.\n"}
{"prompt": "In the first phase, how does the library integration work with the client's infrastructure? \n\n###\n\n", "completion": " uuid: 11354403948 In the first phase, clients would need to have their own infrastructure for training and deployment. The Python library will be provided to the clients so they can import it and then they would train and deploy their own models on their own infrastructure.\n"}
{"prompt": "What kind of timeline are you looking at for deploying machine learning models and hosting them? \n\n###\n\n", "completion": " uuid: 11354403948 The first phase is already complete with the Python library provided to clients. The next phase of providing a cloud infrastructure to train the models and building hyper-parameter tuning and parallel computing capabilities will take at least half a year. Verticalized solutions for specific use cases like fraud detection and recommender systems will be a parallel focus.\n"}
{"prompt": "What is the speaker's plan for December 7th? \n\n###\n\n", "completion": " uuid: 12150828333 The speaker starts working full time on that day.\n"}
{"prompt": "What is the idea behind the speaker's startup? \n\n###\n\n", "completion": " uuid: 12150828333 They are trying to build a YouTube-like platform for comics using generative AI.\n"}
{"prompt": "What is the speaker's goal for a universe of models? \n\n###\n\n", "completion": " uuid: 12150828333 They want at least 40-50 models that can serve the universe of comic creation.\n"}
{"prompt": "What is the speaker's plan for allowing users to fine-tune their model? \n\n###\n\n", "completion": " uuid: 12150828333 They plan on allowing it but are still figuring out the commercials.\n"}
{"prompt": "What is the speaker's multi-cloud strategy for hosting their product? \n\n###\n\n", "completion": " uuid: 12150828333 They use a multi-cloud Kubernetes strategy with multiple nodes in a single Kubernetes cluster.\n"}
{"prompt": "What is the speaker's plan for model versioning? \n\n###\n\n", "completion": " uuid: 12150828333 They plan on building a detailed pipeline to reduce manual parameter tuning.\n"}
{"prompt": "What is the role of the control plane in the speaker's infrastructure? \n\n###\n\n", "completion": " uuid: 12150828333 It helps to talk to the Kubernetes control plane and allows for cluster instance types to be decided automatically across namespaces.\n"}
{"prompt": "What metrics can the speaker auto-log in their system? \n\n###\n\n", "completion": " uuid: 12150828333 They can log CPU, module type, and image metrics.\n"}
{"prompt": "What is True Foundry's role in the speaker's deployment process? \n\n###\n\n", "completion": " uuid: 12150828333 They can allow for the deployment of two services as a canary and can change parameters for each service.\n"}
{"prompt": "How much of the GPU does each model take up in the speaker's system? \n\n###\n\n", "completion": " uuid: 12150828333 They have three models that share the 16 GPU memory and all three are shifted into the GPU at once.\n"}
{"prompt": "What is the process of migrating code to creating images or writing Python files? \n\n###\n\n", "completion": " uuid: 11354403912 The DevOps team handles this process, and developers help in deploying all the services.\n"}
{"prompt": "What is the process for promoting from one environment to another? \n\n###\n\n", "completion": " uuid: 11354403912 Staging is promoted to UAT, and from there to Production. The pipeline has already been automated and there is nothing to coordinate.\n"}
{"prompt": "What cluster is the code copied to when deploying in a different environment? \n\n###\n\n", "completion": " uuid: 11354403912 The code has to be copied to a different cluster because everything is different, such as branches and code. Staging may have code which is not supposed to be delivered, so it cannot be promoted to UAT.\n"}
{"prompt": "Is BitMarket or GitHub used for resource provisioning and deployment? \n\n###\n\n", "completion": " uuid: 11354403912 Both are used.\n"}
{"prompt": "How is secrets management handled? \n\n###\n\n", "completion": " uuid: 11354403912 Google Secret Store is used for some services, and something else is used for others. Secrets management is automatically ingrained build.\n"}
{"prompt": "What is the process for developers to deploy to the workspace? \n\n###\n\n", "completion": " uuid: 11354403912 Developers individually deploy services or Cron jobs to this workspace, which can be scheduled or triggered at their leisure. The deployment to the workspace is very simple and can be done through a YAML configuration or UI without the help of DevOps or infringement for the Kubernetes YAML.\n"}
{"prompt": "What is the workflow for data science? \n\n###\n\n", "completion": " uuid: 11354403912 Instead of TML, it exposes the Python way so that data scientists can do it. There are complexities that come into the platform in terms of doing monitoring at the level of data science rather than just system-level monitoring.\n"}
{"prompt": "What is the concept behind the platform? \n\n###\n\n", "completion": " uuid: 11354403912 It is built agnostic to software engineering, and allows you to connect to a GKE account with authentication, access control, and choice of machines. Once connected, you create different namespaces or workspaces for your different teams which come with resource constraints, and allow you to control access.\n"}
{"prompt": "What is the role of DevOps in the platform? \n\n###\n\n", "completion": " uuid: 11354403912 DevOps acts as a security layer and comes into play if anything breaks or if there is a change in a final approval. If you are okay with your developers directly pushing, that is also fine.\n"}
{"prompt": "What is the benefit of the platform? \n\n###\n\n", "completion": " uuid: 11354403912 The platform comes equipped with monitoring logs, secrets management, CI/CD integration to GitHub bit bucket, authentication systems, and rollout to production in a canary shadow testing manner. All of these come by default with the system.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12361625175 The primary goal of Truefoundry is to enable companies that are on multi cloud architecture to build good, flexible, machine learning deployment platform on top of that and solve for other parts or pieces of the problem that comes with deployment.\n"}
{"prompt": "What is Peter's position at Novartis? \n\n###\n\n", "completion": " uuid: 12361625175 Peter works as an ML engineer in Novartis.\n"}
{"prompt": "What are some of the challenges that Peter faces in his job? \n\n###\n\n", "completion": " uuid: 12361625175 Peter faces the challenge of redundancies that get created because different teams work in silos, making it difficult to aggregate data from different sources. They share no code or solutions across departments, and different teams may build the same thing in parallel.\n"}
{"prompt": "How many ML engineers work closely with Peter? \n\n###\n\n", "completion": " uuid: 12361625175 Peter works mostly with two ML engineers, but he also cooperates with around ten software engineers and probably 20 data scientists.\n"}
{"prompt": "What tools do Peter and his team primarily use for deployment? \n\n###\n\n", "completion": " uuid: 12361625175 Peter and his team primarily use AWS solutions, such as Sage Maker jobs, Lambda functions, and ECS.\n"}
{"prompt": "Does Peter work on real-time models as well? \n\n###\n\n", "completion": " uuid: 12361625175 Peter is working mainly on batch models for internal consumption. However, there are some plans about real-time models as well.\n"}
{"prompt": "Does Peter's team use container orchestration tools like Kubernetes? \n\n###\n\n", "completion": " uuid: 12361625175 Peter is not aware of any use of Kubernetes by his team. He personally has no admin access to EKS, but other teams in Novartis may use it.\n"}
{"prompt": "How many ML models does Peter's team support? \n\n###\n\n", "completion": " uuid: 12361625175 Peter's team supports a few thousands of models, but each is responsible for some single time series, and they are usually very small models.\n"}
{"prompt": "Does Peter face any challenges with permissions or services quota? \n\n###\n\n", "completion": " uuid: 12361625175 Peter mentions that it takes several months to get approval for some additional permissions or to extend service quota for a particular service. So, he tries to do as much as possible on his own and builds a workaround rather than getting permission.\n"}
{"prompt": "Does Peter see a need for multi-cloud at Novartis? \n\n###\n\n", "completion": " uuid: 12361625175 Peter feels it's easier to have everything in one cloud, and he has not seen any clear need for multi-cloud at Novartis. In his experience, it's easier to communicate between AWS services or Azure services.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11185249388 The purpose of the call is to discuss Truefoundry, a machine learning platform the speaker is building and learn from others who are solving similar problems.\n"}
{"prompt": "Who is Bobby? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby is the person who the speaker is talking to on the call, who is a co-founder of the speaker's company.\n"}
{"prompt": "What is the speaker's role in the company? \n\n###\n\n", "completion": " uuid: 11185249388 The speaker is the CEO of the company.\n"}
{"prompt": "What is the company that the speaker sold? \n\n###\n\n", "completion": " uuid: 11185249388 The company that the speaker sold was called Reflection and it was in the HR tech space, which was later acquired by Infoyage.\n"}
{"prompt": "What is Netomi using machine learning for? \n\n###\n\n", "completion": " uuid: 11185249388 Netomi is using machine learning for a variety of things including customer care, conversation AI, and for things like recommending products for upselling and cross-selling.\n"}
{"prompt": "What are some of the challenges the speaker faces with real-time scoring of machine learning models? \n\n###\n\n", "completion": " uuid: 11185249388 The speaker faces challenges like real-time scoring being slower than running a simple database query, and the need to bypass governance challenges for optimal operationalization of machine learning.\n"}
{"prompt": "What problems did you face when getting everyone on board? \n\n###\n\n", "completion": " uuid: 11488154639 Individual pairing with data scientists to get dependencies installed correctly for their chipset.\n"}
{"prompt": "What solution did you find to solve these problems? \n\n###\n\n", "completion": " uuid: 11488154639 Dockerization.\n"}
{"prompt": "What tool did you use for experiment tracking? \n\n###\n\n", "completion": " uuid: 11488154639 Sage Maker and Cloud Watch dashboards.\n"}
{"prompt": "Did you use ML flow for experiment tracking? \n\n###\n\n", "completion": " uuid: 11488154639 No.\n"}
{"prompt": "What is the process to update a dependency with Dockerization? \n\n###\n\n", "completion": " uuid: 11488154639 Update the dependency, run Docker compose build, push it to PR, and once approved, everyone will have it on their local development environment.\n"}
{"prompt": "What is the current deployment tool used? \n\n###\n\n", "completion": " uuid: 11488154639 Team City for CI, and CD pipeline that talks to AWS to upload new docker images.\n"}
{"prompt": "What was the package you created to define the steps in the Sage Maker pipeline? \n\n###\n\n", "completion": " uuid: 11488154639 A package that essentially wraps whatever code you want to execute out of the Sage Maker pipeline, allowing you to slot in any docker image or custom code into any number of steps that you define in Python SDK.\n"}
{"prompt": "What solution are you currently using for machine learning deployment? \n\n###\n\n", "completion": " uuid: 11488154639 Sage Maker.\n"}
{"prompt": "Are there any issues with deployment? \n\n###\n\n", "completion": " uuid: 11488154639 No, deployment is not a problem. There is a CI pipeline set up already.\n"}
{"prompt": "What is the platform you are trying to build on top of Kubernetes? \n\n###\n\n", "completion": " uuid: 11488154639 A platform like Sage Maker on Kubernetes.\n"}
{"prompt": "Who is on the call with anderson? \n\n###\n\n", "completion": " uuid: 12150677061 Akshaya, a member of founder's office and Nikkins, who is from KGP 2013 batch.\n"}
{"prompt": "Where did anderson spend most of his time at KGP and why? \n\n###\n\n", "completion": " uuid: 12150677061 He spent most of his time at RK because KK and Anish were at RK. He knew them from school.\n"}
{"prompt": "What channels are they using for outreach and what themes have they worked on? \n\n###\n\n", "completion": " uuid: 12150677061 They are using LinkedIn primarily and also outbound messaging, referrals etc. Some themes they have worked on includes multi-cloud ML, case studies, platform themes etc.\n"}
{"prompt": "What is the importance of identifying the budget owner in a company? \n\n###\n\n", "completion": " uuid: 12150677061 Identifying the budget owner is crucial as they are the ones who would sign the checks and have the incentive to reduce costs. If the functional load of the initiative is not able to make the case and put through the budget, then it's difficult to solve the problem.\n"}
{"prompt": "What should be considered before getting into a sales meeting with large enterprises? \n\n###\n\n", "completion": " uuid: 12150677061 It's important to establish who the data engineering head reports to and where the budget comes from as well as the interplay between the CDO and CTO.\n"}
{"prompt": "Who got a conflict and won't be able to join? \n\n###\n\n", "completion": " uuid: 11354404209 Mata had a conflict and won't be able to join.\n"}
{"prompt": "Who is one of the co-founders at True Foundry? \n\n###\n\n", "completion": " uuid: 11354404209 The speaker is one of the co-founders at True Foundry.\n"}
{"prompt": "What did the speaker work as at World Fund? \n\n###\n\n", "completion": " uuid: 11354404209 The speaker worked as a portfolio manager managing around 600 million in assets for World Fund.\n"}
{"prompt": "What was the first company that the speaker and their colleagues started? \n\n###\n\n", "completion": " uuid: 11354404209 The speaker and their colleagues started their first company called Entire where they were helping companies hire technically with a talent.\n"}
{"prompt": "What is the goal of True Foundry? \n\n###\n\n", "completion": " uuid: 11354404209 The goal of True Foundry is to help companies speed up their machine learning pipelines and make it easier for developers to deploy models fast while providing automated monitoring and the entire right security framework.\n"}
{"prompt": "What is Pegas AI infrastructure used for? \n\n###\n\n", "completion": " uuid: 11354404209 Pegas AI infrastructure is primarily used for marketing and customer service, and also optimization of business process automation.\n"}
{"prompt": "How big is the data science team at Pega? \n\n###\n\n", "completion": " uuid: 11354404209 The engineering and data science team together could be around 50 people.\n"}
{"prompt": "Who does Pega primarily target for their cloud instances? \n\n###\n\n", "completion": " uuid: 11354404209 Pega primarily targets large and data sensitive companies like banks for their cloud instances.\n"}
{"prompt": "How does Pega reduce latency in their ML Ops for real time marketing use cases? \n\n###\n\n", "completion": " uuid: 11354404209 Pega is trying to see if they can provision Sage Maker into a VPC and then have that latency reduced down to sub ten milliseconds.\n"}
{"prompt": "What is the goal of enabling business users in building models? \n\n###\n\n", "completion": " uuid: 11354404209 The goal is to remove data scientists from the picture and enable business users to build models easily by pointing out the data and what they want to predict.\n"}
{"prompt": "What are some benefits of using the platform for running jobs? \n\n###\n\n", "completion": " uuid: 11189840489 Saves infrastructure costs, provides remote logs for visualization, displays system level metrics, and provides version control for deployments.\n"}
{"prompt": "Can you run jobs locally instead of using the platform's machines? \n\n###\n\n", "completion": " uuid: 11189840489 Yes, it is possible to run jobs on your local machine and track results on the dashboard.\n"}
{"prompt": "Is the platform a good fit for every use case? \n\n###\n\n", "completion": " uuid: 11189840489 No, the platform is being used selectively to ensure immediate value is added for users.\n"}
{"prompt": "What kind of companies are targeted by the platform? \n\n###\n\n", "completion": " uuid: 11189840489 Companies facing challenges with their current solution or have a need for a new solution.\n"}
{"prompt": "What is the purpose of the newsletter? \n\n###\n\n", "completion": " uuid: 11189840489 To provide updates on the company's developments and to share relevant content with readers.\n"}
{"prompt": "Can you provide an example of a possible newsletter topic? \n\n###\n\n", "completion": " uuid: 11189840489 The use cases of OCR text summarization as a team-developed software.\n"}
{"prompt": "What is the only way to scale the data according to the context? \n\n###\n\n", "completion": " uuid: 11185249388 Cache the data.\n"}
{"prompt": "What service is used for caching the data for runtime? \n\n###\n\n", "completion": " uuid: 11185249388 Redis Elasticsearch.\n"}
{"prompt": "What type of server layer is used for the models? \n\n###\n\n", "completion": " uuid: 11185249388 Fast API.\n"}
{"prompt": "Has the team tried using any model servers like TF Server or Todd Serve? \n\n###\n\n", "completion": " uuid: 11185249388 No, the team has not tried using any model servers.\n"}
{"prompt": "How is the machine learning team structured? \n\n###\n\n", "completion": " uuid: 11185249388 There is a DevOps team that handles network and container setup, data science team that does ML Ops with the help from the DevOps and data science vertical teams.\n"}
{"prompt": "What are the steps involved in building a custom model at DMV? \n\n###\n\n", "completion": " uuid: 11185249388 Select a model type, select what aspect of risk you are looking for, provide the required data from s3 bucket or purchased DNB data, wait for the model to be deployed and get data science metrics to evaluate the model.\n"}
{"prompt": "What is the cost for operationalizing machine learning for a startup like Netomi? \n\n###\n\n", "completion": " uuid: 11185249388 No more than $100,000 for two people in India.\n"}
{"prompt": "What is the main source of revenue for the product according to the context? \n\n###\n\n", "completion": " uuid: 11185249388 The real money is in the peak of a database and insurance companies who may want to pay for building their own models using DMV data and deploying it on the DMV site.\n"}
{"prompt": "What is the priority for the company according to Bobby? \n\n###\n\n", "completion": " uuid: 11185249388 The priority is to build models and think about new ways of doing things.\n"}
{"prompt": "What is Bobby's feedback on potentially working with tools to optimize dev workflows? \n\n###\n\n", "completion": " uuid: 11185249388 It has not been a priority currently but he would be happy to provide feedback and try it out later.\n"}
{"prompt": "What is the speaker's location? \n\n###\n\n", "completion": " uuid: 11575824756 The speaker is in Fenton, Michigan.\n"}
{"prompt": "What is the speaker currently doing? \n\n###\n\n", "completion": " uuid: 11575824756 The speaker is traveling to India.\n"}
{"prompt": "What is the speaker's role at Groundspeed? \n\n###\n\n", "completion": " uuid: 11575824756 The speaker is a data scientist at Groundspeed and is involved in ML engineering and ML apps.\n"}
{"prompt": "How does True Foundry differentiate from ML Flow? \n\n###\n\n", "completion": " uuid: 11575824756 True Foundry focuses on the deployment aspect of ML models, manages infrastructure, and handles inference monitoring, while ML Flow's core strength lies in experiment tracking and project packaging.\n"}
{"prompt": "How is the Data Science team organized at Groundspeed? \n\n###\n\n", "completion": " uuid: 11575824756 The Data Science team consists of one person, the speaker, who works on enhancing the extracted data and building predictive models.\n"}
{"prompt": "How are the models deployed and hosted? \n\n###\n\n", "completion": " uuid: 11575824756 The models are containerized and deployed as separate endpoints on Kubernetes. The Data Science team is responsible for creating the helm charts and making the PRs that go into the helm repository, while DevOps manages the deployment process and infrastructure.\n"}
{"prompt": "What are some pain points in deploying models? \n\n###\n\n", "completion": " uuid: 11575824756 One pain point is transitioning from developing models locally to deploying them, which involves translating code from notebooks into PY files and incorporating it into the service. The team is working on alleviating this pain point with a pipe approach that involves packaging the model code into pipi packages.\n"}
{"prompt": "What is the main focus of this demo? \n\n###\n\n", "completion": " uuid: 10455870769 The main focus of this demo is on the deployment piece of the machine learning workflow.\n"}
{"prompt": "What are the two ways in which people typically deploy their models? \n\n###\n\n", "completion": " uuid: 10455870769 People typically deploy their models either as an API entrypoint or by dumping the results to a database.\n"}
{"prompt": "What is the core problem that Truefoundry is trying to solve? \n\n###\n\n", "completion": " uuid: 10455870769 Truefoundry is trying to solve the problem of managing all aspects of model deployment in one place.\n"}
{"prompt": "How long would it typically take to launch a feature change on Truefoundry? \n\n###\n\n", "completion": " uuid: 10455870769 It would typically take around 15-20 minutes to launch a feature change on Truefoundry as long as it's not a completely new data pipeline.\n"}
{"prompt": "Is infrastructure a concern for users of Truefoundry? \n\n###\n\n", "completion": " uuid: 10455870769 No, infrastructure is not a concern as Truefoundry offers abstractions that allow users to move much faster than they would by operating raw Kubernetes.\n"}
{"prompt": "What is the front end feature? \n\n###\n\n", "completion": " uuid: 10611764602 The context does not provide a clear answer.\n"}
{"prompt": "What kind of productionization is being discussed in the context? \n\n###\n\n", "completion": " uuid: 10611764602 Productionization using sage maker endpoints.\n"}
{"prompt": "Has the team faced any challenges in serving the front end system? \n\n###\n\n", "completion": " uuid: 10611764602 Yes, challenges like making the model responsive and optimizing other factors.\n"}
{"prompt": "What is the desired response time for front end system? \n\n###\n\n", "completion": " uuid: 10611764602 The desired response time is within milliseconds.\n"}
{"prompt": "What is the performance goal for the front end facing feature? \n\n###\n\n", "completion": " uuid: 10611764602 The goal is to achieve a P9 of 45 milliseconds.\n"}
{"prompt": "Who does the deployment for the front end facing feature? \n\n###\n\n", "completion": " uuid: 10611764602 The ML engineer handles the deployment.\n"}
{"prompt": "Is there a custom deployment made for each model? \n\n###\n\n", "completion": " uuid: 10611764602 No, the deployments are standard.\n"}
{"prompt": "What is the data platform journey of the ML and data science team described as? \n\n###\n\n", "completion": " uuid: 10611764602 The team is at a stage of proving the ROI and transitioning into optimization.\n"}
{"prompt": "What is the difference between Truefoundry and other ML platform offerings? \n\n###\n\n", "completion": " uuid: 10611764602 The differentiation lies in the developer experience, cost advantages, and ability to be multicloud.\n"}
{"prompt": "Where is the Truefoundry platform hosted? \n\n###\n\n", "completion": " uuid: 10611764602 The platform can be hosted on Truefoundry's own infrastructure or in the customer's VPC.\n"}
{"prompt": "What is Airflow and have you used it before? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker says they haven't used Airflow.\n"}
{"prompt": "What did the platform team do to make it self-served and how long did it take them? \n\n###\n\n", "completion": " uuid: 10784174762 The platform team laid out best practices to make it self-served and it took them 1-2 months with a team of 2-3 engineers.\n"}
{"prompt": "What is the purpose of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The purpose of the platform is to provide a self-service platform for companies from day one, so they don't have to build it.\n"}
{"prompt": "What is the admin level view of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The admin level view of the platform allows you to allocate different parts of the cluster, limit workspaces, and see who is using what, as well as providing cost estimates and insights.\n"}
{"prompt": "What is the developer's view of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The developer's view of the platform allows them to access a service catalog, trigger jobs, view logs and metrics, and create new services or jobs by choosing a workspace and repository.\n"}
{"prompt": "What frameworks are supported by the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The platform supports all frameworks, including Psychedel and Python, and can automatically Dockerize services if necessary.\n"}
{"prompt": "What other features are being added to the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The platform will support model deployment, GPU acceleration, a choice of machines and deployment strategies, and pipeline deployment.\n"}
{"prompt": "What is the speaker's goal for working with other companies? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker wants to work with more advanced tech companies to mature the platform further and improve it.\n"}
{"prompt": "What questions does the speaker suggest asking to evaluate the usefulness of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker suggests asking about pain points, time and effort needed to switch to the platform, and whether it is the right time to experiment with something new versus focusing on other priorities.\n"}
{"prompt": "What is the next step for the speaker and the team at the end of the conversation? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker will arrange a follow-up meeting with the lead engineering and DevOps person on the team, and would like to learn about more pain points for the ML team to better present the platform.\n"}
{"prompt": "Where is the speaker based? \n\n###\n\n", "completion": " uuid: 12428314989 The speaker is based in Santa Clara.\n"}
{"prompt": "What time is it? \n\n###\n\n", "completion": " uuid: 12428314989 It's 1130.\n"}
{"prompt": "Why did the speaker choose that time? \n\n###\n\n", "completion": " uuid: 12428314989 It's the only time the speaker could find since the others are in IST.\n"}
{"prompt": "Where are the others based? \n\n###\n\n", "completion": " uuid: 12428314989 The others are based in India.\n"}
{"prompt": "What are the two major parts that the speaker wants to cover on the call? \n\n###\n\n", "completion": " uuid: 12428314989 The two major parts that the speaker wants to cover on the call are understanding the ML structure at Docusign and discussing multi cloud.\n"}
{"prompt": "What is the product that the speaker's team has built? \n\n###\n\n", "completion": " uuid: 12428314989 The product that the speaker's team has built is called Optical Foundry.\n"}
{"prompt": "What is the goal of Optical Foundry? \n\n###\n\n", "completion": " uuid: 12428314989 The goal of Optical Foundry is to create abstractions for developers so that they can do everything necessary to take models that they are training on local notebooks or wherever to actual real use case.\n"}
{"prompt": "Where is the speaker's startup registered? \n\n###\n\n", "completion": " uuid: 12428314989 The speaker's startup is registered in the US.\n"}
{"prompt": "Where is most of the team located? \n\n###\n\n", "completion": " uuid: 12428314989 Most of the team is located in India.\n"}
{"prompt": "Why is most of the team located in India? \n\n###\n\n", "completion": " uuid: 12428314989 Tech hiring is cheaper in India.\n"}
{"prompt": "Has the speaker ever seen a business reason to support multicloud? \n\n###\n\n", "completion": " uuid: 12428314989 No, the speaker has never seen a business reason to support multicloud.\n"}
{"prompt": "What is the reason that companies would rather not use a managed infra offering? \n\n###\n\n", "completion": " uuid: 12428314989 Most companies prefer to have their systems internally and not be dependent on a managed infra offering.\n"}
{"prompt": "What is the market like for Kubernetes adoption in India? \n\n###\n\n", "completion": " uuid: 12428314989 The market for Kubernetes adoption in India is quite behind, with very few companies adopting it.\n"}
{"prompt": "What is the goal of Banadia? \n\n###\n\n", "completion": " uuid: 12428314989 The goal of Banadia is to take care of everything in terms of the platform image so that the system can be deployed to any client.\n"}
{"prompt": "What is the charter for Junior? \n\n###\n\n", "completion": " uuid: 10611816710 To provide end-to-end infrastructure support for the ML/AI team at Junior, which involves improving the developer experience, post-deploy monitoring and selecting training sets, platformizing all of their orgs, optimizing the cost to run the models, and building a model store for all data points.\n"}
{"prompt": "What are some challenges faced by Junior in terms of their ML/AI processes? \n\n###\n\n", "completion": " uuid: 10611816710 Some challenges faced by Junior include improving the developer experience, building a model store, optimizing the cost to run models, and monitoring the image-based models.\n"}
{"prompt": "What is the company's current usage of Sage Maker? \n\n###\n\n", "completion": " uuid: 10611816710 The company is heavily using Sage Maker operators, which includes training operators and processing operators.\n"}
{"prompt": "What is the purpose of Sage Maker Operators? \n\n###\n\n", "completion": " uuid: 10611816710 Sage Maker Operators are used by the company to train and process their models quickly and efficiently.\n"}
{"prompt": "What is the objective of building a model store? \n\n###\n\n", "completion": " uuid: 10611816710 The objective of building a model store is to collect all the required data points in one place and derive model lifecycle insights, version updates, and model evaluations results.\n"}
{"prompt": "What is the biggest challenge in getting everyone on the same platform at Junior? \n\n###\n\n", "completion": " uuid: 10611816710 The biggest challenge is to convince everyone to switch to a unified platform instead of using their own existing infrastructures and processes.\n"}
{"prompt": "What are the challenges in monitoring image-based models and how can they be solved? \n\n###\n\n", "completion": " uuid: 10611816710 It is difficult to detect drifts in image-based models due to camera changes. Research effort is being made to automate this process. Solutions can also involve optimizing models for specific hardware like Arm and incorporating signals to automate retraining pipelines.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12339399214 To discuss Truefoundry, Nick's background and the challenges Dr. Anish is facing in data science at Doctor Edison.\n"}
{"prompt": "What is Nick's background? \n\n###\n\n", "completion": " uuid: 12339399214 Nick comes from a machine learning background, used to be at Facebook where he built out a lot of conversational AI models for them. Prior to that, he was at a startup called Reflection based in the Bay Area. And he did his masters at UC Berkeley and undergrad there too. Between quitting Facebook and starting Truefoundry, the three of them did one more startup in the talent space that got acquired by Info Age.\n"}
{"prompt": "What challenges is Doctor Edison facing with regards to data science? \n\n###\n\n", "completion": " uuid: 12339399214 Availability of clean data which has been some bit of barrier for them to deploy a few of these models as well. Governance with regards to reviewing the efficacy of the models and improving the models over time.\n"}
{"prompt": "What is Truefoundry? \n\n###\n\n", "completion": " uuid: 12339399214 Truefoundry is a platform to help analytics and machine learning data science teams to operationalize models and their data pipelines.\n"}
{"prompt": "What is the cost of setting up a POC with Truefoundry? \n\n###\n\n", "completion": " uuid: 12339399214 $5,000.\n"}
{"prompt": "How can they set up a POC with Truefoundry? \n\n###\n\n", "completion": " uuid: 12339399214 They need to define a scope of the problem and then they can take one of two directions \u2013 either a lightweight POC or a more integral POC with their DevOps team.\n"}
{"prompt": "How is Truefoundry different from DataRobot? \n\n###\n\n", "completion": " uuid: 12339399214 Truefoundry has built out a tool where they can take the data that is segmenting it and working out what are the most common failure areas in the study. So they can recommend different problem areas and corresponding fixes that helps improve the model. Some part of this has already automated in the tool that data scientists can do by themselves.\n"}
{"prompt": "What is the cost of doing a POC with a very small check? \n\n###\n\n", "completion": " uuid: 12339399214 It doesn't matter so long as there is one check associated with the POC.\n"}
{"prompt": "What is the next step for Dr. Anish? \n\n###\n\n", "completion": " uuid: 12339399214 He will discuss the scope of the POC with his data science team and bring it up to the leadership team to figure out logistics. He will also meet with Nick in-person while he is in Hyderabad.\n"}
{"prompt": "Can you hear me well? \n\n###\n\n", "completion": " uuid: 12428091307 Yeah, I can hear you.\n"}
{"prompt": "Who is Nikon and why did he avoid the call? \n\n###\n\n", "completion": " uuid: 12428091307 It is not mentioned.\n"}
{"prompt": "Who is Jimmy and where does he work? \n\n###\n\n", "completion": " uuid: 12428091307 Jimmy works in the founder's office at 200 and has been there for about six months. He mostly works in product and customer development and sales. Before this, he worked at McKenzie as a management consultant and did machine learning in IT. He is mostly interested in NLP.\n"}
{"prompt": "What is the central team structure of data science at Proof? \n\n###\n\n", "completion": " uuid: 12428091307 There is no central team for data science at Proof. The team is mostly associated with the business units and the use cases that have been identified. Each use case has a separate engineering team associated with it.\n"}
{"prompt": "What are the two main themes of business use cases at Proof and are they product specific? \n\n###\n\n", "completion": " uuid: 12428091307 The two main themes are process discovery and document processing. These come under one substructure, but each of them has a separate engineering team associated with them. They are product lines and features.\n"}
{"prompt": "What is the True Foundry platform and what is their main competency? \n\n###\n\n", "completion": " uuid: 12428091307 The True Foundry platform is an ML platform that is cloud agnostic and they specialize in model deployment and everything after that, including scaling, EB testing, and monitoring models in production using data drift tracking and concept drift. They also provide a unified framework to deploy models across clouds.\n"}
{"prompt": "What are some of the core competencies that True Foundry has over open source ML platforms like ML Flow? \n\n###\n\n", "completion": " uuid: 12428091307 Some of the competencies that True Foundry has over open source platforms include role-based access control, secret management, security layer API authentication, and scaling and provisioning resources for managing Kubernetes for the scaling or parallelization of training with GPUs.\n"}
{"prompt": "Does Proof provide a self-hosted version of their platform for clients who are not comfortable sharing their data? \n\n###\n\n", "completion": " uuid: 12428091307 No, Proof does not provide a self-hosted version of their platform. They provide pre-trained models for clients who are not comfortable with sharing their data.\n"}
{"prompt": "How does Proof automate the processes for their clients using robotic processor automation? \n\n###\n\n", "completion": " uuid: 12428091307 Proof automates processes like manual data gathering and processing for tasks like onboarding employees or verification of uploaded files against data using process discovery via screen recording on a laptop.\n"}
{"prompt": "How does Proof deal with data from clients who don't want to share it? \n\n###\n\n", "completion": " uuid: 12428091307 For clients who don't want to share their data, Proof provides a local deployment of their software on the client's system and sends pre-trained models and bots back to the client for inference only. There is no continuous training or retraining happening from the client's side.\n"}
{"prompt": "Who is speaking in the conversation? \n\n###\n\n", "completion": " uuid: 12336402979 Lida and the other person (not specified by name) are speaking.\n"}
{"prompt": "Where is Lida spending some time now? \n\n###\n\n", "completion": " uuid: 12336402979 Lida is spending some time in India.\n"}
{"prompt": "What was the other person's experience at Kora? \n\n###\n\n", "completion": " uuid: 12336402979 It is not stated in the context.\n"}
{"prompt": "What cloud setup does Kora use? \n\n###\n\n", "completion": " uuid: 12336402979 Kora mostly uses AWS, but has a small footprint on GCP.\n"}
{"prompt": "What is the reason Kora is using GCP? \n\n###\n\n", "completion": " uuid: 12336402979 Kora uses GCP for training a particular model using TPU and for using some of Google's ML API for image and text processing.\n"}
{"prompt": "What do they use for ML workflow orchestration? \n\n###\n\n", "completion": " uuid: 12336402979 They mostly use their in-house platform built on Kubernetes.\n"}
{"prompt": "Do they use Qflow? \n\n###\n\n", "completion": " uuid: 12336402979 No, they don't use Qflow.\n"}
{"prompt": "What do they use instead of Qflow? \n\n###\n\n", "completion": " uuid: 12336402979 They have their own in-house platform built on Kubernetes.\n"}
{"prompt": "What language do they use for building their oxidation workflow? \n\n###\n\n", "completion": " uuid: 12336402979 They use Python, which is the preferred language in the ML domain.\n"}
{"prompt": "Do they provide a UI for developers to visualize the logs? \n\n###\n\n", "completion": " uuid: 12336402979 Developers can view the logs from the airflow UI.\n"}
{"prompt": "What is the point made regarding an alternative NIC being developed? \n\n###\n\n", "completion": " uuid: 12044330588 That the National Security Center or government is considering coming up with an alternative NIC called Digital something.\n"}
{"prompt": "What is the main issue with deployment environments for models? \n\n###\n\n", "completion": " uuid: 12044330588 The deployment environment cannot be controlled, even if it's on the cloud; making it difficult to ensure that models will work on specific devices.\n"}
{"prompt": "What is the goal of the reference ML platform being developed? \n\n###\n\n", "completion": " uuid: 12044330588 To provide a base of integrations for customers, ensuring reproducibility, auditability and model observability, tracking and metric logging.\n"}
{"prompt": "What are some challenges associated with deploying models across different cloud platforms? \n\n###\n\n", "completion": " uuid: 12044330588 Coordination with the government agency's tech stack, the absence of self-managed clusters or Kubernetes clusters, and difficulty in getting access to the necessary clusters.\n"}
{"prompt": "What is the current approach to developing environments for machine learning scientists? \n\n###\n\n", "completion": " uuid: 12044330588 They take a dedicated compute for a project and spin it up for the project's lifetime.\n"}
{"prompt": "What was the agenda of the call? \n\n###\n\n", "completion": " uuid: 12150677061 To discuss the sales outreach and get feedback from Amit.\n"}
{"prompt": "Who are the target personas for the platform at True Foundry? \n\n###\n\n", "completion": " uuid: 12150677061 Data scientists and ML developers within a company, however, the decision maker is usually the head of the platform or data engineering team.\n"}
{"prompt": "What are the two segments of companies True Foundry is targeting? \n\n###\n\n", "completion": " uuid: 12150677061 Upper midmarket (100 million to 1 billion in revenues) and enterprises (1 billion+ in revenues), both of which tend to invest in ML.\n"}
{"prompt": "What is the primary channel used for outreach at True Foundry? \n\n###\n\n", "completion": " uuid: 12150677061 LinkedIn.\n"}
{"prompt": "What is Amit's advice to Anurag? \n\n###\n\n", "completion": " uuid: 12150677061 To study the zero to one sales approach of companies similar to True Foundry, such as Cubo DRUMO, Neo, four J data bricks, and reach out to former employees for their insights.\n"}
{"prompt": "What was the reason for being on mute during the call? \n\n###\n\n", "completion": " uuid: 10097842831 In case IBM was audible.\n"}
{"prompt": "Was the person audible during the call? \n\n###\n\n", "completion": " uuid: 10097842831 Yes.\n"}
{"prompt": "Where is the person based out of? \n\n###\n\n", "completion": " uuid: 10097842831 They are based in Singapore.\n"}
{"prompt": "What is the main focus of Turtlemint? \n\n###\n\n", "completion": " uuid: 10097842831 It is a fintech company primarily focusing on insure tech.\n"}
{"prompt": "How big is the data science team at Turtlemint? \n\n###\n\n", "completion": " uuid: 10097842831 It is a single digit team, less than ten people.\n"}
{"prompt": "What technology stack does Turtlemint use for machine learning? \n\n###\n\n", "completion": " uuid: 10097842831 They use Kubernetes for deployment and are primarily on the AWS stack.\n"}
{"prompt": "How is model deployment handled at Turtlemint? \n\n###\n\n", "completion": " uuid: 10097842831 Deployment is handled using Kubernetes pods and services.\n"}
{"prompt": "Does Turtlemint use Sage Maker for machine learning? \n\n###\n\n", "completion": " uuid: 10097842831 Not yet, but they have tried it in the past and may combine it with ML flow in the future.\n"}
{"prompt": "What challenges might arise as Turtlemint's machine learning processes grow? \n\n###\n\n", "completion": " uuid: 10097842831 ML observability may become a crucial challenge in the future as operations become more complex.\n"}
{"prompt": "What did he find interesting? \n\n###\n\n", "completion": " uuid: 12336403532 The crosscloud hypothesis.\n"}
{"prompt": "Who are Nick and Abhishek and what do they do? \n\n###\n\n", "completion": " uuid: 12336403532 Nick and Abhishek are co-founders at Truefoundry. Nick has a machine learning background and has worked with Facebook and Reflection. Abhishek graduated from It and worked in Facebook before doing a startup of his own.\n"}
{"prompt": "What is Frank's current role at VMware? \n\n###\n\n", "completion": " uuid: 12336403532 Frank is a chief technologist at VMware and does outbound work such as presenting at conferences and talking to customers. He also helps with strategies for patent applications and talks to engineers and principal engineers to create a better product or strategize in a better way. His main focus areas are resource management and machine learning.\n"}
{"prompt": "Which cloud platforms does VMware use? \n\n###\n\n", "completion": " uuid: 12336403532 VMware uses primarily AWS, Google, and Azure for their clouds as well as their own analytics platform that runs internally.\n"}
{"prompt": "Does VMware use Kubernetes? \n\n###\n\n", "completion": " uuid: 12336403532 VMware uses Tanzu internally for Kubernetes, but they also allow other Kubernetes platforms on top of their hypervisor. Frank also mentioned that data scientists themselves prefer Docker containers over Kubernetes.\n"}
{"prompt": "Is there a common engineering layer that spans across different business units? \n\n###\n\n", "completion": " uuid: 12336403532 No, each business unit at VMware has their own goals and deliverables, and they use their own sets of tools. There is an office of the CTO that communicates inter business units for a common strategy.\n"}
{"prompt": "Does VMware have a machine learning platform team for their business units? \n\n###\n\n", "completion": " uuid: 12336403532 No, there isn't a machine learning platform team at VMware for their business units. However, they have specific services like Wavefront that data scientists can use.\n"}
{"prompt": "Should we mail them? \n\n###\n\n", "completion": " uuid: 11656830384 Yeah did already.\n"}
{"prompt": "What did the person say when they couldn't hear? \n\n###\n\n", "completion": " uuid: 11656830384 Yeah, I'm saying I mailed him already.\n"}
{"prompt": "What did someone ask Chinmay to do? \n\n###\n\n", "completion": " uuid: 11656830384 Can you quickly share a couple of questions that you are asking on the monitoring thesis dockingba board rest or the domain directly to you or in the dock, whatever.\n"}
{"prompt": "What are some of the questions Chinmay was asked to share? \n\n###\n\n", "completion": " uuid: 11656830384 What is the current way? What is the change that we will bring sikh MATLAB what is the change in their life that we'll bring with our product or what is the value that we're seeing?\n"}
{"prompt": "What is the problem they're trying to solve for customers in terms of model training? \n\n###\n\n", "completion": " uuid: 11656830384 People would keep retraining models even if it's not necessary or people would just not retrain. Assuming the data is not drifted but the data has drifted basically take care of housing use case how frequently should we retrain the model?\n"}
{"prompt": "What is the second idea they have to solve for model performance regression? \n\n###\n\n", "completion": " uuid: 11656830384 just generally detecting your model degradation basically, right?\n"}
{"prompt": "What is the third thing they're working on for model performance monitoring? \n\n###\n\n", "completion": " uuid: 11656830384 generally if you think about the overall model performance monitoring most of the companies set up an engaging statement like model performance is like you do like an offline evaluation and online joy model performance real time there's usually no performance tracking statement just. Go out of performance.\n"}
{"prompt": "What is the use case for the drift problem that is important to solve? \n\n###\n\n", "completion": " uuid: 11656830384 fraud detection.\n"}
{"prompt": "What is the target customer segment for the product? \n\n###\n\n", "completion": " uuid: 11656830384 consumer focused companies and large enterprises.\n"}
{"prompt": "What is the purpose of creating a template? \n\n###\n\n", "completion": " uuid: 11656830384 to help differentiate the exact customer persona that they are trying to target.\n"}
{"prompt": "What is the platform built using? \n\n###\n\n", "completion": " uuid: 12044331076 The platform is built using Kubernetes, Argo CD, and various integrations such as Streamlit and Jupiter Notebook.\n"}
{"prompt": "How do data scientists deploy models using the platform? \n\n###\n\n", "completion": " uuid: 12044331076 Data scientists can deploy models using a Python SDK or a UI that allows them to click a button and deploy the model for specific use cases like cities or fleets of cars.\n"}
{"prompt": "What kind of ingresses do you use for real-time models? \n\n###\n\n", "completion": " uuid: 12044331076 We use an ingress layer to forward traffic to the thousands of spots running on Kubernetes, allowing data scientists to deal with real-time models in a more efficient manner.\n"}
{"prompt": "How do you manage resource requirements for models of varying intensity? \n\n###\n\n", "completion": " uuid: 12044331076 The cluster is managed by the infrastructure team, but the permissions to play around with the clusters are given to the data scientists. Horizontal port scalar is used to create scale based on CPU and memory usage.\n"}
{"prompt": "How is permission control managed for different users and their respective projects? \n\n###\n\n", "completion": " uuid: 12044331076 The platform has authentication and authorization integrated into the UI. Data scientists log in with Open ID connect and are given a guest role. Permissions are elevated based on project assignments and data set ownership.\n"}
{"prompt": "What are the core problems the company intends to solve in the future? \n\n###\n\n", "completion": " uuid: 12044331076 The company is currently focused on the adoptibility of the new platform. Future plans include trip detection, hyperparameter tuning, and model monitoring, all of which are still in the planning phase.\n"}
{"prompt": "What is Truefoundry's vision? \n\n###\n\n", "completion": " uuid: 12044331076 Truefoundry was developed to solve operationalization problems surrounding machine learning models. After talking to various companies, the team realized that only a few dozen companies in the world could afford to build the kind of platform they were building.\n"}
{"prompt": "What is the process for deploying machine learning models at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Build code in SAS or Python and use a converter to convert the code into Java code. The code is then deployed and results are compared for validation and testing.\n"}
{"prompt": "What is the split between the data science team and the data engineering team at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 For every data scientist, Lending Club has three engineers.\n"}
{"prompt": "What would be done with extra data scientists on the team? \n\n###\n\n", "completion": " uuid: 11564066567 The extra data scientists would be put towards the marketing side of things to find ways for things like multitouch attribution.\n"}
{"prompt": "How frequently are the models updated at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 The models are updated at an annual view for the credit side and every six months for the marketing side.\n"}
{"prompt": "Is model explainability a concern at Lending Club and if so, how is it handled? \n\n###\n\n", "completion": " uuid: 11564066567 Model explainability is not a concern because tree-based models are easy to explain. The decision tree nodes have approved the client outcomes.\n"}
{"prompt": "What are some of the tools used for experiment tracking and deployment monitoring at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Optimize and Heap are used for A/B testing and session tracking. All the tools are on the cloud, stored on AWS Redshift.\n"}
{"prompt": "What is the process for monitoring data drift at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Data drift is checked every month by looking at the production output. If the drift is outside of the range, the previous version is reverted back to and root cause analysis is done.\n"}
{"prompt": "How did the founders decide to start True Foundry? \n\n###\n\n", "completion": " uuid: 11564066567 One founder experienced the problem of hiring and started a company to solve it. While building that startup, he came across the problem of machine learning model building and deployment, which led to the creation of True Foundry.\n"}
{"prompt": "What motivated Ravi to leave his job at McKinsey and join an early stage startup? \n\n###\n\n", "completion": " uuid: 11564066567 Ravi was interested in combining his interest in machine learning with his business expertise from his time at McKinsey.\n"}
{"prompt": "Can Ravi make introductions to his network for True Foundry? \n\n###\n\n", "completion": " uuid: 11564066567 Ravi suggests scanning his LinkedIn network and making a list of cold leads to approach, from which he can make a warm introduction.\n"}
{"prompt": "What is the context about? \n\n###\n\n", "completion": " uuid: 10245510764 A conversation between a group of people discussing an ML platform\n"}
{"prompt": "What is the name of the ML platform being discussed? \n\n###\n\n", "completion": " uuid: 10245510764 Truefoundry\n"}
{"prompt": "Where is the speaker currently located? \n\n###\n\n", "completion": " uuid: 10245510764 Indonesia\n"}
{"prompt": "Where will the speaker be going back to after three weeks? \n\n###\n\n", "completion": " uuid: 10245510764 South Africa\n"}
{"prompt": "Who is Uri? \n\n###\n\n", "completion": " uuid: 10245510764 One of their ML engineers\n"}
{"prompt": "What are they planning to show Alyssa? \n\n###\n\n", "completion": " uuid: 10245510764 A demo of the Truefoundry platform\n"}
{"prompt": "What is the focus of the platform? \n\n###\n\n", "completion": " uuid: 10245510764 Deployment side of things\n"}
{"prompt": "What are some of the features that are still in development? \n\n###\n\n", "completion": " uuid: 10245510764 A lot of features and other things\n"}
{"prompt": "What can be seen in the integration tab? \n\n###\n\n", "completion": " uuid: 10245510764 Clusters that can be connected to\n"}
{"prompt": "What are workspaces? \n\n###\n\n", "completion": " uuid: 10245510764 Separations within the cluster where you can deploy different things\n"}
{"prompt": "What is the importance of resource limits? \n\n###\n\n", "completion": " uuid: 10245510764 To make sure that a particular service does not take up more than a certain amount of the resource that are available\n"}
{"prompt": "How can a job be triggered? \n\n###\n\n", "completion": " uuid: 10245510764 Manually or on a schedule\n"}
{"prompt": "What is a function service? \n\n###\n\n", "completion": " uuid: 10245510764 It takes any function and converts it to API\n"}
{"prompt": "What is Iris data set? \n\n###\n\n", "completion": " uuid: 10245510764 A data set that contains four parameters\n"}
{"prompt": "What is ML Foundry? \n\n###\n\n", "completion": " uuid: 10245510764 A library from Autofound\n"}
{"prompt": "What is the log model feature of ML Foundry? \n\n###\n\n", "completion": " uuid: 10245510764 To log model objects so that you don't have to write custom codes to store your artifacts and can just use the log model command.\n"}
{"prompt": "What is the platform that is being discussed? \n\n###\n\n", "completion": " uuid: 11354392885 The platform being discussed is a Kubernetes based ML deployment platform.\n"}
{"prompt": "What is auto node provisioning? \n\n###\n\n", "completion": " uuid: 11354392885 Auto node provisioning is a recommended feature on AWS and GCP where a node will be automatically joined to the cluster when someone tries to deploy on a specific cluster.\n"}
{"prompt": "What is the reason for reusing hardware in their approach? \n\n###\n\n", "completion": " uuid: 11354392885 They reuse their hardware again and again to avoid incurring costs for provisioning new hardware every time. They have found that GCP's pay on demand provisioning is not reliable for GPUs.\n"}
{"prompt": "What is the reason for using triton as the multimodal server? \n\n###\n\n", "completion": " uuid: 11354392885 Triton is the only open source multimodal server available that provides efficient deployment and inference graph.\n"}
{"prompt": "What is OCR? \n\n###\n\n", "completion": " uuid: 11354392885 OCR stands for Optical Character Recognition, and they have recently been working on this model for efficient deployment on their platform.\n"}
{"prompt": "What did Peter mention about being late? \n\n###\n\n", "completion": " uuid: 10881877574 Running two minutes late.\n"}
{"prompt": "What was the age of Peter's baby? \n\n###\n\n", "completion": " uuid: 10881877574 Four months.\n"}
{"prompt": "How many kids does the person speaking to Peter have? \n\n###\n\n", "completion": " uuid: 10881877574 Three.\n"}
{"prompt": "What was the person speaking to Peter's previous work experience? \n\n###\n\n", "completion": " uuid: 10881877574 Leading one of the conversation AI efforts at Poland and building personalization algorithms for the ecommerce industry at a startup called Reflection.\n"}
{"prompt": "What is the goal of the machine learning platform that Truefoundry is building? \n\n###\n\n", "completion": " uuid: 10881877574 To make it easy for internal platform teams to build on top of and scale up their platform while minimizing resources needed to continue building internal dev tooling.\n"}
{"prompt": "What are some challenges in machine learning experimentation that the person speaking to Peter mentioned? \n\n###\n\n", "completion": " uuid: 10881877574 Speed of testing models, visibility of experiments conducted, and iteration speed and quality.\n"}
{"prompt": "What is the person speaking to Peter's approach to reducing the cost of experimentation? \n\n###\n\n", "completion": " uuid: 10881877574 Building a platform that captures learnings and applies them from one project to the other while providing enough flexibility for teams to build whatever they want on top of the platform.\n"}
{"prompt": "What is the first thing that needs to be set up when using Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 The cluster setup.\n"}
{"prompt": "What types of machines can be added to a workspace? \n\n###\n\n", "completion": " uuid: 10443270777 CPU-based or GPU-based machines.\n"}
{"prompt": "What is the advantage of using Kubernetes in Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 You don't have to spin up clusters every time and can have a shared cluster.\n"}
{"prompt": "What is the difference between a service and a job in Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 A service is a long-running service API endpoint or model demo, while a job is a model training job or batch inference.\n"}
{"prompt": "How can a developer manage their applications in Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 They can manage their services, jobs, and deployed models with version control.\n"}
{"prompt": "Can a developer easily rollback to a previous version of a service? \n\n###\n\n", "completion": " uuid: 10443270777 Yes, with one click they can redeploy the previous version.\n"}
{"prompt": "What types of metrics and logs can a developer view for their service? \n\n###\n\n", "completion": " uuid: 10443270777 Metrics dashboard, log search filters, and log management.\n"}
{"prompt": "What types of models does Truefoundry You support and how are they deployed? \n\n###\n\n", "completion": " uuid: 10443270777 They support online inference models and batch offline modules. For offline modules, you run a service that pushes data to S3 and then stores the data in some database.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12362155036 To discuss about the startup in the ML infra domain.\n"}
{"prompt": "What is Nikunj's background? \n\n###\n\n", "completion": " uuid: 12362155036 He comes from a machine learning background and has worked in Facebook and a startup called Reflection prior to True foundry.\n"}
{"prompt": "What is Chinmay's role in True foundry? \n\n###\n\n", "completion": " uuid: 12362155036 He works in the founder's office and mainly helps with product sales and customer development.\n"}
{"prompt": "What is the structure of the machine learning team in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 The machine learning team is part of Merlin, which handles all the AI work in Zycus. It has AI, Java, UI and deployment teams along with product managers and data analyst team.\n"}
{"prompt": "What is the cloud setup in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 For lower environments like QC and release management environment, the data center in Mumbai is used. Staging and production environments are on AWS.\n"}
{"prompt": "Where is the data stored in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 Data is mostly stored in S3 and some data is also stored in MongoDB or SQL. They also have their own location like storage and data lake.\n"}
{"prompt": "Do they use Sagemaker in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 No, they do not use Sagemaker in Zycus as they prefer to use their own environment for their AI development.\n"}
{"prompt": "What is the deployment process for the models in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 The model is put into a repository, maintained with the model version and some configuration file. It then goes into the actual instances where it has to be used and before deployment, some benchmarking is done.\n"}
{"prompt": "Do they use any ML Ops tool in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 No, they do not use any ML Ops tool in Zycus as there is no expert in the company to start off with containerization for Docker and Kubernetes.\n"}
{"prompt": "What was the reason for Simon's absence? \n\n###\n\n", "completion": " uuid: 9984747349 Simon was in the hospital for something related to his baby for checkup treatment.\n"}
{"prompt": "What is the goal of the startup Netaling? \n\n###\n\n", "completion": " uuid: 9984747349 To make it simple for data scientists and ML engineers to deploy models to products in a faster way.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 9984747349 To understand Commerce IQ's ML stack and the challenges they face on a day to day basis.\n"}
{"prompt": "What is Commerce IQ's solution mostly based on? \n\n###\n\n", "completion": " uuid: 9984747349 Sage maker and they automate those pipelines.\n"}
{"prompt": "How do they store the model? \n\n###\n\n", "completion": " uuid: 9984747349 They store the model on S3.\n"}
{"prompt": "Is any of these models being used or called in real time? \n\n###\n\n", "completion": " uuid: 9984747349 No, they do a batch processing.\n"}
{"prompt": "How is the model improved in iterations? \n\n###\n\n", "completion": " uuid: 9984747349 By giving some manual inputs and there are clashes between the classification.\n"}
{"prompt": "How does Commerce IQ track models? \n\n###\n\n", "completion": " uuid: 9984747349 For the existing mature sales estimation model, they don't need to keep track. But for the classification model, they are making version two and will track them for improvement.\n"}
{"prompt": "What is the platform the speaker is introducing? \n\n###\n\n", "completion": " uuid: 9984747349 It is a platform to deploy models in various ways including endpoints, services and pipelines.\n"}
{"prompt": "Are both Pythonic and YML ways supported? \n\n###\n\n", "completion": " uuid: 9984747349 Yes, they are supported.\n"}
{"prompt": "What made you choose this problem statement to solve? \n\n###\n\n", "completion": " uuid: 12339422352 There were three events that led us to believing this problem is still unsolved. The first was building a horizontal level platform and realizing once a company goes beyond a certain scale in machine learning, things need to be platformized for efficiency reasons. The second was working at Facebook and noticing the amazing features of their platform that trivialised building, deploying, and maintaining models. The third was building our own machine learning models while doing another startup and realizing that doing it with existing tooling still involves a lot of pain and does not get far enough as machine learning matures. We believe it's important for machine learning to follow the same paradigm as other software in the long term and for good practices like version control and automatic rollbacks to be maintained.\n"}
{"prompt": "What is the direction in which you believe the problem has still not been solved? \n\n###\n\n", "completion": " uuid: 12339422352 We believe that machine learning needs to follow the same deployment paradigm as other software instead of a completely parallel setup. Also, good practices like version control and automatic rollbacks need to be maintained to avoid machine learning becoming unmanageable as it becomes more mainstream.\n"}
{"prompt": "What is the infra that here? \n\n###\n\n", "completion": " uuid: 12249609647 Probably they are using some challenges that they are facing.\n"}
{"prompt": "What are the challenges they are facing? \n\n###\n\n", "completion": " uuid: 12249609647 Ankit did not specify any challenges in particular.\n"}
{"prompt": "What are some of the use cases that Locus is focusing on? \n\n###\n\n", "completion": " uuid: 12249609647 The team is currently working on improving geocoding and have other use cases like transaction time, premium pricing, and value-based pricing.\n"}
{"prompt": "What is geocoding and what are some challenges in dealing with it? \n\n###\n\n", "completion": " uuid: 12249609647 Geocoding is converting textual address into latitude and longitude. It requires preprocessing like standardizing the address and spell correction.\n"}
{"prompt": "What is the team structure at Locus? \n\n###\n\n", "completion": " uuid: 12249609647 There are one to two data engineers, one data analyst, and six data scientists.\n"}
{"prompt": "What libraries and frameworks does the team primarily use? \n\n###\n\n", "completion": " uuid: 12249609647 The team primarily uses PyTorch.\n"}
{"prompt": "What is the data lake that Locus is using? \n\n###\n\n", "completion": " uuid: 12249609647 Locus is currently storing their data in S3 file storage, but they may explore using other tools in the future.\n"}
{"prompt": "Are the models primarily batch-based or real-time? \n\n###\n\n", "completion": " uuid: 12249609647 It depends on the use case, but the model can be used for both batch and real-time predictions.\n"}
{"prompt": "What type of data does Locus primarily work with? \n\n###\n\n", "completion": " uuid: 12249609647 Locus works primarily with structured data, although the address is the only unstructured data that they deal with.\n"}
{"prompt": "What problem is Truefoundry trying to solve with their platform approach? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry is trying to expedite the time to value from machine learning models so that they can deliver business impact more quickly.\n"}
{"prompt": "What approach is Truefoundry taking to build their platform? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry is taking a platform approach similar to what has been seen at Facebook and with other leaders outside of Facebook.\n"}
{"prompt": "What is the scope of the ML developer in the model development lifecycle? \n\n###\n\n", "completion": " uuid: 11984272003 The ML developer is responsible for playing around with the data, determining the domain knowledge, selecting which algorithm to use, and selecting which features to use.\n"}
{"prompt": "Where is Truefoundry available? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry is available in two modes: a public cloud mode for trying out the platform with publicly available data and a private cloud mode where the entire platform is deployed on the customer's cloud.\n"}
{"prompt": "Who manages Truefoundry's cloud operations? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry's managed service provider handles all cloud operations, including 24/7 support, infrastructure provisioning, and project management.\n"}
{"prompt": "What other potential ways of engagement does Truefoundry offer? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry has on-boarded angel investors and is willing to share more details with interested parties. They are also willing to meet in person to discuss potential opportunities.\n"}
{"prompt": "What is the potential issue with the GPU and CPU usage when deploying services? \n\n###\n\n", "completion": " uuid: 10097873824 The GPU may consume more capacity compared to the CPU.\n"}
{"prompt": "What is the level of protection provided by the HTTP connection pool? \n\n###\n\n", "completion": " uuid: 10097873824 The HTTP connection pool provides some level of protection when setting up auto scaling.\n"}
{"prompt": "Which Framework is used for writing the rest service? \n\n###\n\n", "completion": " uuid: 10097873824 They have mostly used either Flask or Falcon server.\n"}
{"prompt": "How much is the cloud cost? \n\n###\n\n", "completion": " uuid: 10097873824 The cloud cost ranges around 1.5 lakh or $1500 to $2000 in INR.\n"}
{"prompt": "Are they currently receiving cloud credits? \n\n###\n\n", "completion": " uuid: 10097873824 No, they have already used up the two years worth of free credits.\n"}
{"prompt": "Do they anticipate their cloud costs increasing? \n\n###\n\n", "completion": " uuid: 10097873824 No, as they do not foresee their costs increasing by a lot in the next year or year and a half at least.\n"}
{"prompt": "What is the advantage of building the stack on top of Kubernetes from day zero? \n\n###\n\n", "completion": " uuid: 10097873824 It simplifies the DevOps process and allows for easier migration to Kubernetes in the future.\n"}
{"prompt": "What is the main orchestrator for deployment? \n\n###\n\n", "completion": " uuid: 10097873824 The main orchestrator for deployment is Kubernetes.\n"}
{"prompt": "What is the main functionality of the platform? \n\n###\n\n", "completion": " uuid: 10097873824 The platform provides deployment, monitoring, auto scaling, model traffic splitting, and cost optimization functionalities.\n"}
{"prompt": "Is there a way to run pipelines and automate the training? \n\n###\n\n", "completion": " uuid: 10097873824 The team is currently building a way to run pipelines and automate the training when new data comes in.\n"}
{"prompt": "What is the team size of HDFC Credilla? \n\n###\n\n", "completion": " uuid: 11984272003 There are 20 people now, out of which 15 are full time and five contractors part time, etc.\n"}
{"prompt": "Where is the office of HDFC Credilla located? \n\n###\n\n", "completion": " uuid: 11984272003 The office is located in MG Road, Bangalore.\n"}
{"prompt": "What is the focus of HDFC Credilla? \n\n###\n\n", "completion": " uuid: 11984272003 The focus is on bringing a lot of ticket option in the current organization.\n"}
{"prompt": "What is the in-house engineering team size of HDFC Credilla? \n\n###\n\n", "completion": " uuid: 11984272003 The in-house engineering team size is around 50 members.\n"}
{"prompt": "What is True Foundry? \n\n###\n\n", "completion": " uuid: 11984272003 True Foundry is a startup building a horizontal machine learning platform to support the operational needs of other teams.\n"}
{"prompt": "What was the conversation about? \n\n###\n\n", "completion": " uuid: 11354392663 The conversation was about the ML pipeline in Platinum and the challenges faced.\n"}
{"prompt": "What is EKS? \n\n###\n\n", "completion": " uuid: 11354392663 EKS is a Kubernetes-based service provided by Amazon Web Services.\n"}
{"prompt": "Do the data scientists do the deployments? \n\n###\n\n", "completion": " uuid: 11354392663 Yes, the data scientists do the deployments.\n"}
{"prompt": "How do the data scientists deploy their models? \n\n###\n\n", "completion": " uuid: 11354392663 They would provide pickled models.\n"}
{"prompt": "Are the models hosted as endpoints or batched? \n\n###\n\n", "completion": " uuid: 11354392663 They are hosted as live predictions on request, but they are mostly made for batch predictions.\n"}
{"prompt": "What was the problem that Platinum faced a year ago? \n\n###\n\n", "completion": " uuid: 11354392663 The state of the prototyping instrument was very problematic, so they had trouble retaining people over it.\n"}
{"prompt": "What did they do about it? \n\n###\n\n", "completion": " uuid: 11354392663 They put a plaster on it immediately rather than doing some kind of long overhaul.\n"}
{"prompt": "What is the current challenge of Platinum? \n\n###\n\n", "completion": " uuid: 11354392663 They are currently scaling up the two to three minutes machine learning data sets that they deliver, and the processes don't scale very well for that.\n"}
{"prompt": "What is the purpose of the platform being built by the startup? \n\n###\n\n", "completion": " uuid: 11354392663 The purpose of the platform is to enable data scientists to train and host models in a scalable way.\n"}
{"prompt": "What are the two concrete actionables that the startup proposed to Platinum? \n\n###\n\n", "completion": " uuid: 11354392663 To showcase their platform to Platinum and see if there is a use case for it in their prototyping teams, and to hear from someone from the infra team and see if the platform could help solve the introduction challenges.\n"}
{"prompt": "What is the ideal team composition for managing the entire pipeline? \n\n###\n\n", "completion": " uuid: 10097841502 A data science team with basic engineering skills is able to manage the entire pipeline.\n"}
{"prompt": "How does the platform deploy models? \n\n###\n\n", "completion": " uuid: 10097841502 The platform allows you to deploy models in various ways such as an EML way or a Python way from your CLI, notebooks, or UI. It automatically creates an endpoint, deploys it on your Kubernetes cluster that includes auto scaling and cost insights.\n"}
{"prompt": "What types of models can be deployed on the platform? \n\n###\n\n", "completion": " uuid: 10097841502 Different kinds of models can be deployed such as real-time models or batch-based models.\n"}
{"prompt": "What is the default monitoring provided for the system and ML on the platform? \n\n###\n\n", "completion": " uuid: 10097841502 The default monitoring provided on the platform includes system monitoring for usage of CPUs, memory, resources, and more. The ML monitoring includes monitoring data drift, feature drift, feature importance, and performance degradation.\n"}
{"prompt": "How are alerts set up on the platform? \n\n###\n\n", "completion": " uuid: 10097841502 Based on the monitoring data, alerts are sent based on the customer's preferences and flow to their email and slack for notification.\n"}
{"prompt": "Is Airflow compatible with the platform? \n\n###\n\n", "completion": " uuid: 10097841502 Airflow is part of the platform's roadmap, but it has not yet been shipped in the product.\n"}
{"prompt": "What are the factors looked for during tool evaluations? \n\n###\n\n", "completion": " uuid: 10097841502 Factors looked for during tool evaluations include ease of versioning and experiment tracking, resource monitoring, user-friendliness of the UI, continuous support, and relevancy for the next five years.\n"}
{"prompt": "What is the team composition in terms of location? \n\n###\n\n", "completion": " uuid: 10097841502 Most of the back-end team is based out of India, while offices are in San Francisco, Redwood City, and London. The Redwood City office is mostly sales and marketing, and the front-end team works mostly in the UK.\n"}
{"prompt": "What is the team's approach to platform building? \n\n###\n\n", "completion": " uuid: 10097841502 The team approaches building the platform with principles of scalability, best-in-class infrastructure, and user-friendly developer workflows for seamless use.\n"}
{"prompt": "What is the invitation to use the platform? \n\n###\n\n", "completion": " uuid: 10097841502 The speaker invites the listener to try the platform for their personal use case and provide feedback, possibly leading to further exploration and potential service for the listener's team.\n"}
{"prompt": "What command is used to initiate training in Python? \n\n###\n\n", "completion": " uuid: 12428091307 Python command to initiate that training.\n"}
{"prompt": "Who takes care of creating and killing the VM during Vertex model training job? \n\n###\n\n", "completion": " uuid: 12428091307 The Vertex training job takes care of creating and killing the VM.\n"}
{"prompt": "Where is the model stored after training in Vertex? \n\n###\n\n", "completion": " uuid: 12428091307 The model is converted into PB and then stored in the model register of the Vertex.\n"}
{"prompt": "What kind of reports the data center can create with the data? \n\n###\n\n", "completion": " uuid: 12428091307 The context does not provide enough information to determine it.\n"}
{"prompt": "What is Label Studio used for in object detection? \n\n###\n\n", "completion": " uuid: 12428091307 Label Studio is used to scan through unauthorized data for determining its quality without worrying about it.\n"}
{"prompt": "Who handles the packaging and image making for on-prem deployment? \n\n###\n\n", "completion": " uuid: 12428091307 The infrastructure team takes care of packaging and image making for on-prem deployment.\n"}
{"prompt": "What problems does Truefoundry solve in ML Ops? \n\n###\n\n", "completion": " uuid: 12428091307 Truefoundry tries to empower developers, provide monitoring dashboard, and make promotion from one environment to other easier.\n"}
{"prompt": "Is Flight ex deployed on any on-premises? \n\n###\n\n", "completion": " uuid: 12428091307 It is unclear whether Flight ex is deployed on any on-premises as per the context.\n"}
{"prompt": "Who is the contact person for DevOps or ML Ops in Flight ex? \n\n###\n\n", "completion": " uuid: 12428091307 Nico is the contact person for DevOps or ML Ops in Flight ex.\n"}
{"prompt": "Who is Matt as mentioned in the conversation? \n\n###\n\n", "completion": " uuid: 12428091307 Matt is the director of the speaker in the conversation.\n"}
{"prompt": "What is the goal of the pipeline described in the conversation? \n\n###\n\n", "completion": " uuid: 12339423649 The goal of the pipeline is to optimize multi-cloud deployment environment for best output and low cost.\n"}
{"prompt": "What parts of the system have not been built yet? \n\n###\n\n", "completion": " uuid: 12339423649 The cost optimization across cloud and AB testing automation retraining have not been built yet.\n"}
{"prompt": "What is the recommended focus of the company? \n\n###\n\n", "completion": " uuid: 12339423649 Specialization for one vertical may make more sense in general.\n"}
{"prompt": "How does the company interface with new people? \n\n###\n\n", "completion": " uuid: 12339423649 The company does customized demos.\n"}
{"prompt": "What is the main area of focus for this AI system? \n\n###\n\n", "completion": " uuid: 12339423649 The major focus is multi-cloud deployment environment which is more systems-oriented.\n"}
{"prompt": "What is the team using for managing the intra for research? \n\n###\n\n", "completion": " uuid: 12339423649 There is no orchestration layer like Kubernetes being used. Every developer has their own choices to make.\n"}
{"prompt": "How does the team manage the resources for on-prem research? \n\n###\n\n", "completion": " uuid: 12339423649 The team buys new servers for research which is cheaper than going on cloud.\n"}
{"prompt": "What are some tools used for data extraction from social media and web? \n\n###\n\n", "completion": " uuid: 10128442512 There are tools available but they are either not very accurate or they are very costly.\n"}
{"prompt": "What are some challenges faced while searching for the right customer on social media? \n\n###\n\n", "completion": " uuid: 10128442512 The challenge often arises while finding the right customer on social media due to profile matching.\n"}
{"prompt": "Does Credibly work with vendors or use internal systems for data extraction on social media and web? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly is currently doing data extraction internally by leveraging the API already available from social media platforms such as Facebook and Google.\n"}
{"prompt": "What is the tiering system for Facebook API? \n\n###\n\n", "completion": " uuid: 10128442512 The Facebook API has different tiers - a free version, a mid-tier version, and a premium version that gives access to all the data.\n"}
{"prompt": "Does Credibly build their own data science or machine learning models? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly has a couple of models for their underwriting process which they mostly develop internally but have also subscribed to a vendor called Data Robot.\n"}
{"prompt": "Why did Credibly subscribe to Data Robot? \n\n###\n\n", "completion": " uuid: 10128442512 Data Robot enables faster model building and greater transparency in performance monitoring, and Credibly found this to be of great value.\n"}
{"prompt": "How does Data Robot pricing work? \n\n###\n\n", "completion": " uuid: 10128442512 Pricing for Data Robot is based on the time period and there may be limitations on the server side.\n"}
{"prompt": "What is the approximate budget Credibly pays for Data Robot in a year? \n\n###\n\n", "completion": " uuid: 10128442512 The information on this is not available, but they were negotiating with a competitor called Aquarium and were quoted a price of about $400K or $500K.\n"}
{"prompt": "What are the names of the two people mentioned who were at Facebook? \n\n###\n\n", "completion": " uuid: 9984644130 Nikhunja and Aviate\n"}
{"prompt": "Which companies did the rest of the team come from? \n\n###\n\n", "completion": " uuid: 9984644130 Gojek, Amazon Reserve Postman\n"}
{"prompt": "Who is the founder of Kegle and Abyssia, and what was his role at Facebook? \n\n###\n\n", "completion": " uuid: 9984644130 Anthony, he was the first creator of the FP Learner platform within Facebook for productionizing of models\n"}
{"prompt": "What is the goal of the platform? \n\n###\n\n", "completion": " uuid: 9984644130 To enable teams to get models to production faster and reduce the time to value, allowing more time to focus on building different models rather than worrying about infrastructure and coordinating with different teams\n"}
{"prompt": "What are the design principles that the system adheres to? \n\n###\n\n", "completion": " uuid: 9984644130 Everything is API driven, treated as GitHub in terms of configuration, self serve, access control, cost insight, reproducible\n"}
{"prompt": "What is the central infrastructure of the system? \n\n###\n\n", "completion": " uuid: 9984644130 The deployment infrastructure\n"}
{"prompt": "What are some of the deployment use cases shown on the system? \n\n###\n\n", "completion": " uuid: 9984644130 Deploying a model as a fast API, training job, batch inference, model with artifacts, multiple microservices\n"}
{"prompt": "What is the monitoring system used by the platform? \n\n###\n\n", "completion": " uuid: 9984644130 The system monitoring provided by the platform itself\n"}
{"prompt": "Can the system schedule batch jobs or training jobs? \n\n###\n\n", "completion": " uuid: 9984644130 Yes, it is supported and can be accessed through the beta product\n"}
{"prompt": "How can the platform be used to update models? \n\n###\n\n", "completion": " uuid: 9984644130 Training can be scheduled and tracked through the platform's experiment tracking system, and a manual approval loop can be triggered to deploy the new model, with capabilities for automated retention being developed\n"}
{"prompt": "What is the process for monitoring the performance of automated models? \n\n###\n\n", "completion": " uuid: 12150845733 The process involves setting aside certain cases, monitoring outcomes through a dashboard that tracks both model outcomes and human outcomes, and continuously monitoring performance to determine if adjustments need to be made.\n"}
{"prompt": "Who has ownership of the model deployment setup in an organization? \n\n###\n\n", "completion": " uuid: 12150845733 The data engineering team takes ownership of the deployment setup, while the data science team specifies the requirements.\n"}
{"prompt": "What is the approach that the startup takes in working with enterprises \n\n###\n\n", "completion": " uuid: 12150845733 The startup takes an enabler approach, working closely with the data engineering or platform team to understand requirements, build custom solutions, and integrate end-to-end workflows. They seek help from advisors, accept angel checks, and build out more custom integration as needed.\n"}
{"prompt": "What are some of the differentiators of the startup's product? \n\n###\n\n", "completion": " uuid: 12150845733 The product is multi-cloud, supports custom plugins, and is developer-friendly, making it easy to deploy models in a reliable and scalable way. The architecture is built to allow flexibility and support different workflows depending on use cases.\n"}
{"prompt": "What value drivers does the startup offer to CTOs or SVPs of Data in an organization? \n\n###\n\n", "completion": " uuid: 12150845733 The startup's product can increase the productivity of team members, allowing for reliable and scalable model deployment. It offers flexibility and customization, enabling the solution of specific problems. It also provides multi-cloud support and is developer-friendly, making onboarding quick and easy.\n"}
{"prompt": "Who is introducing themselves on the call? \n\n###\n\n", "completion": " uuid: 12339422352 Jimmy is introducing himself on the call.\n"}
{"prompt": "Do they have a product already or are they still trying to figure it out? \n\n###\n\n", "completion": " uuid: 12339422352 They do have a product and platform, and they also have a few customers.\n"}
{"prompt": "What is Liquin Bhajaj's background? \n\n###\n\n", "completion": " uuid: 12339422352 Liquin Bhajaj comes from a machine learning background and has worked at Facebook and Reflection before co-founding Truefoundry.\n"}
{"prompt": "What cloud provider does Make My Trip use primarily? \n\n###\n\n", "completion": " uuid: 12339422352 Make My Trip primarily uses AWS as their cloud provider.\n"}
{"prompt": "Who writes the Airflow jobs for the model deployment? \n\n###\n\n", "completion": " uuid: 12339422352 The ML engineer or data scientist writes the Airflow jobs for the model deployment.\n"}
{"prompt": "What is the hand off process from the machine learning team to the intra team that's managing it? \n\n###\n\n", "completion": " uuid: 12339422352 The hand off process involves using a standard recipe for deployment and making changes as needed for the specific model.\n"}
{"prompt": "What platformization journey is Truefoundry on? \n\n###\n\n", "completion": " uuid: 12339422352 Truefoundry is working on platformizing multi-arm bandit, making it more accessible for non data scientists.\n"}
{"prompt": "What is the main issue with productionizing the projects at Novartis? \n\n###\n\n", "completion": " uuid: 12044422255 The issue is actually even getting to the production stage, and there has been a big reorganization happening since last year, due to which over the last three years since the organization was set up, they have not been able to show a very good return on investment in the sense that they have been showing proofs of concepts and showing Oh, hey, look, I can apply ML models to come up with new, interesting molecules.\n"}
{"prompt": "Who took over as CEO of Novartis and what was his promise to the shareholders? \n\n###\n\n", "completion": " uuid: 12044422255 In 2018, Vas Narasimhan took over as CEO of Novartis and he's been promising his shareholders to go big on data and digital, as a part of which he set up a chief CEO office and a central team was formed.\n"}
{"prompt": "What are the different applications of data science at Novartis? \n\n###\n\n", "completion": " uuid: 12044422255 The applications of data science currently revolve mostly around the research part, but they have promising opportunities to automate things like legal writing, supply chain and manufacturing, but the problem there is more with the data management side of things.\n"}
{"prompt": "What is the main challenge faced by Novartis in deploying ML models at scale? \n\n###\n\n", "completion": " uuid: 12044422255 The challenge faced by Novartis in deploying ML models at scale is that people don't trust the data or it's in too many different systems or there are too many constraints because of geographical boundaries and different regulations in different places.\n"}
{"prompt": "What are the tools used by Novartis for data management and ML? \n\n###\n\n", "completion": " uuid: 12044422255 Novartis uses data bricks, glassbox, and legacy tools for data management and ML, and they are trying to move some of the legacy tools to newer platforms. The structure is diverse, and there is no central infrastructure as such. The different business pods are doing AIML in different ways.\n"}
{"prompt": "How is the research infrastructure at Novartis managed, and how are models deployed and maintained at scale? \n\n###\n\n", "completion": " uuid: 12044422255 There is not much clarity on how the research infrastructure at Novartis is managed, but for the central team, they use glassbox primarily, and the data pipeline is built using GUI with little bit of coding here and there. The challenge faced by Novartis in deploying ML models at scale is that the business side doesn't fully see the promise yet, so the focus is on solving the right business problem, and there is no proper data management in place.\n"}
{"prompt": "What is the goal of the call and how long is the scheduled time? \n\n###\n\n", "completion": " uuid: 9984644130 The goal of the call is to understand each other's business, explore the possibility of potential partnership and see how Truefoundry can provide a solution to Nexus. The scheduled time for the call is 45 minutes.\n"}
{"prompt": "Who are the participants in the call, where are they based and what are their backgrounds? \n\n###\n\n", "completion": " uuid: 9984644130 The participants in the call are from Truefoundry and Nexus. Truefoundry team is primarily based in India, with some team members in the US, Singapore and Paris. The team members are from the founding team of Truefoundry, with backgrounds in portfolio management and building startups. The Nexus team is based in Singapore and is part of Standard Chartered Bank's eniacventures arm. The Nexus data science team consists of three members- data science lead, senior data scientist and data science analyst.\n"}
{"prompt": "What are some of the topics discussed in the call? \n\n###\n\n", "completion": " uuid: 9984644130 The topics discussed in the call include quick introductions, understanding of each other's businesses, exploring potential partnership, understanding machine learning use case and challenges, understanding data science team's background and use cases, understanding the deployment stack used by Nexus, understanding challenges faced in deploying models, understanding future use cases and challenges faced in building a scalable ML platform team from scratch.\n"}
{"prompt": "What problem is Truefoundry trying to solve and at what stage of the ML cycle do they come into the picture? \n\n###\n\n", "completion": " uuid: 9984644130 Truefoundry is trying to solve the problem of enabling data scientists to take model to production in a faster way and do it in a way that is scalable, cost effective and with some basic monitoring that is in built. They come into the picture in the model serving stage which is basically the deployment piece of the pipeline.\n"}
{"prompt": "What are the examples cited of companies investing in ML platform teams? \n\n###\n\n", "completion": " uuid: 9984644130 The examples cited of companies investing in ML platform teams are Facebook, Google, and Uber.\n"}
{"prompt": "Where is the person based? \n\n###\n\n", "completion": " uuid: 10238582319 In India.\n"}
{"prompt": "Where is their home located? \n\n###\n\n", "completion": " uuid: 10238582319 In Punjab.\n"}
{"prompt": "Is the person part of a remote team? \n\n###\n\n", "completion": " uuid: 10238582319 Yes.\n"}
{"prompt": "Do some team members still join the office? \n\n###\n\n", "completion": " uuid: 10238582319 Yes, a few.\n"}
{"prompt": "Is joining the office mandatory? \n\n###\n\n", "completion": " uuid: 10238582319 No, it's not mandatory.\n"}
{"prompt": "What is the person's background? \n\n###\n\n", "completion": " uuid: 10238582319 Machine learning.\n"}
{"prompt": "Where did the person previously work? \n\n###\n\n", "completion": " uuid: 10238582319 At Facebook.\n"}
{"prompt": "What are some of the projects the person worked on? \n\n###\n\n", "completion": " uuid: 10238582319 Conversational AI.\n"}
{"prompt": "What did the person build at Reflection? \n\n###\n\n", "completion": " uuid: 10238582319 A horizontal ML platform.\n"}
{"prompt": "What is the mission of the company? \n\n###\n\n", "completion": " uuid: 10238582319 To bring Facebook-level systems to all companies.\n"}
{"prompt": "What type of customers does Mathew have? \n\n###\n\n", "completion": " uuid: 10238582319 State agencies in the United States.\n"}
{"prompt": "What are some of the problems with working with state agencies? \n\n###\n\n", "completion": " uuid: 10238582319 Data privacy, model hosting at scale, data and model resiliency.\n"}
{"prompt": "What are some of Mathew's products? \n\n###\n\n", "completion": " uuid: 10238582319 AI products for clinical trials, intelligent document processing.\n"}
{"prompt": "Do the pharma companies use generic models? \n\n###\n\n", "completion": " uuid: 10238582319 No, they use custom models.\n"}
{"prompt": "What is used to deploy and scale the machine learning models? \n\n###\n\n", "completion": " uuid: 10238582319 Kubernetes.\n"}
{"prompt": "Does Mathew use multi-cloud? \n\n###\n\n", "completion": " uuid: 10238582319 Yes, since customers have different cloud preferences.\n"}
{"prompt": "How is resource allocation handled? \n\n###\n\n", "completion": " uuid: 10238582319 Engineers access their own AI servers before handing off to DevOps team.\n"}
{"prompt": "Are there permission controls on the machines and models? \n\n###\n\n", "completion": " uuid: 10238582319 Yes, there are various permissions and authentication controls.\n"}
{"prompt": "What is the speaker's attitude towards receiving the task of providing kwh? \n\n###\n\n", "completion": " uuid: 11189924245 It's like peanuts to him and he doesn't need to worry about it up to 200-300 kwh.\n"}
{"prompt": "What is the concern the speaker would have if he signs SW anytime? \n\n###\n\n", "completion": " uuid: 11189924245 He needs to have a work for that, which he currently doesn't have.\n"}
{"prompt": "What would make the speaker forget about the conflict of interest? \n\n###\n\n", "completion": " uuid: 11189924245 If the other person offers to do his chatbot and everything.\n"}
{"prompt": "What is the first thing the speaker proposes to start with for the chatbot business? \n\n###\n\n", "completion": " uuid: 11189924245 Starting with the chatbot business itself.\n"}
{"prompt": "Is the speaker sure that the proposed chatbot business is aligned with the other person's product line? \n\n###\n\n", "completion": " uuid: 11189924245 No, he thinks it's not aligned.\n"}
{"prompt": "What does the speaker offer to do for the other person? \n\n###\n\n", "completion": " uuid: 11189924245 Help him to get his foot into CVS and introduce him to people.\n"}
{"prompt": "What is the significance of CVS in terms of IT staff and expense? \n\n###\n\n", "completion": " uuid: 11189924245 CVS has 26,000 IT staff, which is a $2 billion plus expense every year.\n"}
{"prompt": "How many data scientists does CVS have according to the speaker and what does it indicate? \n\n###\n\n", "completion": " uuid: 11189924245 CVS has around 600 data scientists, which the speaker thinks is too many and indicates something wrong with their hiring.\n"}
{"prompt": "What is the speaker currently hiring for? \n\n###\n\n", "completion": " uuid: 11189924245 The speaker is currently hiring a lot of individual contributors at a senior director level, paying big bucks for that kind of talent.\n"}
{"prompt": "What does the speaker think is important when they place someone into CVS? \n\n###\n\n", "completion": " uuid: 11189924245 There needs to be one person who's their favorite superstar and who can code fast to take things to the end state.\n"}
{"prompt": "What is the first use case proposed by the speaker and how much money does he think it can make? \n\n###\n\n", "completion": " uuid: 11189924245 The first use case proposed is around drug performance analysis and the speaker thinks it's a billion dollar plus product they can build.\n"}
{"prompt": "What is the second use case proposed by the speaker and what is it focused on? \n\n###\n\n", "completion": " uuid: 11189924245 The second use case is focused on predicting drug shipment delivery times and improving customer satisfaction.\n"}
{"prompt": "Has work already started on any of the proposed use cases according to the speaker? \n\n###\n\n", "completion": " uuid: 11189924245 No, the speaker is the person pushing for these use cases and needs to convince others to prioritize them.\n"}
{"prompt": "When is the speaker available for another call to discuss the use cases further? \n\n###\n\n", "completion": " uuid: 11189924245 The speaker is available on Friday after 5:30pm EST and will send an invite for a call.\n"}
{"prompt": "What does Carlos ask and what is the response? \n\n###\n\n", "completion": " uuid: 11488124534 Carlos asks if he can be heard, and the response is yes.\n"}
{"prompt": "What do Carlos and the other person discuss after confirming the audio is okay? \n\n###\n\n", "completion": " uuid: 11488124534 They discuss their whereabouts and travel plans.\n"}
{"prompt": "What is the other person's profession and what team do they manage? \n\n###\n\n", "completion": " uuid: 11488124534 The other person manages an ML team and manages the back end team.\n"}
{"prompt": "What is Truefoundry and how long has the other person been on an entrepreneurial journey? \n\n###\n\n", "completion": " uuid: 11488124534 Truefoundry is a startup and the person has been on an entrepreneurial journey since quitting Facebook.\n"}
{"prompt": "What is the focus of Truefoundry and what are they building? \n\n###\n\n", "completion": " uuid: 11488124534 Truefoundry is building a platform similar to the predictor service at Facebook for companies that want to build and deploy ML models.\n"}
{"prompt": "Which cloud providers do they use and why do they use two different ones? \n\n###\n\n", "completion": " uuid: 11488124534 They primarily use AWS, but also use Azure for speech recognition because of a strong partnership and technical capabilities.\n"}
{"prompt": "What is the context of the conversation? \n\n###\n\n", "completion": " uuid: 11656830826 The conversation is about the location, weather, and backgrounds of the speakers, as well as their work in the machine learning industry.\n"}
{"prompt": "Where is Beville located? \n\n###\n\n", "completion": " uuid: 11656830826 Beville is located in Canada, very close to Toronto, in a city called Brampton.\n"}
{"prompt": "What is the weather like in Brampton? \n\n###\n\n", "completion": " uuid: 11656830826 The weather in Brampton is usually cold during the winter months, with a lot of snow from December to March, but this year has been better with less snow.\n"}
{"prompt": "Where is the speaker based out of? \n\n###\n\n", "completion": " uuid: 11656830826 The speaker is based out of Bangladesh.\n"}
{"prompt": "What is the speaker's experience in machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 The speaker has a background in machine learning and previously led a conversational AI team at Facebook, as well as worked on personalization algorithms for ecommerce at a startup called Reflection.\n"}
{"prompt": "What is Procore? \n\n###\n\n", "completion": " uuid: 11656830826 Procore is a project management software company focused on the construction industry, offering solutions for financials, project estimation, and more.\n"}
{"prompt": "What is the speaker's role at Procore? \n\n###\n\n", "completion": " uuid: 11656830826 The speaker works on the ML Ops team at Procore, which handles infrastructure scaling, monitoring, and security, as well as adopting new tools for machine learning workflows.\n"}
{"prompt": "What cloud does Procore primarily use for machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 Procore primarily uses AWS for machine learning, while their acquisition, Level Set, uses GCP.\n"}
{"prompt": "Does Procore use SageMaker for machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 Procore previously used SageMaker for machine learning but has since built out their own platform on top of Kubernetes due to limitations with ready-made solutions and the need to customize deployment and contact methods.\n"}
{"prompt": "What is an end point in this context? \n\n###\n\n", "completion": " uuid: 10881905922 An end point is a model application.\n"}
{"prompt": "Does every model created serve as an end point? \n\n###\n\n", "completion": " uuid: 10881905922 No, not each model itself is an end point.\n"}
{"prompt": "What creates a single endpoint for the product? \n\n###\n\n", "completion": " uuid: 10881905922 The service that was built creates a single endpoint for the product.\n"}
{"prompt": "What are the parameters used in the endpoint? \n\n###\n\n", "completion": " uuid: 10881905922 The parameters used are the account name and certain other things.\n"}
{"prompt": "What does the account name tell us in this context? \n\n###\n\n", "completion": " uuid: 10881905922 The account name tells us which model to use in which context.\n"}
{"prompt": "What tool is used for tracking experiments? \n\n###\n\n", "completion": " uuid: 10881905922 ML Flow is used to track experiments.\n"}
{"prompt": "What kind of metrics are tracked in ML Flow? \n\n###\n\n", "completion": " uuid: 10881905922 Metrics such as accuracy, improvements in search or classification, and drifter are tracked in ML Flow.\n"}
{"prompt": "Is the model registry used in ML Flow? \n\n###\n\n", "completion": " uuid: 10881905922 No, the model registry is not used in ML Flow.\n"}
{"prompt": "Which companies are focused on drift tracking? \n\n###\n\n", "completion": " uuid: 10881905922 Fiddler is a company that is focused on drift tracking.\n"}
{"prompt": "What is the primary importance of the company at this point? \n\n###\n\n", "completion": " uuid: 10881905922 At this point, getting things up is of primary importance.\n"}
{"prompt": "What would the speaker do differently if they were starting today? \n\n###\n\n", "completion": " uuid: 10881905922 If they were starting today, they would look at using Fiddler or Tuhu and using what Databrick has.\n"}
{"prompt": "What is a challenge in maintaining a multi-tenant system? \n\n###\n\n", "completion": " uuid: 10881905922 Managing these hundreds or thousands of models depending on the number of customers is a challenge in maintaining a multi-tenant system.\n"}
{"prompt": "What is the speaker's take on building a vector database? \n\n###\n\n", "completion": " uuid: 10881905922 The speaker believes that it is best to take something from outside and use it instead of building a vector database.\n"}
{"prompt": "What is a concern around sending data to a third party? \n\n###\n\n", "completion": " uuid: 10881905922 Sending data to a third party is not permitted by a larger syntax and is legally difficult to differentiate.\n"}
{"prompt": "What technology was used that caused pushback from customers? \n\n###\n\n", "completion": " uuid: 10881905922 One technology that was sending some metadata outside of the customer thing caused pushback from customers and had to be changed.\n"}
{"prompt": "What is the major challenge for machine learning in healthcare according to the context? \n\n###\n\n", "completion": " uuid: 11577360522 Multiple versions of the truth exist.\n"}
{"prompt": "What is the difference between feature-based models and deep learning models in the pipeline? \n\n###\n\n", "completion": " uuid: 11577360522 Deep learning models do not need feature definition.\n"}
{"prompt": "What tools are used for monitoring the models? \n\n###\n\n", "completion": " uuid: 11577360522 Grafana is used for visualization of metrics on Azure logging metrics, and models on Grafana for model performance.\n"}
{"prompt": "What kind of ML models are deployed in the customer environment? \n\n###\n\n", "completion": " uuid: 11577360522 Stateless models are deployed in the customer environment.\n"}
{"prompt": "What is the plan for ML ops adoption for the company? \n\n###\n\n", "completion": " uuid: 11577360522 The company plans to adopt an ML Ops platform in 2023 for consistency in engineering, infrastructure, quality, quantity, and monitoring.\n"}
{"prompt": "What is the team's comfort level with Kubernetes? \n\n###\n\n", "completion": " uuid: 11577360522 They are comfortable with deploying Kubernetes clusters and services, but are not yet using Kubeflow for model deployment.\n"}
{"prompt": "What is the main workflow of the platform? \n\n###\n\n", "completion": " uuid: 12361625221 The main workflow of the platform revolves around deployment multi model and everything. Basically, you can store for each customer. You can probably create probably a model registry here. These models are basically saved here with different versions. If you want to deploy these models, let's say you've already saved the models, then when you want to deploy, it's up to you based on the use case, you might want to deploy it as a real-time service or you might want to deploy it as a batch inference.\n"}
{"prompt": "How do you deploy models in the platform? \n\n###\n\n", "completion": " uuid: 12361625221 If the model is already saved on the system and you want to deploy, you choose the namespace where you want to deploy. These are the list of all the models that you have, and then you select the models that you want to deploy. You can also select if you want your selected models to target GPU or a certain type of CPU machine. Then you can click on deploy where it will create a service. If you want to deploy from Hugging Face model directly, you can give us the Hugging Face link and we'll automatically deploy it.\n"}
{"prompt": "Is everything driven by API in the platform? \n\n###\n\n", "completion": " uuid: 12361625221 Yes, everything in the platform is driven by API, and all the APIs are exposed that can be integrated into the layer for the customer. So all the UIs are not exposed, just the APIs. At the end of the day, everything is a REST API and we also provide our Python SDK.\n"}
{"prompt": "What is the pricing model on the platform? \n\n###\n\n", "completion": " uuid: 12361625221 We charge customers on the basis of the number of users. For now, our pricing has been USD 300 per developer per month. But we can think of a simple blanket pricing that can work for you all.\n"}
{"prompt": "What are the items that will be deployed on the customer's cluster? \n\n###\n\n", "completion": " uuid: 12361625221 Control plane will get Argocd, Argowork, Istio, and if you need auto-scaling, we need Prometheus. Workload cluster will get Argocd, Argowork, and Istio. If you need long-term persistence logs, you can use Loki; otherwise, you can continue using Azure. Elastic search is also available. Prometheus is optional and only necessary if you need auto-scaling.\n"}
{"prompt": "What is the ML flow? \n\n###\n\n", "completion": " uuid: 10881905316 ML Flow is a tool for tracking experiments and managing and deploying models.\n"}
{"prompt": "What happens when you try to log anything nonscalar with the ML flow? \n\n###\n\n", "completion": " uuid: 10881905316 It fails.\n"}
{"prompt": "What does the Truefoundry platform offer to solve the issue of logging nonscalar values? \n\n###\n\n", "completion": " uuid: 10881905316 The Truefoundry platform offers additional data logging functionality for non-scalar values.\n"}
{"prompt": "What is the name of the service deployed on the Truefoundry platform to demonstrate how to write FastAPI code? \n\n###\n\n", "completion": " uuid: 10881905316 The service deployed is a FastAPI service.\n"}
{"prompt": "What is the name of the endpoint that shows the three functions deployed as part of the FastAPI service? \n\n###\n\n", "completion": " uuid: 10881905316 The endpoint name is 'multiply', 'normal', and 'uniform'.\n"}
{"prompt": "What is the resource you need to pass to the service deployment code to specify the GPU to use? \n\n###\n\n", "completion": " uuid: 10881905316 You need to pass the resources parameter to the service deployment code to specify the GPU to use.\n"}
{"prompt": "How can you identify the model to use in the deployment of the Iris service? \n\n###\n\n", "completion": " uuid: 10881905316 You can identify the model by its fully qualified name (FQN).\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12044422255 To learn about the overall machine learning pipeline at Novartis, with a focus on how the multi-cloud comes into play and the challenges associated with it, and to introduce themselves to each other.\n"}
{"prompt": "What is the speaker's background? \n\n###\n\n", "completion": " uuid: 12044422255 He graduated from IAT Karakpur in 2013, worked at a hedge fund called Worldcoint, held two roles in the CEO office and as a portfolio manager, managed $600 million in assets, invested in startups, built a startup in the talent space called Entire and sold it in 2021 September, and then started building True Foundry.\n"}
{"prompt": "Who are the speaker's co-founders in True Foundry? \n\n###\n\n", "completion": " uuid: 12044422255 Vishek and Nickel are his co-founders. Vishek worked at Facebook for six years, and Nickel worked at Reflection and Facebook, where he led the AI team for Portal.\n"}
{"prompt": "Why did the speaker start True Foundry? \n\n###\n\n", "completion": " uuid: 12044422255 The speaker started True Foundry because in his first startup, they had difficulty with deploying models in a reliable way into their website and integrating it. It took them more than a month to understand the cloud systems and then piece together open source.\n"}
{"prompt": "What was the speaker's focus at IBM Research Debt? \n\n###\n\n", "completion": " uuid: 12044422255 The speaker's focus at IBM Research Debt was to work on the problem of reliability, specifically to have some sort of coding over data to protect data in large systems and prevent data loss while at the same time reducing the overhead in terms of cost.\n"}
{"prompt": "What was the main challenge faced by the traditional automotive industry with deploying ML models? \n\n###\n\n", "completion": " uuid: 12044422255 The main challenge faced by the traditional automotive industry with deploying ML models is that the industry does not list all the requirements in the beginning and they have a constantly evolving system that needs to be updated over the air.\n"}
{"prompt": "What is True Foundry's focus? \n\n###\n\n", "completion": " uuid: 12044422255 True Foundry's focus is to provide a machine learning deployment infrastructure on the cloud, to run a seamless training infrastructure and deployment infrastructure over the cloud.\n"}
{"prompt": "Can the session be recorded? \n\n###\n\n", "completion": " uuid: 12044422255 Yes, the session can be recorded.\n"}
{"prompt": "What are the services deployed in production that are sitting under some namespace? \n\n###\n\n", "completion": " uuid: 12428091030 Let's say the services that are deployed in production.\n"}
{"prompt": "Do data scientists have any access to those services? \n\n###\n\n", "completion": " uuid: 12428091030 Yes, they do have access, but to their own namespace.\n"}
{"prompt": "What metrics were being logged for measuring data drift? \n\n###\n\n", "completion": " uuid: 12428091030 There were no drift monitoring metrics being logged before onboarding Selden.\n"}
{"prompt": "Why did they onboard Selden? \n\n###\n\n", "completion": " uuid: 12428091030 One reason was for drift monitoring, but also because Selden provides features beyond just model serving.\n"}
{"prompt": "How did the process of initiation of a new software procurement start? \n\n###\n\n", "completion": " uuid: 12428091030 The machine learning engineers proposed the idea of drift monitoring, spoke to coworkers, manager, product owner, and data scientists, and after everyone liked the idea, it went to the higher-up for final approval.\n"}
{"prompt": "Did they evaluate any other vendors besides Selden for model monitoring? \n\n###\n\n", "completion": " uuid: 12428091030 Yes, they also evaluated Evidently.\n"}
{"prompt": "What is the main purpose of the system they have built? \n\n###\n\n", "completion": " uuid: 12428091030 The system is built on top of Kubernetes and supports all three clouds. It has workspaces for training and production, allows logging of offline metrics, has version comparison, integration with CI/CD for auto scaling, and monitoring for drift and predictions using the same stack.\n"}
{"prompt": "What is the primary reason for onboarding Selden? \n\n###\n\n", "completion": " uuid: 12428091030 Drift monitoring.\n"}
{"prompt": "Which workflow management systems have they worked with? \n\n###\n\n", "completion": " uuid: 12428091030 Airflow 2.0 and Argo workflows.\n"}
{"prompt": "What do they plan to do during the next demo call? \n\n###\n\n", "completion": " uuid: 12428091030 They plan to show a demo of their platform and learn from each other.\n"}
{"prompt": "Who did the person speak with on phone? \n\n###\n\n", "completion": " uuid: 12339423649 Siddharth\n"}
{"prompt": "Who is the uncle mentioned in the conversation? \n\n###\n\n", "completion": " uuid: 12339423649 Not specified.\n"}
{"prompt": "What are the two teams mentioned by Siddharth? \n\n###\n\n", "completion": " uuid: 12339423649 AI team and Empora.\n"}
{"prompt": "What questions has the person not sent to Siddharth? \n\n###\n\n", "completion": " uuid: 12339423649 Multicloud questions.\n"}
{"prompt": "What is Truefoundry's motivation behind the call with Stryker? \n\n###\n\n", "completion": " uuid: 12339423649 To understand the problems faced by companies that are multicloud by design, and to understand their demo pipeline.\n"}
{"prompt": "What is Stryker's current AI structure like? \n\n###\n\n", "completion": " uuid: 12339423649 Stryker has formed a central AI hub, which includes an AI research group, AI systems group responsible for deployment and monitoring, an AI application team, and a bit of analytics.\n"}
{"prompt": "What is the goal of the model building process in Truefoundry's system? \n\n###\n\n", "completion": " uuid: 12339423649 The goal is to go from building a model to deploying it to production, including basic monitoring.\n"}
{"prompt": "What happens after the researcher finishes a training run in Truefoundry's system? \n\n###\n\n", "completion": " uuid: 12339423649 The system will automatically shut it down and return all the logs needed to select and launch it, deploy it to a test environment, or create a basic front end demo.\n"}
{"prompt": "What kind of logs are getting generated? \n\n###\n\n", "completion": " uuid: 10439869350 The logs being generated are used for metrics dashboards, everything, lambda, API.\n"}
{"prompt": "Where are the logs being pushed to? \n\n###\n\n", "completion": " uuid: 10439869350 They are being pushed to something like Grafana.\n"}
{"prompt": "What is the planned usage of Kaan? \n\n###\n\n", "completion": " uuid: 10439869350 Kaan is planned to be used because there is a user layer written in Java that needs to go on Promises.\n"}
{"prompt": "Where is the monitoring happening currently? \n\n###\n\n", "completion": " uuid: 10439869350 Currently, monitoring is happening on CloudWatch and laptop tracking.\n"}
{"prompt": "Is the current monitoring ML monitoring? \n\n###\n\n", "completion": " uuid: 10439869350 No, the current monitoring is not ML monitoring.\n"}
{"prompt": "Are there plans for ML monitoring? \n\n###\n\n", "completion": " uuid: 10439869350 There are currently no plans for ML monitoring.\n"}
{"prompt": "What kind of testing is done for deploying a new model? \n\n###\n\n", "completion": " uuid: 10439869350 There is currently no use case for testing different models with different percentages of traffic.\n"}
{"prompt": "How is the roof platform built? \n\n###\n\n", "completion": " uuid: 10439869350 The roof platform is built to make it easy to deploy models in a scalable way and offers other functionalities to complete the flow of a data scientist or ML.\n"}
{"prompt": "What is the major benefit of the roof platform? \n\n###\n\n", "completion": " uuid: 10439869350 The major benefit of the roof platform is that it integrates training and deployment workload on the same service or box, resulting in cost savings.\n"}
{"prompt": "What is the primary use case being looked for at this point? \n\n###\n\n", "completion": " uuid: 10439869350 The primary use case being looked for is experimentation with the roof platform in terms of tracking and comparing different versions of models.\n"}
{"prompt": "What is one of the use cases for the platform? \n\n###\n\n", "completion": " uuid: 10439124882 The platform is primarily used for monitoring data drift and distribution drifts between training and actual data in industries such as real estate, pharma, and tech.\n"}
{"prompt": "What is the target audience for the platform? \n\n###\n\n", "completion": " uuid: 10439124882 Industries that are not very tech oriented and do not have their own data science team, or those who only have one analyst or data scientist are the target audience for the platform.\n"}
{"prompt": "How long does it take for data scientists to start using the platform? \n\n###\n\n", "completion": " uuid: 10439124882 Data scientists can start deploying on the platform within a matter of a couple of hours, making the onboarding process less than a day.\n"}
{"prompt": "How does the platform differentiate from others such as Sage Maker? \n\n###\n\n", "completion": " uuid: 10439124882 Unlike Sage Maker, the platform is user-friendly and not a black box. The platform is easy to use and provides users with the necessary support they need, even if something goes wrong.\n"}
{"prompt": "What is the target strategy for the platform? \n\n###\n\n", "completion": " uuid: 10439124882 It is initially better to have a few, slightly bigger customers for the platform to evolve and make it easier for smaller customers to use it and then distribute it to multiple industries.\n"}
{"prompt": "What is the UI like for deploying a model? \n\n###\n\n", "completion": " uuid: 10439124882 The UI for deploying a model is straightforward and only requires selecting the source, repository, name, and branch, and then clicking deploy.\n"}
{"prompt": "Can the platform accommodate data of different types? \n\n###\n\n", "completion": " uuid: 10439124882 Yes, the platform has a schema for every model that allows data scientists to define the features and associate a type with them. An error will be thrown if the data type does not match the schema.\n"}
{"prompt": "How can the platform be used for model training? \n\n###\n\n", "completion": " uuid: 10439124882 The platform allows data scientists to deploy a model training job by writing Python code, and they can trigger it to run on the infrastructure with one click.\n"}
{"prompt": "What is the purpose of the model registry? \n\n###\n\n", "completion": " uuid: 10439124882 The model registry serves as a central repository for all versions of the model that users have retrained, making it easy to keep track of them.\n"}
{"prompt": "How many versions of the model can users keep running on the platform? \n\n###\n\n", "completion": " uuid: 10439124882 Users can keep running all versions of the model on the platform.\n"}
{"prompt": "What does the speaker mention about heavy computations? \n\n###\n\n", "completion": " uuid: 11185249632 Do it on your own machine or your own database.\n"}
{"prompt": "According to the context, what is the process of running a computation on a specific server? \n\n###\n\n", "completion": " uuid: 11185249632 You can just point to all those servers and make a connection.\n"}
{"prompt": "What does the speaker say about pushing computation to Data IQ? \n\n###\n\n", "completion": " uuid: 11185249632 For big data sets, it's a bit of a trouble.\n"}
{"prompt": "Which industries can benefit from AutoML models according to the speaker? \n\n###\n\n", "completion": " uuid: 11185249632 Retail, ecommerce, and OTT companies\n"}
{"prompt": "What does the speaker say about the cloud providers' AutoML solutions in comparison to their platform? \n\n###\n\n", "completion": " uuid: 11185249632 From an economic standpoint, the AutoML guys provide some of these, but just because something is free doesn't mean it works.\n"}
{"prompt": "What does the speaker suggest at the end of the conversation? \n\n###\n\n", "completion": " uuid: 11185249632 The speaker suggests testing their platform by taking any of their models or even basic models and trying to see if they are actually able to use the platform to deploy and if they like the process.\n"}
{"prompt": "What is being discussed in the context? \n\n###\n\n", "completion": " uuid: 11317793541 Control plane installation and service deployment, building infrastructure for Dream Eleven platform, overview of data pipeline and distributed training.\n"}
{"prompt": "How many ML models are deployed in the environment that is being discussed? \n\n###\n\n", "completion": " uuid: 11317793541 Around 10,000.\n"}
{"prompt": "What is the role of Bharat in the project? \n\n###\n\n", "completion": " uuid: 11317793541 Building the entire infrastructure from the ML side.\n"}
{"prompt": "What is the goal of the project for Dream Eleven? \n\n###\n\n", "completion": " uuid: 11317793541 To give a detailed overview of the platform from a technical and product perspective, including AB testing.\n"}
{"prompt": "What is the focus on regarding the CI CD system? \n\n###\n\n", "completion": " uuid: 11317793541 Making the system robust from an engineering perspective for scale.\n"}
{"prompt": "What is the request count for Dream Eleven? \n\n###\n\n", "completion": " uuid: 11317793541 10 million requests by 1 million users daily.\n"}
{"prompt": "What is the topic of discussion for the 5-10 minutes overview? \n\n###\n\n", "completion": " uuid: 11317793541 The stack being used for the data pipeline and distributed training.\n"}
{"prompt": "What is the time limit for the call? \n\n###\n\n", "completion": " uuid: 11317793541 The call needs to be wrapped up in 5 to 10 minutes.\n"}
{"prompt": "What did the speaker say they wanted to do on the call? \n\n###\n\n", "completion": " uuid: 10611764294 The speaker wanted to get to know each other a little bit, learn about Maggie a bit, understand the stage of the current data science project at Amagi, and dive into a little bit of the pipeline and infrastructure.\n"}
{"prompt": "How many co-founders did Anirudh have in his previous startup? \n\n###\n\n", "completion": " uuid: 10611764294 Anirudh had two co-founders in his previous startup named Abhishek and Nikung.\n"}
{"prompt": "What is Amagi primarily into? \n\n###\n\n", "completion": " uuid: 10611764294 Amagi is primarily into cloud-based transcode or cloud-based content delivery solutions.\n"}
{"prompt": "Is the ML pipeline mostly batch or real-time processing? \n\n###\n\n", "completion": " uuid: 10611764294 The ML pipeline is mostly batch processing, and there are a few upcoming use cases where live content will be processed in real-time.\n"}
{"prompt": "What tools does the team use for infrastructure allocation? \n\n###\n\n", "completion": " uuid: 10611764294 The data science team is independent and can spin up any instance they want. They primarily use spot instances that are reasonably priced.\n"}
{"prompt": "What does the speaker want to learn more about in a follow-up call? \n\n###\n\n", "completion": " uuid: 10611764294 The speaker wants to learn more about the monitoring and automated retraining pipeline, and dive into more details of Proof Foundry as well.\n"}
{"prompt": "What is the context of the conversation? \n\n###\n\n", "completion": " uuid: 11354403489 A discussion between two individuals about their work in machine learning and data science.\n"}
{"prompt": "Who is involved in the conversation? \n\n###\n\n", "completion": " uuid: 11354403489 Two individuals, possibly working in the field of data science or machine learning.\n"}
{"prompt": "What is the seniority level of one of the individuals? \n\n###\n\n", "completion": " uuid: 11354403489 The junior individual is not very junior, but is not a decision maker.\n"}
{"prompt": "What is the focus of the conversation? \n\n###\n\n", "completion": " uuid: 11354403489 They are discussing how they can potentially add value to the machine learning pipeline of companies that use data science and machine learning.\n"}
{"prompt": "What is Netradyne? \n\n###\n\n", "completion": " uuid: 11354403489 A company that produces products for monitoring roads and drivers, which uses deep learning models.\n"}
{"prompt": "What are some of the features of Netradyne's products? \n\n###\n\n", "completion": " uuid: 11354403489 Detection of road signals, lanes, and driver drowsiness among other facial expressions.\n"}
{"prompt": "What kind of products does Netradyne have? \n\n###\n\n", "completion": " uuid: 11354403489 They have three different products, including NVDI based products and Qualcomm based products.\n"}
{"prompt": "What deployment pipelines do Netradyne's products use? \n\n###\n\n", "completion": " uuid: 11354403489 For Qualcomm based products, they use a pipeline provided by Snappy while for Nvidia, they use Tensor RT.\n"}
{"prompt": "Is the conversation being recorded? \n\n###\n\n", "completion": " uuid: 11354403489 No, it is not.\n"}
{"prompt": "What is the purpose of the call today? \n\n###\n\n", "completion": " uuid: 9133766297 To understand the problems that the team is trying to solve and figure out if it's a good time to potentially showcase what Trufoundry is working on.\n"}
{"prompt": "What types of models is the team currently working on? \n\n###\n\n", "completion": " uuid: 9133766297 The team is currently working on lead scoring, retention scoring, supply chain optimization, and product recommendations.\n"}
{"prompt": "Are these models already in production? \n\n###\n\n", "completion": " uuid: 9133766297 One of the models, lead scoring, is already in production. Supply chain demand distribution is also in production and the other two models are currently in data engineering phases.\n"}
{"prompt": "Who is currently working in the data science team? \n\n###\n\n", "completion": " uuid: 9133766297 There are four people actively working on the data science team: Nigen, Priyank, Shaans, and Sri Lank. There are two other people, Rohan and Kayhan, who are working on the communications platform and data engineering pipelines, respectively.\n"}
{"prompt": "Does the team have separate engineering support for taking models to production? \n\n###\n\n", "completion": " uuid: 9133766297 It's a hybrid approach. Depending on the need for product help and individual bandwidth, the team either provides data and relies on back end engineers or completes models end to end themselves.\n"}
{"prompt": "What was the context of the call? \n\n###\n\n", "completion": " uuid: 10611764602 The context of the call was to understand upSTOCK's ML needs and infrastructure.\n"}
{"prompt": "Who was the first hiring of the data tribe at upSTOCK? \n\n###\n\n", "completion": " uuid: 10611764602 The principal ML and data engineer was the first hiring of the data tribe at upSTOCK.\n"}
{"prompt": "What kind of use cases is the ML team working on at upSTOCK? \n\n###\n\n", "completion": " uuid: 10611764602 The ML team at upSTOCK is working on use cases such as associate partner incentivization, trading nudges, loyalty programs, RFM cohort, churn detection, sentiment analysis, personalized watch list, revenue forecast models, CLDP prediction, and customized cycle value.\n"}
{"prompt": "What platform is upSTOCK built on and what ML tools do they use? \n\n###\n\n", "completion": " uuid: 10611764602 upSTOCK's platform is built on Kubernetes and the ML team uses Sage Maker extensively, while the data engineering team uses Blue ETL.\n"}
{"prompt": "What is the migration process for upSTOCK to Kubernetes? \n\n###\n\n", "completion": " uuid: 10611764602 The migration process for upSTOCK to Kubernetes is already underway, with more than 50% of their tier one services already migrated.\n"}
{"prompt": "What is the workflow for a business case going from product manager to model production at upSTOCK? \n\n###\n\n", "completion": " uuid: 10611764602 The workflow for a business case going from product manager to model production at upSTOCK involves a discussion between the product team and the data strategy team to determine the best approach. Afterwards, there is an exploration phase to determine the model, data, and pipeline, followed by a standard deployment strategy with feature generation job scheduling.\n"}
{"prompt": "What was the difficulty the speaker faced with Zoom? \n\n###\n\n", "completion": " uuid: 10439124882 Clicking on the bottom because they were using Zoom instead of Google.\n"}
{"prompt": "How did the speakers know each other? \n\n###\n\n", "completion": " uuid: 10439124882 Debug was one of the speaker's seniors at Idi Krakpur and also a customer to their earlier startup when he was running Slintel.\n"}
{"prompt": "What is the goal of Two Foundry? \n\n###\n\n", "completion": " uuid: 10439124882 To create an easy-to-use platform for data scientists and ML developers to deploy models to a final state in a scalable way without relying on infra teams and making it not a black box.\n"}
{"prompt": "What are some of the features offered by Two Foundry? \n\n###\n\n", "completion": " uuid: 10439124882 Monitoring, scalability, and open access to allow building on top of the platform.\n"}
{"prompt": "What industry is Two Foundry currently targeting? \n\n###\n\n", "completion": " uuid: 10439124882 They are currently doing a horizontal approach and are open to any industry, but it might be beneficial to narrow down to one.\n"}
{"prompt": "What is one example of a specific use case that companies might target in their platforms? \n\n###\n\n", "completion": " uuid: 10439124882 Imbalance classification, such as in the fraud domain, which can be one of the hardest problems to solve.\n"}
{"prompt": "What is the speaker's opinion on auto training? \n\n###\n\n", "completion": " uuid: 10439124882 She is not a fan of auto training and believes that good models should be responsible for it and that it's important to monitor the models and understand when to retrain them.\n"}
{"prompt": "Who handles the deployment of models in the speaker's previous companies? \n\n###\n\n", "completion": " uuid: 10439124882 In her previous startup and in PayPal, there was a separate team of data engineers that handled the production deployment.\n"}
{"prompt": "What is the speaker's opinion on feature engineering? \n\n###\n\n", "completion": " uuid: 10439124882 She believes it is critical and that having a good pipeline for feature engineering is more important than building a model, as the model is only 5% of the work. She also mentioned that it is important to tailor feature engineering to specific use cases.\n"}
{"prompt": "What was the speaker's role at PayPal? \n\n###\n\n", "completion": " uuid: 10439124882 She was a data science leader.\n"}
{"prompt": "What is the process of building a model like? \n\n###\n\n", "completion": " uuid: 11655736993 It involves spinning up training resources, comparing web models, testing the workspace, secrets management, authentication, system monitoring, and basic monitoring out of the box.\n"}
{"prompt": "What tools are used for interactive computation and deployment? \n\n###\n\n", "completion": " uuid: 11655736993 Data bricks are used for interactive computation, while Kubernetes is used for deployment.\n"}
{"prompt": "What is the pipeline model builder used for? \n\n###\n\n", "completion": " uuid: 11655736993 It is used to extract one file, put it in a code base, and run a pipeline for multi-cloud use.\n"}
{"prompt": "Who evaluates the models and when is this done? \n\n###\n\n", "completion": " uuid: 11655736993 Business teams with statistics backgrounds evaluate models during the model evaluation phase, which is generally done before the dev environment.\n"}
{"prompt": "What is the process of deploying a model to production? \n\n###\n\n", "completion": " uuid: 11655736993 The engineering team handles the logistics once a model is deployed, while the data science team provides an endpoint for the model.\n"}
{"prompt": "What is data drift and how is it measured? \n\n###\n\n", "completion": " uuid: 11655736993 Data drift is the change in the relationship between the input and the response over time. It is measured by comparing the predictions of the model over time with the actual results.\n"}
{"prompt": "How are new data models ingested by the pipeline? \n\n###\n\n", "completion": " uuid: 11655736993 The pipeline has to adjust to new ways of storing data and it ensures that data is ingested at any given moment.\n"}
{"prompt": "What is the process for managing resources and ensuring cost visibility? \n\n###\n\n", "completion": " uuid: 11655736993 Tags are assigned to each resource, and a cost reporting system ensures that costs can be seen and monitored for the last week.\n"}
{"prompt": "What tools are used for monitoring and tracking performance metrics? \n\n###\n\n", "completion": " uuid: 11655736993 Software engineering uses Graphana and Prometheus for monitoring and tracking performance metrics.\n"}
{"prompt": "What tools are used for deployment, and what programming languages are used? \n\n###\n\n", "completion": " uuid: 11655736993 Python deployment is done with Flask or BentoML, and complex models are done in Scala and PMML. The KPM Columbia framework is also sometimes used for open source models.\n"}
{"prompt": "What is Soma's background and what has she been doing for the past few years? \n\n###\n\n", "completion": " uuid: 12044330588 Soma's background is in engineering and statistics. For the past few years, she has been working in the field of AI for social impact. Currently, she works at the Urban Institute for AI for Social Impact, where they work on various problems concerning public health, education, and agriculture.\n"}
{"prompt": "What is the structure of the organization and how do they fund their projects? \n\n###\n\n", "completion": " uuid: 12044330588 The organization is project-specific and works with government machinery and partner organizations rather than direct stakeholders like farmers. They write grant proposals and receive funding from large funding agencies like the Google for India grant, the Melinda Gates Foundation, and the US funding arm. They have subject matter experts like physicians, doctors, and technical experts as well as a team of about 120+ personnel.\n"}
{"prompt": "What are some of the overarching objectives for their work on ML platforms? \n\n###\n\n", "completion": " uuid: 12044330588 One of the overarching objectives is to open up their innovation process and allow undergraduate students to pick up problems that they have already worked on to make improvements in every aspect of the ML cycle. They also want to have an absolute decoupling from platforms and have an open source, open sync model that anyone can contribute to, subject to data governance and privacy concerns.\n"}
{"prompt": "What is the DevOps practice followed by the company? \n\n###\n\n", "completion": " uuid: 10238582319 The company follows the DevOps practice of having four environments, sometimes five dev testing, performance, UAT or RC, basically release candidate and the final production for their products.\n"}
{"prompt": "Can you explain the testing and performance testing involved for products with AI models? \n\n###\n\n", "completion": " uuid: 10238582319 Manual testing is involved in the testing phase and then the performance testing is done with scripts that put a lot of load on the system to check the throughput and other factors. There are also test cases for each module which measure code coverage.\n"}
{"prompt": "What external tools are used for internal monitoring? \n\n###\n\n", "completion": " uuid: 10238582319 For internal monitoring, Grafana is used to catch all the logs of Kubernetes Pods and to give a view of memory utilization, CPU utilization and more.\n"}
{"prompt": "What information is provided to customers on the admin dashboard? \n\n###\n\n", "completion": " uuid: 10238582319 The admin dashboard talks about the usage, not the infra level metrics of how the system looks like. It provides information like number of API calls, how much they have burned versus how much they had quota for and so on.\n"}
{"prompt": "Are there any external tools used for ML model monitoring, data monitoring, and experiment tracking? \n\n###\n\n", "completion": " uuid: 10238582319 The company uses ML Flow for their machine learning workloads. However, for data monitoring and experiment tracking, it's all custom-built and stored in databases for later retrieval.\n"}
{"prompt": "What is the company's approach to solving problems around data resiliency, reproducibility, scalability, and data privacy and security? \n\n###\n\n", "completion": " uuid: 10238582319 The company solves problems by controlling the system configurations and allowing for one-click deployment to upscale infra as needed. However, they are still working on making their platform completely scale down to zero when no traffic is present, and making it model agnostic.\n"}
{"prompt": "What mode of engagement does the company use with customers? \n\n###\n\n", "completion": " uuid: 10238582319 The company works in a design partner mode, where they pick up one or two problems that are pressing and work with the customer to build out that feature that can be used by the customer's team. They work together with the customer in a weekly meeting or as needed to understand requirements and timelines.\n"}
{"prompt": "What are the next steps in the engagement process with the company? \n\n###\n\n", "completion": " uuid: 10238582319 The next step is for the customer to view a demo of the company's platform. From there, they will identify synergies and discuss potential NDA agreements before moving forward with any partnership.\n"}
{"prompt": "Why do companies have a multi-cloud environment? \n\n###\n\n", "completion": " uuid: 12361625175 It takes several years to migrate everything and sometimes it's easier to keep a 50-50 split on both clouds.\n"}
{"prompt": "Was this the case at Ross? \n\n###\n\n", "completion": " uuid: 12361625175 The speaker has seen this in at least three big companies, one of which is Roche.\n"}
{"prompt": "How is Roche's approach different from Novartis'? \n\n###\n\n", "completion": " uuid: 12361625175 In Novartis, there is a tool set to be followed, while in Roche, every project has a different tool set.\n"}
{"prompt": "Why was Sage Maker chosen over other tools? \n\n###\n\n", "completion": " uuid: 12361625175 Someone decided to use it three years ago and now people don't want to migrate everything. Additionally, using only one tool helps avoid the need to maintain different tools.\n"}
{"prompt": "Who is the decision maker when it comes to choosing tools? \n\n###\n\n", "completion": " uuid: 12361625175 The speaker does not know and usually people in big companies attribute these decisions to others.\n"}
{"prompt": "Do multi-cloud systems have any benefits for compliance or security? \n\n###\n\n", "completion": " uuid: 12361625175 From a security perspective, it may be difficult to handle, but the speaker is not a security expert.\n"}
{"prompt": "Who is the target user for Proof Only? \n\n###\n\n", "completion": " uuid: 12361625175 ML Ops people, but the speaker suggests targeting data scientists as their user pool is much larger.\n"}
{"prompt": "How can data scientists use Proof Only without deploying anything? \n\n###\n\n", "completion": " uuid: 12361625175 They can use the UI and request deployment without touching AWS as an aspirational option.\n"}
{"prompt": "Can Peter try out Proof Only offline? \n\n###\n\n", "completion": " uuid: 12361625175 Yes, the speaker is willing to try it on his private machine and provide feedback.\n"}
{"prompt": "What is the main concern in regards to having a loss? \n\n###\n\n", "completion": " uuid: 12362155036 The manual work involved in maintaining models, metadata, and everything.\n"}
{"prompt": "What is the desired solution to the concern over manual work? \n\n###\n\n", "completion": " uuid: 12362155036 Having a tool that can automate the maintenance of models, metadata, and everything.\n"}
{"prompt": "What kind of tool is needed to automate maintenance of models? \n\n###\n\n", "completion": " uuid: 12362155036 Any tool that can automate the maintenance of models, metadata, and everything.\n"}
{"prompt": "What are some examples of tools that have already helped in the maintenance of models? \n\n###\n\n", "completion": " uuid: 12362155036 Docker, OCD pipelines.\n"}
{"prompt": "What is the process of building and deploying models in the Merlin team? \n\n###\n\n", "completion": " uuid: 12362155036 Extract data > Build models > Demo models to product manager > Develop API > Input Java integration link > Predictions go back to Java layer > Displayed on UI.\n"}
{"prompt": "How is the Merlin team structure organized? \n\n###\n\n", "completion": " uuid: 12362155036 Based on use cases, AI expertise is not relevant. There are DevOps teams for all five AI teams and they have the same process.\n"}
{"prompt": "What is the process for introducing new technologies in the Merlin team? \n\n###\n\n", "completion": " uuid: 12362155036 Experimentation within the AI team followed by the involvement of DevOps consultants for implementation.\n"}
{"prompt": "Who is responsible for driving engagement with consultants when introducing new technology in the Merlin team? \n\n###\n\n", "completion": " uuid: 12362155036 The DevOps leads.\n"}
{"prompt": "Is the move to Kubernetes only for the ML team or for the entire company? \n\n###\n\n", "completion": " uuid: 12362155036 The move to Kubernetes is for the entire company.\n"}
{"prompt": "What is the typical approach for development? \n\n###\n\n", "completion": " uuid: 12249630284 Start with notebooks and then move forward with different use cases such as microservices, exploratory data analysis, and model training.\n"}
{"prompt": "How do developers handle microservices use cases? \n\n###\n\n", "completion": " uuid: 12249630284 They handle it differently, and don't needed to document it. They rely on exploratory phase perspective.\n"}
{"prompt": "What tools do they use for distributed processing? \n\n###\n\n", "completion": " uuid: 12249630284 They use Spark for distributed processing, and EKS or something like that.\n"}
{"prompt": "How do they store and query data for microservices? \n\n###\n\n", "completion": " uuid: 12249630284 They store data in structured format in Snowflake, so they don't need to write a job as the data is in their data lake. They use a data pipeline for faster and specific data query.\n"}
{"prompt": "What is the usage of notebooks today? \n\n###\n\n", "completion": " uuid: 12249630284 Notebooks are mostly used for training purposes.\n"}
{"prompt": "Are notebooks running over Kubernetes cluster? \n\n###\n\n", "completion": " uuid: 12249630284 Yes, they are running over a Kubernetes cluster.\n"}
{"prompt": "What are the two things that caught their attention? \n\n###\n\n", "completion": " uuid: 12249630284 Jupyter notebook thing and Airflow adoption.\n"}
{"prompt": "How do developers conduct tests on trained models? \n\n###\n\n", "completion": " uuid: 12249630284 Developers use a shadow model approach where they flip the switch when new model performs better. They also use Prometheus and Grafana open source tool for publishing metrics.\n"}
{"prompt": "How do they handle cost perspective with developers using a lot of notebooks? \n\n###\n\n", "completion": " uuid: 12249630284 DevOps team control resource allocation to developers to restrict their memory and CPU usage. Resources are limited by the underlying node and new resources are allocated only when required.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 10038142068 It is primarily to understand the machine learning problems that the company is trying to solve and to get feedback on what they are building at True Foundry.\n"}
{"prompt": "What is One Concern's business model? \n\n###\n\n", "completion": " uuid: 10038142068 One Concern sells the data which they generate from their models at scale to various customers who pay for it through some subscription of the data.\n"}
{"prompt": "What is Truefoundry's focus area? \n\n###\n\n", "completion": " uuid: 10038142068 Truefoundry's focus area is post model pipeline, which is essentially deploying models to production while following best engineering practices like logging, monitoring, and alerting. They also focus on developer experience to meet data scientists in their own toolchain.\n"}
{"prompt": "What are the main concerns that Truefoundry is trying to solve? \n\n###\n\n", "completion": " uuid: 10038142068 They are currently focused on productivity and repeatability of pipelines to ensure they can provide updated data to their customers quickly.\n"}
{"prompt": "Have they explored existing tools in the market for their model and data registry? \n\n###\n\n", "completion": " uuid: 10038142068 They are still in the development phase and have not made a decision yet but may end up using existing tools like ML Flow or build a similar custom solution.\n"}
{"prompt": "What are the systems in place for reverting to a previous version of the model and reproducing results? \n\n###\n\n", "completion": " uuid: 11773896093 Back population systems are in place to facilitate these tasks if necessary.\n"}
{"prompt": "What is the platform that will be overviewed and demonstrated? \n\n###\n\n", "completion": " uuid: 11773896093 The platform is not explicitly named.\n"}
{"prompt": "What is the speaker's job title and what was their previous experience? \n\n###\n\n", "completion": " uuid: 11773896093 The speaker is a machine learning engineer. They previously led a conversational AI team at Facebook where they worked on building machine learning models using that platform at the learner. Their work mostly dealt with NLP, NLU, and ASR.\n"}
{"prompt": "What are the three primary areas when it comes to deployments on the platform? \n\n###\n\n", "completion": " uuid: 11773896093 The three primary areas are services, jobs, and models.\n"}
{"prompt": "What are services in the context of deployment? \n\n###\n\n", "completion": " uuid: 11773896093 Services are long-running API endpoints that can be deployed on the platform.\n"}
{"prompt": "In what ways can the services be deployed? \n\n###\n\n", "completion": " uuid: 11773896093 Services can be deployed as a model API endpoint or as any arbitrary Python code.\n"}
{"prompt": "What are the jobs on the platform? \n\n###\n\n", "completion": " uuid: 11773896093 Jobs are batch inference or model training jobs that run once.\n"}
{"prompt": "How does the platform handle version control for deployments? \n\n###\n\n", "completion": " uuid: 11773896093 All deployments done through the UI are translated to a format that is tracked on a user's GitHub repository. Each deployment version is also associated with that specific deployment.\n"}
{"prompt": "What are some ways that the platform allows for experiments to be tracked and compared? \n\n###\n\n", "completion": " uuid: 11773896093 Experiments can be tracked as tables which include information on metrics and hyperparameters. They can also be compared by checking against each other as well as against older versions.\n"}
{"prompt": "What is the purpose of the model registry? \n\n###\n\n", "completion": " uuid: 11773896093 The model registry holds all the different versions of a model, including metrics and usage with the ability to see schemas and metadata for each.\n"}
{"prompt": "What are some of the differences between the platform and ML Flow's features? \n\n###\n\n", "completion": " uuid: 11773896093 The platform goes beyond what ML Flow can offer, allowing for deploying models directly through an integrated UI, logging plots as artifacts and interactive plots, and real-time model monitoring hierarchically from model summary to raw data.\n"}
{"prompt": "What is an area of interest for the listener that they would like to discuss in a future call? \n\n###\n\n", "completion": " uuid: 11773896093 Monitoring is an area of interest for the listener.\n"}
{"prompt": "What other capabilities does the speaker mention the platform offers besides the primary areas of deployment? \n\n###\n\n", "completion": " uuid: 11773896093 The platform offers an infra allocation layer and compatibility with existing tools.\n"}
{"prompt": "How is Nikonj doing? \n\n###\n\n", "completion": " uuid: 10277539714 Nikonj is doing great.\n"}
{"prompt": "What time is it for Nishan? \n\n###\n\n", "completion": " uuid: 10277539714 It's 10:17 a.m. for Nishan.\n"}
{"prompt": "What is Truefoundry building? \n\n###\n\n", "completion": " uuid: 10277539714 Truefoundry is building an ML platform similar to Facebook's fi learner.\n"}
{"prompt": "What is Branch and what is their primary business? \n\n###\n\n", "completion": " uuid: 10277539714 Branch is a micro lending app-based company primarily operating in African countries and India.\n"}
{"prompt": "What is the role of machine learning in Branch? \n\n###\n\n", "completion": " uuid: 10277539714 Machine learning models are used for loan evaluation, credit scores, and generating offers.\n"}
{"prompt": "Does Branch have a separate data science team? \n\n###\n\n", "completion": " uuid: 10277539714 No, the machine learning team at Branch is responsible for end-to-end work and includes feature creation and analysis.\n"}
{"prompt": "How many models are currently in production at Branch? \n\n###\n\n", "completion": " uuid: 10277539714 At any given time, Branch has roughly 10-12 models in production for different borrower types in four countries.\n"}
{"prompt": "What is the workflow for training and deployment at Branch? \n\n###\n\n", "completion": " uuid: 10277539714 Training happens on Sage Maker and each model is a repository where each branch is a version of the model. Deployment happens on Tactile's clusters, which have endpoint endpoints for different use cases.\n"}
{"prompt": "How does the Truefoundry platform help companies deploy their machine learning models to production? \n\n###\n\n", "completion": " uuid: 11655736739 The Truefoundry platform helps companies quickly deploy their machine learning models to production by building a platform for that purpose. It also helps companies build a developer platform where they can ship their software engineering services quickly to production on top of either multi-cloud environments or so on.\n"}
{"prompt": "What is the structure of Truefoundry's Kubernetes cluster and how is it managed? \n\n###\n\n", "completion": " uuid: 11655736739 Truefoundry's Kubernetes cluster structure consists of creating small units of clusters called namespaces within one cluster, which can also have multiple workspaces. These workspaces can be allocated to different groups of developers, with admins granting user permissions to deploy applications. The cluster is managed by Truefoundry's DevOps team and can also be managed from the UI or CLI.\n"}
{"prompt": "How does Truefoundry handle authentication and credential management for their cloud platforms and docker registries? \n\n###\n\n", "completion": " uuid: 11655736739 Truefoundry uses an internal authentication system for credential management for their cloud platforms and docker registries. Users can connect AWS, ECR, Google Container Registry or whatever is required, and can also connect their git repositories and secret stores like Google Cloud's parameter store.\n"}
{"prompt": "How many clusters and workspaces does Truefoundry currently have, and how much cost is associated with each one? \n\n###\n\n", "completion": " uuid: 11655736739 Truefoundry currently has one cluster which has multiple workspaces within it. The number of workspaces and associated costs for each one will depend on the resources allocated to it. The cost of each workspace is based on the resources being used, such as memory and storage, and will be shown in the UI for each application.\n"}
{"prompt": "Who has permission to deploy applications in Truefoundry's workspaces, and what are the limits on resource allocation? \n\n###\n\n", "completion": " uuid: 11655736739 Permissions to deploy applications are granted by admins who can assign users as editors or viewers depending on their level of access. Resource allocation limits can also be set for each workspace, so users cannot exceed the defined limits. This helps limit costs and prevents users from exceeding the resources available.\n"}
{"prompt": "What can we do if a feature is missing from the platform? \n\n###\n\n", "completion": " uuid: 11942347136 You can let us know and we can actually build it because most of these things will have to build.\n"}
{"prompt": "How does the platform enable quick deployments? \n\n###\n\n", "completion": " uuid: 11942347136 With a code or even with a docker image or anything, you can easily deploy it to a corresponding environment of your choice.\n"}
{"prompt": "What kind of libraries are provided for making it easy to learn? \n\n###\n\n", "completion": " uuid: 11942347136 Python libraries or Python SDKs are provided, generally understood by data scientists, ML engineers, everyone.\n"}
{"prompt": "Are best practices followed automatically by the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Yes, the platform automatically ensures best practices from a security standpoint are taken care of.\n"}
{"prompt": "What sits on top of the team's workflow? \n\n###\n\n", "completion": " uuid: 11942347136 The platform sits on top of whatever your actual team's workflow, whatever your team might be using at IP, if your use currency AWS use currency without creating a separate pipeline.\n"}
{"prompt": "What are the three major parts of the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Connecting to infrastructure, deployment, and resource allocation are the three major parts of the platform.\n"}
{"prompt": "How is deployment done on the platform? \n\n###\n\n", "completion": " uuid: 11942347136 You just click like whatever you want to deploy from a source code, like if you were using Azure, or if you have a docker image, you can directly upload your docker image.\n"}
{"prompt": "What happens when something goes wrong with the system? \n\n###\n\n", "completion": " uuid: 11942347136 Our team will be available, we create like a slack channel or anything that is convenient to you, and all times our team will be available.\n"}
{"prompt": "How is data protected while using the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Only the source limits are stored, no client data, nothing flows to us. Lecture will not have access because it's installed on your cloud, so all data will flow through your cloud. So we don't even have access to it.\n"}
{"prompt": "Can you provide a demonstration of the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Yes, a demo can be scheduled either later this week or early next week, for a detailed understanding.\n"}
{"prompt": "What question does Emily ask about model performance during candidate deployment? \n\n###\n\n", "completion": " uuid: 12336402979 Do you have you you still use the airflow UI for like visualizing let's say they want to know a few metrics regarding the model?\n"}
{"prompt": "How are the metrics regarding models monitored according to Emily? \n\n###\n\n", "completion": " uuid: 12336402979 All the metrics are right to some. Time series database and mostly more online survey monitoring are done through the GRAFANA\n"}
{"prompt": "What is the reason some traditional organizations do not prefer a multi-cloud approach? \n\n###\n\n", "completion": " uuid: 12336402979 Because for all the cloud, if you try to get the bytes data out, you need to pay actual price. This has turned out to be very significant.\n"}
{"prompt": "What is the purpose of the intra management layer according to the speaker? \n\n###\n\n", "completion": " uuid: 12336402979 To abstract away, not only Kubernetes but also any details related to any infrastructure, pretty much from the developer\n"}
{"prompt": "What happens when a developer connects a cluster to the platform? \n\n###\n\n", "completion": " uuid: 12336402979 When they do that, they can provide us the cloud provider. Okay. That okay, I'm running an AWS cluster. Yeah or GCP Azure cluster, anything right?\n"}
{"prompt": "What are the challenges related to supporting existing clusters as per the speaker? \n\n###\n\n", "completion": " uuid: 12336402979 I think that those are some of the barriers that we are currently facing. And that's why we right now say that okay, we will have our own separate cluster\n"}
{"prompt": "What is the ratio of platform developers to ML developers at Quora according to the speaker? \n\n###\n\n", "completion": " uuid: 12336402979 Less than 10 platform developers and about three to four times the platform developers are the ML developers.\n"}
{"prompt": "How is Angel doing? \n\n###\n\n", "completion": " uuid: 12361625221 Good.\n"}
{"prompt": "What is the purpose of the meeting? \n\n###\n\n", "completion": " uuid: 12361625221 To summarize their understanding and walk through the major components needed for the solution.\n"}
{"prompt": "What are the major components needed for the solution? \n\n###\n\n", "completion": " uuid: 12361625221 Architecture perspective, platform design, and APIs that can be used to expose the solution to customers.\n"}
{"prompt": "What is Resolve.ai providing? \n\n###\n\n", "completion": " uuid: 12361625221 Support in their platform that they provide to their SaaS companies.\n"}
{"prompt": "What is the use case provided for Resolve.ai's platform? \n\n###\n\n", "completion": " uuid: 12361625221 For example, a client called Modi uploads their knowledge bases and specific information related to their policies and ticketing system. AI will respond to the queries and if unable to, it goes to an agent.\n"}
{"prompt": "How is the model retrained when a customer uploads their data? \n\n###\n\n", "completion": " uuid: 12361625221 The platform retrain the model and expose it as an endpoint to the customer's data.\n"}
{"prompt": "How is the model loaded and deployed on the platform? \n\n###\n\n", "completion": " uuid: 12361625221 Using Python for serialization and mlFlow to save the models to ONNX format. It is then pushed to the model registry and can be deployed using the provided SDKs.\n"}
{"prompt": "How can a data scientist log in their models? \n\n###\n\n", "completion": " uuid: 12361625221 They can use the provided model registry and SDKs to deploy their models and log parameters as well as datasets.\n"}
{"prompt": "How can a data scientist run their training job? \n\n###\n\n", "completion": " uuid: 12361625221 They can use the provided API and SDKs to run the training job on the cluster.\n"}
{"prompt": "How does the platform handle GPU-based loads? \n\n###\n\n", "completion": " uuid: 12361625221 The cluster administrator must first add a node pool with GPU. The platform uses dynamic node auto-provisioning in AWS and GKE, while pre-adding a node pool with the minimum size set to zero in Azure.\n"}
{"prompt": "What cloud platforms does the company currently support? \n\n###\n\n", "completion": " uuid: 11354403948 AWS, GCP, and Azure.\n"}
{"prompt": "Is on-premises an option for the company? \n\n###\n\n", "completion": " uuid: 11354403948 Yes, they are looking into supporting on-premises due to client demand for air gap environments.\n"}
{"prompt": "What is the company's plan for cloud support? \n\n###\n\n", "completion": " uuid: 11354403948 They want to provide a similar web experience for launching training infrastructure and are considering a no-code experience in the future.\n"}
{"prompt": "What programming environment does the company's cloud support? \n\n###\n\n", "completion": " uuid: 11354403948 Python Jupiter environment hosted on any of the Cloud platforms.\n"}
{"prompt": "What does the company plan to do in terms of deployment space for models? \n\n###\n\n", "completion": " uuid: 11354403948 After focusing on training, they plan to start worrying about the deployment space. They are considering Kubeflow and other solutions.\n"}
{"prompt": "How big is the team currently working on creating the platform? \n\n###\n\n", "completion": " uuid: 11354403948 The engineering team has about ten people.\n"}
{"prompt": "Does the company have any full-time data scientists on their team? \n\n###\n\n", "completion": " uuid: 11354403948 No, the data scientists are more on the customer solution team and collaborate closely together to build tools for support.\n"}
{"prompt": "What is the company's vision for their platform? \n\n###\n\n", "completion": " uuid: 11354403948 They want to simplify the experience for data scientists, developers, and clients by abstracting the complexities that a data scientist is usually not familiar with and providing a one-stop solution for everything post-model training till deployment.\n"}
{"prompt": "What does the company want to offer for model deployment? \n\n###\n\n", "completion": " uuid: 11354403948 The company wants to offer support for serving models through model servers, creating fast API endpoints, and creating Cron jobs or dual jobs for it.\n"}
{"prompt": "Is the company open to collaboration with the Truefoundry team? \n\n###\n\n", "completion": " uuid: 11354403948 Yes, they are open to collaborating with the Truefoundry team and would love to schedule a demo to discuss further.\n"}
{"prompt": "What link are they referring to? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What is the name of the dock that they are discussing? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What is the thing they just put on WhatsApp? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "When will they put their five minutes back? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What report did they find? \n\n###\n\n", "completion": " uuid: 12249630284 Multicloud report\n"}
{"prompt": "Who did they thank for tips on Telegram? \n\n###\n\n", "completion": " uuid: 12249630284 Muthu\n"}
{"prompt": "What did the tips on Telegram help the person achieve? \n\n###\n\n", "completion": " uuid: 12249630284 Visa for Singapore\n"}
{"prompt": "What was the advice that people gave the person about applying for a visa in Singapore? \n\n###\n\n", "completion": " uuid: 12249630284 Not to risk it as they were going to India anyway\n"}
{"prompt": "What did the person do instead of going to Singapore for a visa? \n\n###\n\n", "completion": " uuid: 12249630284 Applied through Telegram groups and got slots in 2023\n"}
{"prompt": "Where is the person currently located? \n\n###\n\n", "completion": " uuid: 12249630284 Bay Area\n"}
{"prompt": "Who welcomed Muthu on board and to what? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What hypothesis are they trying to learn about? \n\n###\n\n", "completion": " uuid: 12249630284 Whether their platform can serve the needs of companies deploying across multiple clouds\n"}
{"prompt": "What specific domain is Balbix in? \n\n###\n\n", "completion": " uuid: 12249630284 Cybersecurity quantification domain\n"}
{"prompt": "What are the targets for companies that Balbix is interested in? \n\n###\n\n", "completion": " uuid: 12249630284 Companies with a minimum requirement of 15,000 devices\n"}
{"prompt": "What ML platform does Truefoundry deal with? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "How many clouds is Truefoundry serving currently? \n\n###\n\n", "completion": " uuid: 12249630284 Three clouds\n"}
{"prompt": "What was the focus of the team in the last year? \n\n###\n\n", "completion": " uuid: 12249630284 Data platform and operationalization of machine learning\n"}
{"prompt": "What is the current process of deployment for training? \n\n###\n\n", "completion": " uuid: 12249630284 Train models in GPU node and store in the history packets\n"}
{"prompt": "What was Airflow used for? \n\n###\n\n", "completion": " uuid: 12249630284 Jobs and orchestration of work\n"}
{"prompt": "What graph database are they using? \n\n###\n\n", "completion": " uuid: 12249630284 Neo4J\n"}
{"prompt": "What is next on their list for deployment? \n\n###\n\n", "completion": " uuid: 12249630284 Jupyter Hub\n"}
{"prompt": "How do developers currently run notebooks? \n\n###\n\n", "completion": " uuid: 12249630284 Through GPU node and access from local host\n"}
{"prompt": "Do developers submit jobs as scripts or through notebooks? \n\n###\n\n", "completion": " uuid: 12249630284 Both\n"}
{"prompt": "What was the trigger for starting True Foundry? \n\n###\n\n", "completion": " uuid: 11942346630 They realized that operationalization of machine learning models was hard and they saw the state-of-the-art system at Facebook.\n"}
{"prompt": "How does True Foundry see itself in relation to platform teams within large companies? \n\n###\n\n", "completion": " uuid: 11942346630 True Foundry sees itself as an ally to platform teams within large companies.\n"}
{"prompt": "What are the different stakeholders that a platform team typically deals with, and what are their requirements? \n\n###\n\n", "completion": " uuid: 11942346630 A platform team typically deals with data scientists, machine learning engineers, and business decision makers, and their requirements differ depending on their technical maturity.\n"}
{"prompt": "What is True Foundry's solution to the challenges that platform teams face? \n\n###\n\n", "completion": " uuid: 11942346630 True Foundry is building a platform on top of which other platform teams can build, with layers that interface with their own stakeholders and handle under the hood plumbing.\n"}
{"prompt": "What is the specific problem that True Foundry is trying to solve? \n\n###\n\n", "completion": " uuid: 11942346630 True Foundry is trying to solve the problem of building a platform that is generic enough to serve all stakeholders of a platform team, without requiring them to build everything from scratch.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12150845733 The purpose of the call is to learn from the experience of CBS and understand the state of machine learning at their company.\n"}
{"prompt": "What is Crew Foundry? \n\n###\n\n", "completion": " uuid: 12150845733 Crew Foundry is a startup founded by Rag, Abhishek, and Bibik with the goal of building a machine learning platform to simplify the process of model deployment and monitoring.\n"}
{"prompt": "What type of models is the CVS team building? \n\n###\n\n", "completion": " uuid: 12150845733 The CVS team is focusing on automating claim processing for their healthcare insurance unit using computer vision and NLP.\n"}
{"prompt": "Does the CVS team use outside vendors for document processing? \n\n###\n\n", "completion": " uuid: 12150845733 Yes, the CVS team uses a vendor called Conduent to handle the manual processing of documents received through physical mail.\n"}
{"prompt": "What is the differentiation of Crew Foundry's platform compared to what is already available, such as Azure or GCP? \n\n###\n\n", "completion": " uuid: 12150845733 Crew Foundry differentiates itself through potential customization for companies and working on supporting current use cases. They are also focusing on monitoring and surveillance of models once deployed.\n"}
{"prompt": "What types of models is the CVS team building? \n\n###\n\n", "completion": " uuid: 12150845733 The CVS team is focusing on automating claim processing for their healthcare insurance unit using computer vision and NLP.\n"}
{"prompt": "What is the team structure for machine learning at CBS? \n\n###\n\n", "completion": " uuid: 12150845733 There is a central SVP who manages both the Data Science and Data Engineering team, which serves the entire company. Data Science builds the models while Data Engineering supports deployment and maintenance of the models.\n"}
{"prompt": "What is the primary focus of the models being built by the CVS team? \n\n###\n\n", "completion": " uuid: 12150845733 The primary focus is on optimizing operations and cost savings through automating claim processing.\n"}
{"prompt": "Does the CVS team use A/B testing for real-time models as well as batch models? \n\n###\n\n", "completion": " uuid: 12150845733 Yes, the CVS team uses A/B testing for both real-time and batch models in order to create control groups and monitor model performance.\n"}
{"prompt": "What has changed in the dynamic between data scientists and ML engineers over time? \n\n###\n\n", "completion": " uuid: 11487646267 Data scientists needed less and less help from ML engineers as they became more mature\n"}
{"prompt": "What was the hard part of putting data jobs into production? \n\n###\n\n", "completion": " uuid: 11487646267 Serving layer, API changes, and ensuring platform resources could support the model\n"}
{"prompt": "What specific task did data scientists need to verify before putting models into production? \n\n###\n\n", "completion": " uuid: 11487646267 Ensuring the real time production features were the same as the features used to train the model\n"}
{"prompt": "What framework does the team use for TensorFlow models? \n\n###\n\n", "completion": " uuid: 11487646267 They use the TensorFlow serving framework\n"}
{"prompt": "How many people are on the platform team? \n\n###\n\n", "completion": " uuid: 11487646267 Roughly 6 people are on the platform team\n"}
{"prompt": "What is a key challenge the team is facing with onboarding data scientists? \n\n###\n\n", "completion": " uuid: 11487646267 Making it easy to onboard data scientists onto the platform and reducing the need for MLE involvement\n"}
{"prompt": "Is the team currently using any monitoring for models in production? \n\n###\n\n", "completion": " uuid: 11487646267 They have some qualitative monitoring available but it's not fully matured as a standard platform feature\n"}
{"prompt": "What experience does Avishek bring to Truefoundry? \n\n###\n\n", "completion": " uuid: 11655736677 Avishek led the software engineering and infrastructure side of things at Facebook for almost six years.\n"}
{"prompt": "What was the author's previous work experience? \n\n###\n\n", "completion": " uuid: 11655736677 The author used to work with a hedge fund called World Fund, doing a lot of algorithmic trading and investment across different asset classes.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 11655736677 The goal of Truefoundry is to enable every company to be an ML led company by providing a platform that speeds up the deployment of machine learning models.\n"}
{"prompt": "What challenges does Truefoundry solve for data science teams? \n\n###\n\n", "completion": " uuid: 11655736677 Truefoundry solves the challenges of democratizing the development of machine learning models along with testing, speeding up developer workflows, and providing flexibility through Python, SDKs, and other libraries.\n"}
{"prompt": "What does Truefoundry's platform provide for data science teams? \n\n###\n\n", "completion": " uuid: 11655736677 The platform provides independence and flexibility through Python, SDKs, and other libraries, full security and control for the infrastructure, and monitoring for model performance and debugging.\n"}
{"prompt": "What is the value of Truefoundry's platform for big tech companies? \n\n###\n\n", "completion": " uuid: 11655736677 Big tech companies can see improvement in their overall process efficiency by 30% to 40% and additional revenues being generated in the range of 10% by investing in internal platform teams that accelerate the time to value of ML projects.\n"}
{"prompt": "What is the purpose of the follow-up with the team? \n\n###\n\n", "completion": " uuid: 11655736677 The purpose of the follow-up is to understand the team's use cases and workflow and present potential useful features of Truefoundry's platform as well as potentially do a small pilot to add value to the team.\n"}
{"prompt": "What does the author hope to achieve through an investment in Truefoundry? \n\n###\n\n", "completion": " uuid: 11655736677 The author hopes to have good leaders who can be a part of their journey and take help of their network and guidance to build a really good global SaaS platform.\n"}
{"prompt": "What is the major difference between lenders like Credibly versus lenders like Chad or MX? \n\n###\n\n", "completion": " uuid: 10128442512 Lenders like Credibly target subprime customers who cannot get loans from banks and charge higher interest rates whereas banks are highly selective and cater to mostly prime customers with lower interest rates.\n"}
{"prompt": "What is Credibly's business model? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly is a fintech company in the commercial lending space and provides loans and MCAs to small medium owners digitally.\n"}
{"prompt": "How does Credibly acquire customers? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly acquires customers through external agents or brokers who bring in subprime customers that the banks cannot cater to.\n"}
{"prompt": "What is the challenge in customer acquisition for lenders like Credibly? \n\n###\n\n", "completion": " uuid: 10128442512 The challenge is that subprime customers generally do not have a good web presence and conventional marketing channels like email, physical emails, and phone calls need to be utilized.\n"}
{"prompt": "What is hybrid underwriting process for Credibly? \n\n###\n\n", "completion": " uuid: 10128442512 It is a combination of automation using robots and manual underwriting or human decision making.\n"}
{"prompt": "What kind of data parsing is required in the underwriting process for commercial loans? \n\n###\n\n", "completion": " uuid: 10128442512 Parsing of application data, external sources such as credit bureau, web data, social media data, and public report data from the Secretary of the State, and financial information such as bank statements and tax returns.\n"}
{"prompt": "What kind of signals are picked up from the bank statement data in the underwriting process for commercial loans? \n\n###\n\n", "completion": " uuid: 10128442512 Consistency in revenue generation, any bad signals such as negative days or overdraft fees, and changes in deposits.\n"}
{"prompt": "What kind of signals can be picked up from social media data in the underwriting process for commercial loans? \n\n###\n\n", "completion": " uuid: 10128442512 It varies depending on the industry, but for example, good social media presence may be important for restaurants or other consumer-facing businesses that rely on customer reviews and ratings.\n"}
{"prompt": "What is the goal of the ML developers platform? \n\n###\n\n", "completion": " uuid: 11655737135 To provide a value add to the business team and make ML developers faster while saving on the cost of building and maintaining.\n"}
{"prompt": "What are the main differentiators of the platform from existing solutions? \n\n###\n\n", "completion": " uuid: 11655737135 The platform is built deeply for the developers, with multiple interfaces for deployment depending on the developer's comfort level, and aims to unify the machine learning deployment process with software deployment process, following the same principles that are followed in software engineering. In addition, the platform aims to make custom plugins building simple and easy.\n"}
{"prompt": "Who is the target customer of the platform? \n\n###\n\n", "completion": " uuid: 11655737135 The platform targets both data scientists and machine learning engineers, as the platform is built to meet the skill sets of both and the belief that both will likely use the platform for production use cases.\n"}
{"prompt": "What are the three parts of the ML platform? \n\n###\n\n", "completion": " uuid: 11655737135 The platform has an intra-team interface for creating a secure environment, a developer-exposed interface for deploying services and jobs, a monitoring interface to track performance and detect issues.\n"}
{"prompt": "What are the three types of deployments you can do on the platform? \n\n###\n\n", "completion": " uuid: 11655737135 You can deploy a model, a service, or a job on the platform.\n"}
{"prompt": "What is the metrics visualization process for performance monitoring? \n\n###\n\n", "completion": " uuid: 11655737135 The metrics visualization process in the performance monitoring dashboard includes a hierarchical overview of model performance, with the ability to compare metrics across different time windows and track subsets of data with different log losses to debug model performance issues.\n"}
{"prompt": "How are you? \n\n###\n\n", "completion": " uuid: 10097841502 I'm good, how are you doing?\n"}
{"prompt": "May I record this? \n\n###\n\n", "completion": " uuid: 10097841502 Yeah, please.\n"}
{"prompt": "What is the goal of talking to companies in the machine learning domain? \n\n###\n\n", "completion": " uuid: 10097841502 To try and see what the use cases are and what kind of challenges they have been facing.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 10097841502 To make machine learning productionization simple and easy for companies to deploy ML models.\n"}
{"prompt": "What does Simpler do? \n\n###\n\n", "completion": " uuid: 10097841502 Simpler is an employee experience company that facilitates communication within organizations and provides insights to leadership based upon employees' conversations.\n"}
{"prompt": "What channels is Simpler connected to? \n\n###\n\n", "completion": " uuid: 10097841502 Simpler is connected to Slack, Confluence, Jira, Atlassian products, Microsoft Teams, and Google Drive.\n"}
{"prompt": "Where does the AI team get all the data? \n\n###\n\n", "completion": " uuid: 10097841502 The AI team gets all the data on Salesforce and then the data is aggregated onto Snowflake for experimentation and building model stuff.\n"}
{"prompt": "What kind of infrastructure does Simpler use for training the models? \n\n###\n\n", "completion": " uuid: 10097841502 Simpler uses AWS instances and GPUs for training the models.\n"}
{"prompt": "Do you use any models server to run your models? \n\n###\n\n", "completion": " uuid: 10097841502 No, we are exploring triton but we haven't adopted it at scale. Most of our models are consumed by APIs that are deployed on EKS, so Kubernetes, and we have Auto scaling enabled.\n"}
{"prompt": "What is the biggest challenge that Simpler's AI team is facing? \n\n###\n\n", "completion": " uuid: 10097841502 The biggest challenge is the combination of scalability and monitoring, specifically how to deploy 400 models, monitor the quality of these models, and have alert mechanisms to tell the team where there is a need to work upon.\n"}
{"prompt": "Who is Mike Boufford? \n\n###\n\n", "completion": " uuid: 10881877574 Unknown\n"}
{"prompt": "Who is the CTO of Greenhouse? \n\n###\n\n", "completion": " uuid: 10881877574 Unknown\n"}
{"prompt": "What is the speaker's experience working with startups? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker is still working with startups.\n"}
{"prompt": "What is the speaker's view on innovation? \n\n###\n\n", "completion": " uuid: 10881877574 Innovation happens when there are different problems and the speaker needs to talk to new people to understand those problems.\n"}
{"prompt": "What is the speaker's view on the future of machine learning? \n\n###\n\n", "completion": " uuid: 10881877574 Adoption of machine learning is contingent on how easy it is and it is going to happen. It is important to make it 100x easier for mass adoption.\n"}
{"prompt": "What are some of the lessons the speaker learned from Facebook? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker learned that Facebook had different tools built out for each part of the ML development lifecycle, deployment was done seamlessly and parallel computation should be used to solve resource allocation problems.\n"}
{"prompt": "What simple tweak did Facebook do to reduce unnecessary computing costs? \n\n###\n\n", "completion": " uuid: 10881877574 Facebook showed developers the cost of each training run, which made them more conscious of their computing usage.\n"}
{"prompt": "How did the speaker and their team incorporate lessons learned from Facebook into their platform? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker and their team are trying to incorporate Facebook's lessons one by one into their platform.\n"}
{"prompt": "What kind of experience is the speaker trying to build for developers? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker is trying to build a more developer-friendly experience.\n"}
{"prompt": "How did the speaker schedule a call with the person they were speaking with? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker shared their calendar link and will email the person to set up a call with RC together.\n"}
{"prompt": "What was causing pain points with deploying ML models to Kubernetes? \n\n###\n\n", "completion": " uuid: 11575824756 The approach being used for other types of applications was being used to deploy ML models.\n"}
{"prompt": "What was the previous approach used to deploy ML models? \n\n###\n\n", "completion": " uuid: 11575824756 Models were packaged into Jupiter notebooks and then handed off to someone who would create a PY file and understand the code.\n"}
{"prompt": "Why was the previous approach problematic? \n\n###\n\n", "completion": " uuid: 11575824756 Assumptions were made in the notebook that were not necessarily true in the production or development environment, causing problems and requiring extensive diagnosis.\n"}
{"prompt": "What is the current approach to deploying ML models? \n\n###\n\n", "completion": " uuid: 11575824756 Using a clean API to handle preprocessing, inference, and post processing, with a library approach and a very organized and fast process.\n"}
{"prompt": "Where are the fitted model artifacts being stored? \n\n###\n\n", "completion": " uuid: 11575824756 The artifacts are being stored using the ML Flow model registry and stored on S3 backend.\n"}
{"prompt": "How often are models in production updated? \n\n###\n\n", "completion": " uuid: 11575824756 Not very frequently - the models are only updated if there is an issue and are driven by client feedback.\n"}
{"prompt": "What is the main challenge currently faced in model monitoring? \n\n###\n\n", "completion": " uuid: 11575824756 Lack of a solution for monitoring and being very reactive, not proactive, in detecting drift.\n"}
{"prompt": "What is the current strategy for monitoring model performance? \n\n###\n\n", "completion": " uuid: 11575824756 Doing batch audits every so often to track accuracy and F1 scores.\n"}
{"prompt": "What are the current top challenges being addressed? \n\n###\n\n", "completion": " uuid: 11575824756 Monitoring and deploying ML models effectively, and finding the right workflow and solutions to address these challenges.\n"}
{"prompt": "Why is Groundspeed looking for external monitoring solutions? \n\n###\n\n", "completion": " uuid: 11575824756 Assumption that there are great tools out there already, and it might not make sense to build internal tools for model monitoring.\n"}
{"prompt": "What does the speaker mention about provisioning clusters? \n\n###\n\n", "completion": " uuid: 11488124534 They provide clusters as needed.\n"}
{"prompt": "Has the team considered using AWS, Sage Maker, or Azure ML for ML operations? \n\n###\n\n", "completion": " uuid: 11488124534 Yes, they have considered using Azure ML, but primarily for training.\n"}
{"prompt": "What was the main reason to move from Azure ML to Databricks? \n\n###\n\n", "completion": " uuid: 11488124534 The requirement that the data does not leave basically a VPC as Azure required the use of a remote desktop or remote shell to hop into the VPC.\n"}
{"prompt": "Has the team evaluated Sage Maker? \n\n###\n\n", "completion": " uuid: 11488124534 No, they have not evaluated Sage Maker.\n"}
{"prompt": "Were you part of the decision-making process to deploy on Kubernetes rather than a managed ML Ops platform? \n\n###\n\n", "completion": " uuid: 11488124534 No, the decision predated the speaker's involvement.\n"}
{"prompt": "How many test cases does the team write for their models? \n\n###\n\n", "completion": " uuid: 11488124534 Probably not as many as they should.\n"}
{"prompt": "What area stands out frequently as a challenge for model monitoring? \n\n###\n\n", "completion": " uuid: 11488124534 Monitoring is an area that stands out frequently.\n"}
{"prompt": "Will Carlos be open to spending some time going through a platform demo and giving feedback? \n\n###\n\n", "completion": " uuid: 11488124534 Yes, Carlos agrees to spend some time going through the platform demo and giving feedback.\n"}
{"prompt": "Do the team members work mostly remotely or from the office? \n\n###\n\n", "completion": " uuid: 11488124534 They work mostly from home, but have scheduled office visits.\n"}
{"prompt": "Does the office remain empty throughout the year? \n\n###\n\n", "completion": " uuid: 11488124534 No, the office is reserved throughout the year, but more people are coming back.\n"}
{"prompt": "Where is the person based? \n\n###\n\n", "completion": " uuid: 12428091030 The person is based in Canada.\n"}
{"prompt": "How long have they been in Canada? \n\n###\n\n", "completion": " uuid: 12428091030 They have been in Canada for almost six years.\n"}
{"prompt": "What is the goal of the call? \n\n###\n\n", "completion": " uuid: 12428091030 The goal of the call is to understand more about the company's data science initiatives, use cases and structure, the tools they use, key priorities, and any challenges they are experiencing.\n"}
{"prompt": "Who are the co-founders of Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 The co-founders of Truefoundry are Rogue, Abishek and Nikonju.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 The goal of Truefoundry is to help companies in their journey of machine learning operationalization.\n"}
{"prompt": "What internal system did Facebook build that inspired Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 Facebook built an internal system called Bill on Earth which allowed ML developers to be quite independent and abstracted out many pieces of infrastructure.\n"}
{"prompt": "What previous experience does the speaker have? \n\n###\n\n", "completion": " uuid: 12428091030 The speaker worked for six years with a hedge fund, using data to build trading strategies and also did portfolio management for worldwide.\n"}
{"prompt": "How many people are on the ML team at Son of C? \n\n###\n\n", "completion": " uuid: 12428091030 The ML team at Son of C has grown to almost 350 people.\n"}
{"prompt": "What tool stack do they use? \n\n###\n\n", "completion": " uuid: 12428091030 They use Eks for provisioning resources, Kubernetes and Terraform for deployment, Snowflake for data storage and Selden for logging model metrics.\n"}
{"prompt": "Who is responsible for deploying the models? \n\n###\n\n", "completion": " uuid: 12428091030 The ML engineering team is responsible for deploying the models.\n"}
{"prompt": "What question did Stevetha ask first? \n\n###\n\n", "completion": " uuid: 11185249632 How are you?\n"}
{"prompt": "What did Stevetha ask next and what was the response? \n\n###\n\n", "completion": " uuid: 11185249632 Stevetha asked if Sivasa could see them and Sivasa responded that he couldn't see them yet.\n"}
{"prompt": "Who did Sivasa say was with him and what was his role? \n\n###\n\n", "completion": " uuid: 11185249632 Sivasa said Vishak was with him and he was a hands-on data scientist who was an AutoML platform's hands-on practitioner perspective also.\n"}
{"prompt": "What is the goal of Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11185249632 The goal of Truefoundry platform is to build a platform for enabling companies to test out and deploy models seamlessly.\n"}
{"prompt": "What kind of problems and use cases does Maverick deal with? \n\n###\n\n", "completion": " uuid: 11185249632 Maverick deals with problems around banking, including predicting default for loans, predicting home prices in the US, cross-sell and up-sell for customers, and marketing analytics for wealth management firms.\n"}
{"prompt": "What AutoML platform does Maverick primarily use? \n\n###\n\n", "completion": " uuid: 11185249632 Maverick primarily uses Data IQ for its AutoML platform.\n"}
{"prompt": "How does Data IQ handle preprocessing and postprocessing functions? \n\n###\n\n", "completion": " uuid: 11185249632 Data IQ has recipes for transformations and can handle preprocessing and postprocessing functions.\n"}
{"prompt": "What is the size of the ML team at Maverick? \n\n###\n\n", "completion": " uuid: 11185249632 The ML team at Maverick is about 40-45 people, including data analysts and table specialists, while the data validation team is around 150 people and the rest is made up of ETL, data engineering, and other staff.\n"}
{"prompt": "What is the revenue of Data IQ? \n\n###\n\n", "completion": " uuid: 11185249632 Data IQ is a $100 million revenue company with global customers and is the second-largest AutoML platform.\n"}
{"prompt": "What event is the speaker logging in from their mobile for? \n\n###\n\n", "completion": " uuid: 11354392663 They are logging into a search event.\n"}
{"prompt": "Why is the speaker not able to connect to the internet? \n\n###\n\n", "completion": " uuid: 11354392663 The speaker is not able to connect to the internet due to some issue.\n"}
{"prompt": "Who is the co-founder of the company that is mentioned in the conversation? \n\n###\n\n", "completion": " uuid: 11354392663 The co-founder of the company mentioned in the conversation is Anurag.\n"}
{"prompt": "What is the goal of True Foundry? \n\n###\n\n", "completion": " uuid: 11354392663 The goal of True Foundry is to make it easy for data scientists and ML engineers to take their machine learning models to production.\n"}
{"prompt": "What tools do the data scientists use for prototyping? \n\n###\n\n", "completion": " uuid: 11354392663 The data scientists use XGBoost and PyTorch for prototyping.\n"}
{"prompt": "How do they extract information from the patient chart? \n\n###\n\n", "completion": " uuid: 11354392663 They use NLT to extract specific data points from massive clinical documents.\n"}
{"prompt": "What kind of monitoring platform do they have? \n\n###\n\n", "completion": " uuid: 11354392663 They have an internal monitoring platform where they maintain a representative test set that is curated with time.\n"}
{"prompt": "What kind of models do they deploy and where? \n\n###\n\n", "completion": " uuid: 11354392663 They deploy different kinds of models and use them in production. They don't have extensive feature stores and they load the text either directly from Elastic. They deploy on EC2 machines and are currently piloting with Databricks.\n"}
{"prompt": "What type of web server generally works better? \n\n###\n\n", "completion": " uuid: 12249609647 Right border server generally work better.\n"}
{"prompt": "Have you heard of thoughts of anything along those banks? \n\n###\n\n", "completion": " uuid: 12249609647 Not at the moment, I would be very open and frank here.\n"}
{"prompt": "What are the challenges that you see with respect to this entire model frameworks? \n\n###\n\n", "completion": " uuid: 12249609647 Currently, there is some transition going on, and unfortunately, I have decided to move on. So, in that case, I think challenges and everything maybe it will be better for you guys, you know, discuss with the one who will take it over from there.\n"}
{"prompt": "Will all the problems be prioritized at the same time? \n\n###\n\n", "completion": " uuid: 12249609647 No, the ones which are priority in terms of the business outcomes will be prioritized over everything that I mentioned.\n"}
{"prompt": "Have you decided where you are going? \n\n###\n\n", "completion": " uuid: 12249609647 Some options. I still need to figure out the best possible from there.\n"}
{"prompt": "Who is going to take over your old position? \n\n###\n\n", "completion": " uuid: 12249609647 Currently, not somebody from my role for sure. It's going to be somebody within the team who is just a, you know, data science types.\n"}
{"prompt": "What does True Foundry focus on? \n\n###\n\n", "completion": " uuid: 12249609647 True Foundry comes at the model level. So, we don't deal too much with the data and feature engineering side of things. We do deal with model and beyond Basically, okay?\n"}
{"prompt": "What is the main thing that True Foundry is solving for? \n\n###\n\n", "completion": " uuid: 12249609647 The main thing that we are solving for is obstructing away infrastructure in a data science, friendly using data science.\n"}
{"prompt": "What can you do once you put a model to production using the True Foundry platform? \n\n###\n\n", "completion": " uuid: 12249609647 Once you put a model to production using the platform, you can also get very quick monitoring model monitoring and data drift dashboards as well.\n"}
{"prompt": "What is the objective of True Foundry? \n\n###\n\n", "completion": " uuid: 12249609647 The main thing that we are solving for is obstructing away infrastructure in a data science, friendly using data science, Friendly APIs essentially.\n"}
{"prompt": "Are you able to quickly deploy the model without making the data scientists deal with infrastructure? \n\n###\n\n", "completion": " uuid: 12249609647 Yes, technically a data scientist could get an API endpoint directly from the Jupiter notebook.\n"}
{"prompt": "What are some areas that True Foundry is working on? \n\n###\n\n", "completion": " uuid: 12249609647 We would love to show the product demo as well to you and get some more concrete feedback at some point. So, those are the areas that we are working on.\n"}
{"prompt": "Are you going to continue to work in data science? \n\n###\n\n", "completion": " uuid: 12249609647 Yeah, I'm into data science. Only I generally like to build products in data science data related products, basically I generally not get biased by ML only stuff.\n"}
{"prompt": "What is your mental model of True Foundry? \n\n###\n\n", "completion": " uuid: 12249609647 If you think about the data scientist journey from licking building a model, right from left to right? So they typically spend a lot of time and data and feature, engineering and then model training, hyper parameter tuning deployment of the model and monitoring of the model. So true foundry comes at the model level basically.\n"}
{"prompt": "What are the stages that TrueFoundry helps people with in relation to models? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry helps people with the training deployment and the monitoring stages of the model.\n"}
{"prompt": "What is the purpose of the platform that TrueFoundry provides? \n\n###\n\n", "completion": " uuid: 11942346630 The platform that TrueFoundry provides is a place where data scientists or an ML developer can come run experiments on which model works the best.\n"}
{"prompt": "What is TrueFoundry's approach towards deployment? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry covers a wide range in terms of deployment and pays special attention towards different types of deployment like time-sensitive and offline batch inference kind of things.\n"}
{"prompt": "What is the closing the loop part that TrueFoundry handles? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry handles the closing the loop part, which is monitoring the model so that when it starts underperforming, it can be known very quickly.\n"}
{"prompt": "What is the core differentiator of TrueFoundry compared to other platforms? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry is designed to work with existing systems, which means that it fits in well with existing components and only solves parts of the problem that are important.\n"}
{"prompt": "What is one platform that TrueFoundry works well with? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry works well with Databricks because Databricks focuses on the offline and batch inferencing side of things, whereas TrueFoundry's strength is on the real-time inferencing side of things.\n"}
{"prompt": "What is the time frame discussed for a follow-up demonstration of the platform? \n\n###\n\n", "completion": " uuid: 11942346630 The time frame discussed for a follow-up demonstration of the platform is mid-fab. A time will be arranged between Robbie and the other party.\n"}
{"prompt": "What does the speaker ask when they first connect with George? \n\n###\n\n", "completion": " uuid: 11942287761 Hey, can you hear me?\n"}
{"prompt": "What is the response given by George? \n\n###\n\n", "completion": " uuid: 11942287761 Yes, I can hear you.\n"}
{"prompt": "What is the purpose of the companion mode that they discuss? \n\n###\n\n", "completion": " uuid: 11942287761 To join both audio and video from the phone and laptop.\n"}
{"prompt": "What is George's background and where did he work before Soroco? \n\n###\n\n", "completion": " uuid: 11942287761 He has a PhD in Computer Science from Carnegie Mellon and previously worked at Harvard.\n"}
{"prompt": "What is Soroco's goal and how do they achieve it? \n\n###\n\n", "completion": " uuid: 11942287761 To help organizations understand how work gets done and they do it by collecting digital interactions that happen between individuals.\n"}
{"prompt": "How do Soroco's machine learning models help improve business processes? \n\n###\n\n", "completion": " uuid: 11942287761 By allowing organizations to understand where inefficiencies are in the process.\n"}
{"prompt": "What is the size of Soroco's team? \n\n###\n\n", "completion": " uuid: 11942287761 The team size is between five to ten.\n"}
{"prompt": "How does Soroco ensure consistency between their training and serving code? \n\n###\n\n", "completion": " uuid: 11942287761 They ensure the version of the product and the pipeline that basically takes the data, preprocesses, etc., is all lined up with the model that will ship in production.\n"}
{"prompt": "Do Soroco use Kubernetes? \n\n###\n\n", "completion": " uuid: 11942287761 Yes.\n"}
{"prompt": "What is the purpose of Truefoundry and how does it work? \n\n###\n\n", "completion": " uuid: 11942287761 The speaker will share an overview of what Troop Onto is doing, where they are, and what are the next steps they can decide.\n"}
{"prompt": "Can you hear me okay? \n\n###\n\n", "completion": " uuid: 11773896093 Yeah, I can hear you.\n"}
{"prompt": "Can you see me? \n\n###\n\n", "completion": " uuid: 11773896093 Yeah, I can.\n"}
{"prompt": "What happened when the video did not load? \n\n###\n\n", "completion": " uuid: 11773896093 Yusuf disconnected and rejoined to figure out the problem.\n"}
{"prompt": "What was the goal of the meeting with Yusuf? \n\n###\n\n", "completion": " uuid: 11773896093 To get feedback on his ML pipeline, challenges, use cases, and infrastructure and to get to know him better.\n"}
{"prompt": "What is Yusuf's background? \n\n###\n\n", "completion": " uuid: 11773896093 Co-founder and CEO of Truefoundry, worked at Facebook in conversational AI, was leading the ML team at a startup called Reflection, did a masters at UC Berkeley and undergrad at an IT school in India.\n"}
{"prompt": "What type of work does Yusuf do now? \n\n###\n\n", "completion": " uuid: 11773896093 Building a platform to enable other companies to build, deploy and monitor their models faster.\n"}
{"prompt": "What is Pay You and what does Yusuf lead there? \n\n###\n\n", "completion": " uuid: 11773896093 Pay You is a lending business, Yusuf leads the credit side of the business.\n"}
{"prompt": "What is the team size of Yusuf's machine learning team? \n\n###\n\n", "completion": " uuid: 11773896093 Around 40-45 people including data science team.\n"}
{"prompt": "What cloud provider does Yusuf's team use? \n\n###\n\n", "completion": " uuid: 11773896093 AWS.\n"}
{"prompt": "Does the team use Sage Maker? \n\n###\n\n", "completion": " uuid: 11773896093 Initially they did, but stopped using it.\n"}
{"prompt": "How long does it take to deploy a model? \n\n###\n\n", "completion": " uuid: 11773896093 It depends on many factors such as fintech audit approvals, feature pipelines, etc., but once all systems are in place, it should not take more than a week or two weeks.\n"}
{"prompt": "How does the team request for infrastructure/resources? \n\n###\n\n", "completion": " uuid: 11773896093 They ask DevOps and they do it for them.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 10777412370 In the context of the startup that you're building, the purpose of the call was to understand IBM spending a lot of time talking to practitioners, understanding their current workflows, how are they building and deploying models today and where do they see that there are currently some gaps that exist in the workflows.\n"}
{"prompt": "What is Shane's background? \n\n###\n\n", "completion": " uuid: 10777412370 Shane comes from a machine learning background. Prior to starting Truefoundry, he was at Facebook where he was leading one of the conversational AI efforts. Before that, he worked quite extensively in the e-commerce domain.\n"}
{"prompt": "What kind of interactions does Shane want to do directly from their desktop? \n\n###\n\n", "completion": " uuid: 10777412370 Shane wants to build their training algorithm in VS code and then fire it off and say 'run training' that goes up and specifies certain instance sizes with specific input and output locations, creating the artifacts and pushing them into s3 in one seamless way.\n"}
{"prompt": "What is productionizing? \n\n###\n\n", "completion": " uuid: 10777412370 Productionizing basically means deploying the training job somewhere, mostly for them, it will be probably AWS Airflow, which will continuously keep on training while also productionizing their inferences so that every day they take their model, package it into like a Rest API and put it into some AWS container, dockerize it, and put it into AWS container using airflow to invoke it and get output from it.\n"}
{"prompt": "What kind of models is Shane primarily using? \n\n###\n\n", "completion": " uuid: 10777412370 Shane is using a mix of both classical ML types like Xg boost psychedelarn types, and TensorFlow Python types.\n"}
{"prompt": "What kind of server is Shane not using for the inferences? \n\n###\n\n", "completion": " uuid: 10777412370 Shane is not using anything like TF server or Torch server, any zoom conference servers for the inferences.\n"}
{"prompt": "What is Shane's response to using some of those servers to speed up inferences and on? \n\n###\n\n", "completion": " uuid: 10777412370  Shane is open to using some of those servers, but doesn't have a lot of information about them and needs more information.\n"}
{"prompt": "What is the platform that IBM has built is used for? \n\n###\n\n", "completion": " uuid: 10777412370 The platform IBM has built is used for DevOps, developers can deploy their models, training jobs, or batch inference jobs on the platform\n"}
{"prompt": "What led to the realization that a platform was necessary for building machine learning models? \n\n###\n\n", "completion": " uuid: 11942287761 When the speaker was at Reflection, they had five teams building out machine learning models and ended up building a horizontal machine learning platform due to the challenges they faced with model deployment, monitoring, and other aspects.\n"}
{"prompt": "What is the focus area for Truefoundry? \n\n###\n\n", "completion": " uuid: 11942287761 Truefoundry is building a platform that focuses on the model stage of an ML development workflow, enabling easy model training, deployment and monitoring.\n"}
{"prompt": "What are the three ways in which developers interact with the Truefoundry product? \n\n###\n\n", "completion": " uuid: 11942287761 Developers can interact with the Truefoundry product through the CLI, a Python library, and a web-based GUI.\n"}
{"prompt": "What is the purpose of Truefoundry building their platform in a cloud agnostic fashion? \n\n###\n\n", "completion": " uuid: 11942287761 Building their platform in a cloud agnostic manner enables Truefoundry users to deploy models on multiple cloud providers from a single pane of management and optimize costs across clouds.\n"}
{"prompt": "What is the current stage of Truefoundry's product and what is their approach to working with enterprises? \n\n###\n\n", "completion": " uuid: 11942287761 Truefoundry have built out the core parts of their platform and are working with a handful of enterprises in design partner mode. Their goal is to handhold these enterprises for the next nine months or so and make sure that the platform meets their needs. They will eventually go for general availability once they are more mature.\n"}
{"prompt": "What are the two modes in which people use Truefoundry's platform? \n\n###\n\n", "completion": " uuid: 11942287761 People can use Truefoundry's platform through the public cloud mode, which allows immediate access to the platform and an API key, or they can take the entire platform and deploy it on their cloud which ensures none of their data leaves their cloud.\n"}
{"prompt": "What is George's reason for connecting with Truefoundry and what is his approach to implementing this product? \n\n###\n\n", "completion": " uuid: 11942287761 George wishes to introduce Truefoundry to his team and circulate its material so the team can identify its ML aspects and consolidate their efforts. He plans to bring in someone from his team who has enough visibility into building and deploying models to help determine if Truefoundry's platform can help solve their pain points early on.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11577360522 To learn from Ricashi about AI functions in healthcare and to discuss True Foundry's current ML stack, use cases, challenges, and goals for the next six months.\n"}
{"prompt": "Who is leading the call? \n\n###\n\n", "completion": " uuid: 11577360522 It's unclear who is leading the call.\n"}
{"prompt": "What is Truefoundry? \n\n###\n\n", "completion": " uuid: 11577360522 Truefoundry is a startup that helps companies move fast with data by testing out and deploying models to production, as well as monitoring them in the right way without much effort needed from developers.\n"}
{"prompt": "What is Advertiser? \n\n###\n\n", "completion": " uuid: 11577360522 Advertiser is a healthcare machine learning company that focuses on pre-operative care and revenue cycle management. They are leading the research and machine learning team and are based in Seattle, USA.\n"}
{"prompt": "What are the unique challenges associated with ML in healthcare? \n\n###\n\n", "completion": " uuid: 11577360522 The unique challenges associated with ML in healthcare include the diversity of users and the use of domain-specific parameters and codes. Clinical decision making needs to be validated beyond just using GitHub workflows and requires a deep understanding of the data.\n"}
{"prompt": "What is the main focus of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11577360522 True Foundry's platform primarily focuses on the deployment side of ML, orchestrating everything over Kubernetes, making it easy for data scientists and ML engineers to train models, deploy them in a testing environment, and move them to production environment while having complete monitoring.\n"}
{"prompt": "How does one deploy a model in a stateless model versus a model based on certain data that gets pre-processed every day? \n\n###\n\n", "completion": " uuid: 11577360522 Deploying a stateless model is relatively easy, but deploying models that use large numbers of features can be more challenging, as an IT team may be required on the other end to manage the pipeline to ensure data comes in and goes out correctly, even if the clinical user on the other end is less technically experienced.\n"}
{"prompt": "Where did the interesting career journey person work before joining SAP? \n\n###\n\n", "completion": " uuid: 11656829007 The person worked at Flipkart for four years before joining SAP.\n"}
{"prompt": "Why did the person join SAP? \n\n###\n\n", "completion": " uuid: 11656829007 There is no information provided to answer this question.\n"}
{"prompt": "What are some suggestions that Hannah made? \n\n###\n\n", "completion": " uuid: 11656829007 There is no information provided to answer this question.\n"}
{"prompt": "Are the 600 users already segmented? \n\n###\n\n", "completion": " uuid: 11656829007 Yes, the 600 users are already segmented.\n"}
{"prompt": "What are the different ways the users can be segmented? \n\n###\n\n", "completion": " uuid: 11656829007 The users can be segmented as top of funnel, bottom of funnel, very technical versus leader type of segmentation, psyche engineers, Kaggle data scientists, and high level.\n"}
{"prompt": "Can the meeting be postponed to tomorrow or day after? \n\n###\n\n", "completion": " uuid: 11656829007 Yes, the meeting can be postponed to tomorrow or day after.\n"}
{"prompt": "What does the speaker plan to do in the first week? \n\n###\n\n", "completion": " uuid: 11656829007 The speaker plans to spend the first week onboarding with the platform.\n"}
{"prompt": "What are the speaker's plans after spending a few weeks with the company? \n\n###\n\n", "completion": " uuid: 11656829007 The speaker plans to take three days off and go somewhere to enjoy before coming back to work.\n"}
{"prompt": "What team outings does the speaker plan to attend? \n\n###\n\n", "completion": " uuid: 11656829007 The speaker plans to come to the office a minimum of three days per week and attend team outings around that.\n"}
{"prompt": "What can be tracked while the job is running? \n\n###\n\n", "completion": " uuid: 10777412370 CPU memory, network usage, and logs of the job.\n"}
{"prompt": "How are different versions of the same model tracked? \n\n###\n\n", "completion": " uuid: 10777412370 All runs of the same model can be tracked through different versions and it is easy to see which version of the particular job ran when.\n"}
{"prompt": "Can previous versions of a job be redeployed? \n\n###\n\n", "completion": " uuid: 10777412370 Yes, redeploying a previous version is practically just a click away.\n"}
{"prompt": "What is the developer experience like with this platform? \n\n###\n\n", "completion": " uuid: 10777412370 Developers can run jobs from their local machine and leverage the power of the cloud. Creating a job object, providing the name of the job and command, and hitting job dot deploy can create a docker container from the training script and run the job on a remote cluster.\n"}
{"prompt": "On which cluster will the job be run? \n\n###\n\n", "completion": " uuid: 10777412370 The job will run on the Kubernetes cluster that is linked on the platform dashboard.\n"}
{"prompt": "How can infrastructure specifications be specified for a job? \n\n###\n\n", "completion": " uuid: 10777412370 The type of machines can be specified for a cluster and a workspace. You can specify the type of machines you care about and the pool of machines for your cluster will be selected from this specification.\n"}
{"prompt": "Are machines always running? \n\n###\n\n", "completion": " uuid: 10777412370 No, machines only exist as part of your cluster and are only spun up and used when a job is scheduled to run.\n"}
{"prompt": "Can performance metrics be tracked for machine learning models? \n\n###\n\n", "completion": " uuid: 10777412370 Yes, you can track a lot of metrics on the platform dashboard, such as the configuration, metrics, training graphs, and distribution of the data set.\n"}
{"prompt": "What is the histogram graph showing? \n\n###\n\n", "completion": " uuid: 10777412370 The histogram shows the distribution of a feature across the training and testing data sets. The x-axis is the range of values for a particular feature and the y-axis is the count of data points within that range.\n"}
{"prompt": "Can artifacts generated by a job be tracked on the platform? \n\n###\n\n", "completion": " uuid: 10777412370 Yes, all files and artifacts generated or used during a job can be tracked on the platform dashboard.\n"}
{"prompt": "What is Truefoundry and what is the goal for Michael on the platform? \n\n###\n\n", "completion": " uuid: 10881905316 Truefoundry is a platform for deploying and managing machine learning models. The goal for Michael is to familiarize himself with the platform by deploying a couple of jobs and services.\n"}
{"prompt": "Is it possible to pass in dependencies to the code being deployed on the platform? \n\n###\n\n", "completion": " uuid: 10881905316 Yes, it is possible to pass in dependencies such as requirements.txt or other files.\n"}
{"prompt": "What is the difference between ML Foundry and Service Foundry? \n\n###\n\n", "completion": " uuid: 10881905316 ML Foundry is used for experiment management and metric logging, while Service Foundry is used for deploying services and jobs.\n"}
{"prompt": "What is the purpose of a workspace in Truefoundry? \n\n###\n\n", "completion": " uuid: 10881905316 A workspace is a logical partition of a cluster and allows for allocation of permissions for certain resources at that level. It can also be used for dev-staging-prod environments.\n"}
{"prompt": "What does the promote feature in the UI mean? \n\n###\n\n", "completion": " uuid: 10881905316 The promote feature is used to promote changes from a lower environment to a higher environment, such as from staging to production.\n"}
{"prompt": "How do you pronounce the name? \n\n###\n\n", "completion": " uuid: 9905698123 Nikhunj\n"}
{"prompt": "Where is the speaker based? \n\n###\n\n", "completion": " uuid: 9905698123 Toronto\n"}
{"prompt": "Were you able to discuss the machine learning engineers in the company? \n\n###\n\n", "completion": " uuid: 9905698123 Yes\n"}
{"prompt": "How many machine learning engineers and data scientists are combined at the company? \n\n###\n\n", "completion": " uuid: 9905698123 Three ML engineers, five data scientists.\n"}
{"prompt": "What kind of machine learning models are currently in production at the company? \n\n###\n\n", "completion": " uuid: 9905698123 Simple regression models\n"}
{"prompt": "What library is used for machine learning, particularly for neural networks? \n\n###\n\n", "completion": " uuid: 9905698123 TensorFlow\n"}
{"prompt": "What program is used for pipeline management by the company? \n\n###\n\n", "completion": " uuid: 9905698123 Cadre\n"}
{"prompt": "What caught the speaker's attention during the demo? \n\n###\n\n", "completion": " uuid: 9905698123 The simplicity and ease of use of the platform\n"}
{"prompt": "What is the focus of the company's platform? \n\n###\n\n", "completion": " uuid: 9905698123 Optimizing machine learning development workflows for companies with one full-time ML engineer\n"}
{"prompt": "What was the challenge with adding external calls and why was it a big challenge? \n\n###\n\n", "completion": " uuid: 12362100552 Most external calls were expected by the models and adding more external calls would add more latency, making it harder to serve features online. This was a big challenge for the team.\n"}
{"prompt": "Are remote calls possible? \n\n###\n\n", "completion": " uuid: 12362100552 Yes, remote calls are possible, but making a remote call for every model call would be too expensive in terms of latency.\n"}
{"prompt": "What is the team's primary focus in terms of feature engineering and A/B testing? \n\n###\n\n", "completion": " uuid: 12362100552 The team's primary focus is feature engineering, serving, and A/B testing.\n"}
{"prompt": "What tools and platforms does the team use for training and serving? \n\n###\n\n", "completion": " uuid: 12362100552 The team uses Databricks notebooks and Spark for training, and their serving layer is built on top of Kubernetes. They are exploring using TF serving for hosting, and are developing Omega ML platform for feature transformations and workflow management.\n"}
{"prompt": "How does the team manage costs on their Databricks clusters? \n\n###\n\n", "completion": " uuid: 12362100552 The team's cost monitoring systems are limited, and they usually look at Azure's cost management tool for monitoring. They do not have any fancy solutions or real-time monitoring of costs for individual jobs.\n"}
{"prompt": "Do the team separate models by different advertisers? \n\n###\n\n", "completion": " uuid: 12362100552 The team trains all advertisers together, and do not have any major concerns about sharing data between advertisers. They are exploring having models for different advertisers.\n"}
{"prompt": "What did the person say to start the conversation? \n\n###\n\n", "completion": " uuid: 10540896567 Hello.\n"}
{"prompt": "Who did the person greet and how did they respond? \n\n###\n\n", "completion": " uuid: 10540896567 They greeted a kid and the kid responded with 'Good.'\n"}
{"prompt": "What was the misunderstanding about the call? \n\n###\n\n", "completion": " uuid: 10540896567 The person was waiting for a call, thinking it was not a Google meet.\n"}
{"prompt": "Where is the person based now and where did they recently move from? \n\n###\n\n", "completion": " uuid: 10540896567 They are based in the Bay Area now and moved from Boston.\n"}
{"prompt": "Where is the other person based and where did they recently move to? \n\n###\n\n", "completion": " uuid: 10540896567 The other person is also in San Francisco and recently moved to Dublin.\n"}
{"prompt": "What area are they looking for a house in and what specific locations are they interested in? \n\n###\n\n", "completion": " uuid: 10540896567 They are looking for a house in Dublin area, preferably in East Bay, from Mission to Danville.\n"}
{"prompt": "What did the person say about their recent decision to buy and remodel a house? \n\n###\n\n", "completion": " uuid: 10540896567 They felt it was a bad decision as construction is taking more than four months.\n"}
{"prompt": "Who else did the person want to buy a house in San Jose area? \n\n###\n\n", "completion": " uuid: 10540896567 The person asked the other person where they would buy in San Jose area.\n"}
{"prompt": "What did the person reveal about their past and how they decided to start a company? \n\n###\n\n", "completion": " uuid: 10540896567 They revealed that they and two others went to college together, and later built a company together to solve issues around machine learning models.\n"}
{"prompt": "What kind of companies are they working with and how are they approaching them? \n\n###\n\n", "completion": " uuid: 10540896567 They are working with some large companies like Synopsis as design partners, building out integrations to add business value for them.\n"}
{"prompt": "What is the focus and importance of lead scoring and what other areas are they focusing on? \n\n###\n\n", "completion": " uuid: 10540896567 The focus is on lead scoring, fraud detection, and marketing analytics, with some focus on NLP related to customer satisfaction.\n"}
{"prompt": "What is the team size and how many models are currently in production? \n\n###\n\n", "completion": " uuid: 10540896567 The team size is small, with only a handful of data scientists enterprise wide. There are only a handful of key models in production, with many more being built.\n"}
{"prompt": "What is the biggest challenge in building out personalization models and scaling up the platform? \n\n###\n\n", "completion": " uuid: 10540896567 The biggest challenge is the lack of decent structure, internal architecture, feature store, and the abilities for machine learning engineers to work together.\n"}
{"prompt": "What did the person ask at the end about the other person's interests? \n\n###\n\n", "completion": " uuid: 10540896567 The person asked if the other person is still playing cricket.\n"}
{"prompt": "What is mixed precision and how does it relate to OnX runtime? \n\n###\n\n", "completion": " uuid: 11354392885 Mixed precision is a concept that involves using FP16 support to synthetically double the amount of RAM available. OnX runtime efficiently supports mixed precision for better performance.\n"}
{"prompt": "What is the approach to managing multiple models without deploying them one over another? \n\n###\n\n", "completion": " uuid: 11354392885 The approach involves deploying the model as a function on Kserv, incrementally copying one third of it to a multimodal server with GPU backend support. XGBoost provides the inference file format supported by Triton for this purpose.\n"}
{"prompt": "What is the role of OCR model in detecting and recognizing rows and requests in gRPC? \n\n###\n\n", "completion": " uuid: 11354392885 The OCR model detects each row, rotates them if required, and subsequently recognizes the requests using gRPC. This helps in generating multi-people communication for better throughput.\n"}
{"prompt": "Which two types of jobs are used for images and what was the initial use case for Taipei and Lithuania? \n\n###\n\n", "completion": " uuid: 11354392885 The two types of jobs used for images are real-time and batch. The initial use case for Taipei and Lithuania was mostly batch-oriented, but later realized about adequate reserve for real-time use cases.\n"}
{"prompt": "How is model deployment and versioning managed, and what is the role of TensorFlow server in standardizing the inference protocol? \n\n###\n\n", "completion": " uuid: 11354392885 Models are deployed and versioned using CASER, with versions automatically stored for every model. TensorFlow server and Python service are used to standardize the inference protocol for different frameworks. The model deployment is powered by CASER, and TensorFlow server is used for every framework.\n"}
{"prompt": "What is the role of snowflake and feature store, and why was Firebase replaced with fees? \n\n###\n\n", "completion": " uuid: 11354392885 Snowflake acts as the data warehouse, which is updated at a frequency of 15 minutes. Feature store compiles static data by policy and serves load functions. Firebase was replaced with fees due to scaling limitations.\n"}
{"prompt": "What is the main reason behind not using Vertex, and how is the deployment of the system managed? \n\n###\n\n", "completion": " uuid: 11354392885 The main reason behind not using Vertex is its cost effectiveness and scalability issues. The system deployment is managed using knative, Triton, and cloud run for better performance and routing specific payloads.\n"}
{"prompt": "What is the thought process of the tech team while repurposing models for different use cases, and how is testing of the system done? \n\n###\n\n", "completion": " uuid: 11354392885 The tech team focuses on repurposing models for different use cases, and testing of the system is done by debugging the detectron model and converting it to tensor RT for better scalability and efficiency.\n"}
{"prompt": "What is the goal of the system that they are building? \n\n###\n\n", "completion": " uuid: 10611764294 To give control to the ML team and deploy models in a more systematic and optimized way with SRE practices and cost efficiency.\n"}
{"prompt": "What kind of environments can be deployed with this system? \n\n###\n\n", "completion": " uuid: 10611764294 Testing, production or staging environments.\n"}
{"prompt": "What complex use cases are supported by the system? \n\n###\n\n", "completion": " uuid: 10611764294 Traffic splitting, shadow testing for models, and auto scaling.\n"}
{"prompt": "What kind of machines can be used for different deployments? \n\n###\n\n", "completion": " uuid: 10611764294 Certain kinds of machines can be restricted or used for different deployments.\n"}
{"prompt": "How is monitoring enabled for automatic deployment? \n\n###\n\n", "completion": " uuid: 10611764294 With a few lines of code the platform automatically generates a monitoring dashboard.\n"}
{"prompt": "What helps optimize costs with this system? \n\n###\n\n", "completion": " uuid: 10611764294 The way the system is structured.\n"}
{"prompt": "What type of companies are they looking to work with? \n\n###\n\n", "completion": " uuid: 10611764294 Companies with mid level or advanced ML pipelines.\n"}
{"prompt": "What is the process for working with companies and solving their problem statements? \n\n###\n\n", "completion": " uuid: 10611764294 Working closely to understand the problem statement, doing a POC to prove value, and customizing specific things for the company.\n"}
{"prompt": "When will they schedule a meeting to discuss more in depth? \n\n###\n\n", "completion": " uuid: 10611764294 Next week, on Thursday or Friday at 04:00. An invite will be sent.\n"}
{"prompt": "What will be sent to the person to help them understand more about Two Foundation? \n\n###\n\n", "completion": " uuid: 10611764294 A small deck that will give an overview of the company and their use cases.\n"}
{"prompt": "What was the first thing the speaker said to begin the conversation? \n\n###\n\n", "completion": " uuid: 11487646267 Thank you.\n"}
{"prompt": "What did the speaker ask when they couldn't hear the other person? \n\n###\n\n", "completion": " uuid: 11487646267 Hi, can you hear me?\n"}
{"prompt": "What was the response to the speaker's question about being on the road? \n\n###\n\n", "completion": " uuid: 11487646267 Yeah.\n"}
{"prompt": "What was the reason for the call? \n\n###\n\n", "completion": " uuid: 11487646267 To learn more about the specific problems that Priyanka's team is trying to solve within Zulili.\n"}
{"prompt": "What are the three broad business cases that Zulili's platform is used for? \n\n###\n\n", "completion": " uuid: 11487646267 Personalization and recommendation, forecasting, and supply chain.\n"}
{"prompt": "What are some technologies that Zulili's platform is built on? \n\n###\n\n", "completion": " uuid: 11487646267 Fiest for feature store, Qflow for training platform, and Model DB for tracking experiments.\n"}
{"prompt": "What was the speaker's role in the previous startup with Nikonj and the two co-founders? \n\n###\n\n", "completion": " uuid: 11487646267 Part of the founder's office and worked with Nikonj and the other co-founders in the HR tech space.\n"}
{"prompt": "What is Priyanka's timezone? \n\n###\n\n", "completion": " uuid: 11487646267 US PST timezone.\n"}
{"prompt": "What university did Akshay attend for his master's degree? \n\n###\n\n", "completion": " uuid: 11487646267 UC Berkeley.\n"}
{"prompt": "What are the two clouds that Zulili uses and why were they chosen? \n\n###\n\n", "completion": " uuid: 11487646267 AWS and GCP, because GCP had good data management capabilities and AWS had good real-time production services.\n"}
{"prompt": "What tool does Zulili use to track experiments? \n\n###\n\n", "completion": " uuid: 11487646267 Model DB.\n"}
{"prompt": "What was a challenge with using Kubeflow as a training platform? \n\n###\n\n", "completion": " uuid: 11487646267 It heavily favors TensorFlow as a training platform, but there are other libraries that may do better, like for example training GBA decision trees.\n"}
{"prompt": "Who manages the Kubernetes clusters at Zulili? \n\n###\n\n", "completion": " uuid: 11487646267 The platform team.\n"}
{"prompt": "What teams work together to put models into production in Zulili's platform? \n\n###\n\n", "completion": " uuid: 11487646267 Data scientists and applied MLE teams.\n"}
{"prompt": "What is the goal of the product? \n\n###\n\n", "completion": " uuid: 10441289250 The goal is to make it easy for data scientists and ML developers to test and deploy their models into production without having to depend on ML engineers or DevOps team.\n"}
{"prompt": "Why do data scientists and ML developers need this product? \n\n###\n\n", "completion": " uuid: 10441289250 Because they often lack core engineering skill set and working with infra becomes challenging for them.\n"}
{"prompt": "What are the ways to deploy a model using this product? \n\n###\n\n", "completion": " uuid: 10441289250 You can deploy a model using Python code, YAML, or through the UI.\n"}
{"prompt": "What is the platform designed to work with? \n\n###\n\n", "completion": " uuid: 10441289250 The platform is designed to work with Kubernetes, which is cloud native and can be used on any cloud like AWS or GCP.\n"}
{"prompt": "Can you integrate your own Docker register? \n\n###\n\n", "completion": " uuid: 10441289250 Yes, you can integrate your own Docker register.\n"}
{"prompt": "What is the purpose of integrating GitHub repositories in the platform? \n\n###\n\n", "completion": " uuid: 10441289250 Integrating GitHub repositories allows you to choose options when you deploy.\n"}
{"prompt": "What is the purpose of creating a workspace in a cluster? \n\n###\n\n", "completion": " uuid: 10441289250 To give every data scientist or team a safe space to play around with, where they can do their own deployment and not exceed beyond that.\n"}
{"prompt": "What are some components of the product? \n\n###\n\n", "completion": " uuid: 10441289250 The product has components for tracking runs and metrics, data monitoring, and browsing through the raw data of the model.\n"}
{"prompt": "Will the conversation continue over email? \n\n###\n\n", "completion": " uuid: 10441289250 Yes, the conversation will continue over email.\n"}
{"prompt": "What is the primary infrastructure that the research team heavily relies on at the moment? \n\n###\n\n", "completion": " uuid: 12150828398 The research team heavily relies on Google Kubernetes engine and Cloud File store at the moment.\n"}
{"prompt": "What is the typical YAML file submitted by researchers, and what does it contain? \n\n###\n\n", "completion": " uuid: 12150828398 The typical YAML file submitted by researchers contains the image they want, the Python packages they need, and specifies the resources they want to use such as GPUs, CPUs, and memory. It may also specify persistent volumes for storing data sets and model checkpoints.\n"}
{"prompt": "How do researchers track their progress and monitor logs and metrics? \n\n###\n\n", "completion": " uuid: 12150828398 Researchers use Kubestl or GCP Console to track their progress and monitor logs and metrics.\n"}
{"prompt": "Is there a limit on how much infrastructure researchers can request? \n\n###\n\n", "completion": " uuid: 12150828398 There are no limitations on CPU and memory requests, but for GPUs there are limits.\n"}
{"prompt": "How does the request for allocation of infrastructure come to your team? \n\n###\n\n", "completion": " uuid: 12150828398 There is no need for permission to request CPU and memory resources. However, for GPUs, there are limitations and the request may need approval from the infrastructure team.\n"}
{"prompt": "What was the main reason for the speaker to move on from their India centric business? \n\n###\n\n", "completion": " uuid: 11656830826 They wanted to explore something newer.\n"}
{"prompt": "What is the objective of the speaker in reaching out to people in the industry associated with the ML Ops domain? \n\n###\n\n", "completion": " uuid: 11656830826 To get to know more about the challenges faced by users in the tools they have been using.\n"}
{"prompt": "What is the challenge that most ML engineers face after training a model? \n\n###\n\n", "completion": " uuid: 11656830826 Optimizing the model.\n"}
{"prompt": "What is quantization in machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 It means doing calculations in 16 or even 8 bits instead of Floating Point 32 bits, and helps in making the model faster.\n"}
{"prompt": "Which tool did the speaker use for deployment at Procore? \n\n###\n\n", "completion": " uuid: 11656830826 Selden Core.\n"}
{"prompt": "What was the main reason for the speaker not continuing with the support license of Selden Core? \n\n###\n\n", "completion": " uuid: 11656830826 The team at Proco was confident in their competence to fix issues, and they felt the support was not providing enough value.\n"}
{"prompt": "Why did the speaker not go for an enterprise version of Selden Core? \n\n###\n\n", "completion": " uuid: 11656830826 The manager felt building their own solution was better since the tools were not mature enough.\n"}
{"prompt": "What topics do the speaker want to dive deeper into in the next meeting? \n\n###\n\n", "completion": " uuid: 11656830826 Sage Maker, competition with Selden, and monitoring.\n"}
{"prompt": "What time and day did the speaker suggest for their next meeting? \n\n###\n\n", "completion": " uuid: 11656830826 Tuesday, the 17th of the next month, same time as the current meeting.\n"}
{"prompt": "What is Truefoundry? \n\n###\n\n", "completion": " uuid: 11189912081 Truefoundry is a platform developed for operationalizing machine learning models.\n"}
{"prompt": "How can you connect Kubernetes cluster with Truefoundry? \n\n###\n\n", "completion": " uuid: 11189912081 You can connect a Kubernetes cluster with Truefoundry dashboard.\n"}
{"prompt": "What is the purpose of installing helm charts on the Kubernetes cluster? \n\n###\n\n", "completion": " uuid: 11189912081 Installing helm charts on the Kubernetes cluster sets up the infrastructure required by Truefoundry to run machine learning models.\n"}
{"prompt": "Can Truefoundry work with any infrastructure? \n\n###\n\n", "completion": " uuid: 11189912081 Truefoundry supports working with Kubernetes and can be deployed on multiple cloud platforms, on-premise architectures, and even specific clouds, if required.\n"}
{"prompt": "What do data scientists need to do to deploy their machine learning models using Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189912081 Data scientists can deploy their machine learning models on the Truefoundry platform by installing the Truefoundry client-side library on their Jupiter notebook, invoking API's to deploy models on the remote server, and scaling the deployment system.\n"}
{"prompt": "Who is addressing whom at the beginning of the conversation? \n\n###\n\n", "completion": " uuid: 12249629853 Hey punit addressing someone\n"}
{"prompt": "What is the response to the initial greeting? \n\n###\n\n", "completion": " uuid: 12249629853 Hi is the response\n"}
{"prompt": "Who else is on the call besides the speakers? \n\n###\n\n", "completion": " uuid: 12249629853 Rog is on the call\n"}
{"prompt": "What is the speaker's response when asked how they are doing? \n\n###\n\n", "completion": " uuid: 12249629853 I'm doing well, thank you.\n"}
{"prompt": "Why is one of the speakers not able to see the other? \n\n###\n\n", "completion": " uuid: 12249629853 It seems like they are using a different platform, Teams instead of Meat.\n"}
{"prompt": "What is the speaker's question about the platform they are using? \n\n###\n\n", "completion": " uuid: 12249629853 Is it like the video?\n"}
{"prompt": "What does the speaker say about the platform being discussed? \n\n###\n\n", "completion": " uuid: 12249629853 The platform being discussed is Meat Wrapped Around Teams.\n"}
{"prompt": "What happens when someone else tries to join the call? \n\n###\n\n", "completion": " uuid: 12249629853 The speaker forwards the invite to others so they can join.\n"}
{"prompt": "What does one of the speakers suggest when someone else is unable to join the call? \n\n###\n\n", "completion": " uuid: 12249629853 Create a separate link from their enterprise account.\n"}
{"prompt": "How does one of the speakers suggest they deal with the issue of others not being able to join? \n\n###\n\n", "completion": " uuid: 12249629853 By creating a separate link and asking others to join that.\n"}
{"prompt": "Who is mentioned as possibly being the main audience for the call? \n\n###\n\n", "completion": " uuid: 12249629853 The speaker's team is mentioned.\n"}
{"prompt": "What do the speakers plan to do when someone else is ready to join the call? \n\n###\n\n", "completion": " uuid: 12249629853 They will join the link Punit creates.\n"}
{"prompt": "How does one of the speakers say they joined the call? \n\n###\n\n", "completion": " uuid: 12249629853 They joined using their mobile app instead of the laptop.\n"}
{"prompt": "What is one of the speaker's response when told others are waiting for them? \n\n###\n\n", "completion": " uuid: 12249629853 They express their willingness to wait for Punit's link to join the call.\n"}
{"prompt": "What kind of metrics does this service provide? \n\n###\n\n", "completion": " uuid: 10611765880 The service provides metrics for CPU, memory, disk usage, request stats, success rate, and live logs.\n"}
{"prompt": "What is the purpose of the FastAPI? \n\n###\n\n", "completion": " uuid: 10611765880 The FastAPI allows developers to write a Pythonic model which gets converted to JSON for deployment.\n"}
{"prompt": "What is the purpose of the Deploy.py file? \n\n###\n\n", "completion": " uuid: 10611765880 The Deploy.py file imports the SDK and defines a service, which can be customized in terms of its CPU resources, memory, and machine type.\n"}
{"prompt": "What is the function of the Workspace in the platform? \n\n###\n\n", "completion": " uuid: 10611765880 The Workspace is a collection of resources where the pods will be deployed to, and it is used to deploy a service definition.\n"}
{"prompt": "What is the main difference between deploying a job and deploying a service? \n\n###\n\n", "completion": " uuid: 10611765880 Jobs only consume resources when they are running, while services require a web app or extra code to call the model and generate predictions.\n"}
{"prompt": "What is the beta feature for model deployment? \n\n###\n\n", "completion": " uuid: 10611765880 The beta feature for model deployment allows users to take a model from a model registry and deploy it directly as a working service without having to write extra code.\n"}
{"prompt": "What is True Foundry building? \n\n###\n\n", "completion": " uuid: 11655737135 A reliable ML platform to facilitate the deployment of ML models, making it simple and enforcing best practices.\n"}
{"prompt": "What is the goal of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11655737135 To enable deployment of ML models at all stages, from running training jobs to deploying to production spaces, while enforcing best engineering and SRE principles.\n"}
{"prompt": "What is the system built on? \n\n###\n\n", "completion": " uuid: 11655737135 Kubernetes as the PaaS.\n"}
{"prompt": "What is the Python library used for? \n\n###\n\n", "completion": " uuid: 11655737135 To enable Data Scientists to deploy their models without needing knowledge of Kubernetes.\n"}
{"prompt": "What principles are enforced in the system? \n\n###\n\n", "completion": " uuid: 11655737135 Best engineering and SRE principles such as authentication, secret management, and monitoring.\n"}
{"prompt": "Who leads the ML platform team? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker is asking who leads the ML (Machine Learning) team in Hadabad.\n"}
{"prompt": "Who is the manager and who's the manager's manager? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker is seeking to know the manager and their manager's manager in the ML platform team.\n"}
{"prompt": "Are both the manager and manager's manager in Hyderabad? \n\n###\n\n", "completion": " uuid: 12339635717 Yes, both the manager and their manager's manager are in Hyderabad.\n"}
{"prompt": "What is the goal of the speaker? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker's goal is to learn what challenges companies face in building and orchestrating their machine learning models across clouds.\n"}
{"prompt": "What are some challenges in building and orchestrating machine learning models across clouds? \n\n###\n\n", "completion": " uuid: 12339635717 Some of the challenges include visibility of all the models running across clouds and the speed of execution due to the need to be cautious about many things that are typically abstracted away.\n"}
{"prompt": "What is the speaker's plan for setting up a follow-up call with Abhishek and the interviewee? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker will set up a call for 30 minutes between the three of them and would like to get the interviewee's WhatsApp number.\n"}
{"prompt": "What is the thesis of the speaker? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker's thesis is that companies that are cross cloud might face more challenges in building and orchestrating their machine learning models than companies that are on one cloud.\n"}
{"prompt": "What will the speaker do after gathering information on different companies building cross cloud solutions? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker will build out a more core thesis on what problems can be solved as a startup.\n"}
{"prompt": "What is the speaker asking for at the end of the call? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker thanked the interviewee and asked to set up another call later.\n"}
{"prompt": "What is the first sentence in the context? \n\n###\n\n", "completion": " uuid: 12362100552 Are you in midst of travel?\n"}
{"prompt": "What is the issue with the voice on the call? \n\n###\n\n", "completion": " uuid: 12362100552 Hello? It's very bleak. Like the voice is breaking out.\n"}
{"prompt": "What does the speaker ask after the issue with the voice is resolved? \n\n###\n\n", "completion": " uuid: 12362100552 Is it better now?\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12362100552 So Kalan, just to kind of I think from the email thread basically we were connected by Adithta caldro who is actually one of our advisors and angels.\n"}
{"prompt": "Who are the three co-founders of Truefoundry? \n\n###\n\n", "completion": " uuid: 12362100552 Nick Kunj, Abhishek and myself\n"}
{"prompt": "What was the first startup that the founders built in the talent space? \n\n###\n\n", "completion": " uuid: 12362100552 an Entire\n"}
{"prompt": "What did the founders discuss while building models for matching candidates and resumes? \n\n###\n\n", "completion": " uuid: 12362100552 the systems that existed at Facebook at that time and Vishik and Nicole mentioned about Epiler, which is their internal ML platform.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12362100552 to build a multi cloud system on top of Kubernetes, wherein it's very easy for data scientists and ML engineers to quickly take their models tested and then deployed in production in a reliable and cost effective manner.\n"}
{"prompt": "What is Kalyan's role in InMobi? \n\n###\n\n", "completion": " uuid: 12362100552 I look into the ML platforms in mobile over here and at the same time I also work with one of our business units, demand side platform which is heavy, and data science in general.\n"}
{"prompt": "What external capabilities and tools do they use in Inmobi? \n\n###\n\n", "completion": " uuid: 12362100552 only data bricks notebooks, that is primarily for data analysis also, any idea purposes?\n"}
{"prompt": "What internal capabilities are used in Inmobi? \n\n###\n\n", "completion": " uuid: 12362100552 the ref framework and feature store on top of Databrick feature store.\n"}
{"prompt": "What is the latency requirement for running the models in Inmobi? \n\n###\n\n", "completion": " uuid: 12362100552 We have around 20 milliseconds to run all of our models, right. In a request request path.\n"}
{"prompt": "What is the current state of the conversation? \n\n###\n\n", "completion": " uuid: 11189924245 Yogesh and Niquinh are discussing a potential call and their availability.\n"}
{"prompt": "Who is Niquinh? \n\n###\n\n", "completion": " uuid: 11189924245 Niquinh is a person who is speaking to Yogesh.\n"}
{"prompt": "Who are the target customers for Niquinh\u2019s startup? \n\n###\n\n", "completion": " uuid: 11189924245 Their target customers are large companies who need help with machine learning.\n"}
{"prompt": "How many companies is Niquinh currently working with? \n\n###\n\n", "completion": " uuid: 11189924245 Niquinh is currently working with three companies.\n"}
{"prompt": "What does Yogesh think about the sales pitch for Niquinh\u2019s startup? \n\n###\n\n", "completion": " uuid: 11189924245 Yogesh thinks that the sales pitch needs to change.\n"}
{"prompt": "What advice does Yogesh give to Niquinh about working with large companies? \n\n###\n\n", "completion": " uuid: 11189924245 Yogesh advises Niquinh to focus on relationship-building and finding a champion at the top level of the company.\n"}
{"prompt": "What is the purpose of Truefoundry? \n\n###\n\n", "completion": " uuid: 11564066567 To build a startup in the machine learning domain, helping companies build out ML platforms.\n"}
{"prompt": "What is the main problem that Truefoundry is trying to solve? \n\n###\n\n", "completion": " uuid: 11564066567 To help companies get the level of productivity without the actual internal tooling by building an ML platform.\n"}
{"prompt": "Who are the companies that Truefoundry is currently working with? \n\n###\n\n", "completion": " uuid: 11564066567 A few companies like Early Enterprises.\n"}
{"prompt": "What type of machine learning problems is Ravi looking to understand? \n\n###\n\n", "completion": " uuid: 11564066567 Machine learning problems that major companies face, what's top of mind for them from a modeling and infrastructure perspective and how do they get business outcomes from machine learning?\n"}
{"prompt": "What is the issue with ML in the fintech space? \n\n###\n\n", "completion": " uuid: 11564066567 The regulatory hold on explainability of ML models is much greater because of lending and insurance's need to have a very clear explainability.\n"}
{"prompt": "Are there use cases where regulatory hold is not that great? \n\n###\n\n", "completion": " uuid: 11564066567 Yes, in marketing there is less regulatory hold.\n"}
{"prompt": "What kind of models are typically used at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Risk models, which are mostly decision trees, are used.\n"}
{"prompt": "What is the role of data scientists at LC? \n\n###\n\n", "completion": " uuid: 11564066567 They build the models and the next generation six to twelve months out once they have more fresh data.\n"}
{"prompt": "What does LC do with the models after they are built? \n\n###\n\n", "completion": " uuid: 11564066567 The data engineers do the deployment, testing, launch, and maintenance. They manage the one version in production while the data scientists keep looking for more data and keep refreshing the buyer in progress.\n"}
{"prompt": "What is the broad objective of the call? \n\n###\n\n", "completion": " uuid: 10881905922 To understand the ML process and pain points while getting to know each other.\n"}
{"prompt": "What is the current location of the person on the call? \n\n###\n\n", "completion": " uuid: 10881905922 The person is currently located in Bangalore.\n"}
{"prompt": "What is the focus of the startup? \n\n###\n\n", "completion": " uuid: 10881905922 The startup's main focus is on the platform for machine learning teams and optimizing model deployment and monitoring.\n"}
{"prompt": "What is the company's stage? \n\n###\n\n", "completion": " uuid: 10881905922 The product is in pre-launch, with a seed round of funding, a small full-time team, and working with design partners.\n"}
{"prompt": "What is Freshworks' machine learning engineering charter? \n\n###\n\n", "completion": " uuid: 10881905922 They are verticalized and cover the full gamut of one particular thing, with a large part being machine learning engineering and some regular application type engineering.\n"}
{"prompt": "How does the machine learning team work at Freshworks? \n\n###\n\n", "completion": " uuid: 10881905922 They maintain their own infrastructure and have a layer that abstracts the application from the ML service. The service is stateless with different models for each account loaded from S3.\n"}
{"prompt": "Does Freshworks use Kubernetes or Sage Maker? \n\n###\n\n", "completion": " uuid: 10881905922 Freshworks does not use Sage Maker, but they do use Kubernetes for their infrastructure.\n"}
{"prompt": "What is the current stack being used by you.com? \n\n###\n\n", "completion": " uuid: 10784174762 you.com is built on azure, using data bricks for analysis, plotting and dashboarding, Kubernetes for deployment and PyTorch for machine learning. They are currently in the process of figuring out nvidia triton for model serving.\n"}
{"prompt": "Who does the deployment of models in you.com? \n\n###\n\n", "completion": " uuid: 10784174762 Deployment is mostly managed by ML Ops and DevOps people, with some back end engineers. An ML engineer may also do the deployment themselves, after having learned the pattern.\n"}
{"prompt": "Can you explain briefly what Truefoundry does? \n\n###\n\n", "completion": " uuid: 10784174762 Truefoundry is a path on top of Kubernetes designed to help ML developers deploy their models to production. It provides support for real time as well as batch case deployment of models, monitors resource utilization and costs, and allows for easy optimization of deployment for better cost efficiency.\n"}
{"prompt": "What are some features of Truefoundry that make it user-friendly? \n\n###\n\n", "completion": " uuid: 10784174762 Truefoundry enforces best practices and supports fast deployment through UI, CLI or Python. It supports traffic splitting and other complicated features by default and has a low learning curve.\n"}
{"prompt": "What are the goals of Truefoundry? \n\n###\n\n", "completion": " uuid: 10784174762 The goal of Truefoundry is to make deployment of machine learning models easy and efficient, enforce the best practices, ensure CI/CD, and enable developers to quickly deploy services through UI, CLI or Python.\n"}
{"prompt": "How is Anrag introduced on the call? \n\n###\n\n", "completion": " uuid: 11942347136 Anrag introduces himself as one of the co-founders at IIFL True Foundry.\n"}
{"prompt": "What is True Foundry's main goal? \n\n###\n\n", "completion": " uuid: 11942347136 To make it easier for data teams to get access to a better platform for testing out and deploying models in a scalable way to production with the right security, with the right authentication and with monitoring in building.\n"}
{"prompt": "Who are the co-founders of True Foundry and what is their background? \n\n###\n\n", "completion": " uuid: 11942347136 Apart from Anrag, the co-founders are Nikkunjana and Vishek who come from a Facebook background with the same educational background as Anrag.\n"}
{"prompt": "Who is Arihan and why does he reach out to Anrag? \n\n###\n\n", "completion": " uuid: 11942347136 Arihan saw the True Foundry platform and reached out to understand what kind of things the company can support in terms of data science initiatives within IIFL.\n"}
{"prompt": "What is the size of the Data Science team currently at IIFL? \n\n###\n\n", "completion": " uuid: 11942347136 They have between two to ten members but they have not been segregated between Data Science and ML.\n"}
{"prompt": "What kind of models are being used by the Data Science team in underwriting? \n\n###\n\n", "completion": " uuid: 11942347136 They are using four thought models but they have not been deployed so they are not running in a production environment.\n"}
{"prompt": "Where are the batch compute processes being done and how are they run? \n\n###\n\n", "completion": " uuid: 11942347136 They are currently using Azure but they are looking to move towards AWS. They run the processes in a patch compute manner.\n"}
{"prompt": "What is the current traffic expectation for the Fast API endpoints once the models are deployed? \n\n###\n\n", "completion": " uuid: 11942347136 Around ten to fifteen hits per minute.\n"}
{"prompt": "What are the necessary components that Anrag is looking for in a platform for deploying the models? \n\n###\n\n", "completion": " uuid: 11942347136 A deployment part, a dashboard for performance and failure monitoring, and intelligence for retraining models and model performance metrics such as population stability index, AUC k or characteristic stability index.\n"}
{"prompt": "What is True Foundry's core focus in terms of platform deployment? \n\n###\n\n", "completion": " uuid: 11942347136 To build a platform that allows for very seamless deployment with every deployment being a dockerized containerized script that can be deployed to a corresponding environment on top of a Kubernetes cluster on whatever cloud provider is being used.\n"}
{"prompt": "What is Two Foundry? \n\n###\n\n", "completion": " uuid: 11354404149 Two Foundry is a startup founded by Ansul, Abhishek, and Nikkunj with the goal of providing an ML platform for companies around the globe. The platform aims to provide ML developers the ability to quickly test out and deploy models using the best engineering practices, including monitoring, auto scaling, and the right authentication and security systems, while also allowing for flexibility for developers to build on top of it.\n"}
{"prompt": "What is the target customer of True Foundry? \n\n###\n\n", "completion": " uuid: 11354404149 The target customers of True Foundry are ML developers who build models, the DevOps or intra-engineer team in companies who want a full view of the infrastructure, and ML engineering leads or managers who want to have a faster ROI for their ML models.\n"}
{"prompt": "What are some of the challenges for on-device ML deployment? \n\n###\n\n", "completion": " uuid: 11354404149 Some of the challenges for on-device ML deployment include optimizing models for device size limitations, figuring out the right approach for SDK, TensorFlow dependencies, distillation techniques for model size reduction, and overcoming privacy concerns for models that need to stay on the device.\n"}
{"prompt": "What components of Sage Maker does Prove use the most? \n\n###\n\n", "completion": " uuid: 11354404149 Prove uses Sage Maker notebooks for easy prototyping, Sage Maker pipelines to package up code and run experiments, and Sage Maker regression for running experiments.\n"}
{"prompt": "What is the structure of the data team at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 There is a central data team which works with different business units.\n"}
{"prompt": "Do they work with external vendors for ML work? \n\n###\n\n", "completion": " uuid: 11655736677 Yes, they do work with external vendors.\n"}
{"prompt": "How do they measure the ROI from the central data team? \n\n###\n\n", "completion": " uuid: 11655736677 The structure is more of a federated structure where skills are at central level control but teams are embedded within the business functions to work closely with them on use cases and create value.\n"}
{"prompt": "What challenges do they face from a data perspective? \n\n###\n\n", "completion": " uuid: 11655736677 There are significant opportunities for them to scale up and become better, but expectations are far higher as most businesses are becoming data-led businesses.\n"}
{"prompt": "What is the size of the True Foundry team? \n\n###\n\n", "completion": " uuid: 11655736677 The True Foundry team is currently a 15 member full-time team with a few full-time contractors and interns. In total, it is a 24 member team.\n"}
{"prompt": "What is the name of the person being addressed in the conversation? \n\n###\n\n", "completion": " uuid: 10441289250 Richard/Anurag/ANU/Anna\n"}
{"prompt": "What is Richard responsible for at Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 Richard is responsible for the tooling in all ML operations at Wayve, developing better workflows for model developers and measuring improved driving quality on the vehicles.\n"}
{"prompt": "How many people are there in the ML engineering team at Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 Around 60-70 people for a company of 200.\n"}
{"prompt": "What external tooling is used by Wayve for experimentation? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve uses Weights and Biases and Azure for training and experimentation workflows.\n"}
{"prompt": "What is the biggest time sink in Wayve's pipeline that they want to improve? \n\n###\n\n", "completion": " uuid: 10441289250 The biggest time sink is the feedback loop for identifying bugs and fixing issues during the deployment of models.\n"}
{"prompt": "What is the ideal solution for the problem that Richard faces? \n\n###\n\n", "completion": " uuid: 10441289250 Richard would like a way to identify bugs in the model during deployment, understand the issues that the model has during deployment and how to fix those issues.\n"}
{"prompt": "What is the mode of engagement for the company? \n\n###\n\n", "completion": " uuid: 10441289250 The company works with a few companies closely and builds a product along the way, instead of working with a lot of customers.\n"}
{"prompt": "What can the other company provide to Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 The other company can provide clarity on what the product might look like based on Wayve's use case, and they can think about a co-development project if it's necessary.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11185249388 The purpose of the call was to discuss Truefoundry, a machine learning platform being developed to solve problems faced by large startups and enterprises.\n"}
{"prompt": "Where is Bobby based? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby is based in the New York City area, just a little bit north of the city.\n"}
{"prompt": "What is Bobby's background? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby comes from a machine learning background, has a master's from UC Berkeley, and has worked at startups such as Reflection and Facebook. Bobby is the current CEO of his second startup with the same set of co founders.\n"}
{"prompt": "What is the company Bobby sold? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby sold the last startup to Infoyage, the parent company of Nockley.com. The startup focused on building an HR tech platform.\n"}
{"prompt": "What is Netomi's use of machine learning? \n\n###\n\n", "completion": " uuid: 11185249388 Netomi uses machine learning in its customer care platform to provide service and recommendations, such as for upsell and cross-selling.\n"}
{"prompt": "What challenges does Netomi face with machine learning operationalization? \n\n###\n\n", "completion": " uuid: 11185249388 Netomi faces challenges with real-time scoring being slower than database queries, as well as the need to score within a few seconds for their voice platform to avoid timeouts.\n"}
{"prompt": "Who is leading the call? \n\n###\n\n", "completion": " uuid: 11354403912 The person says they are happy to lead the call.\n"}
{"prompt": "What kind of approach does the leader want to take? \n\n###\n\n", "completion": " uuid: 11354403912 The leader wants to try to lead through the floor on the user flow.\n"}
{"prompt": "Who is joining the call? \n\n###\n\n", "completion": " uuid: 11354403912 Michelle is joining the call.\n"}
{"prompt": "What is Michelle's background? \n\n###\n\n", "completion": " uuid: 11354403912 Michelle was working at Times Square as the head of engineering before being acquired by Delivery Hero. Before this, she worked with startups in various engineering roles.\n"}
{"prompt": "What is Proof.Truefoundry presenting? \n\n###\n\n", "completion": " uuid: 11354403912 Proof.Truefoundry is presenting an ML platform focused on model deployment that can ease the process for enterprises.\n"}
{"prompt": "What kind of use cases does TabSquare work on? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare works with restaurants, providing an integration for their menus and helping manage online and offline orders.\n"}
{"prompt": "What is the team size for TabSquare? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare has around 15 people on their data science team and around 120 people on their product engineering team.\n"}
{"prompt": "Where is TabSquare's data stored? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare's data is stored in GCP, including their analytics database and ML models.\n"}
{"prompt": "What tool is TabSquare using for monitoring? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare is using Data Dog for monitoring.\n"}
{"prompt": "Who writes the YAML configuration for TabSquare's infrastructure? \n\n###\n\n", "completion": " uuid: 11354403912 The DevOps team writes the YAML configuration, but the engineering team writes the Docker files for their services.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11354404209 To gather information about Pegasystems' current ML pipeline.\n"}
{"prompt": "What is Pegasystems' primary use case for AI? \n\n###\n\n", "completion": " uuid: 11354404209 Pegasystems' primary use case for AI is marketing, and they are a gartner leader in real time interaction management.\n"}
{"prompt": "What is the latency requirement for Pega's ML infrastructure? \n\n###\n\n", "completion": " uuid: 11354404209 The latency requirement for Pega's ML infrastructure is 7 milliseconds.\n"}
{"prompt": "What does Pegasystems specialize in for business process automation? \n\n###\n\n", "completion": " uuid: 11354404209 Pegasystems specializes in process AI, which is optimizing processes.\n"}
{"prompt": "Does Pegasystems have a data science team? \n\n###\n\n", "completion": " uuid: 11354404209 Yes, Pegasystems has a data science team of around 50 people.\n"}
{"prompt": "What is the main reason for the call? \n\n###\n\n", "completion": " uuid: 12428091307 Introducing themselves and discussing the company's product line and use cases.\n"}
{"prompt": "What is Jimmy's background? \n\n###\n\n", "completion": " uuid: 12428091307 Jimmy worked as a management consultant at McKinsey before joining his current company where he works mostly on product and customer development and sales. He has a degree in machine learning and is mostly interested in NLP.\n"}
{"prompt": "What is the company's approach to data science? \n\n###\n\n", "completion": " uuid: 12428091307 The company's approach to data science is business-driven rather than centralized. They identify use cases that are associated with various business units and have separate engineering teams associated with each of them.\n"}
{"prompt": "What are the main products that the company is working on? \n\n###\n\n", "completion": " uuid: 12428091307 The company is working on two main products, one of which is a document processing system that automates the manual tasks users might have of gathering data from multiple files and combining them into one file. The other is a process discovery system that identifies the exact process that users are performing and generates a report of these processes automatically.\n"}
{"prompt": "What is Truefoundry's core competency? \n\n###\n\n", "completion": " uuid: 12428091307 Truefoundry's core competency is model deployment and everything after that, including scaling, EB testing, concept drift tracking, and monitoring with data drift tracking. They provide a unified framework to deploy models across clouds.\n"}
{"prompt": "Do you have any clients who are not comfortable sharing data back to the company? \n\n###\n\n", "completion": " uuid: 12428091307 Yes, the company has clients who do not want to share their data back, so in those cases, the company provides them with a locally deployed version of their system.\n"}
{"prompt": "What is the company's approach to ML training and research? \n\n###\n\n", "completion": " uuid: 12428091307 The company's approach to ML training and research is mostly on generated data, and they do not do continuous training or ML work using client data. They continue to update their software and release new versions for clients who are interested.\n"}
{"prompt": "How do developers do training on the company's system? \n\n###\n\n", "completion": " uuid: 12428091307 Developers can submit a training job to Vertex AI, build an image, and then use VMs to conduct the training.\n"}
{"prompt": "Who is joining the call? \n\n###\n\n", "completion": " uuid: 11354392885 Abhishek and Sabnesh\n"}
{"prompt": "What is Abhishek's background? \n\n###\n\n", "completion": " uuid: 11354392885 Abhishek graduated from IT in 2013 with a degree in Computer Science and worked at Facebook for around 5 and a half years. During his time at Facebook, he worked on different teams like the Distributed Caching System team, leading a mobile performance team, and eventually leading the business organization there.\n"}
{"prompt": "What does Trip Foundry focus on? \n\n###\n\n", "completion": " uuid: 11354392885 Trip Foundry is focused on solving the ML deployment platform.\n"}
{"prompt": "What is the main infrastructure used in the company? \n\n###\n\n", "completion": " uuid: 11354392885 The main infrastructure used in the company is GKE-based.\n"}
{"prompt": "What is used for the feature store? \n\n###\n\n", "completion": " uuid: 11354392885 Feast is used for the feature store.\n"}
{"prompt": "What is used for scale-to-zero things? \n\n###\n\n", "completion": " uuid: 11354392885 CSI driver is used for scale-to-zero things.\n"}
{"prompt": "What is used for monitoring? \n\n###\n\n", "completion": " uuid: 11354392885 Google's internal monitoring tool is used for monitoring.\n"}
{"prompt": "What is the purpose of Pub Sub Enabled Cloud Function? \n\n###\n\n", "completion": " uuid: 11354392885 The Pub Sub Enabled Cloud Function is used to send requests to cases and provides throughput control so that it does not choke like Kubernetes chokes.\n"}
{"prompt": "What is the name of the multimodel server used? \n\n###\n\n", "completion": " uuid: 11354392885 The name of the multimodel server used is Triton.\n"}
{"prompt": "What is the purpose of OCR model? \n\n###\n\n", "completion": " uuid: 11354392885 The purpose of the OCR model is to efficiently deploy it on the infrastructure without incurring additional GPU costs.\n"}
{"prompt": "What is the purpose of using Secret Manager? \n\n###\n\n", "completion": " uuid: 11354392885 The purpose of using Secret Manager is to store the secrets permanently and securely, and not rely on Kubernetes to store the secrets.\n"}
{"prompt": "What are some of the challenges that Ankit and his team at locus are facing? \n\n###\n\n", "completion": " uuid: 12249609647 Some of the challenges that Ankit and his team at locus are facing include improving geocoding as a problem, addressing transaction time at the door prediction, figuring out the premium pricing for the prime delivery slot, and possibly identifying the value-based pricing\n"}
{"prompt": "What is the data lake that Ankit and his team are using? \n\n###\n\n", "completion": " uuid: 12249609647 Ankit mentioned that they currently use file storage S3 for the data lake since their load is currently not large enough, but they may explore other options like Snowflake in the future\n"}
{"prompt": "What is the team structure like at locus? \n\n###\n\n", "completion": " uuid: 12249609647 Ankit has a team of roughly 7 data scientists, one or two data engineers, one data analyst, and a DevOps. The team collectively works on structure and non-structured data and leverages pre-trained models and libraries like PyTorch for development and experimentation.\n"}
{"prompt": "What type of models is the team at locus currently experimenting with? \n\n###\n\n", "completion": " uuid: 12249609647 The team at locus is currently experimenting with several machine learning models for different use cases, including optimization, geocoding, addressing transaction times and premium pricing for prime slots for delivery, but nothing has been put into production yet.\n"}
{"prompt": "What do the experiments the team at Locus have in addressing the address problem? \n\n###\n\n", "completion": " uuid: 12249609647 The Locus team has experimented with different approaches to NLP that specifically support address problems, either to train from scratch or to use pre-trained embeddings. They concluded that character-based embeddings tend to perform better than token-based embeddings because they preserve the punctuation and other significant characters in addresses.\n"}
{"prompt": "What is the business model of Health IQ? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ acts as a middleman between insurance carriers and customers with a focus on healthy lifestyles, offering discounted rates to customers who are likely to use insurance less. They generate leads and engage with customers to sell policies. The company is currently focused on Precision Medicare, which uses health data to recommend the best plans for individual customers.\n"}
{"prompt": "What kind of ML problems do they solve at Health IQ? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ works on lead scoring, identifying additional features for leads, and augmenting demographic data from third-party vendors. They use AWS, including Sage Maker and Sage Maker Studio, for model deployment and batch inferencing. All work on ML is done in-house by a team of engineers, without a formal differentiation between data scientists and machine learning engineers.\n"}
{"prompt": "What are the three broad areas of Health IQ's business? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ's business can be broadly divided into marketing and lead generation; sales and dialing leads; and the back-end process of getting paperwork together, sending it to carriers for approval, and getting policies in effect. ML is used to identify the best features, score leads, and augment demographic data.\n"}
{"prompt": "How does the company prepare for AP (annual enrollment period)? \n\n###\n\n", "completion": " uuid: 10346094649 AP is a 55-day period during which insurance companies do 70-80% of their annual business. During this time, companies focus on selling policies and do not engage in extra work or code development that could potentially break anything or slow down the business.\n"}
{"prompt": "How does Health IQ use data to recommend the best plans for individual customers? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ uses health data from electronic health records, lab tests, doctors and pharmacy visits, and drug history to build models that predict a person's needs and recommend the best plans. They are currently focused on Precision Medicare, which is a multi-level, multi-classification problem for each of 150 diseases, and requires identifying which plans are active and which are most suitable for individual customers.\n"}
{"prompt": "Where is Beville located? \n\n###\n\n", "completion": " uuid: 11656830826 Beville's location is not mentioned in the context.\n"}
{"prompt": "What is the issue with Beville's Chrome? \n\n###\n\n", "completion": " uuid: 11656830826 Beville cannot connect to their camera on their Chrome.\n"}
{"prompt": "Where is Brampton located? \n\n###\n\n", "completion": " uuid: 11656830826 Brampton is located close to Toronto in Canada.\n"}
{"prompt": "What is the weather like in Brampton? \n\n###\n\n", "completion": " uuid: 11656830826 During December to March, the weather in Brampton is very snowy. However, it is currently not a lot of snow.\n"}
{"prompt": "Where is the speaker, Nikki, based currently? \n\n###\n\n", "completion": " uuid: 11656830826 Nikki is currently traveling in India and may take a bus soon. However, Nikki is based out of SF.\n"}
{"prompt": "What is Truefoundry's primary focus? \n\n###\n\n", "completion": " uuid: 11656830826 Truefoundry focuses on deployment and monitoring of machine learning models.\n"}
{"prompt": "What cloud does Procore use? \n\n###\n\n", "completion": " uuid: 11656830826 Procore primarily uses AWS.\n"}
{"prompt": "Where do they primarily do their machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 98% of machine learning work is performed on AWS.\n"}
{"prompt": "Does Procore use Sage Makers? \n\n###\n\n", "completion": " uuid: 11656830826 They used to use Sage Makers, but they now prefer their own solutions.\n"}
{"prompt": "Does Procore use Kubernetes? \n\n###\n\n", "completion": " uuid: 11656830826 Yes, Procore primarily uses Kubernetes for their machine learning.\n"}
{"prompt": "What is the reason for the call? \n\n###\n\n", "completion": " uuid: 12339635717 The caller is working on a thesis and is trying to validate by talking to practitioners.\n"}
{"prompt": "What is the caller's background? \n\n###\n\n", "completion": " uuid: 12339635717 The caller comes from a machine learning background, worked at Facebook and a startup, and has a master's degree from UC Berkeley and a bachelor's from IIT Kharagpur.\n"}
{"prompt": "What is Chandram's background? \n\n###\n\n", "completion": " uuid: 12339635717 Chandram has a CD in Computer Science and Engineering from KIAT University and is currently working as a software engineer related to machine learning operations and previously worked as a data scientist.\n"}
{"prompt": "What cloud providers does High Radius use? \n\n###\n\n", "completion": " uuid: 12339635717 High Radius uses AWS, Google Cloud Platform, and on-premises for their cloud environments.\n"}
{"prompt": "What is the biggest challenge faced in orchestrating cross cloud models and architecture environments? \n\n###\n\n", "completion": " uuid: 12339635717 Performance-related issues such as memory leakages in inference endpoints and use cases that require loading and returning of predictions for huge model file sizes.\n"}
{"prompt": "How many people are on the MLS platform team and data scientist team? \n\n###\n\n", "completion": " uuid: 12339635717 The MLS platform team has 15 people, and the data scientist team has over 100 people.\n"}
{"prompt": "How are the code and dependencies across multiple cloud providers managed and abstracted? \n\n###\n\n", "completion": " uuid: 12339635717 Cloud-native utilities are written, and a naming convention is used for files paths that denote which cloud environment is used. The code is written in a way that all cloud environments are abstracted by a single function that knows from the file path which cloud environment to fetch the file from.\n"}
{"prompt": "What was the goal of the call? \n\n###\n\n", "completion": " uuid: 12428091030 To understand more about the company's data science initiatives, use cases, structure, tools, key priorities, and challenges.\n"}
{"prompt": "Who are the co-founders of Truefoundry and what is their background? \n\n###\n\n", "completion": " uuid: 12428091030 The co-founders of Truefoundry are Aman Raj and his teammates Abishek and Nikunj. Abishek and Nikunj used to be at Facebook where they saw a really good system called Bill on Earth that allowed ML developers to be independent.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 The goal of Truefoundry is to help companies in their journey of machine learning operationalization, by providing infrastructure for training, testing, and deploying models to a broader environment with the right cost effectiveness and engineering practices.\n"}
{"prompt": "What is One AI? \n\n###\n\n", "completion": " uuid: 12428091030 One AI is an internal platform that helps data scientists spin up their own small workbench to work on, based on a microservices platform. It also has built-in support for Jupyter notebooks and VS Code.\n"}
{"prompt": "What data storage system is used for storing experimentation data? \n\n###\n\n", "completion": " uuid: 12428091030 Snowflake is used for storing experimentation data.\n"}
{"prompt": "What metrics platforms are used by the data science team? \n\n###\n\n", "completion": " uuid: 12428091030 The data science team uses MLflow and Seldon for logging model metrics.\n"}
{"prompt": "Who is responsible for deploying the models created by the data scientists? \n\n###\n\n", "completion": " uuid: 12428091030 The ML engineering team is responsible for deploying the models created by the data scientists.\n"}
{"prompt": "Do you use GPU instances for deployment? \n\n###\n\n", "completion": " uuid: 12428091030 No, only CPU instances are used for deployment.\n"}
{"prompt": "Do you maintain separate namespaces or projects within Kubernetes? \n\n###\n\n", "completion": " uuid: 12428091030 Yes, namespaces are used to maintain access control and are sometimes based on projects, but not necessarily.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11942287761 To understand more about Soroco and Truefoundry and see how they can potentially help each other.\n"}
{"prompt": "What does George mention about the companion mode? \n\n###\n\n", "completion": " uuid: 11942287761 George mentions that he just learned about it and that his audio is always better through his phone.\n"}
{"prompt": "What is Soroco's goal? \n\n###\n\n", "completion": " uuid: 11942287761 Soroco aims to help organizations understand how work gets done globally through collecting data points and analyzing patterns in the data.\n"}
{"prompt": "What is an example of a real use case of Soroco's analysis? \n\n###\n\n", "completion": " uuid: 11942287761 A real use case is when Soroco worked with a large supply chain customer to improve their purchasing process.\n"}
{"prompt": "How does Soroco deploy their models? \n\n###\n\n", "completion": " uuid: 11942287761 Soroco puts the model into a Blob store location and when the product gets deployed, they are fetched by the product and then loaded locally.\n"}
{"prompt": "What cloud platforms does Soroco use? \n\n###\n\n", "completion": " uuid: 11942287761 Soroco uses Azure and AWS.\n"}
{"prompt": "Does Soroco plan to migrate to GCP soon? \n\n###\n\n", "completion": " uuid: 11942287761 No, Soroco does not see any current customers on GCP.\n"}
{"prompt": "Does Soroco use Kubernetes? \n\n###\n\n", "completion": " uuid: 11942287761 Yes, Soroco does use Kubernetes.\n"}
{"prompt": "What are the three broad business cases that Zulily is trying to solve? \n\n###\n\n", "completion": " uuid: 11487646267 The three broad business cases that Zulily is trying to solve are \u2014 personalization and recommendation, forecasting the sales of a product, and supply chain optimization.\n"}
{"prompt": "What kind of models is Zulily using for recommendations? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses a mix of decision tree-based models and deep learning models for recommendations.\n"}
{"prompt": "What cloud platforms is Zulily using? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses both AWS and GCP as their cloud platforms.\n"}
{"prompt": "What is the tech stack used by Zulily for deploying models? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses Kubernetes for deploying models, and everything is containerized using Docker.\n"}
{"prompt": "Why did Zulily choose to live in two clouds? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily chose to live in two clouds to leverage the best of both worlds. Google BigQuery and data management across Google Cloud and productionizing models for real-time customer services on AWS.\n"}
{"prompt": "What ML training platform is Zulily using? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily is using Kubeflow as their ML training platform to manage and deploy ML pipelines and custom components.\n"}
{"prompt": "What is the in-house tool used by Zulily to track experiments? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses Model DB instead of ML Flow to track experiments.\n"}
{"prompt": "How is Zulily's team structured? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily's platform team manages the infrastructure and Kubernetes clusters. Data scientists build the models and there are applied ML engineers who bridge the gap between the platform and the models to put them into production.\n"}
{"prompt": "What is the interface between data scientists and ML engineers at Zulily? \n\n###\n\n", "completion": " uuid: 11487646267 ML engineers work closely with data scientists to bridge the gap between their work and putting the models in production.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " 1) One of the projects I am working on - if connecting to internet using Wifi => would like to know what device we are having and every detail on that. + would also like to learn the difference between IPhone12 or IPhone13 etc. Would want to have feedback loops. Some statistics on models will be difficult to deliver. Some sort of annotation tool => feedback tool.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " - [ ] TECH STACK: Python/Scala => Make a package => Push that to artefactory (Frog repository - internalised) \n\n- [ ] In both of these places => 1st job had a platform to launch the model. 2nd place had data bricks to help with compute, had to do own version controlling etc and all the pipelining that will be in AWS and Azure. 2 Cloud providers. Everything will be partitioned into WorkSpaces => before prod, there will be diff stages. It did;t matter much for us. A/B Testing was not very important for us. \n\n- [ ] There are few things that are vital: Model Monitoring, Feature Monitoring, Data Monitoring.  (MLFlow or some version of that) => Model objects in place etc. Some visualisation for the same. Discrepancy between multiple records => all will be pushed into DAG. \n- [ ] We use MLFlow but not for model versioning. It is taken care by us using Artefactory. Some of the deep learning models are too big. Only use for performance tracking the model. All KPIs etc. Anything that is data intensive => directly goes into the artefactory. Docker also artefactory. \n- [ ] Version control - release process, Jenkins. \n- [ ] DAG: use airflow for triggering things. Cronjob that runs that. Data Curation to model building etc has to be in another thing. One Airflow Dag. \n- [ ] Its how the leadership deals with utility providers - earlier Azure, then AWS. \n- [x] Velocity: In my 1st job, basically created a DAG structure. Every node would be some compute => data transformation etc. Entire structure would be created in R => make the DAGs. and then encapsulate all data requirements as Class objects in R. Not utilising airflow or anything. Gave very nice performance improvements. (PROBIA)\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * Cost Optimization \n\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Would you help with optimizing the Cost for training? Because if the Training is non-optimal, it would eat a lot of cost. \n* Is there a way to know if the model is eating too much cost - don't want to be monitoring the UI 24*7 (- [ ] One project at Velocity - one model ran us 1000$ a night and we were not optimised. We want to know when not doing great. Can\u2019t keep on monitoring that UI 24*7. \n)\n\n* How do you guys Manage Artfacts? Important for Deep learning models. Also data logging is a problem for Deep Learning Models. WanDB has a good solution around it\n\n* If I have to switch from the current system to your, would it be a seamless switch or integration? i.e. just adding some Boiler plate code and it will work?\n\n* How much have you thought of IP? How do you protect it? When we say these are loosely coupled => we give onus on the MLOps person to be able to stitch these things together => HAVE TO EXPOSE APIs in some capacity. Because of APIs, has access to some code. How do you limit that?\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " - [ ] Would you be able to add annotations? Spacy etc. Brainless integrations. IF some model training where there is very few data points. We would not know every time what the final label is. In the inference thing if we surface the records up, 2 things can happen: * Could go into retraining * Add annotations \n\n- [ ] SERVICE FOUNDRY FEEDBACK: Its Basically - borrowing functionalities from cloud Providers. Something that is on mind for few years. Say we know there\u2019s one DAG that is supposed to run and you want to somehow optimise the cost of it. Because of running this workflow, you want to optimise the cost in terms of load balancing etc that needs to happen. If not rely on kubernetes, the problem is there is this gap. AWS - Actual compute and DataBricks to utilise the compute. I know I could use like 30 nodes, 40 nodes, 100 nodes => and i want to scale up and Spark is good at that. I also want to optimise on the code being written. But we could surface that: If you are running a Spark job utilising the Kubernetes - can tell real time stats. HOW much of CPU is utilised, how much multi-threading you are doing etc. Because of this, you reduce the cost. SURFACING that would be nice. If we have this capability, smaller companies that are in crunch of money. Get a HSTOP output and surface it in a nice UI. Grid Map or HeatMap somewhere that if your process ran for 20 mins, what is the distribution plot => First 100 processors or first X processors to tell that the engineer has to optimise.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Conversational AI Platform - automate conversations that Enterprises are having with consumers. SDK that can go inside Apps, etc. Along with the bot building platform, complementary product for Contact center agent. \nOutbound communication - Campaign Mgmt etc and personalisations => Campaigns can be delieered \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " 100 Member Engg team, 10 member DS Team - 3 persons more on research and remaining doing both research and engineering.\nModels: BERT and fine tune it for our use case. Also create classifications model. Bot level models are there - which sentence lead to what.\nUsing Collab, have custom dashboards where pump in data into Open search. Deployments are all containerised - Kubernetes and cloud - GPU based. Support all 3 clouds - because of data localizations and loss in diff geographies, have to support all clouds.\nDevOps team maintain kubernetes cluster and developers have access to it. Healing etc are taken care of by DevOps. For CI/CD pipelines => all the code goes into BigBucket => Container registry and then Jenkins triggers the rest. Thinking of using ArgoCD.\nEKL Jobs - are based on AirFlow => data goes into blob stores for Azure and S3 for AWS. So far, have exposed spark clusters. Experimenting with SnowFlake - it can be the tool that other teams can use to extract data for needs.  \n\nThey were trying versioning using MLFlow => but it hasn't been operationalised. It was a need. Once model is built, ML Engineering team converts the model into services.\n\nFor DB Mgmt and Kubernetes monitoring => L1 alerts from NewRelic. Kubernetes metrics - go into Prometheus. Model Performance => how diff versions are working, for that, we are pumping data into Open sEARCH and have built custom logs. \n\nHave one common Jenkins to control all regions. Prometheus - data is stored separately. Thinking of making the entry points common. Open Search - they are currently different.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " They were trying versioning using MLFlow => but it hasn't been operationalised. It was a need. Once model is built, ML Engineering team converts the model into services.\n\n* A lot of 0 to 1 thing happened before I joined. Building repeatable flow would have taken 6-9 months. Automation keeps on taking the backseat. A lot of things we haven't handled => Drift analysis eg. (KUBERNETES ADOPTION - We started doing in 2019) => Developers were facing challenges in scaling up and down. Microservices side and it got propagated to ML Side. \n\n* Currently struggling to be GDPR Compliant. If they have to rely on us to expose all the controls, it will become difficult for them. \n\n* HIGH USE CASE: Real time Monitoring for a Real-time use Case. Have only real time. Batch use cases are not there.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Is Deployment FastAPI based or FlaskAPI? You can use anything like PytoRCHServe, TensorFLowServe etc\n* Every single Deployment => you can deploy wherever you want. \n* We can expose the part of cluster creation automatically => want a cluster in XYZ. SLEEP WorkSpace => its constantly incurring cost. It will re-start the machines as well. Each Dev can also track the billing part of it. \n* Are the deployments happening in our Kubernetes cluster or TF Cluster? (Collab ++ Kind of thing => You can do whatever you want). You can get a copy of the entire Infra on your own cloud => Only your own workloads on your side. \n* 2ND QUESTION: Let's say we have currently 6 different regions: Will we need to have 6 diff dashboards or could I go to one single UI and see? There will be a clusters tab => There is a Control Plane. You deploy CP on one of the clusters. CLUSTER LEVEL Access and WORKSPACE Level access.\n* What is the current Stability of the Product say, a hem chart you have to install \n* Will MLFoundry only work in training? Or even after depoyment, you can continuously keep tracking. Real time inference monitoring will not be handled by this\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " SaaS platform => Companies can geenrate content using AI Algos. Generative kind of models - not a GAN. Very hard to get perfect fidelity.\nMultiple AI Models which do different things. We don't scale very well: 1) Narrativ Model - what's the narrative telling to users. 2) What kind of content should go into what sequence\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Predictive system => The ad which the system has proposed : Is it going to be a winner?\nOff the shelf solutions. \nEven in these, its not 1 Uber Model. There is a model from our side which works from our side. Lots of decisions coming from different things. \n\nAI Pipeline: Small and niche: 1) Pytorch 2) Tight control on what kind of models we develop. 3) Have own way of versioning the models and things. 4) How do you deploy? AWS mostly but most solutions are not asynchronous. Its not a HTTP Kind of time frame or response time. Job is created => job runs, soluton space exploration. Simple EC2 machines through Kubernetes.\n\nIs it mostly batch inference on the models: Actors come on what kind of space we explore. Models give decisons on discrete points on the space. Do a guided generation. Push the models towards certain areas in the space. \nTraining is offline, GPUs in office. System itself has a large re-inforcement loop. Re-inforcement learning at a higher level. \n\n** A lot of things we have done is manual - everything is not automated. Collectively brainstorm => we compare -> etc. What I see imissing is DATA VERSIONING For reproducibility.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * Lots of good solutons for Model Mgmt and deployment => Hard challenge is taking it all the way from tracking, Experimentation and then documenting it. Have to do it manually and post production model including traffic etc. Still feels too much hassle.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Where do you host the model and load it? Model stored and hosted in S3. By the time model is laoded, it seems the model is not responding to health checks. S3 becomes too slow to pull the model and load it from there. What we have done is we use EFS and mount directly on to the machines. And then you have to do a lot of jugglery to get the model to be loaded. (HEALTH CHECK TIMING is customizable - AWS will not wait, AWS API Gate will crash)\n\n* Inferencing Code: We could write anything in the inference code? There is a lot of pre-inference call that needs to be done. It runs through a pipeline of things and then take a decision.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * What I see imissing is DATA VERSIONING For reproducibility.  How is the data changing etc? Need to connect the loop back => how do you connect the data, how do you loop back to the model.\n\n* There seems to be a bias that every model is a classification model => Eg- generative and ranking models which are hard to fit. The thing is most teams tend to have logging and monitoring by themselves? If this can fit into existing workflow, then it becomes easy. When you have an issue, you don't want to be scrambling here and there.\n \n* If you have issues, you don't want to be keeping track of service or model. Right now, the dashboard feels a bit of flat. If you want to be dealing with 4-5 projects within it, it might be easier to visualize it. And then again you are lost. \n\n* When you say Service foUNDRY, or could you configure it to deploy in our own VPC? We can ship it as a Helm chart and you can put in your own Kubernetes cloud. Not grant public access etc. How do you do security? How would you configure those scenarios? If you are already using VPN, all endpoints are in your cluster. We are using ISTIO as a load balancer.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * We are a Multi-tenanted system => User see only models triggered on their side of the system. \n\n* Operators see all the side of the system\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * What volume of data is your platform capable of handling?\n* Is there a dashboard where we can correlate - outputs and also comparing with different ORGS or diffeerent verticals? (Is there we can compare different points)\n* Could we compare the data statistics between models and see?\n* Is there a way to get holistic view of alerts in terms of training? \n* Purely in terms of Pipelines? AUTO-RECOVERY => infra level re-price => We don't control any of that.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * We have a model that does Propensity calculation => Example which customer has higher propensity. Want to enable brand users to see. There have to be a MLOps pipeline that makes it self-serve for the user? If it fails for some reason => what all feedback will go back to the user.\n\n* Prediction to show how much time the model will take to learn? User is running a long user call. Feedback to the user => Expose the APIs from our system. \n\n* Why is it a long running job? Because its not just model inferencing that is happening. But there will be training process also initiated. Whether the process is successful.\n\n* If N is running, X is failed => We can do easily.  \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " * Building Recommender Systems => Understanding and seeing the data, how it is organized etc.\n* Track which tab to tab do they travel? Learning path could have audios, etc. Try and maintain a flow of where the user has stopped. \n* We also have Logical profile of the users => psychological metrics. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " DATA STACK: As I told, we are still not there - transactional data etc. But don't have Data Warehouse set-up. Trying airbyte to create different schema which could be used for analysis and creating models. \n\nData Stack: It's currently at 0. Where is the data getting stored? Its in 2 phases => MySQL and some part of data is in MongoDB. \nWhat kind of analytics are we working on? Mental Health company => people can come and do self care sessions, speak to counsellors etc.\n\n* When user signs up, we have all of these things in the app. We have an initial understanding from psychometric tests. Conclude User profile based on 4-5 parameters. 1) PERSONALISED Tab for them => Whatever goals they have chosen => these are the 1st few things you have to do. 2) MOOD Ratings of the user => Recommendation based on what user is feeling day to day. And what you have been doing about it. \n\n* Can't be build like a normal Recommendation system: If 2 people are doing a stress related path, it doesn't mean they have the similar problem. CONTEXTUAL Information in place.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Have a huge User base growing everyday => Can help the user become better ==> Little Personalised.\n* Is there any model already? Build something that is clinical efficacy. Doing research as to how physical and mental data be correlated.\n\n* From a data standpoint, what distinguishes these folks? Mood Rating.\n\n* Most companies try to think of it is the trending items? I want to keep the baseline better. User Cohorting => it helps group users. Age, Geography, state etc. 1) USER PROFILE => Changing 2) COLD START PROBLEM: Bayesian => Learning pathway is well defined?\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Intelligent Document processing - Medical invoices, Loan documents, etc. Classify, extract the information.\nMonitoring is most important. \n\nThey provide intelligent Document processing for Industry Applications. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " They wanted to use MLOps for Deployment and Monitoring - 100% will happen only based on data confirmed by customers. \nWe are using VMs => trying to move towards Kubernetes based solution. \nShowed a small demo where uploading an income statement, able to extract entities out of it and mark if correct or not. \n\n80-90% Use cases are NLP\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " 215 People team in iSchoolConnect. WebDev - 25 members, ML Engineers - 15 Engineers. + Huge data annotation team. \n\nIn 2020, very few companies working in inference side of things: \n1) Candidate Recommendation Engine: 2 sides - * When students come, similar to what Yocket has. Where you are likely to get admitted.\nCurrently, 5 verticals that work on ML.\n2) Search: \n3) VIA: Video interviewing analyser => Better speaker in interviews etc.\n4) DWM: I lead currently. Document writing mentor. For admission purposes, students hvae to write essays.\n5) Proctering Engine: Eg - GRE etc.  When Covid hit, all the businesses went online - ETS. 30 Mn students apply every year. The entire load came to us. Built the systems, scale them. 10Mn load. 3RD Party to Procter U. All the load that came - backend went to us. \n6) Analytics: How products are doing in market etc\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Started in 2017 and been here since the beginning of iSchoolConnect.\nMost of the things are in GCP => We are official Google partners. We don't have internal platforms.\n\nWe used to use VMs earlier, now making move to VertexAI. \n1) For Model training, we use VMs. We don't have to train models so frequently. \n2) For serving, depending on use case => * Recommendation engine => API Servers and scale horizontally. * Procter Engine =>We used to work on 6 underlying models => Orchestrated it through Docker Compose => 32GB of GPUs. Lot of data movements \n3) For monitoring, Data Drift and others => EvidentlyAI => recently tried to work with them => has a huge potential for us. APIs also allows to dump output in JSON format. Build separate dashboards for every purpose \n4) Model Cards and training: Used MLFlow but even though we went into establishing practices => not a lot of models get screened. DONT REQUIRE TRACKING MODEL VERSIONS much. Use a combination of DVC and then use GCP.\n5) Internal demoing part: Built on StreamLit. LabelStudio - did POC with them. Spent 1.5 months with them => won't waste my time. Started with streamlit and built the entire platform.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Monitoring was a big need - started using Evidently. \nBefore Evidently, was building own using PyChart etc. No point of building anything from scratch. It took a lot of engineering efforts otherwise- UI was also ready. There are places where it is not able to track Multi-variate (Milti-label or multi-classes) distributions, only binary distributions. (OPEN SOURCE PROJECT => If using for commercial purpose, you need to open source) \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Have had discussions with other start-ups on trying to use the platform.\nThere was this issue of Data privacy => What are the options that will be available? Just like we use GCP, we can spin up instances and we can use it as a cloud. While inferencing, code is also pushed and deployed in one of the pods in Kubernetes. \n\nWhat are the options to keep the data in particular region? Eg: We want to keep the data in USA and Europe. Can we keep data in region? 2ND and 3RD OPTION work best --  We will want our GCP. You take the infra and set-up whatever you want to set-up. Updates can be pushed.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Honestly, all the 3 components you are integrating - it will be very useful for us. At iSchoolConnect, we don't have big DevOps teams. A lot of time gets wasted asking for permissions and all. You have terraform and spin up things, we also use Terraform to automate a lot of internal things. \n\n\nIf we want to spin up an instance just like we do in SageMaker, I will spin up and works. Something could integrate all the things we have. My role should be solving problems and ship things faster => Solving problems. Staging, Production, Release. \nIf someone new comes, with their access keys, we can restrict permissions for resource => No worry about Cost. \n\nLast bit: UI side => it depends on project to project. Different dashboards built and gets integrated at the end. Used streamlit and built everything including annotations etc.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " - Focusing on NLP problems. \n- Just hired an MLE, 2 full-stack, 0.5 frontend engineer.\n- Good number of design partners - few between Series A and enterprise. \n- Main model that we are deploying is a huggingFace model and we are doing typical out of box deployment. \n- Not doing any training, any evaluation and we are about to start fine tuning versions of it. \n- We are about to get to a point to alleviate a lot of headache on our end. \n-\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " - Only huggingFace. \n- worked most with Amazon Sagemaker for most purposes. \n- Also have worked with MLFLow and Kubeflow as well. \n- Mostly tracking experiments. \n- Use colab for training. \n\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " 1. Soc2\n2. What if we have our own Kubernetes cluster. Its cool to be out of the box on the cluster. How does it interoperate with existng infra. \n3. Some amount of caching some result as well. We are caching results and dealing with real time predictions. \n4. We expose two endpoints and prediction endpoint does not. \n5. We anticipate that we might have some hierarchical models vs a simple sentence similiarity model. \n6. How do you add extra value from pure MLFlow and pure Kubeflow. \n7. How do we rely on an alpha product. Stability or security. \n8. Custom graph logging  \n9. Deploying of a service\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " - Ad personalisation at Spotify. \n- 8 engineer at Jupiter.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " - Worked with a few startups helping them build. \n- Honestly, I didnt get a time to explore TF. \n- What would I use right now. We are building a lot of Airflow and data pipelines. And we dont have strong monitoring on them. \n- We have data pipeliens which run weekly. We have some ML model that read those data pipelines. \n- Everything is running by Airflow. \n- Something should be outside of Airflow which will tell me here is a data that I expect to be there and if things fail report to me. I just want quick feedback. \n- Data drift or pipeline breaking is what I was going to report. \n- These pipeline would geenrate tables with statistics, predictions hapen in real time. We dont want to aggregate everything and we want to make those estimations uikc. \n- Evrry Sunday night we run something and Tuesday 3 PM user faces the order. Last statistics of the pieplien. \n0 Ther eis an ML Backend service which will read the latest stats, what the user did , create some featurs and pass it to a heuristic or ML model. \n- FastAPI based - backend engineers maintains the Terraform setup. I just create a docker container and they figure out. \n- We have a few applications. I think all of them have at least one ML model in them. Usually some model and heuristics. ML models - I am using XGBoost only. \n- We have a lot of categorical data and use XGBoost. We dont jave advanced features. \n- Get retrained every week. We dont track the versions of these models. If te mdoel gets trained every week- its going to go to a cloud storage bucket. Whenever a request comes it reads the latest model. Its a hot swap. \n- Because the models don't block the user UI. As we move towards more UI stuff. I have worked on MLOps a fair bit.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " - Tech stack- Google cloud, - Data pipeline, - Airflow for deployment\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " - What would I use right now. We are building a lot of Airflow and data pipelines. And we dont have strong monitoring on them. \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " - Data pipeline monitoring outside of Airflow. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " - Deployment is not a concern currently.\n- Experiment tracking is. \n- Might be awayed a bit because of minitoring as well. \n\n\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " - Use notebooks for training. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " - Large language models, like BERT. Want to be able to track both for short term and long term. \n- Give explanation of how we are better than WandB / Neptune / MLFlow etc. Factors- ease of use, cost. Dont want a lot of features. Simple logging, reliable, shareable, searchable.  \n- Actually okay with public cloud. Need to mention about VAPT. \n- Dont necessary need a lot of magic. Okay to do their own logging. Want checkpoints, metrics, hyperparameters, Git sha- ideally have those things connected neatly. \n- Should work from both Jupyter notebooks & python scripts. \n- Show demo of the product in the meeting/ \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Bengaluru: 10 people, 20 worldwide\n2018- Since 2018, ML\nMostly a backend engineer till i joined MindsAI. \nBuild a prduct similar to New Relic\nEarlier on system side.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " We have our ow product which is a training platform built on top of Ray.\nOn top of that, building domain specific product for Semiconductor fab scheduling problem.\nTaking our platform and customizing it for them. Our product is called DeepSim. \nMore work was on training side as well as inference\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Stack: RayServe => Inference. Not yet anything for Monitoring and deployments.\nKubernetes - cloud agnostic. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " - Big part of problem for us is that its windows. Support of all these things on Windows. Most of cusotomers tooling is on Windows.\n- Support for Ray is not great on Windows. Have to do hacks like keep minimal stack on Windows and use GRPC kind of thing.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Do you handle fractional GPUs. Can see multiple teams using it. For a staging kind of a use case, they may want to share GPUs within the team.\n\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * If comparing to our platform, it is nor productised and its not API first. Use case is for internal usage. \nWe don't offer the platform as an offering on its own. \n* It looks really cool. Can be used in places that are ML Shops.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Focus on Human resources Insights data. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Using TFServe. Want to keep models as simple as possible. TF 1.0 is a bit of a pain. Now, they have added Keras. \nWe are very traditional - mostly excel for tracking. Report all the findings. \nWe just have TFServe. Serve is as a GRPC Object. Still trying to figure out. Earlier, was not using docker. Right now, dockerizing it. We have a simple docker compose file and we run those commands.\nFor Inferencing, use CPUs. For training - we have own set of computers to train models.\nWe don't do tracking on the DS side. When engineering has issue calling our models, they call us. TFServe - GRPC report has been quite sable.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * When we create a model, too many parameters involved and we do Brute Force manner. One pain-point is what tool to optimize.\n* The way we have data, it is not well. For new data coming in, hard to marry the data. \n* Optmizing the model is problem. \n* We are Microsoft partners and hence it makes sense to use Azure products. Cost and logs is quite easy to see. Applications Insights => quite useful to us.  \n* Validation is very tricky. We don't have the global minimum but we have the local minimum. \n\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Code syntax in MLFoundry seems to be similar to Keras. Do you use Keras under the hood?\n* Sign-up on app.truefoundry.com and will try on free time \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * Major concern for us is private cloud. That will be a huge cost for us. Pipeline for creating models and deploying models.\n* Even when we ingest data, you can use our own storage ==> Control plane or Data plane. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " 4 Months - Buddy in HC Sector. Germany for 2 years. Before that, doing PhD.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Multiple domains: 1) Recommendation Engine, Fraud Detection etc. Other projects related to 360 virtual tool. Have DataBricks in place.\nEvery company has their own systems ==> Build models using Pre-trained models etc => Take models in Prod with AWS. We dockerize and convert models into APIs. And deploy in the form of dockers. Either in EC2 . Also trying out diff things related to DBricks -- Experiment tracking etc.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Currently, deployment is handled by our team and trying to have MLOps guys internally in our team.\nKubernetes : Not using right now. \nDataBricks: Started POC few months back, using it for 1 of the projects. DS - who has deployed using DBricks ==> there are some challenges. I am not a very big fan of AutoML Solutions.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " DataBricks provides good AutoML. They don't provide any IDE kind of stuff as integrated with DataBricks and that is something I don't like.\nAre you using Spark internally? For inferencing pipeline, we will try to use Spark in near Future. All our code is in Python. Also use DBricks for our deployment. Create Feature Store in DBricks itself. We use Feature Stores quite a lot. Can deploy APIs using DBricks. \nFor feature stores, not sure exactly how that is being done. \nPREDICTONS: Both Online + Batch predictions. DBricks doesn't handle real time deployments well. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Data Drift/Feature Drift: Will it be supported?\n* Could we define the Custom Metrics in the monitoring dashboard?\n* Does it power the deployments via Docker?\n* Suppose there is a training data problem or data drift: Could I set a threshold on what level of threshold should I re-train the model? How frequently do I need to measure Data Drift ==> Alerting part of it. \n* We want to have IDE Support, support for custom files etc. We don't provide the editor part of it. As of now, you can use Collab or etc. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Based in India - malout. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " * It was about last year - discovered MLFlow. Doing POC with another company => structured tabular data. \nDidn't have time to cover the best practices with respect to reproducibility etc as well. \nThat's when we looked at tools: Lightweight, easy ===> Started using MLFlow. MaqV- incubated by MTX. Also proposed using this to the Director of AI and team leads. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Still defining MLOps and it will be priority in 3-4 months. \nBe ready for future when need comes. \nDEPLOYMENT: Doing manually - use KServe or Flask. We are mostly on GCP, But also using AWS for business decisions. All of the models deployed are for customers in the own cloud. \n\nMONITORING: Using Grafana - only system/resources monitoring.\n\nOnly one using it - Doing in a local instance\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " One of the concerns raised: 1) RBAC - Role based access control. \n2) Teams work on different tasks - collaboration makes a lot of sense. \n3) One of the requirements was set-up a Model Zoo. \nModel Registry compoenent of MLFlow would be a good solution. \n\nFeatures missing: RBAC, If want to use it in dev CI/CD Pipelines. Any dev can do something and it can create havoc. Others felt personally - use 1 instance for one project. If you want to do this centrally. If we want to deploy central MLFlow Server, in that case, there's no good way native to the way it is designed.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * CI/CD Integration is most important.\n* They do deployment themselves with some help from DevOps teams.\n* Could we do logging of images at a bigger Scale? Could we do something that DVC does. Note: UI takes space and hence might be difficult. Under the hood, ours is the same thing. BENCHMARK: Metrics and Images we should check as to what happens if we log a lot of things. \n* Do we support for all the integrations that MLFlow has? Eg- Optuna, H20 etc. ===> Lightning integration is on the way and we are adding integrations that MLFlow supports. NOTE: We don't have support for these.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * Model Registry along with Model lifecycle Management is important. Note: We will have this by end of month \n* MqaV- Building and integrating with MLOps. Eg- MLFLow provides a RestAPI for everything. Do we have python APIs or do we  have Java APIs or SDK etc? Suggestion: Python SDK for now. Haven't standardized the documentation interfaces for the REST Interfaces we have added. (INTEGRATION FOR CUSTOM MAQV PLATFORM) . We can plan to expose the other APIs but it will be a lot of work - they are undocumented. Other languages we are not considering  now. \n* Could we visualize the CSVs? We can add the visualiaitons. Helps in better visualizations. => Note: This is now available \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Working for 5 years => Lead the efforts on DS side. Lead efforts on DS Side. How to go about product, features to helping deploy all those pieces.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " QUESTIONS: * Is it batch inference? You don't host the model as an API => We will do it when we make things realtime. \nCurrent blocker is actioning system itself is not good.\n\n* Old or new architecture? Signal processing or neural Nets? Some are Deep Learning Models. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " When we start an account with an idea, whatever use cases => Jupyter Hub. Has security access. \nStart with experimentation of data on Jupyter Hub. Audio needs to be brought on the server itself. Files can get corrupted.\n\nExploration: 1) Experimentation => Start with analytics => DeepDive using ML. Start using simple models and then do state of art (Hyperparameter tuning starts coming into play) \n\nBest Model: Set out to put into Production ==> How we do it? GitHub Pipeline. Use SageMaker to push model into it. Goes into Engieering team. They use spot instances to run batches of pipeline. PostGres SQL DB. Workflow starts with sometihng ==> else we pick up calls from that through sampling algorithms. (5-7 PIPELINES that are live)\n\nTracking: * Things in AWS Configured * Are the models running fine. Error messages etc.\nActionable part: Data also needs to be presentable. DS Team does the monitoring => use MetaBase for ML Monitoring. Coverage .\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " 1) As we scale => we have to keep changing the batch sizes to make it optimal. X Hours have to be maintained as we grow. \n2) As number of pipelines increase, ML Engineering effort keeps on increasing. \n3) We did explore ML Tools but never went into moving forward => Engg team will take the chalelnge\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Questions: \n* Do we have to expose the data to our servers?\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Computer Engineer, Master in PhD\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * Lower cost of APIs. They have a cheaper crude single end point concept ==> Data Science do not need to be backend engineers. Want a way to Productize some analytics. VOLA - reporting tool on top of jupyter notebooks. Still a Jupyter Notebook. Don't have that as a service\n\n* Data Governance \n* When you call deploy, how do you know the service is up and running? Is it synchronous or asynchronous \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Disadvantage for us: Is we are 70% of what you have. \nReally interested in is the Automatic wrapping from Jupyter to FastAPI Container.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Right now, you are priortizing control in the Jupyter notebook. Have you considered using the Cell magic support so that it can hide bit of the boiler plate. Offering both would be an interesting pitch. \n\nWe can give you images that you deploy on your cloud. Don't see before Q3 ==> Any clearance to buy software. \nMID Q3: Defining the OKRs ==> As soon as I see the ML Team ====> We can do a SandBox. We can do a Paid experiment.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Natural Language Generation - blog article generation. \nHow we use large language models - HFace and OpenAI models. We are also in a lot of their data programs\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Largely self serve. Team of engineers who do the backend etc. \nETL Pipelines - GCP, Kubernetes Cluster that runs and scheduler. Unconventional. \nGoes into the data warehouse that feeds the lot of research stuff. \nR&D and ML - A lot of predictive models around user conversion and user churn etc. \nWe also have proprietary online experimentation engine that we use to split test variance of models. Randomization and allocation of users. We have a handful of metrics that we monitor + secondary and tertiary metrics as well. \nWe use custom analysis as well. \n\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Experimentation is what is interesting for us ==> That is of core value to orgs.\nOne of the early employees.\nWe are better than most other competitors. \nIncreasing the cadence of the tests on the experimentation side of ML ==> from 1 to 10 to 100 of experiments per day. \nScheduler - built it out with KubeFlow as it supports experimentation\n\nWhen you get generative models from GPT, you handpick? Does it run offline or the end user has application? ==> No these experiments are all online.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " We limit the blast radius if things get wrong. We are in 1 Mn user base range.\nKubeFlow does operates in batch. Well designed, scalable. If it needs to be distributed, it has the capacity to do it.\nMetric is - is the user happy?\nHow do you host these models? Backend - OpenAI but support 3rd party vendors for that. We manage a lot of models overall - managed at the source control, etc. \nTypically do 2 variants for a model ==> Is it like a control plane, data plane ==> Where the control plane decides which one goes to Model 1 or Model 2 ?? Allocation to expriment groups is done randomly.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " KubeFlow - have you put that up? Or planning to put. I just push code and it fires off. \nWhat is the blocker in going to 100 experiments? What is the blocker? It is just time constraint and in meetings all day.\n> Firing the model\n> Fine-tune the model\n> Deployment : Its not yet integrated into my application. No end point ==> Engineering resources that need to be allocated\n> Analysis => Observation\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " 1) We are more of a MSFT shop => GitHub, we are on Azure, etc. We have GitHub actions and things coming in, Deployment has become easy. Until and unless we run out of GithubActions free quota.\n2) We are working on CLoud Native architectures - Kubernetes, Docker ==> removing dependencies ==> Latest tech direction.\n3) We need more people to know about Deployments - coders who haven't been trained on deployment. How easy is it for developers to come and start using the Product.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " \"Wants to move to Cloud Native way of deployment - cross-cloud strategy is very common these days => We used to be on app services. Connect GitHub to apps service => costs significantly went up so we had to take up another strategy (PRE-SALES etc) ==> Customers are on different cloud. We allow you to go cloud native!\n(1 effort for deployment of a containers - 3 to 4 days) ==> It could go up if people don't know.\"\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " DevOps is becoming an integral part of every service provider. How are we adding value in terms of differentiation from Azure?\nMost platforms will let you do one click deployment and will allow things like Splitting between Models, A/B Testing, etc. We are trying to make that experience as fast as possible.\nWe support 14 programming languages and combinations.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Problems we are solving: 1) Recommendation problem, 2) Estimation, 3) Optimization. Market basket etc as well that is needed in the advertising industry.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Use algorithms in-house and running as a python code in different platforms.  (Stack is AWS Boxes - some other servers).\nIn our use case, it is not always needed that we have to expose the things in real-time. \nHeavy computation happening in the offline job. Can't model and predict at the same level. \nExperimentation and making the impact of it is missing - A/B Testing. \nKubernetes is not incorporated into the ML/Data Science pipeline. \nEventually we will be adopting it. \n>> DevOps team: They do initial and every engineer is enabled to do them. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Kubernetes is not incorporated into the ML/Data Science pipeline => Resources issues => Eventually we will be adopting it.  \nObviously that is definitely better than previous approaches of deployment. It is very easy to go there. \nIf we can get SandBox access and can try it out. \nOn Kubernetes, are you using Helm Charts to deploy? Lot of algorithms running on offline mode. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * If I have my inference function, how much time will it take for me to deploy? It will take 15 minutes. Notebook experience is fastest. \nLet's look at the deployment log and see how much time it took to deploy. \n(3-5 minutes + 5 minutes ==> 10-15 minutes to deploy) \n\n* How do we handle the failures in deployment? 1st thing - your pod will not come up. You will be able to see the stack trace. \n* Call went into experiment tracking a bit. \n\n* This platform is towards exposing the entire platform as real time metrics?\n\n* How do we estimate the cost of the service? Could we estimate it before hand ??\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * Cost insights before the deployment \n* 60% is still as is how it is? I will want to try out once as to how it will help us in terms of deployment and monitoring? Splitting the experiments with training percentage\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Building a couple of CV models. Sort of a 5-6 models in a pipeline. What is the TAT of one model. What is the performance for 50% of the load etc, whats' the performance of 100% load.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Current, we need 30 minutes delay, that is fine. So we don't need real-time. \nWe batch process the listings every 5 models. We orchestrate using Prefect. Flow everything using Prefect. \nWe have taken a VM and then we use Prefect for Orchestration. \nModel runs on CPU - no GPU. You mentioned you use Docker - are you using AWS EKS. We haven't started it and moving entire thing into Kubernetes, but some cost issue came up. (GCP is used, kubernetes Control plane was charging something). \nScale - 5 minutes, 30-40 listings ==> 80*12 ==> 300 to 600 listings.\nWe are using label studio for labelling the data.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " ** If you have any orchestration set-up for active learning, that would really help us. In active leanring, we are building for monitoring the inference data. \n** We are doing everythign at VM Level, there are lot of issues. If we move to serverless, then it would also help us ==> We are using multi-processing to do it. Sometimes, the other containers are not up.  In a day, it happens twice or thrice. We don't run it as a service but run it as a batch. ==> This is dynamic CPU and memory allocation. If you ahve deployed 4th model and you are loading 5th model, we will dynamically load. \n** Cost of moving to kubernetes\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * How many services could I deploy in a single WorkSpace?\n* Let's take an example - I have a large model. If I hit a lot of load, what if it exhausts the whole 4 GB Memory. Will it auto-scale? \n* Can you go to create WorkSpace? I can only see upto 8GB Workspace.\n* Will this be Kubernetes or something? We can also attach it to your own Kubernetes cluster\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " I like how easily you have orchestrated everything in the interface. I really feel this is very useful wrt deployment.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " We went on to introduce ourselves. IIT Madras - 2009 (13 years) ==> then in Airbus, started DS in AirBus. Then Emirates for 6 years. Emaar - owners of Burj khalifa. Lead the entire DS agenda (10 colleagues) ==> 1.5 years\n\nBossed kept changing in Emirates: Not a stable team.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " We were attempting a start-up sometime - 4 business lines (Property, Malls, Hospitality, Entertianment) . Biggest chunk is with properties and retail, which is malls. Record sales in properties ===> How do you price the properties?\n\nProperty sales team wants to know how the sales is going to look like? Property sales forecast. \nWhen want to sell properties - there's a customer acquistion channel. Which agency is likely to increase leads.\nHow to generate leads - marketing campaigns etc.\n\nDubai Mall has a marketing platform => how do we bundle offers, how do we personalize offers. How do we forecast footfalls in the malls? Shopkeepers- how do you price the shop rent. Forecasting problems.\n\nPersonalizaiton: Which offers is going to be more appealing to the users? Its' not distinctive.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " * Tech Stack: Plain DataBricks ==> We have made tech investments ==> Migrated to real cloud solutions. AzureML Studio - migrated. \n* Azure notebooks. Deployment also happens through Azure platform.\n* To save costs, instead of real time, we run it in batches. We pre-catche what is relevant to customer. \n* Do a lot of A/B Tests ourselves . Have some bit of monitoring\n* When we choose Azure v/s DataIku, Oracle, AWS are competing heavily ===> Enterprise level architecture ==> there is a bias to choose MSFT. \n* Do you use Azure Studio - Drag and drop? Yes. We use the feature store concept on Azure Platform ==> 80% time goes not in model building, but doing things around it. Feature engineering, pre-processing, etc to making models production ready for deployment. \n* We use SnowFlake and Azure Synapse too. Data Cleaning and customer 360 degree - Informatica is being used.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * I have kind of bootstrapped - run in start-up mode. Person is able to do end to end.\n* No dedicated DevOps team. Structure is more aligned so that folks are focussed on delivering 1-2 projects. As of now, this is how it is.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * If I had to compare to an open source framework like KubeFlow => it has its own logging and monitoring. It has A/B Testing etc. It took me 3 days to deploy Kubeflow and you will spend time in understanding the system. Developer Experience. We also have model registry and things that integrate tightly with training. (Our Learning curve is very small - User journey is defined to be very simple)\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " If I am a cloud resident, will TrueFoundry help me in reducing the cost of my cloud?\nFor the parts of the platform that Anuraag showed, I will have to lean back. \nI will not be able to do away with my cloud costs ==> think it as a question. If somebody is already invested, then how would you get adoption?\n* If TrueFoundry can show a great pre-processing part, as to how do I reduce the pre-processing time, I will want to buy.\n* Models in Prod. Different versions - how do I do versioning on top of that. \n* If you are only giving me monitoring, then my main cloud costs are still there ==> the business case of monitoing then is not very useful.\n* If the Product is too close to Open Source and very complicated to the Cloud base, your set of customers will be restricted. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Deployment in a Production set-up: Both Online and Offline Use cases. \nRight now, deploying a model takes weeks. And we are enabling that in 15 minutes.\n* How are you deciding the Data Pipelines? What's the boundary? Our focus is on deployment - offline training, Batch inference and real time. \n* Platform comes to the developers code as a library ==> Package from python notebook/CLI \n* Suppose you are deploying a particular algorithm - there is a model => both offline and online. For training, it takes user data as input. For exisitng users, you want offline production so its catched and online cache, you want a copy of the mode.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " 1) Spark Pipeline \n2) Take the model as a service => Just explain within this example. \n3) We are developing ingress graph APIs - as of now you will only deploy it as a service. \n\nComplete Pythonic way -> deploy it as a service or CronJob . On top of it, if you want to take data from S3 and pass that, you can define it in a complete pythonic way. \n\nTaking code and plugging into production - harder problem is when you put into produciton, lot of new cases that need to be handled. Is it related to the transformation code? Or is it related to the input? When doing offline, there are a lot of assumptions that some input won't be 0. \n\nThe engineer needs to have a lot of cases to put that into Production. If its a live service, you still need to handle the requests. Where we see maximum Gap: Parallel Logging => Model 1 I have put a service, now I want to put Model 2 live ==> I want to comapre the output etc. Real life feed - Model 1 ==> Shadow trafficking. A/B Testing is different. MODEL CONTROLLER: You can do random traffic or you can do random at a certain stage. \n\nA/B Testing: \nIncome Prediction or CTR Prediction : To put a model out is very revenue impacting => there will be a 2nd order effect. I want to comapre a model 2 that I have evaluated in the past compared to model 1. Log inputs => compare offline. LOG => RUN => OFFLINE PROD. A convenience whcich a lot of companies do - in Online service itself, I log another model ==> Live Dashboards that will compare Model 1 and Model 2.\nI built this for InMobi (this is something around 2015) => In ad networking scenario, SMA for prediction is very small. A framework called NLeap => a lot of modelling was happening in Spark and it supported pythonic use case. Supppose XGBoost - a predictor class where you will have a lightweight version\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Based out of Bangalore - next time can meet in person in office. Started going to office. Only shut down when there was peak. Lot of business depends on operations. // Data and analytics background - primarily worked in retail for 10 years or so. I have been working on retailer side or CPG side or manufacturers etc. \nHeading DS for 2 years - 5 year old company.\nSignificant share of market in furnitures and home decor. Working to establish ourselves as a complete home solution.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Tech as a vertical is not very old - before that, the scale was pretty low and hence not worried about how to process the orders. Data as vertical is only 2 years old. Journey - adhoc requests to a lot of collusion of requests and blending into reports - tableau for the same. \n\nTYPE OF MODELS:\nForecasting and estimation models - used for capacity planning, strength planning, raw material planning. Daily models for Last mile logistic planning - how many days do we need for handling? How many inventory days are there? Daily fulfillmnet models are also there. Minimum inventory needs are also there with 90% adherence. \nIntent Model: Working with Product team to deploy - possibility of a customer to conversion.\nProduct affinity: Probability of conversion from X to Y. \nRecommendation Model: Product ranking models, recommendation models.\nImpact analytics for models that have gone live => models for this.  A/B Testing is not posisble in many cases.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Replicas created for Production - we started looking at data warehouse, resides on - RedShift. Not using kubernetes. \nThe Production: OLTP - Legacy (more of a solution etc) ==> RDS (AWS primarily) \nEvery order that comes from marketplace comes from RDS. Dashboards - tableau. \nWe have onboarded another tool called DataChannel to pull data from various APIs => allows us to download data into our system and give us a 360 degree view. \nLibrary - supports Data Engg and dev needs. \nModel building came 1 year back.\n\nDo you run models in a run-time mode or Live ? Process is there - Sales and Ops planning. That is monthly exercise. Everyone meets and agrees on a demand. Every month we project for next 3 months. Everything is stored in database.  \nPersonalization is restricted to the CRM - minor tweaks here and there. Search analytics is part of development. \n(MOST Models are offline - but pipeline is ready and it is deployable as an API etc)  \nWhat is in pipeline is Product based recommendation.\n\nDedicated EC2s and managed services like DynamoDB.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * Roadmap I have: Driven based on needs of the organization => a lot is happening on pipeline side. A lot is happening on CX.\n* Other problem we face is optimization of budgets. Recently on-boarded a person as brand ambassador.   \n* Forecast models were not working well - all our parameters - MAE etc was too high. We used Prophet and that was giving a high RMSE. WakeFit FB Prophet. \n\nMembers in DS Team: 12 members in the team. About 4-5 months back, make it 20 members. After 6 months, all of them are data engineers.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * As of now, we don't have support for Offline. Deploying as a Cron job and deploying as a job - that feature is coming in 2 weeks.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " All the use cases I asked is asked because team has built a lot of APIs and all of them can be deployed as a rest service, even if its not a model.\n\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Was with IHS Markit for 8 years and around the end of last year, got an opportunity to lead a team of DS. \nI am part of the SLACK group and i wanted to experiment with TF. Will be more than happy to have a walkthrough.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " A lot of cases where we don't experiment much and just try a few versions and choose one.\nSome teams use Hyperparameter testing tools. \nExperimentation Tracking: MLFlow and improves on a lot of things. We are adding integration for Minio - Kubernetes native. Internally building a pythonic library on top of MLFlow. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " OCBC Bank - it is South East Asia focussed bank ==> they are more like the ICICI or Axis of India. Given the domain they are in, they are completely OnPrem \nEnterprise Data Platform: Bought from Cloudera => Runs on our server. \n\nBecause its on Prem, a lot of tools are coming from Apache DataFrame // Apache Ozone - equivalent to S3 // FLink as well. Managed by IT. These tools talk to Cloudera Python Platform. \n\nDeployment Process: Data Platform is similar to a SageMaker. Does Cloudera provide direct support for Jenkins and WorkSpaces? Cloudera mainly provides the data science interfaces. WorkBench is on top of Kubernetes? Create a Kubernetes cluster - on top of this, the Cloudera Application runs.\n\nRay to distribute the overall training piece. \nThere are 2 Facets to it. For some domains, the performance of models is not high of priority. All Products don't need performance side.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Let's say I want to publish my model training as a Service itself? As a service because it should have the ability to take an input and give out the output. (We will be able to do simple job - name your job as autojob and provide some stuff) ==>  Can I parametrize the Job? In Enterprise especially in Banks : One enterprise is FB, Google etc// And then there are orgs starting to adopt this technology. We are building HyperParameter sweeps. \n\n* Even in terms of deployment of Services - (department within OCBC: ChatBot) - The way we deploy is take a model and deploy in a  service. If you are expecting a heavy load on the service => say we have multiple clusters running on the service.  Will the infra be able to support that? \nWe have built a better solution - autoscale=\"true\" \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Suppose you don't have few models. You have 20 teams building the models. \n\nYou are a data scientist - do a bunch of experiments. You have the whole script of model training etc. Every week, you train the model. All models are approved through a feature training workflow. (MENTIONED ABOUT ANOTHER WORKFLOW) - We showcased the Pipeline deployment. \n\nWhich features are important? \nView will be biased: Training jobs will take priority, Pipeline should be at last.\nOnce you have a trained model, every thing becomes repetitive. People don't do Hyperparameter tuning every month. \nA/B Testing and Shadow Traffic - It is good thing and is done in conjunction with business line. \n\nFEEDBACK:\nIf I start overlaying how we are using Cloudera today => There is a disconnect between training and deployment. \n1) Training and Deployment should be in the same layer ==> Environment is different but production has a CMM that it is running. WORKSPACE : could it be generic enough that it has a jupyter notebook, connect to database and within the same environemnt, I can deploy the service. \n\n2) Distributed thing is very important if you are doing 64 GB of RAM. Using Ray for distributed training. Data processing - Spark.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Growing organically and inorganically - Sizeable presence in Middle East.\nPersonal Employee of the company. We offer Consulting and professional services - Financials and Telecom. We do a traction in other services as well. \n\nWorking majorly as a ML Engineer - we have good presence in Data Engineering. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Present Use Cases that the team is working on - building solutions that are similar to Google lens. When open, access the objects => Similar kind of product for one of our clients. \nB2C Product: For that, we are trying to get the data and building a solution that can detect household objects. Object Detection Part.\n\nBuilding ML is a pain point - Lack of annotated data is the biggest Problem. We tried to use data available in Open Source. Accept somewhat okay model - we have to deploy this to mobile. We have to deploy it to applications that are built using Flutter. Considering how do we automate that.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We are using AWS in the current project - that is the platform where we are building our solutions. Model deployed in the Mobile application - using Flutter application, deploying it. We are not exposing model as a web srvice.\nDeploying the model as a service will come much later. On the edge model - very light model. We can't have a big model here.\nWe are using PySpark and Kafka. A lot of data is tabular. \n\nWe are using MLFlow for Experiment Tracking. For Orchestration purpose, we are considering to use KubeFlow.  We deployed it in AWS. We are getting different tracking information. \nRight now, we are training on AWS GPU. That process, we want to also go to KubeFlow. We are going to make it as Cloud Agnostic as possible.    \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " If we get a lightweight system that can help us orchestrate, that will be great. \nWe are using Kubernetes, but not for ML WorkFlow. Using it for Backend Meta Services. The way - FastAPI, Docker etc and deploying using Kubernetes. \n\nThe reason for not using Kubernetes? This is still in progress. We considered running in different CPU/GPU instances. We might have to use KubeFlow for that. \n\nWe are planning to Deploy the Model: How do we get all the information and how do we re-train the model. We are using KubeFlow but not sure where it will be useful. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * What are the advantages of using your Platform over MLFlow as Anuraag said?\n* Is there anything we are providing for automating labelling?\n* Someone can use the service for free? \n* Are you using platform as well? Say entire service. \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Wanted to recommend it to his management and team. We can get members from the team and give them a demo. \n\nWhere do you see utility? Is it possible to provide only specific Piecemeal support. We can provide individual parts and not want the infra. \n\nFeedback on the deployment System: I wouldn't be able to take the decision from my company's perspective.  \nShould we connect in 2 weeks ? I may have to push it by sometime.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " MLOps at Holcim. I was at Unilever - DS there. Moved more towards MLOps. I have been working in this initiative - Plans of tomorrow. Industry 4.0 vision => large line of products. TrendSetters in Industry.\nSold off the Indian arm as well as Russia arm.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Some on AWS as well as some on GCP.\nRest Dockerized and not on Cloud.\nUsing BigQuery etc . Also have a global data center - we push data output to GCS/BigQuery for pushing the predictions etc.\n\nModel is in the edge. Compute is in the edge environment but batch output gets pushed to a cloud environment. \n\nFor one product, for training: using AWS. Rest, DataRobot and scripts.\n\nFlows of deployments - \n* SAGEMAKER: SageMaker pipeline => it has SageMaker experiments. \n \n* Edge Deployment: Test environment and then Edge deployment.\nOnly problem with Edge deployments - experimentation tracking is a problem.\nHow is the Edge deployment done? Sensor data collected.  \n\n  \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * Deployments being edge oriented. \nHow we can use the plant's infra in their virtual infra. We cannot move completely to the cloud as others are able to do. \n\n* DataRobot - being used .Sagemaker - for model monitoring\nHave had conversations with Weights and Biases, Neptune, Truera. We have been in conversations with lot of vendors but haven't found a solution that fits our needs. \n\n* Monitoring is one key aspect where they have explored solutions. Experimentation and tracking is version 2 => that's second priority.\n* Reason for Weights and biases not getting up: Not being able to be flexible. We have variety of different infrastructures. Not very PLug and Play. Good for Citizen DS. Not ready for an enterprise application. \nMonitoring: To be honest, still in talks with vendors.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Are their enterprises using the Product?\n* How do you package the Product?  => It depends on the number of Users.\n* What's the experience been with AutoML Solutions like DataRobot. How is it different from MLFlow? => What will be the benefit over that? \n* Can I run some tests using the library? We will send you a demo account where we have logged a few things. \n* Could I integrate the deployment piece with my own cloud provider? We are using Kubernetes, so everything is dynamic. We are using Google Artifact registry - could you integrate with that? \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Besides the deployment, what would be the benefit for me to not use MLFlow over this?\nLot of benefits we provide on top of MLFlow: 1) MLFlow doesn't have multitenant system (RBAC first class), 2) Dataset logging, Image logging is not in MLFlow, 3) One Click Deployment\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Past context from G2 Calls there. Using this to get a progress update on how they have progressed on this.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " These are already discussed in the past. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Progress in ML Pipeline from last time we spoke\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Progress from last time: \n*  From the last time we met, not much has changed internally => Still deployment is using AWS Data Pipeline.\n* Stakeholder Mgmt and Experiment Tracking side: Lot of mgmt => consistent feedback. Don't know exactly what each person is doing. \n* From a deployment side, since we don't have a lot of models, it is not a problem much. Gradio and StreamLit interaction. ML Team is still using AWS Data Pipeline => there was a delay as many folks were on sabattical. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Mgr is not hands on in Data Science but good at setting up metrics etc. \nIt becomes difficult to manage all the projects => Log files don't help him much => Tracking the experiments help him. \n\n>> FIGMA Design - we have done. We could have something similar. Track all the experiments. \nAll our Recommendation models are based on Language Models -> what does Hugging Face mean?\nMLFLow : Siloed activity that we are doing => Using it locally => Plan is to deploy it in G2.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " One thing MLFlow doesn't have is Role Based access Control. \nHow is it different from MLFlow?\n\n* Not everything can be handled by the framework => whatever framework magic you can provide. \n* It becomes very difficult to understand.\n\nCurrent ML Team is very small: Experiment issues + Stakeholder issues.\nWhat kind of drift do we do in terms of NLP Models today? Just basic data drift. \n\n* We can visualize nouns etc. and Docan - Annotation platform   \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " IIT Patna - One of the founding member at ClearFeed. Extract info from different frameworks and present insights to customers. \nAll models are NLP Models.\nData Science - only 1 person, Engineering team: 12 members\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Most models are classification, Other is text generation Model.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We have 3-4 models in Production.\nDeployment side: We deploy to ECS. Docker image => Push to ECR Registry => Deploy the ECR image into a ECS Task. \nAlready we are using AWS - we actually took service from another company - they implemented the DevOps side of the framework. Button in the AWS Cloud build. (Key Value systems - for DevOps) .\nModel Training is on GCP and deployment on AWS side. We started with GCP and actually Software dev part shfts to the AWS.\nAll models are real-time.  We process messages in Real-time. \nData Pipeline: We use DVC => inHouse datasets we have built. S3 bucket is managed by DVC.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Main pain-point is monitoring of the models. \nWe don't have access to the customer data and we don't know what is going on the customer side. \n\nOther than storing the data, what all things do we need on top of data? Text data is unstructured - most monitoring tool is for Tabular data. What are the things you will need to make sense of the data? Model output probabilities across the distribution, Compare distribution across ground truth. Want to be able to detect if something wrong is going on. \nYou want to be able to monitor at the label as to what is predicted. \n\nCurrently, we are using DagsHub to manage the experiments and they connect to the GitHub. They monitor the training of the model. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * DEPLOYMENT OF COMPLEX ML MODELS: While its actually very simple function to deploy. If we have a complex Deep Learning model and it has a weights file associated., how will it work?\n\n* In this Product, do you also have experimentation side of the product? We can showcase you the demo for the same as well. \nWould this work if we manage the models through MLFlow registry?\n\n* We have test, staging and Production environment. How do we manage Dev and Production Services separately ?  \n* Does the product contain user level access control so that one one can touch the other Parts?\n\n* Could we connect TrueFoundry with the GitHub Repo? Most of our code is on GitHub repo. We are working on a feature where you give us a repo link.\n\n* Does this also support the monitoring part by itself? \n* Our data is sensitive - how will it work for us then?\n* How do we manage Keys in your system ? We have a way to store secrets!   \n\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Deployment framework is really good.\nIs it possible to try it out? There is a lot of complication when we deploy at our end. In the way we deploy, there is a lot of steps. \nWe can manage multiple models like v1,v2, v3 etc. In current deployment side, if you want to create another environment, it is very difficult. \n\n* Could we copy the workspaces? Like create a clone of the services to different workSpaces. We can map the WorkSpace to different Environments. Other than environment level, you can also divide at team level. \n* How do we manage Code? Is their any system for reviewing the code etc\n\n* One more problem is there: How do we store/log the model as a python function so we can directly call the model as needed. We allow you to store it as a serialisation function.  \n* MLFlow supports logging the model. Does TF support logging the model/artifacts etc?\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " We have built a web applications, haven't deployed yet. \nCurrently we have 1 model - want to deploy it. \nTotal of 7 members are there in team.\nOne of the pickle format models - done for the sensor format of data. Live streaming data => Need a cloud platform and can track it. Currently its batch mode - but will want to be Real-time mode.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " - ProcFiles and all : Do we need to write our own or will it work automatically?\n- Could you show me the CLI demo? Folder structure etc. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Harshul - Found cool ways to integrate with DataBricks and spin off on IDE. They do allow remote pairing of Hosting clusters - POC with DataBricks went well. We are using DataBricks a lot - all Data Lake etc. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " We have a Project on Fraud Detection where we need Data Drift Capabilities => What is it we are trying to do in this model? API or platform on Housing.com => If we want to do credit card payments, its high fees and people try to make Fraud transactions using Stolen cards, etc. API is up and running and helped us reduce the frauds - 1.5-2% earlier and decreased to 0.3% now. We have deployed a ML Model to solve this problem. Happens for every Single transaction that is happening.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " API Call for the Fraud detection- REST EndPoint is exposed by another endpoint we have built => we then clean and pre-process and then send to MLFlow. BACKEND SERVER: Will clean up the data and respond to the user. Backend server is written in Python and FastAPI or FlaskAPI. Do you work with dedicated Customer success person from DataBricks? ///  Fraud detection: Model serving feature is supposed to be in Beta ==> Shouldn't be using Model Serving in Production. Even if requests hit 10 APIs/sec  - - > It seems like a critical application. For FRAUD DETECTION, MLLib or Skicit learn libraries. USER FLOW - when transaction got blocked or got unblocked => Red, Yellow, Green - Red is for sure Fraud. Yellow Being borderline case. Green - good. PRODUCT team decides whether to let go through or Block. 24 hours hold - Someone is recording the fraud or not. Ultimately this data is being recorded to re-train the model.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Data Drift => Why the need? // * What's the feature set we are talking about? - 20 to 30 features is when the categorical features using one hot encoding etc. No text features that you have to convert to encoding - No. Cardinality - Can be high as well, but will have to check.   * Model Type - Outsampling or Insampling?  * How much requests are we talking about? - During Training time, we did POCs to understand Data Drift etc. Re-Training pipeline after 3 months. We did it experimentally. No of transactions would be a few millions. PRIORITY:  As behaviour keeps on changing, output space and behaviour keeps on changing => Frauds have decreased. Originally trained model might not work is highly possible.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " What characteristics do you need in a Product? Have tried some open source tools - used FB algo. Its a post on Linkedin. Don't have the Data Drift Pipeline in Production - we do know how to solve the Problem. Asking to take some help from people like us and if we can integrate the system. END EXPERIENCE: Offline and Online - we did offline measuring the data and came up with thresholds - we should then re-train. Might change after few months. Online - can tell the DS the window for re-training. It gives a push notification over email and then using the Push notification. \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " WHAT'S THE TRANSFORMATION YOU WILL SEE? \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Ankit - What's your biggest PainPoint? Provide a way to deploy the code from the Experiment part ===> If we log the model, we should be able to log/version and deploy directly from there. GOVERNANCY: Deployment needs a change approval process. There has to be a change control in most companies!! \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Could I run the model several times - could I stop and resume the run?  // * Do we have the tie-up between the experimentation branch and the deployment? (What I find discomforting is - Act of deployment is different from the act of Experimentation => by the time you get to end point, you will find that something is different) * Suppose we have multiple customers- could we add a 3rd dimension and see how the features are performing across multiple customers? Could we compare how the data drift is happening across customers? Do we want 1 v/s all.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Never say that you don't need to push it to GIT when talking to someone who comes from such a good engineering mindset. We use DVC to pull the model /// Q) Could we annotate some of the data from Production environment in this tool?  The reason I am asking this is that to calculate the data drift, you need the ground truth. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Deepanshu - working with MLOps team (Model Deployment, retraining) , adding more features, improvement of features.\nPranjal - Works on Data Science problems\nSolving Client Problems \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Model Complexity: Simpler models - collection of models => multiple simple models and averaging them out to generate results. What we have different types of data => we get different versions of Models (each version is trained on a different dataset). \nWe have multiple level of versioning in models. How many models get generated in 2-3 iterations => got dataset from client that has 10 data points. For each output, have 6-7 internal models.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We have to configure each model - configurations related to each one so that we can train/re-train. We create configs for each structure - these are the models we have trained, these are the S3 location. If there is an optimized way to handle this. \n\nDoes training happen parallel? No its sequential. Once we have this, how do we deploy them. \nCustomer makes API calls to the models. For hosting these models, we create custom APIs? If we have 2 customers, are we going to create 2 different learners for them? \n\nModels are not hosted directly - they are not directly deployed. How many models would you have that are serving inference?\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " We are in an EC2 instance - facing scalability challenges. \nIf multiple users start training simultaneously, we have issues. \nWe also provide Optimizations - you want these sort of properties, you can use these sort of things. \n\nRight now, we are upscaling our resources. Looking for microservices etc. If we can separate out the training part separately and if inferences can happen at a separate place. Training is asyncrhonous => we let the user know that the model is trained and you can use them now.\n\nExpected Inference time: 2-3 seconds. \nHow do you do re-training?  Hyper-parameter tuning - when we train the models  . When we train, we get the logs => Single place for monitoring all the training logs\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " How do we handle if simultaneously trigger predictions?\nWhere are the models stored? It is stored in a model registry. We provide Python APKs. \nRight now, it is deployment focussed? \n\nCOULD WE UNDERSTAND WITH AN EXAMPLE: Start with a User flow - Linear Regression model trained => What are the different ways in which the pickle file is available to me?  You can call our SDK and tell MLFoundry.save . It will automatically store model in SDK bucket. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Sumanth has experience of 2 years, Chethan has experience of 2 years. Akhil - Fresher (June), Amal - Data Scientists (Joined in June), 4 Folks including Sydney - we can get started. Manu and others - all joined in June. ( Love to discuss a few problems you are trying to solve) . Sumanth and Prashanth have more experience in terms of deploying.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " SUMANTH - Currently, we are working on 1 project using ML - Volume Forecasts. Doing in a modular way through code itself. Pre-processing followed by forecasts. Eventually we will need pipelines, like AirFlow and DAG. \nAMAL - We try to read up and try to deploy some stuff. Its something outside of our daily duties. Its not something we want to be bothered about. \nIf we can get away by just writing DS and ML Code and not worry about how to scale it. Don't want to ML Engineer.DevOps team is also very young and we are doing it ourselves. Volume forecast is still in dev ==> Pipe forecasting ==> Prescriptive analytics (3 MONTHS) : 3 to 4 diff applications.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Hosted Notebooks - We tried using DeepNote (allotted resources are very minimal) => Will have to go premium.\nWe continue to use Google Collab. \nPrefer Local machines or VMs for those reasons ==> We are using Azure. VMs - we create it there. COMPANY IS CURRENTLY MAKING USE OF AZURE. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " ** Problem is data is updated everyday - you have to train the model everyday ==> Taking data into local => getting it done. \n** When we go ahead with Fraud and Descriptive, it will be close to Real-time scenarios. \n** Being able to schedule a few jobs as soon as data is there. \n** When data is changing on a daily basis, how could we build the pipeline well => Keep the margin of error low. \n\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * Is there timeout configuration for Batch deployment? These configurations are also available to you as a YAML File\n* Self-hosting on AWS is fine\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " DS Sales team - Manage MarketShare, Other is DS Advertising. Both use same tech stack - 2nd team's tech stack is mature. \nData Scientist: 3 Data scientists => CLassification part I am the full owner. Delivery is managed by another DS. 2 Intenrs and few product analysts\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Most solutions are based on SageMaker. Created our own CLI and environments. Setting up automated pipelines - lot of things happening here and there. Models depend on a lot of other models. SageMaker instances are doing pretty well for us. \nTech Stack: Python, Queries: SnowFlake, Everything is set-up on Sagemaker\nAmazon is so dynamic - Dataset is too dynamic. Majority going for unsupervised models - mostly on Sagemaker notebook instance. Given Dynamic data, we will have issues on scalability\nDidn't have an idea on Kubernetes. EndPoint is hosted on the UI managed by UI Team. \n\nStore the models on S3 => The communication of SageMaker to S3 is pretty fast.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " What happens is the model output is not given. Sales estimate, classification => then combine the models. \nFor each client, the model changes - Do you host separate models for different clients? \nRESOURCE ALLOCATION: We were struglling. \nSet of scripts running manually. \n\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " The issues of adopting new platform is people are from engineering backgrounds and people are comfortable with SAgeMaker, unless models expnd and it becomes complicated. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " We are building the Product - we have to dockerize, creating the FastAPI, deploying on cloud. Around 100 DS and ML engineers\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Convert code to Python and then deploy .\nDepends on the client - if we are getting data from client. If HC or finance related thing, they share access on their envrionment. \nUSE Cases: Mainly related to Forecasts, but not on the basis of the data. For example - expert person available in HC => then from data, how to build a model. \nWe can deploy on our cloud or their cloud. Mostly batch based models . It depends on how data drift happens. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We have created EndPoints => clients can interact there and we get the feedback. \nOne clarification to ask: Once the models are ready, are they hosted on Accrete's infra or client gives access\n\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Building FastAPI endpoints and dockerization is a problem. We want to give them image that they can directly use in their system. \nGenerally, end points will work. \n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Wanted the Product to be more modular and see and do everything from the Notebook itself. \nSomeone is developing, someone is packaging, etc. If everything is in one place and one person is able to do. \nHe wanted to see eevrything in the same place ie. in Jupyter notebook, doesn't want to come to the UI Interface. \nIf UI, then everything should be on UI. If Jupyter notebook, then there itself. Could we have a Jupyter section here, would be useful. \nHe is also not appreciating the amount of effort going into building things. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Was earlier Senior DS at Uber - it seems they build the platform for SC. \nNexus is banking as a service platform - They partner with e-commerce companies. Bukuwarang eg. Using Nexus, other companies. 3 Members in the DS Team.\n150 Members in the Nexus - Was started within SC Ventures. Central team is in Singapore.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " In terms of growth, just launched Product in the public domain: Getting users to sign-up. With data collected, can build data products. \n\n* Churn Prediction: Given transactions of users, how will they churn.\n* Built a number of dashboard to monitor metrics for the business. \n* AirFlow for scheduling, Super\n* Customer Lifecycle Prediction \n* How will the user transition from a high value to a low value customer.  \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Models are tested in local environments. These models will be real-time. Built as a micro-service. \nStack: Rope in the data engineers but in a nutshell - our Data Lake is on S3. We use kubernetes platform to deploy our micro-services. \nInterested in our solution and how it can be used. HAVE you worked in a bank? They are actually quite dfferent and what you can do in banks is not as easy. \nWe do micro-service in a local environment and pass it to DevOps to deploy it to Cloud. \nMostly doing the training locally - its done locally. \nFramework - ScikitLearn => currently not using GPUs.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Looking at for example - for DS ==> Modelling aspect. Data Engineers and DevOps => DEngineers and DevOps will be tied up with different other tasks. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * We have a real time model and we update the model in 1 week? We test and deploy the new model to Production => what kind of workflow do you have for this kind of scenario. I am fine with doing re-training every few weeks. We have both. 1st one => schedule a training job and can be done easily in our platform. \n\nBuilding a complete approval loop is something we are working on. UI for the platform and then do a real-demo with your team. \n\n* Suppose I say I see the result is good and I want to deploy the new one? The old one is already running. Standard procedure - you will want to do it using CI/CD. We have examples in our documentation as to how we are using GitHub actions. Once you committ your changes, it will automatically commit your changes. Go to UI - click a model and click deploy. \n\n* When models are running in production, do you have a tracker which models are running in Production => How many customers are on new models and how many on new models. All your instances will get updated quickly. You need to make sure a gracious exit of all models. OLD Models might still be serving some models - we don't want connection to be stopped. 2 Ways to handle it ==> 1) Adding a hook in the code meaning we will not force-kill your system. It will not be a forcekill - it will be a gracious kill.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Do you support multi-Kubernetes system? It could be private cloud but different locations. \nYou could have different Kubernetes clusters as you like and have Kubernetes Clusters from different platforms. \n\nMaybe you can also send the slides => if interest from them, we can get them into the call. There are various competing tools. Bank has been using DataRobot, DataIku, H20 - AutoML Platform. \n\nFew parameters where we are different: Solely focussed on Deployment and making it very deep and different. We have HC companies as clients.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " - [x] AI Industry for 4 years => NSIT 2018. During that time, involved in research in IBM etc. After that, personally interested in start-ups. \n- [ ] Had joined SkitAI earlier -> Exciting company, working on VoiceAI. Solved a number of ML Problems, wanted to solve ML Problems and hence joined Simpplr. Solutions at Vernacular were client specific. Hence wanted scalable solutions.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " - [ ] Started ML journey 1 year back - 7 people ML Team. Trying to solve a range of Problems. Employee experience company. Intranet where company can put organisation level announcements. We were working on Problems like - Sentiment Analysis to analyse overall sentiment of Employees, trying to find topics they are talking about, What people want with the help of ML. Earlier just facilitating conversations. (JIRA, Confluence, Atlasssian, Drive, Teams, Slack) , Attrition rates - the biggest problem when it comes to scaling ML Models \n- [ ] Clients: Companies like Zoom, Nutanix. The kind of conversations for both these companies would be different. \n- [ ] 400 Customers => Individual models per client. Train, Deploy and Monitor a model is a challenge.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " - [ ] Till last year, ML trained on data from all orgs, but fine tuning the data. Data sits on SnowFlake Infra (Platform is based on SalesForce and data aggregated to SnowFlake). 7 DS, D Engineering team is different, SE Team - works on Deployment side of things. We are designing the infra. Which AWS Service would be best to deploy the model? SE Team also does integration of models onto the main platform. Need to get a ML Engineer to do MLOps work. \n- [ ] Integration: Sentiment Analysis model - they will deploy and do CI/CD Pipeline - integrate with backend service. \n- [ ] Right now - Experimentation part and building the end Point. GPUs for training - AWS Instances like EC2 Instances. Started with hosted notebooks, but better pipelines. We are using dumps - dumping something on S3. Scripts that picks the data, train and dump the model ==> DVC for versioning the model and data. (Using DVC for linking it to GitHub repositories)\n- [ ] Phase of exploring MLFlow, NeptuneAI, etc. Targets in quarter to finalise the MLOps platform (Model Experimentation) // (Deployment) // (Monitoring). Was exploring Triton but haven\u2019t adopted. APIs are deployed on EKS - Kubernetes but we are not exploiting benefits of GPU based infra. Have a person who understand Kubernetes - Engineering team part.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " - [ ] Combination of Scalability in Deployment and Monitoring. Generally, general model and then fine-tuning the model. How do we ensure we have 400 different models and how to monitor the quality of these models. ==> Alerts mechanism of the same, Improving the results of the services. KUBECTL - Data Scientists are used to using KubeCTL\n\n- [ ] Monitoring is Ad-hoc. We are doing offline evaluation of batches. That is something we are trying to roll out. Data out of the system, get the metrics etc. Small team and don\u2019t plan to expand size of team. (MONITORING - CloudWatch + Grafana for the system monitoring)\n\n\nDevOps team writes the Helm Charts when deploying. Using GitHub for mgmt. \nBENTOML: How was the experience? Yet to ship a service using BentoML . Just using the open Source Solution. Use the model registry - then programatically fetch it. 6 services in Production ==> DEVOPS: It takes them 2 weeks to deploy a service. \n\nMULTI-MODAL in a single Service : This use case will keep on coming quite Often. 400*7 GB RAM always ==> Very un-optimal\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " - [ ] We have started experimenting with Airflow but not sure if we are going forward with it. Using it for creating these pipelines - Mostly doing NLP. Standard transformations that are happening with data. We host a different service and then things flow. Looking to do parallelisation to reduce latency of the system. \n\n- [x] TOOLS EVALUATING: Want to be able to use it for next 5 years and will it be relevant. Makes the adoption process a bit slow. Most of the Evaluation has been for Single tools. Evaluated - MLFlow and NeptuneAI ==> Model Mgmt tools - how easy is to do versioning, experiment tracking. How is the UI? How is it to do resource monitoring? Follow trends a lot. Product has a continuous support - most tools are Open SOURCE tools that are community supported and how actively versions are being released. THINKING  of trying out SageMaker and haven\u2019t tried it out so far - no flexibility.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Features need to be fine-tuned for every client of ours - 400\n\nThere was a suggestion to try PREFECT. Was exploring AirFlow but it didn't work well. \nTreatment of ML Service is not different from that of a Backend Service. We want to explore GPUs and make use of it well. \nStarted to use Amazon Elastic service - that gives flexibility.\nWe were exploring BentoML and using FastAPI.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Worked with Mayank in the 1st org earlier. Services start-up, end to end apps. ECommerce and personalization data space - acquired by Flipkart. \n\nHave worked on Engineering side of technologies.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " B2B SaaS company - Ecommerce store owners. Beauty is 90%. AI Selfie solution - Zero party data personalization. 150 data parameters => personalization layer on top. \n\nAI has been a strong selling segment for us. Makes us stand out and apart from competition. \n\nAI Models - SKin condition detection, some for hair segmentation, etc. InHouse Kubernetes Cluster where we deploy. AI will be a part of our product as we go forward. It will be the enabler. AI will have some share of it. 10 People here - AI Researchers: Couple of them. DevOps and Backend - I take care.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " AI Researchers put models in production themselves - how and where we should deploy? Have shared access to them and they do it themselves. \n\nWhat made you choose Kubernetes? Ideally we will keep on adding these models - some will have more load depending on requirements and we will need small microservices. Docker Swarm and Kubernetes - Kubernetes is easier to manage. We are currently on Azure and not on AWS. Helm Charts are not updated that frequently - Any new model to be trained and deployed takes months => to take it to Production Quality. \n\nWe have few test machines where we used to do any kind of scratchpad work . After we have tested things on separate machines, then do it. Push to Docker hub and then deploy on Kubernetes. \n\nWe recently made dev space and prod space. Jupyter notebooks live on the same machine? Right now, we use the normal IDEs instead of Jupyter Notebooks. Not using it for scripting. USE More of command line. GPU requirments are there and they are not fulfilled on local machines . \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Models in Production are a combination of CPU and GPUs . Real-time or Batch? Mostly RealTime. Do you use Inference servers or use FastAPI etc. \n 2 cases: Models and services scale differently OR where they scale together. \nWe haven't found a need where we have to do it separately. Haven't found the need to scale it separately. \n\nPros for scaling it separately: Say you have GPU Model and then transformation happens on CPU. If you get a request, you have to make sure GPU is at full capacity. People will take the part that runs in GPU and extract in a separate service. (LISTEN RECORDING: 21 minutes to 26 minutes) \n\nWhich framework? Django, Flask, Fast etc. Mostly Flask or a Falcon server that is pretty light for model inference. Cloud Charge as of now - is it very small? 1500-2000$ per month. Don't expect Cloud costs going up a lot from here. Product not expanding on AI side as much. \n\nYou know you have to do it eventually - migration becomes a problem later on. We have talked to customers that you will reduce cost by 30% if you migrate. But too big to migrate. DO you also have any inference monitoring? Do you label, sample etc to improve the model in anyway? For us, the data is majorly selfies. When re-training, how do you do model evaluation?\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " 2-3 Problems - \nWhile training, we keep on tweaking these hyperparameters => if go to something older, try on that. \n\nThis is something that can be tried out at our end. Other things are not a problem for us.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Connect via Linkedin - MLOps is pretty hot space. Look at the entire ML Journey of Turtlemint. \n\nAshish - Late last year through acquisition joined Turtlemint. Been in Software product for more than 20+ years. Earlier product was in Cloud Analytics space. \n\nLarge enterprise experience. Joined to start off Data Science and Data Engineering - was there basic level.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Data science: CV for recommendation and NLP based problems - Performance improvements. \nOpen problems around Finance - fintech (Insuretech). Open problems as well. Business Centric and highly aligned to business. \nStatistical things, Core ML Algo and Deep Learning also in picture. Reinforcement - nothing yet. \n\nFintech with major focus on Investment through MFunds - but small part. Turtlemint pioneered B2B insurance through brokers.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Primarily based out of AWS Stack - we use Kubernetes, everything is managed. Good team in DS and ML. \nPrimarily applied - lot of things in production. \n\nIntent: Can't answer or share all data. Benefitting - Team wise: < 10 Members in DS. More focus on Quality rather than Quantity. 2000+ Employees, 200 Engineers. 15+ Data Team (Small team) \n\nModels in Production: Everything is applied. Can write papers on XIV - Emphasis has been on putting models in Production. K8S for deployment, EKS => SAme thing. Deploy on Pods and can scale them. Through APIs gets into Production. Backend Data pipelines. \n\nThing could be - at juncture of company, you might not worry about scaling using K8S. Some use pHP and remain on PHP for many years. Data Scientists will come from non-CS background. Data Engineering team is well positioned to handle it. \n\nBoth real time and batch inferencing. Not using SageMaker - was tried and maybe we could use it later. MLFlow, EKS could be used. Would like to see TrueFoundry.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " You cannot imagine DS to be writing YAML. \nLooking at ZenML, SageMaker. \nWas not giving concrete answers - seemed to be fearful.\n\nK8S is not seeing adoption but based on the company, it could be different. \n\nCheckins on the KubeFlow side have stopped. \nEgress and Data Security both are important\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Good Questions Overall- Couldn't record this though\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Skit - lot of work with ML Models. Text to speech, Speech to Text. One Product. Before 2018, doing ChatBots. Collecting a lot of data for Indian Languages. Now we are focussing on US for a while.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Base system is same, Separate system for Orchestration, Python is used by most folks and Go, Don't have preference on frameworks on ML - PyTorch. \n\nWe are using EKS - Amazon (was earlier on GCP). Most things are inhouse because of the way things have been historically. We started with Kubernetes only initially - the decision was taken early on. It has worked out well for us as well.\n\nRecently started using Kubeflow for Pipelines. Deployment - OnPrem => moved to OnCloud. Everything is real-time. In Voice, need to be real-time. We do have a lot of systems that we want to have. Systems for Anomaly and Drift Detection. \nEarlier we had a role called MLSolutions Engineer. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We are not solving anything new in the ML as of now.  We have strong ML as well as ML Engineering Team. \n\nAll Models we have been wrapped around something: B2B System - have to customize it for every client and ship. There we have faced challenges in terms of mgmt of models for different clients. We have faced issues with how we manage models, how we roll out. \n\nWe also have an evaluation system that we trigger from Slack. Those things are also running KubeFlow Pipelines. \nAre you using KFServe? We mostly wrap the models in custom stuff. We used Flask, then blackship. We use C++ for ASR. The server is actually Open Source. For SLU - We have a python based system - has been optimized sufficiently. \n\nMake the Model, dump it on S3, someone else can then use it. Docker Image => Load Testing => Deploy it via the regular process\nCore ML Team - they will select the right Docker Images. This team is integrating your thing in their system.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " 1) How do we ensure that we upgrade the models well?\n2) How do we roll out the models faster?\n3) At one point, we were seeing issues with Quality of annotation => we needed to build our own platform. \n\n* What has worked for us: Gradient, DataBricks => they are trying to do everything and that doesn't work for us.. ASR kind of things. We have found Data Annotation to be a major problem and we are looking to explore solutions there. LABEL STUDIO: 200$ per member per month. \n* Where ML acceleration is possible, we have gone out and found vendors. \n* Spoke to Snorkel.AI => It would be good if there was something that works for company like us. \n* We don't do Drift detection and all - monitoring has been a problem for us => Setting up stuff around System monitoring as well as ML Monitoring. INPUT is voice and transcription \n\nWe have a framework that we have built in-house => It tracks training, testing and validation data.There is no versioning happening. QA/QC is not that great. Not good CI/CD for the model systems.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Been at WhatFix for 10-12 months. AI Consultant to a Data Engineer. Leading team of DS and insights team.\n\nAbhishek: Senior DS with Whatfix for 2 years. Engineering side of things. Use models and monitoring - Deployment/ Retail side of things.\n\nWHATFIX\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Kind of Use Cases: We don't have Supervised learning use cases. Most use cases are Recommendation (but doing it in an unsupervised learning way) or NLP Based models. Use cases for Supervised models are minimal. \n\nToday, we don't have anything that runs on client side. Tomorrow we might have. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Multi-Node Hadoop set-up to do all the development. All models had Batch models deployments. Artifacts are scheduled, they run overnight and they are used in the product. \nBatch Inference - do you use Spark or something else? \n\nA lot of the use cases we have - We need a architecture: 1) CREATE easily deployment code and package it well and create service out of it 2) SERVICE should be fault tolerant. \n\nSTACK ON CLOUD: We have an infra where we do experiments (Hadoop clusters) // All the VMs are Azure (I think we would want it in Azure) // For same company, it could be different account. \n\nAvailability of the infra and engineering team - we have to wait for months to get their availability. If there was a method through which we could generate the APIs. Model goes through the changes. I want to make sure we have the ebst things avaiable at hand to reduce time to production. \n\nB2C World - this is very relevant.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Aim is to give Data Scientists an API. Supervised learning model, Python Script, Unsupervised learning model. \nInferencing framework. Have you seen any solution - almost about to finalise a vendor.\n\nIt is about the use - what other vendor?We can do a Quick POC - Azure POC was not smooth. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Based in Bangalore - 3.5 years. Last 1 year, leading initiative of setting a ML Platform -> we have done a few things. \nStart-up focussed on Supply Chain Financing before that. \n\nI have seen the newsletter. Its okay/good :)\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " When we started, we didn't want to go down the vendor purchase route. We wanted to understand how to solve them in the most optimal manner. AWS - Preferred partner for Cargill. If possible to enable the SAgeMaker stack itself. \n\nThere is no 1 Team. There are a lot of DS and non DS Teams. There is a Digital Foundry team - building solutions for identifying pests in grains.  \n\nFunctional Use cases as well: Lot of needs that we are unable to satisfy. Semantic Segmentation - advanced problems. \nTotal DS : 200-250 People including analysts, DataOps, DS Teams, deployments \n\nML Platform team is small: Entire team - Solutions architect from AWS assigned to us. I am leading the team. SE, ME, DS- 3 people for advisory sort of role (customer advisory)\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " 2 Use cases: 1) Proof of Value 2) Funding Stage\n\n1st one - people don't care about MLOps. 2nd - Production ready way of catering. \nProof of Value - set up SageMaker Notebook + set-up storage. If they want to explore, they are able to explore and connect to internal Cargill data platform. You can also deploy the model but its in data science side only. All of this can be done by the users themselves. They can't set up resources themselves - S3, EKS, etc. They can launch things. \n\n2nd : Funded Projects. GitHub enterprise repository - MLFlow Pipeline or SageMaker pipelines. \nWe also provide them bridge notifications. There is another repository based pipeline. Sets up Production API gateway for them. They can specify: 1) Give API EndPoint 2) Give me serverless. You can observe 3x-4x Errors. They can choose what monitors they want for the model. \n\nAPI is protected with rate limitation, firewall, security. We have set-up the Waf accordingly. API accessible from API key. \n\nEverything is single click registry Ops - With one click, it will deploy. We have used SageMaker runtime - it provides Canary deployments as well. People can specify what % needs to be changed. It also monitors Operational monitors and then it replaces. If alarms are triggered, it rolls back as well.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Tried to connect to Cloud Platform Team - tried to connect to see if we can piggyback on their solution. 2 Months wasted there. \nDid everything after that ourselves. Connectivity to Data Platform, setting up VPCs, Setting up infra in a way that people can do hybrid multitenant kind of work. \n\nVPC and infra bit is common to everyone but access control is there at the team level => They can choose compute as well to a certain level. Training jobs, data wrangling jobs etc. \n\nDEPLOYMENT: For deployment, they don't write Sagemaker related code. Someone who writes the code - that's completely abstrated out. Model building or MLFlow pipeline - that's something that they can do. In the codebase, it will invoke the MLFlow. They can use Prophet etc as well. They can bring their own kernels or if they want to bring their own inference images, they can use that as well. Model sitting on device use cases as well available. \n\n\nTraining pipeline stops with Build. We enforce Registry Ops. You have to bring your MLFlow runs, you can deploy it. \n\nBringing up Airflow as a Service - its in the pipeline. Bringing it in - its in the roadMap. Or use Managed Airflow as a service. Could be a vendor - Astronomer etc.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Material sciences - You have to draw and detect objects in a microscopic images. \nSometimes I feel shitty that I am not doing innovation. \n\n* Do you have use cases where Model is there => there are a lot of pre-processing and Post processing use cases. We provided a solution to them. From infra perspective, we have enabled based on what is called Pipeline Model. When request comes, 1st container will do pre-processing. THERE IS NO ONE SOLUTION FOR IT. Even the SageMaker pipeline - you have to make multiple containers, docker files. We want to be able to put this solution outside the purview of the Data Scientists. \n\nMaybe its time for Feature Store. However, its not easy in a Big org. Sometimes, size of the project also matters. \n\nAt Cargill, if you wanted to build a kubernetes based app, you can easily do it. You need a deployment spec and GitHub repository - SQS, SES, etc. You can even get a database- Dynamo DB. \n\nWHAT IS THE IMPACT YOU JUSTIFY INTERNALLY? Earlier, even for deployment, they used to take couple of days. In a matter of an hour, they have model registered in registry. Now, in one hour, they will get the API out. If you go and buy Domino or DataIku, 5000$ per user per year => if have 100 => $500K $ .\n\nWant to provide Airflow with DBT as a service. DE+ ML platform or Data Warehouse + ML Platform. Managed MLFlow - we are exploring. Swap that with openSource MLFlow.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " We decided to go over Kubernetes: \n\n* How has it been going with SageMaker? You have extracted everything and people don't realise. DS - they don't care if it runs in Kubernetes or not. \nWe have talked to a few vendors as well - Pachyderm, KubeFlow. \nIf you focus there, the end to end experience goes for a toss. \nYou need a really good onBoarding experience. \nInstead of going piecemeal, let's go full time. \n\n* Stayed away from going anywhere near Kubernetes - its going to consume Engineering hours. Whatever you do, endpoint runtime is SageMaker. Recipe is ready to put into a Kubernetes requirements. \n\n\nMotivation was end to end feature complete. As techies, its exciting that Kubeflow is there. Whatever people will be doing in platform, let's enable that end to end. \nMonitoring is coming in next. \n\nOUR Heavy work - multi-tenant, role setting, CICD pipeline. Whatever we offer as Products are also going through CI/CD pipelines. Model should be available as an API. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " 1) People update resume, we have to keep the embeddings. We have the model - but we have a model. That model doesn't change. But what changes is the embeddings of the explainaton. When we want to match the question to best explanation, we get a score for each. \n\nHow many embeddings are you talking about? 20-40K embeddings. Every query we get - it will go over, rank them and return. Now, on these 20K => these are updated 100 times a day. 200 of them change each day for example. \n\nWhy do you want to use TrueFoundry? COST OPTIMIZATION \nRapidAPI - We would love to sell our endpoint outside of our own universe. You have API, You have security, etc. If its a use case you already have (RapidAPI)\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " A good documentation to integrating a RapidAPI on top of our Hosted Endpoint. Could we have a paid API ?\n3 Days - 1 Week to write the documentation. Arnaud - the payment per API call is the only part that needs to be handled. \nHow do I integrate TrueFoundry with RapidAPI?\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Models are having memory issues: Right now - T3A, 2/8 Slacks. Memory was not that big before. \n2 Models - Summary and takeaways. It takes quite a bit of our memory. \nIt takes around 500MB memory. We have multiple models at the same time. It is about 16 GB. \n\nYou can put multiple models in a single container or you can put 1 model in one container. If models are getting high amount of traffic, then you put it in different containers. \n\nYou are using multiple workers and then it creates the problem. Everytime, it will multiply the memory. If we operate on one worker, we lose information. \nSpringBoot API and the AI Models. \n\nIf we want to do some form of clustering etc etc - we can do it at our end or different end. If I do some work at our end and then some at our end. \nWhen I update the code => how easy is it to modify code? YOU CAN ALSO GET THE CI/CD SET-UP\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Deployment on our cluster for now. \nWill you deploy on your cluster? Or use ours? \nSecurity side. We are not big enough yet. \n\nAWS Machine type: CPU, T3A 2X Large, Do you need GPU? Wondering how you would do the model without GPU that I sent.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " * Could you give us a Dummy Model? Request that is working == > We can ask them to put any of the transformer models from Hugging Face and we can replace it. \n\n* You can deploy it. We can give access to the account, we can play with it. If we are able to integrate it easily with what we are doing. \n\n* POC: We re-train our models in a Weekend. I would love if it was a single repository, but inside 1 repository would be great. \nRe-train the model via CI/CD. We have a FrontEnd, API Backend => the layer communicates to the AI Model.  \n\n* DEPLOY in US East one - Could IP Filter the access request?  We can do that. => Not needed at the second.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Wipro Accelerating Innovation Team \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " You deal day-in and day-out with AI Initiatives. Collateralls - Stakeholders. AI Practices - Banking and financial services. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " 4 folks from Data Science team including leaders. \nWe have in-house MLOps Platform. \n\nSet-up context a bit on TrueFoundry => 2-3 mins overview.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Lambda - ETL written (AirFlow is trigerring Lambda) => Time is not a constraint. \nThere is a data on S3 => ETLs.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Bhavesh and Abhinay - PhableCare. Abhinay - KGP 2016\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Lot of enterprise application - b2b to b2c. Data Science and Data Engineering.15 member team. Working on AI Problems in HealthCare. \n\nWould like to see our offering - much value right now to talk about what our set-up is. \n\n6 Member team in Data Science team, Fresh out of IITs , Abhinay comes with HealthCare Background. Problem Statement perspective - Computer vision and NLP. There are other things like Ecommerce problems - like recommendation and marketplace\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " DataBricks + AWS Combination we use. We will look at in terms of building our processes. We only got very recently. \nDev and model training on EC2 platform. We haven't completely transitioned on it. \nDepending on PS, we will look at those opportunitues.  \n\nDo you use Kubernetes at any point? Software Engineering \nOne of the models is in Production => it will be used by Internal teams. It is Batch Mode, Real Mode.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Abhinay: Working on some initiatives. \n\n* Volume and Scale - Deployment, will look at Scale.\n* In the real sense of world, it will not be huge. Will not need heavy infra behind it\n* Eventually we will increase capabilities and features. \n* Bunch of initiatives we have on paper \n\n\nDeployment of the Model was fairly easy - it was not complicated. All the pieces of puzzle built in. \nObviously I am sure there is a lot of opportunities. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " EC2 Auto-scaling? DevOps helps the different kind of configurations. Based on load and traffic, they manage.\n\nHow varied our Deployment process will be?\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Use cases : We repriortised. Focus is on reporting and Business Intelligence. Did deployment for models in Text recognition. \nWe revamped some of the busienss Operations. \nFocussing on getting the things done - see need for Location based prediction. Start with BI and then go to building Models. \n\nCentral Data team - work on. Citizen data scientists.Current focus is on dashboards and BI. Trying to get some of the data that we might need for models. Customer data etc. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Stack remains the same - GCP over Kubernetes. \nApplication side - MySQL DB / MongoDB as well, GCP - Kubernetes (Central data warehouse) , Using BigQuery as primary data base, Use MetaBase for Dashboarding. For deployment, we do batch deployment on Kubernetes. Text AI and Custom models.\n\nVertexAI is used to build models. Why not use Vertex AI for hosting models. We have a Production cluster and hence it is easier. Kubernetes is much easier. \n\nWe are using HevoData for most of the Pipelines. For data warehouse, we use schedule before usign Big Query. \nMany platforms are targeted for large teams. Both from cost and operations perspective! Makes sense for a bit larger teams. \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Mostly use cases will take time to evolve - Doing only based on Need basis. Some of the Products are evolving and still evolving new features. \nWe are taking any critical need. Otherwise focussed on data Ops. \nIn 3-4 months, wil see more traction on the DS side. \n\nBUSINESS: Don't understand the use cases. Being ops driven business. Constant thing between Business and tech. \n\nA number of companies invest in Platform => 9 months. ML Engineers - start building the platform themselves. \nWhen data collection is itself becoming an issue => Basic Data Platform or ML Platform.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " A little bit about the Deployment Stack: Mohan and team currently working on the deployment side as well. \nWe have some ML Engineers - kind of data analysts trying to learn ML. \nThere, some of the data tools we are trying to bring up to speed. \n\nTill now, our idea is to use off-the shelf ML Models with our customization. Next step - identifying a lot of use cases, pick up models and then start using them. DEVOPS Team - Core thing is in kubernetes. \nThere is a centralised DevOps team that handles that. We have mainly 3 frameworks - Go, Ruby, Node. All frameworks have been set-up. \nWhen it comes to ML or so, its collaborative etc. SRE Team - collaborative thing => JIRA task etc.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " * Could we use it for any deployments or is it generic to Python? (Service, Job, Model => If you select a model, library of models we will keep adding) \n\nWhat do I need to provide to deploy a Model and create a service on top of it? \n\n* How is the cost controlled for the Infra?\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " We have clients take out data from unstructured data - documents, invoices. We understand data sources and try to create Models. \nChallenges: 1) Figure out which model to choose 2) How do we re-train or orchestrate it? \n(We do our cloud, client's cloud and orchestration) \n\nWhatever learning we get from a customer while working with them and not re-discovering. \nRAHUL - Customers who are using the code in Production. How do you showcase automated training is happening etc. \nWe are aware of most recent things. Best Practices in terms of continuous training and deployment happens in UAT. \n\nOUR: Its a truly horizontal capability. We end up targeting BFSI because of the background that Rahul and Abhishek has.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " In case a client is okay to use our own environment - samples are hidden. Everything has to be done in their environment (quite often). We do entire dev of the model in their environment. Except for the code, everything remains there. \n\nHow is the Deployment Orchestration? Jyoti can elaborate better => Entire solution we deploy using Docker. We develop the Docker containers. We don't have much expertise on Kubernetes clusters. Mostly limited on model side. Mostly deployment is via docker, either on client environment. CURRENTLY - Stack for Model building: Notebooks, ETL Pipeline etc? => We have dedicated notebooks on the dedicated environment and for running the traning. Our prediction environment is nothing but our Products. Evaluated models are deployed and integrated with the workflow. \n\nFlask API is the major way of deployment. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " We have moved to Docker based environment. We can support all te environments. \nDo you use any tool? We have automations in our existing flow, but not 100 %. Annotations, Model training and deployment etc => not automation. \n\n\nBase models are there: How the CI/CD could be integrated using MLOps. Do you use GitHub?\nTraining code is also pushed to GitHub. \nModel Registry: Using GCP as a model registry. \n\nIt is a SaaS product - so there is a GUI. Some cases, could be through that and some through API.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Offline and Online Training: Offline is what is happening in a batch. Online is close to real-time use cases. \nBest cases where Online can happen. \nIs the platform support both offline and online ? \nHow do we see if the model is performing as per testing. \nHow is the testing managed? \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Connect via Deepak, who is an angel. 18 years ago, there was only Data mining. \nBased in Iran and then worked in US for a couple of companies.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " 6Sense: MidSize. In 6Sense, WB - Internal tool that we use to deploy models.\nDS Leader - 1) DS Team has a good pipeline for feature engineering. Good platform - do feature engineering, do testing. When you have this capability => installation would be 50ms, in 6sense- it could be for a day. \nNeed to have understanding about data - Descriptive analytics. Then you start to build a model. What if there is a tool - looks at the data and tells you what model is best to use.  2) Some sort of metrics in market eg ADC etc - I prefer to lose at the percentile analysis of the model. 3) Its important to monitor the model => Auto-training I don't like. Only if distribution of data is changing, then re-train the model.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Data Engineering team does the Productionization in PayPal. In 6Sense, data scientists do it. \nIndustries where SLA is more important: That industry needs complicated platform. \nMy team writes SQL on a Hive. The Vinci is the internal system for deployment. In PayPal, we have something called TypeRest. \nImbalance classification is the hardest problem to solve in Fraud detection. \n\nCanvasAI: PayPal start-up\n\nIndustry which is tech oriented is hard to target. Industry where core is not tech. Don't spend too much on complicated the model.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " We provide all the Production loads and DS. Tooling to help with offline experiments. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Data Science team is about 30 folks + 11 on engineering. Analytics is doing insight driven research. Domain for Insights - Marketing, product. Engineering - a lot of forecasting. Some personalization - delivery time predictor. \nPopularity prediction etc.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We are on Nomad - not on Kubernetes OR managed AWS version of something. A lot of what we are doing is fairly bespoke. Highly coupled into the Production or application code. \nActual application is written in GO. \nFull Spectrum - AWS Compatible. Do you have Jupyter hub? Or SageMaker? Use Sagemaker only for compute supplements. We don't run things online in Jupyter hub. Increasingly, people are moving things to Hex. Hex connects to the data sources etc? We are very conscious of what we are giving HEX access to. Hex Data WareHouse and other data warehouse. \nAll of the application loads are running on Nomad. \n\nThere is no specific need - We have adopted tools as we found them :) Realised that they solve the problems. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Productionisation depends on Online or Offline - If Offline, we have a framework that the DS can themselves deploy something.\nRead from Data WareHouse, write back to Data WareHouse.\nOnline one - DS Engineering on the outset. We give them the title ML Engineers. \n\nInfra team gives a server. Use anything for tracking ? We have an internal A/B testing platform - we don't use that to re-train models. \n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " How does the system integrate will all the Software Sysems? \nWe are on top of Nomad. \nMonitoring could be one thing interesting - all is structured data. \nCurrent metrics: Drift, Outlandish predictions => Would want to track what? \nVolume of predictions you get: It differs significantly => highest volume of traffic ==> Avg - 300 predictions per event page field. \n\nNo of features: 10s -100s for each model.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " They build on top of AirFlow. This is not expected to be a very relevant call. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " THIS CALL IS useful to understand how they have built around the niche or getting started use case. \nFor users to get started, it is not easy => Often time, people will pick something else without ever talking to you. \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " What is your overall thing on top of Argo or KubeFlow? \nWhat's your ICP? What is your target customer? \nWe had the advantage of the AIRFLOW Community - we backed into that. We were using Airflow as the backend and we became savvy at using it. \n\nStart with small teams/Mid Market team: Platform could be a one stop shop. \nThe kubernetes users aren't going to be final users. INTEGRATION marketing is a good channel to go around. The more specific you can be is useful. \n\n1st thing that was valuable: Multitenancy as part of our value Prop. We will help you run as many airflows as you want. Very very specifically. MULTITENANCY PROBLEM. That became the heart of our customer messaging\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " AIRFLOW - How did you get into it? AirFlow is the backend of the product we built. Hired a lot of their top committers. \nGot the person from AirFlow as the advisor. It was very much earned. It was different - we have earned the right to commercialise a product we didn't start. \n\nDEPENDING on timing - right now, only DataBricks model. It is just AirFlow in the backend. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " VERY GOOD USE CASE - We have to convert them \n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We have the GOOGLE bucket, we have all the config files in the same bucket. All models exposed through GRPC in the same box. \nRight now, its just a box with Kubernetes connected. \nCPU Inference time: Depends on the type of Model. The most similar one will be similar to inception network. Most complex ones have Million weights. Inference time is roughly how much? 1000 Batch requests - half a second to deliver the output in 1000 classifications. Not really real-time as the 1000 is available offline. \n\nThere are use cases where we do need real time as well. \n\nRoughly - what is the memory consumption of these kind of models - None of the models would take more than 2GB. GPU is T4. It is a pretty normal standard machine with 16GB of RAM. \n\nEND USAGE: 1) Web Portal => Upload the data => Get a report (Support)  2) Wearables and Sensors - which you wear with our app => pushed to the cloud.\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " * What is the Problem you are facing? 1) 100 Simultaneous requests if I do, it crashes immediately. Docker file has to re-start.  We don't know how much it can handle?\nLoad testing and optimization has not been there. But its critical. If a clinical trial is running, ML Service fails, no report generated => 1000$ for someone doing the trial. \n\n2) Authentication: I did a hack using Private and Public key. How do you ensure that GRPC end point is not open to anyone outside the Dev team. \n\nAPP Team is deploying on Kubernetes. 2 Questions here - Why not deploy on Kubernetes?\nIs the ideal state? One Service for Models? Or want different endpoints for each model?\nOne AUTHENTICATION is fine. Optimize Money and Reliability - Clubbing some of the bigger ones together and then the smaller ones in another. \nThe Real time one could be a separate Box itself. There inference time matters. But in batch, it doesn't matter - takes upto 5 minutes. \n\nTraffic pattern: Some models will have morning traffic. \n\nWhy not in Kubernetes? Within the company, very few people have access to the models. Only few people in development know deployment.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Cost: Paying a $1000 bucks for a few customers.\nFor me, it doesn't make sense. \n100 Customers - We are paying 1000$ right now. \n\nRPS: Very Few requests ==> Clinical folks will identify a lot of files together. \n\nEVERY 6-7 months, it crashes a lot.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " I have tried Cortex - its only on AWS. It is like wherever the credits go, we follow. We got new credits on AWS, so we can move to AWS. \nWas a year and half back - it wasn't as easy as the website says. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " To see what we have built is useful for them or not. AWS+ Kubernetes Stack. Amit - leads the DS Team (NLP focus). 7-8 people who work full time with us. Biggest KPI is push models to Production.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Atul - ML Engineer for 3 years. ML Pipelines. DS Part + Latency of deployments (2018) // Chintan - 5 years- lot of work on NLP and Semantic journey // Praful - 2022 grad => Intern - joined Full time and have been exploring full time. \n\nDifferent Product lines: Major focus is on collections. Beyond collections, also open to other parts. Real time as well as Non real time - how agents performed in the call, etc. Recent additions: Real time capabilities to guide the agents in the call. How to navigate the conversations in the most optimal way. Transcribing it in real time. If deviations, we prompt agents on how to say. \nSummarization model - that is purely powered by ML. Auto-submitted in the CRM system. There could be model to identify 1 marker or 10 markers at the same time.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Most stack is inhouse. AWS Stack. PyTorch and TensorFlow. Everything is dockerized. Kubernetes is the only thing we attach the models to. All models are GPU Instances or Sagemaker notebooks. \n\nWe push the image to ECR and then DevOps team comes into play. We use those data points to pull to a EKS cluster. Most services in Production have logging enabled - that's where we use CloudWatch services. \n\nWe usually set a SLA for making the endpoint available in production from the time image is ready. Instance selection logic => does the DevOps team decide? \n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Everty model - test it against 6-7 machines using SageMaker notebook. The numbers are published and it gives info to the consumers of model. \nFor Non real time, we don;t care about The latency as much. \n\nDo you use FastAPI? Or use Model servers? We have the backlog items for time. You work with things until that break. \n\nGold Standard is to train a model, containerize it and deploy it. Staging and Production environment? Does DevOps come in every piece ?\nModel Side: Data Drift, Model Drift and Concept Drift. Functional aspects - we realize mostly on users.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " We had been using EC2 instances for training =>started to adopt SageMaker as well. It saves us cost by charging us only for time when training the models. Sagemaker deployments - we tried, but it is higher than EKS. \n\nWe have used MLFlow and WandB as well for tracking experiments -> they are not a big part of our platform. \nSageMaker doens't do well on the Data capturing for NLP tasks. We want to have a tool that is integrated with the entire system. Annotation - label studio. We need to label it, process it and then go to training. \n\nUntil now, we had public endpoints - Enterprise customers care about data privacy.\n"}
{"prompt": "What is the feedback on the TrueFoundry product? \n\n###\n\n", "completion": " Answers on bottleneck -  \n\n1) SageMaker - have tried out different kind of deployments it offfers => What better we offer than SageMaker. \nTheir Annotation tool and entire ML Pipeline - lot less offering on NLP side. \nFor NLP models - do we offer something where annotation is done on the same machine etc.\nAre you more Cost effective than SageMaker? Batch, Real-time, Synchronous \n\nAMIT: \n\n1) Integration of Systems or Cohesive environment to work in => Collaborative way of working in a Problem without having to share Notebooks explicitly. \n2) Maintenance of models and improvement over period of time => Doing pretty well in terms of getting them on production. \n\nCHINTAN: 1) Optimization of the Model Inference. ONNX or Trition or any route we are goi\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Have been in work for 20+ years. First was in process engineering. Then did technical mkting for Kodex. Came to know about the audio-video space. \n\nThen realised that happy to know what happens in the marketing space. Wanted to be more technical. \n\nStarted with Network company, then with Stylumia - Vision and segmentation. \nThen with Financial mgmt space - Document extraction etc.\n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Video ML - Building ML Graphs, add descriptors for the videos. \nBread and butter is cloud based content delivery solutions. There is a lot of videos viewing that has been happening. A lot of people wanted to move to cloud on content side. \n\nOver 500 channels that we deliver. \nWe don't deliver or control the final UI - Roku sons and tv ==> content owner comes that I want to monetize. \n\nData Science: Long Tail content => there is very less metadata. Looking at the video, what could you infer about the video. It could talk about a historical documentary etc \n1) Where do you want to insert advertisements given a video? ==> Digital players - don't want to spend time\n\n2) Recommendation aspect - Nature of ad, Recommendation \n\n(Current size is 5 members + offers for 3 more people)\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " We use AWS, GCP, SageMaker, VertexAI - There is a separate platform team that helps in scaling. \nDelivering containers to the Infra team. They will build deployment containers on top. \n\nCurrent use cases is batch - unless business need, not looking to move to real time. Video files -> do annotations -> add to knowledge graphs. Live ue cases - looking to start. \n\nI don't hire people who come in with mindset that I only work on Jupyter notebooks. MONITORING PIPELINE, RETRAINING Etc. Hire people with CS skillset or people who are okay with taking these things up \n\nRarely work on Jupyter Notebooks. Mostly CLI using dockers extensively. Automated training - lot of parameter search. We are cloud agnostic - we haven't done distributed training. We use MLFlow, use DVC for dataset mgmt. For training, we use something wrapped around MLFlow - launch instances. \n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Would love to know about our offering and where we specialise in. Set up the entire ML thing from scratch. Transitioned from Principal Engineer to an architect role. \nRecently also report to Chief Architect. Looking at other aspects of Platform engineering like Chaos Engineering etc. \nSet-up practices, leave it upto the Individual teams to take it forward. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Started from Ground 0 => No way to interact with Company's data. How many trade orders were placed in the last week? Took 3-4 days to get access to the data. Very slow process was there. \n\nThe gap was produced because of the data exposure events. We ended up setting a Lakehouse from Scratch. AWS Cloud - Native AWS Services and frameworks we have built ourselves. From ML Side - actively from April, May and June of this year. \n\nTIER 1 - \n1) Associate Partner Incentivisation\n2) Trading Nudges program - Push the user in doing things (eg: Not understand the F&O Market)\n3) Loyalty Programs \n4) RFM Cohorts - How much active a particular user is? User classification and MArketing campaigns \n5) Churn Detection \n6) Re-activation campaigns 7) CLTV Prediction \n\nSearch is painstaking. Abhishek is someone who is trading the Equities. Don't show him ETFs. \n\nUser Base of 11 Mn users - not possible for us to priortize.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Search is not Typo Tolerant. Lot of personalization related objectives. \nWe are heavy on K8s- its the Green Field Project. Migrating all of our workloads to Kubernetes ==> Application part: Tier 1 services, more than 50% have migrated. \n\nData Science Team is Serverless - SageMaker Notebooks / BI is working out of Lambda Notebooks (EARLIER they were using R Studio) . Other application services - one of the top priorties for migreation to Kubernetes. \n\nAll of the models we have hosted are Batch Models and all the workloads are hosted on SAgeMaker. Why using SAgeMaker and not general Kubernetes Infra. Only have 1 MLOps engineer and rest all the team is Data Scientists. We want to see quick time to value - doens't matter if the infra is complicated or well managed. For setting up a new tribe, you need to show the ROI.  \n\nUSER Flow and MLOps Pipeline look like? \nWorkLoads are batch processes that run for 5-10 minutes in the day. \nEverything is on SageMaker itself. \n\nRequest is Product and Data Strategy team - we sit together and deliberate on it. Exploration phase - figure out the model or data => Feature Engineering is needed or not? Once done --> Deployment strategy is pretty standard. Feature generation job that runs based on trigger. We don't have ML Offering exposed to API EndPoint. ML Offering is not integrated with Frontend. We can support easily using SAgeMaker Endpoints. There are also challenges in serving those kind of responses\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " One of the features that Data Engineering team made live - 45 Ms for the latency for Data Science team. \nAs your portfolio value grows, your net worth also keeps on fluctuating. \n\nML Engineer is the one that does it. There is no custom deployment for each of the models. You just configure the final script tht the DS team has given and then there is a CI/CD pipeline. \n\nSageMaker notebooks => convert to script => commit to BitBucket. Jenkins automation jobs for CI/CD.\n\nWe have not reached the stage - at a stage where we are proving the ROI. These kind of problems can be solved using ML. Have gone through the same journey in Data Engineering. \nCost incurred in infra? 1st part of the journey.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " NIMBLEBOX.AI => They have been in touch with us for the past year. They have also built something similar. \n\nUnderstand the shortcomings of SageMaker - they are however not even relevant to us. Data Platform also we set-up => work with the AWS Service teams => we have a say in priortization of features as well. \nWe have a leverage working with AWS. \n\nWhy would I like to use TrueFoundry? Buy v/s Build => Its always because there is a time to market. \nHOW are we different from other guys as well? What's our X factor? \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Major Questions going into the call: 1) Role of the platform team that maintains the central Infrastructure \n2) Monitoring and Debugging Capabilities - how does the re-training pipeline look like \n3) MLFlow, DVC for Dataset Mgmt. Something on top of MLFlow for Distributed Training \n\nOverall: 500-600 Team members\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " 1) Maintaining of Secrets in an easy way - who can launch machines, who can create more clones. Broadly as it stands now, we have unfederated access to GCP Resources. Platform team comes into picture in scaling. EVERYTHING related to Scaling is taken care of by the Infra team. \nContainerisation: Itself is not a big task - whatever dev environment we have, we use. We don't have to use new containers.\n\n2)  Fully on Kubernetes? - Evaluating DataBricks right now. BROADER Data Lake - common umbrella. \n\n3) We are not too much on Jupyter notebooks. Most of the work is on CLI\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Videos is stored in cloud env. Most of it is CLI. Dev - mostly Remote. OnPrem GPU ==> Its only when work overflows the OnPrem GPU, we look to train on Cloud Env. Mostly use Spot instances for training. \nHow do you spin training? We go ahead and get started. \n\nMostly using state of Art Models. We use SageMaker and their Model API. And that works. Where we are at: If we get a 24 CPU Ram Machine - the moment it starts overflowing, we will look to have a separate server. \n\nInternal infra to launch these runs. Video files are put on S3? You mount them and download them over the network. \n\n\nThere is a Job Queue => processing the jobs ==> In between capturing metrics that are stored in MLFlow. \n\nOverFlow of the Models Memory during Inferenencing. Suppose there are several aspects we can get out of the Video. Currently the Overflow doesn't happen. 16GB Instance is good enough.\n"}
{"prompt": "What are the most common questions asked about the product? \n\n###\n\n", "completion": " Where does DBricks fall short?\n\n9902264196\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Was earlier also at MU Sigma - Decision Sciences division. Abhishek - hands on Data Scientist kind of guy.\nMaverik - working with MuSigma. Will come to what we were doing at other places. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " In other places, there was no platform - custom build models using python. Clean data, Univariate, BiVariate. \nHere at Maverik - Partnership with AutoML Product Dataiku => getting people up to speed. \nThat adds a lot of value to businesses - EDA much better for businesses. We work with only banks. \n\n\nProblems- 1) Predicting default for loans 2) Internally - Home Pricing prediction in the USA 3) Data gets updated, etc. 4) Cross sell, Upsell, Marketing analytics for Wealth Mgmt firm.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " Python and R \nDataiku - lot of wrappers around Python and R \nAdd a trigger in terms of deployment \n\nIsraeli company: BigPI => Help build pipelines 5-6 times faster. Visually driven. Showed a demo\n\nDo you serve the models to clients?\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Banks have their own version of AutoML they use - H20, Dataiku, etc. \nPipeline based models? Data Engineers on the team - who builds pipelines. \n\nData Pipelines are also executed on Dataiku. \nThey have recipes - Azure teams // Teams who connect snowflake to Tableau.\nData Side - will be 350 people \n\nIf you want to do heavy computation, do it on our own database. In 1 linux server, there is Dataiku for example.\n"}
{"prompt": "Give me a brief about the company and the individual? \n\n###\n\n", "completion": " Get the list of features => Library where it computes the features. Feature library is built from beginning. \n\nOffline also - we recompute features. Feast is being used. \nDockerize => ? (Go CD pipeline is there, Everything is pushed to Git) \n\nEndPoint is generated -> Engineering team integrates the APIs. \n\nDev, QA and Prod => Good promotion flows. Check for a few users and see. Even before going, Model evaluation process. \n"}
{"prompt": "What are the most important use cases and types of models for Machine Learning? \n\n###\n\n", "completion": " Model Evaluation: Business teams with statistic background. They will check and give a go-ahead. 1 month of Model evaluation phase. ==> Even before Dev => do the analysis. \n\n\nProd: Couple of days, it runs in Shadow, Monitoring and Drift. \nShadow => Roll out \n\nOnce deploy to Prod, everything is by Engg team. Once you deploy, dev effort is done. \nWe were using Drift ourselves - pipelines get triggered at end of day => performance metrics and Drift metrics \n\nLet's take use case of lending // Re-training: We have automated the pipeline for daily re-training => acceptance crtieria is set. \nWe push the pickle file to S3 => CI/CD pipeline is triggered from DataBricks => As soon as it puhes to docker => then it will download, containerise.\n"}
{"prompt": "What are the commonly used tech stack for ML deployments and pipeline? \n\n###\n\n", "completion": " USE OF GPUS: Only for training, not for inference. Distributed training might be needed. \n\nMODEL ENDPOINTS: Flask/BentoML. Few we do with Scala. Some cases, it will not work. Neural net complex model - wont work and we go ahead with BentoML. \nModel servers are not needed. \n\nMONITORING: Grafana, Prometheus, etc\n"}
{"prompt": "What are the common challenges and what solutions are people looking for? \n\n###\n\n", "completion": " Process is well set- underlying data => there is a problem or something. \nPrimary Use case: Lending use case - we will not see the results today; Results will come with a lag to us. 6 Months -12 months. \n\n6-12 Months back data: We use for model training. \n\nPipelines have to adjust to the change to ingest the data. PIT data is very important => How do you ensure this? \n\nDataBricks - Migrating to EMR Mainly. Being able to run daily jobs on EMR. \n\nRESOURCE MGMT: Some tags assigned to every resource being assigned. \nCOST VISIBILITY: Everyday report for last 7 days to 30 days => what's the cost your team has incurred. \n\nINFRA team is really good here. Visibility to things is really good. All business metrics, all ML metrics is published. Tableau, Metabase.\n"}
