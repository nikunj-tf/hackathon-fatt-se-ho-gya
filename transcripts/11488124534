Carlos, can you hear me okay? I can. Yeah. Can you hear me? Yes, I can. Good to see you again. Been a really long time. Carlos, how have you been? Good. Yeah, I can't complain. How about you? I'm doing very well. Am taking a bit of a travel right now, currently in India. Nice. You're based in Seattle, right? Yeah, we have snow right now. Snowing in redmond. Nice. Oh, you're in redmond, okay, understood. Nice. Do you have any plans for the Christmas break? We're going to stay around here, so plans with some friends and going skiing, stuff like that. Nice. Sounds fun. Are you an avid skier? No, I'm an average middle of the run snowboarder, ice snowboard. Okay, lovely. Just enough to have fun. Great. Are you keeping in touch with Facebook folks from our team? So Kushal works in my team. Do you remember Kushal? Yes, Kushal Lakodia. Yeah. Krishal works in my team and then Go Away is kind of my peer. So he manages the back end team. I manage an ML team, you remember? Go away. Go away. She yes, I haven't worked together, but yes. I work with it kind of on a regular basis. Oh, nice. So you have a couple of folks from the team like your coworkers again. Good. Tell me what you've been up to through Foundry. Yes, truefoundry. We took this, I think since quitting Facebook, actually. I've been on this entrepreneurial journey, Carlos. I actually started up initially in the HR tech space first and spent about a year building that startup and that got acquired by one of the largest HR tech players in India. And now with the same set of co founders. This is the second gig that we're doing together through founder. We're fairly early stage right now, maybe like 1011 months in our journey of building out the product and seed stage. Currently at a seed stage. So we raised some money from Sequoia and working with a small team to build out the platform. And the idea is to build out something similar to the predictor service at Facebook. I don't know if you remember. Okay. Yeah. So think of it as almost like a continuation live. If you think of the machine learning pipeline from left to right live, that is the data and feature store. And then model training, and then model deployment, and then the model monitoring. Think of it as going from towards the end of training to deployment to monitoring. So like every learner, like end of every learner to the next predictor service. I guess that's how we think of ourselves. Or at least I communicate to Facebook folks. So it's not like full EPI learner, but it's like you're able to launch your training jobs on our platform, you're able to deploy your models from there. That's the part that we end up focusing on, actually. Okay. Yeah. And the idea here is that like, different. Like there are live basically like two. When we talk to companies which are not like very large tech companies like Facebook, Uber, Airbnb, et cetera, companies still end up spending a lot of time building and deploying ML models. When you talk like this, people who are building models and then they hand off models to other people or Live, this is a separate intra team and there's generally not a very large team who has bandwidth to build out. Live a full fledged ML platform. So that's the segment for which we are currently building out for companies that have enough ML models that they want to build but don't have enough resources that they can build out every learner like platform or a predator like platform, basically. So that's live the sweet spot that we are essentially trying to target. I see. Okay, is this for online inference scenarios? Yes, primarily we do both. We do batch inference and real time inference as well. So people can actually run batch inference jobs on the platform, or they can use we actually convert their models to API endpoints that they can invoke for. Online inference as well. Got it. Okay, cool. How about you, Live? What part of outreach are you currently leading? What's the work that you're focusing on? Yes, so primarily my team is anything that is NLP or text processing within outreach. That's kind of what my team owns. So we have a couple of scenarios. Some are around email processing. So we block some entity extraction out of emails. We do some sentiment analysis on emails right. From these pipelines that your sales representatives have with potential buyers. There's kind of a lot of processing that we do over the emails and then I know you're familiar with. So outreach has this voice assistant assistant that joins your meetings and provides live transcription. And then there's some models, some NLU basically cash buyers and extractors that run on top of that. So for example, if you have a meeting, we have something that is running and the texting action items, we have something that is kind of think of it as a small Q and A engine. So you have a little database of questions and answers that your reps need to be able to answer. So if your buyer asks you a question and we detect we have a match for that question, we'll pop up on we call a content card for the rep to have little bullet points to answer the question. So that's some of the online kind of real time inferencing that we do. So yeah, primarily, as I said, email and then conversational kind of real time on top of transcription. Got it. I see, understood. So Live, the first use case, that is the email analysis and the sentiment analysis entity extraction kind of use case, I'm assuming that's primarily batch, right. Live this, there's a little bit of both. So we do have a semi online. So as emails come in, they go into a catch up queue and we're processing this out of this catch up queue. So it's not real time, but it's close to real time. So that as you go through your emails and we can kind of provide you in as soon as possible, but we do have a batch process also that catches anything that the online piece missed and serves us as a backup, as a backfill, all of those type of scenarios. Got it. I see. Understood. And do you guys use a lot of hugging face models? Is that like the bread and butter of doing most of the MLP now? Yeah. So basically we have some sort of a small PyTorch framework on top of that can consume and load kind of hogging phase models as kind of the base model. So it's basically a little bit of python on top of hogging phase to build. Most of the models are kind of in that reality. Got it. I see. Because live the PyTorch wrapper helps fine tuning the models a little bit better. Yeah. And just kind of some options for configuring live kind of the last layers and doing some managing the rounds. And there's a little bit of a framework that we build on top of that because she'll build most of that for us. Interesting. Okay. I was actually supposed to talk to Kushal also at some point. I will ping him and connect with him once as well to understand this. Yeah. So one of the things that I wanted to chat with you, Carlos, was I guess, I guess two different parts that I wanted to understand live, get your perspective perspective on, which is number one in the NLP world, the team organization bit. Right. Do you see more and more people who are building the models? Are they the same people who are deploying and maintaining the models live end to end, including the infrastructure? Or do you see that mostly people are split across the model builders and would love to hear what are you guys doing at outreach? And then the second question is that if you think about the overall stack that we discussed right? Like feature engineering and deployment and monitoring and stuff like that, where are the biggest gaps that you are seeing in this world? I actually get fairly different answer to these questions when I talk with people who work with more structured data set versus people who work with more unstructured data set. So that's why I want to get your perspective specifically on the NLP world. Yes. On the team split, there's been kind of a shift. Originally we have originally there were two teams, there were an email team and we call the Voice team, which is like any kind of prescriptions, those teams are now merged. The Voice team was very much from the team. Everybody deals kind of everything into end. Right. So the people building the model was the person live, deploying the model and kind of doing everything. Whereas on the email side it was a little bit more of you had a scientist building the model and you had like an ML Ops engineer doing the deployment and the pipelines and that side of things. Now we kind of have this little reorg where we merged the two teams and then we split off some of the machine learning Ops engineers into a platform team. So now there's kind of a dedicated machine learning platform team. But to be honest, I think that's still a bit of flux exactly where that boundary is of who does what. In general, the criteria has been if there's a piece of infrastructure of machinery or something that applies across multiple models or across multiple teams that will be owned by this machine learning platform team, but anything that is kind of specific to a particular model or a particular team, the team will build it EndToEnd. So right now for the most part, we're kind of doing everything like my team is owning from data to deploy model, because in particular because this MLS team is kind of new, is ramping up and so they're still trying to find exactly what pieces they're going to support kind of as a general thing. But yeah, for the most part right now it's more kind of single team managing or building things end to end. Got it? Understood. Understood. And how about the intra location on this bit? Live? I understand that the deployment, like the actual maintaining the pipelines and stuff is something that team is owning, like getting the machines live, scaling up the clusters. Is that the same team that does live your regular application infra? Or this is a separate ML infra team? Anything that is specific to our live, let's say one of these models. Right. So we'll basically do the only training and offline stuff is on data bricks. So there's a team that manages the databreaks instance and they make sure that it's running smoothly, but just kind of the general infrastructure. They take a look at costs and all of that, but like running the specific jobs or building the pipelines that's on the individual team. Right. So we build those pipelines within Kinetics. That's kind of for online and training for online. Right now we deploy to Kubernetes. So we do our own Kubernetes deployments. We roll those out. We are responsible for having the Pots running, for doing kind of the monitoring of those. Interesting. I see. So do you end up using any Argo workflows or something on top of it? Right now our deployment is on DevOps, Azure DevOps. And it's fairly simple. On the voice side, you also have this split thing where anything that is on this voice and transcript stuff is on Azure and anything that is on email is on AWS. So that's where the things are. A little bit of split on the email side, I know they do have some margo stuff that I tried to migrate out of, but I'm trying to remember what they're moving towards. I'm lacking on, but there is a little bit of more additional workload. The email side is a little bit more mature. So that's kind of the original piece of outreach that was built first, and Kayak, which is the voice assistant, was kind of a second. So it's a bit of a newer product. So the interest is not as mature as on the email side. I see. What you mean. Okay, got it. I do have a follow up question, but I want to take up the second question that I asked you, which is, in this pipeline live, where do you see things are the most broken currently or things are the most time consuming that you would rather not have your team spend time on? That's a good question. I think, for example, for online, for monitoring right now, to be honest, it's a bit of a manual process, right? So the monitoring itself is happening mostly on the calling side. So the service that is consuming the model right now, it's doing kind of effectively the login the metrics, for example, computing like distributions or logging live metrics for distributions and things like that. And that is to get an impact to Data Dog. And that's where we put the dashboard and alerts and everything. So that's a little bit kind of a manual type of thing. I feel like there could be a little bit easier way of just saying like, okay, lock me and monitor distributions. Right. And where evaluating I lost you. I'm saying that process is a bit manual in terms of in the Go service that calls these models, we're writing code to publish this metric into Data Dog. Then we build the dashboard in Data dog using TerraForm. So there's a bit of a manual process here that I could see there could be something for right. To support this a little bit better. So I'll tell you, we're evaluating a vendor for some of the monitoring right now. I don't know if you've heard of robust intelligence. Robust intelligence? Actually, I have not heard of them. I've heard of a lot of vendors. In this space, but yeah, okay, robust intelligence, yeah. Okay, interesting. Okay, hold on, I'll take a look at them. Yes, understood. So I have one question here that you mentioned. So when you're talking about monitoring here, do you mean to say the machine learning, model level monitoring live things like, is your data drifting, is your model performing good? Because I'm assuming that the system monitoring and the API health monitoring, et cetera, is well taken care of by datadog, right? Yes. And that so our platform team, like Goa's team, actually, they build some sort of, I guess a little bit of infra layer on top of data docs to do that. So most of that is pretty simple for us. It's a couple of API calls and a couple of statements here and there to enable that. That is mostly there almost for free for us. So the availability, latency, things like that. Yeah, right. So the part that is missing is the machine learning model monitoring side, right. The distribution shifts. Yeah, right, okay, understood. I see. And on this one, like Carlos, actually, have you also evaluated some other vendors like Arise, AI, Fiddler, True Era, et cetera, or Robust Intelligence is the first. Platform that you're the first one I know a different team was evaluating Wild. Okay. But I don't know how far they've gone with that yet. Got it. I see. Understood. You also mentioned about the AWS and Azure part. Right. So is there any technical reasons why the company is using two different cloud providers? For business reasons. Yeah. So the company itself is primarily on AWS. And the reason for you going on Azure is we have a strong partnership with Microsoft for the speech recognition. So we have a both, I guess from a business perspective, our relationship with them, and also from a technical perspective, they give us the ability to customize the models in the way we need and that has been a close partnership with them. But primarily it's because we run the Azure Spatial condition is that most of that, all of the voice processing and transcription and everything is an Azure. You got it. I see. Understood. I see. One other thing, Carlos, is in the part where you mentioned and I'm asking some follow up questions from my first question that I asked you about the team structure. Right. So, for example, if a developer needs more machines to train their models on, like at Facebook, we used to have this UI where we can go get more machines or live in Apple and we launch a job and it automatically figures out whatever machines that it needs to run on. Right. Is that part also currently automated for developers or they need to interface with some DevOps team that is going to allocate the machines? Yeah. So basically right now we use data bricks and there you can provision your cluster right on site that you need. So we kind of do it on your own. You do get that sometimes where you'll meet the quota of whatever your subscription or your subscription is set up for. So a couple of times we've had to go back to Microsoft and ask for a quote increase. So that's where you can get a little bit of friction. But for the most part, yeah, it's us. Just provisioning clusters as needed. Got it, understood. I see. And for this part, have you guys not considered using AWS, Sage Maker or Azure ML, which is, take a note, managed ML of the platform? Yes. So build up something on top of Open, it seems like, right. Azure me for deployment, for the deployment side yeah. For deploying your machine learning models. Yeah. So for deployment side, to be honest, we didn't explore too much on the Azure ML side. We did try Azure ML for a little bit, primarily for training. And there it was not a great experience because we have a requirement that the data does not leave basically a VPC. Right. So we have like a cluster within Azure that all the data should kind of remain. And the way we had to deploy Azure mail to be able to be part of that BPC basically required that to interact with Azure mail to the front end, you have to use this kind of this VM to hop into that VPC. And that was very painful. Right. To have this additional set of hop into effectively a remote desktop or a remote shell to do that. And then that was the main reason. There were a few little quirks here in HML, but that was the main reason to move to the networks because databreaks, they have this data plane control plane. So the data plane we could host within the BPC, but the control plane could be kind of outside and that allows us to interface directly with databricks without having to kind of hop into these grid configurations. Plus the rest of the company on the AWS side was already on data breaks. So that was also kind of a reason to go with them. But that's primarily for the training. Got it. I see. And for this one, like you talked about, Azure ML Live. Is Sage Maker similar experience or Sage Maker something that you never evaluated? I've never evaluated. The history here is that I primarily have worked mostly on the Azure side of outreach. It was relatively recent that the email side kind of got merged into became a part of my team. So I personally have not worked a whole lot on the AWS side, even though now some people in my team kind of are on that side. But yeah, I haven't gotten as familiar with that. Got it. Understood. And the other thing is the choice of deploying it on Kubernetes as opposed to one of the more managed ML Ops platforms, was that taken, like, before you joined? Was there something that you were part of that decision making process? I would love to understand any rationale behind that. No, that was kind of there before and it just has not risen to the top of the list of things to reevaluate. So we haven't really gone much further down route. Yeah, got it. Understood. Okay. So it just works that way and people are fine with it. So you never hear complaints about managing Kubernetes clusters and debugging on Kubernetes from ML developers of the sort. Right. Is it not really, no. Actually Go's team manages most of the Kubernetes cluster and yeah, so it was set up before I joined. So it was relatively low friction to just add a couple more deployments into kind of something that was set up. So it was not too hard for us to kind of expand on that. In terms of runtime and debugging, it has not been bad. I can't remember any kind of particular difficulties around debugging there. I see. Understood. And here one of the other things, is that with NLP model, specifically for that matter, all the unstructured data sets live, being able to debug what's happening live, what's wrong is fairly hard generally because it's not like you can look at live, identify which particular segment of your text hello? Can you hear me okay? Yeah. You broke for like 10 seconds. Okay, can you hear me now? Yeah. We're talking about the kind of the difficulty debugging text models. Debugging? Yeah, debugging text models and writing test cases, maybe for these models. Do you think that the team is already writing a lot of test cases for the models itself? Not as probably not as many as we probably should. That's one of the areas where this robust intelligence offering seems appealing. They have a framework for doing stress testing on NLP models. You can look at the roughing, but that's one of the areas we do have kind of our typical test set on BBT, but that could be a little bit more comprehensive. Got it. Understood. Okay. I think this is very helpful. I think at this point, I'm actually spending quite some time talking to people and understanding where are they seeing problems. It turns out, actually, monitoring is one area that stands out quite frequently, as you mentioned as well, that people are facing a lot of challenges in the model monitoring side of things. So something that I should look a bit more deeply into, like as a platform, we have not focused too much on specifically NLP monitoring. I think we've been focusing a lot on the structured data monitoring, like figuring out data driven on individual features, because a lot of those algorithms actually don't work so well for NLP use cases. So we are doing a little bit of that. Actually. On that note, Carlos, it would be very interesting for me to kind of at some point get some feedback from you on the platform that we have built out in terms of how to set up the infrastructure, how to deploy models and monitor the models and stuff. If you would be open to whatever, spending 30 to 40 minutes with me going through a platform demo and giving me some feedback there. Okay, yeah, I could do that. Maybe we can reconnect after the holidays, or if you prefer, during the holidays as well, given that you mentioned that you'll be around in the city itself. So if you feel like you have more time there, that works for me too. Yeah, probably after, because I will take some time off. Okay. After the holidays, maybe I can pay you again on LinkedIn or something. We can set up a time to time to chat. Sure. Yeah. I'll be curious to see what you've been building. Yes. And besides that, do you travel to the Bay Area frequently? Not really, no. The company's seattle based. We don't have a small office in the Bay Area, but I never have a need to go there. Got it. Do you guys generally work live mostly remotely or do you guys work mostly from the office. So we're in a once a week scheduled right now, and in February, we were going up to two days a week and then the rest from home. Oh, I see. Okay. Wow. Okay. Nice. Yeah. So that's fairly comfortable. And for the once a week, do you guys keep live the entire office space reserved throughout the year? Yeah, so I don't know how the lease works, but the same office we've had for a long time, and yeah, it's been empty for quite a while, but more people are coming back, and some people that live in Seattle live closer, just decide to go more often. Right. I have one person on my team that usually goes three times a week because it's convenient for them. Okay. Yeah, understood. All right. Very nice. Super nice to connect with you again, Carlos. Yeah. I would keep in touch with you live. I'll reach out to you for the feedback call that I mentioned. And yes, we would love to stay connected. Yeah, sounds good. Let's chat in the new year. How's? Happy New Year. Happy holidays. Have a good one, Carlos. Happy holidays. Bye.