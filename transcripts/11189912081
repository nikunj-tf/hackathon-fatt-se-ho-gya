Bye. Hello. Hello. Hi, how are you? Hi Jeff. I'm good, how are you? I'm good. Thank you for choosing this. Yeah, of course. Are you dialing in from New Jersey? Are you in which location, where located? Sorry, right now I'm traveling to traveling to India. My co founder and Rag is based in India. Oh hi Ragla. How to pronounce him ragna. You can call me ANU. ANU. Nice to meet you. Nice to meet you. Jeffrey so your company is in San Francisco or in India? San Francisco, basically like our company headquartered in Delaware. Okay. I need to meet with you guys in India. He just meant for us to take this call and figure out some good next steps in terms of like the ML of Set, merck and stuff like that. That's the context. I can give some more context. Do you work very closely with Suman? Yeah, I work under Suman's organization. Okay, understood. So the context here is that Summer and I had a chat about one of the platforms that we are building. I will give you some background about our team as well. Jeff this is around operationalizing your internal machine learning processes. So imagine like deploying models, deploying batch and print jobs, monitoring your models and stuff like that. And someone really liked building based on the discussion. So he was like, we should definitely do a POC so we can figure out how can this help merck in general in his process. Right, so that's where someone connected us with you. Let me share a little bit of my background and rock and also tell you some details. So I personally come from a machine learning background jeff I did my masters at UC Berkeley and since then I've mostly been working in the Bay Area in ML. So initially I worked at a startup called Reflection where we built out a lot of recommender systems for the ecommerce industry. So there I got a chance to scale our machine learning systems from 100 users to like 600 million users a month across hundreds of ecommerce websites. Most of I joined Facebook to lead one of their conversation AI teams. So if you have used their virtual assistant product called Portal, which is like the Alex or Google home of you, that's the team where I was leading out of the conversation AI efforts. And between quitting Facebook and starting True Foundry, actually Anuraga, Vishek and myself, the three co founders here also did another startup that got acquired by the largest HR tech player in India. So that's a little bit about my personal background. Also telling you about one of my co founders, Abishek, who's not joining this call right now. Abhishek actually joined Facebook and spent like about six years there. Three years out of New York office and three years out of the Bay Area office. And before he quit Facebook, he was leading the entire videos.org as an IC basically. So actually one of the fastest growing engineers at Facebook. He has also led some of the Caching and Preoptimization teams as well. Okay, I can add maybe briefly just like again batchment of anikunjana Vishek from Karakpur. After that I worked for a hedge fund called Worldwide. We used to do asset management across global markets. I was managing around 600 million in assets for them primarily again across global markets trading equities and during that time I was also a member of the CEO of Is looking after various strategic initiatives for the firm. Spent part of my time in Mumbai and then around three and a half years between us and Singapore myself. Used to also angel invest into a number of startups and then finally that Mercedes into our journey of finding our startup and then now building through foundry with them of optimizing ML models. Okay, I see. Yeah. We would love to learn a little bit about you as well Jeff before we start. Yes, sure. So I need engineering team here and also have a couple of projects like MBX and Business Engine and mostly so I'm on the engineering side, I manage the product development deployment like going out to the market. My background, I jumped different health care company mostly in the healthcare AI space. Before Merck, I worked for clarity and voxo cloud. They all healthcare AI startup. And also before that I have spent half year in Cisco. I work as a software engineer and I graduate as a commercialized degree. So would love to hear more about your products for sure. Thanks a lot for sharing your background Jeff. Actually in this call we will obviously share a little bit about our product as well. But we would love to spend some time trying to understand a little bit getting more context on some of the messages that I think someone sent out. Like he mentioned a few names that obviously we don't understand because they're kind of internal names right now. NBX and all that's one thing. And the second thing is we also wanted we had a few specific questions about how is the team at work structured in terms of building and deploying models, what are the tools, technologies, cloud on prem, et cetera that you all are using. So we had a few questions as well, if that's okay with you. Yeah, maybe before that it might be good to kind of give a two minutes overview so that context then you can focus on telling problems around those areas. Can you share me some of your solutions, what you are selling like the product or service? Let me give you a little bit of a background very quickly. Okay. Just give me 1 second. I'm going to pull up one slide and show you that. I think that should clarify and Rogue, you have that slide right where we talk about what roof on Is building. Do you want to quickly share that and give him some context on what we're building. Okay, sure, I can do that. Are you able to see my screen? Yes, we can. Jeff. So basically, like, the ML workflow, as you know, it involves like data and feature engineering to kind of get the data from different silos into one place. Then there is the model building where data scientists are building their own models. Then you need to deploy it, which could be in production environments, and you need to scale this deployment system. And then at the same time, you want to be able to monitor it in the way that you can ensure that there is any data. Then you can retrain if something is going wrong. So we are in this part of the pipeline. So first you have built out the model, the entire deployment, the entire monitoring piece. So basically the thing around operationalizing ML, if you think of our platform, we have built a platform to speed up the developer workflows with full security and control for the Internet. We make it very easy to kind of deploy models for data scientists or ML engineers. We make it also like the platform works in a way that it is very simple to learn for anyone in the team. Like even if they do not have knowledge about complex infrastructure, or if they do not have engineering skill sets, it works. And even if they have engineering skill sets, the platform kind of speed set up, it kind of ensures the best si practices by default, and at the same time, it ensures that everything is done on the same infrastructure that you are currently running. So roughly, basically, there are three major parts. One is related to setting up your infrastructure in a secure way. The second is making the model deployment of different types with the right scaling, with the right practices in the right way, and then finally being able to do basic monitoring on top of that. So, just wanted to kind of like this picture so that you have that. And then we are working with companies and customers to build around this as well as at different solutions around this, so that we can help them speed up their overall deployment or the operationalization challenges that they are facing. And that is where someone had connected, as Nicole mentioned. Probably. I would love to hear about the kind of challenges you are seeing at Merck and then very specific to also some of the things that okay, so. Are you trying to provide service or this is like a platform. We can use it's. A platform you can use, yes, you can use platform. And if you want, you can build on top of this as well. Or we can help you build on top of it, working closely with you as well. Okay, how to use this platform? If there is a data scientist they want to deploy the model, how to use it? Yeah. So basically what will happen is that we provide like one of our client side library so that you can install do your data scientists frequently use like Jupyter notebooks or like Python? Okay, so you can actually directly install that client side library that we provide on your Jubilee notebook itself. And imagine that you have like written a training script that you wanted to run on a cloud machine or you have written like an inference function that you wanted to expose an endpoint for. So for each of these we provide you APIs as part of that library. You can invoke that API directly from a Jupiter notebook and it will quickly deploy your model on a remote server. Basically let's see which infrastructure you require, what kind of infrastructure do you need. So we work with pretty much overall any infrastructure right now. The platform supports Kubernetes and can work across multiple cloud on premise as well. But we are open to working where people are using specific clouds as well. Plan with the infrastructure inside work you need kubernetes, I'm not sure, do you have like infrastructure? Basically we need to deploy your package or deploy my system right here. So you will generally deploy the package in your infrastructure. So we make it, we work with your infrared team to make that happen. And that's why we wanted this call to understand a little bit more about the entire pipeline and we didn't want to give you the full product because a lot of times there are nuances in the product that is on your deployment. So I think just wanted to give an overview so you have a sense of the problem. But if you can tell us a little bit more about the ML pipeline at more about the specific problem areas, that will help us also understand your problem and then we can probably give you a better suggestion to how you can use it seamlessly within more as well. Okay, yeah, I can give you some overview of the team setting here. So, basically, we have multiple products like MBC stands for Next the Best Experience. Next Business Experience. So It's recommendation platform, it's already been built and served for different countries. And we have piercing inside engine. We have business. Engine. Those are pretty matured products. Another part of the large group, they are technical analytics and they do like ad hoc stuff and they analyze the patient journey or market size or just commercial business analytics and they provide the insights back to the stakeholder so they can decide how to sell more job. And there's a data strategy team, they onboard the third party vendors. So we have a lot of vendors like Ikea, Komodo, those are the data vendors. They provide the claim data to us and we need to onboard those data set and standardized data set. Yeah, that's basically the settings here and there's the It team, so we need to communicate with them. It's called HSID, they provide AWS environment. So I assume if we use your product, we have to deploy your product. Because we manage the Python package, we have the internal pipeline, and we only can install from internal pipeline. We cannot download from outside. I need to think about how to sort of onboard your package and deploy your system. Because we have limited sort of budget, if your system costs too high, the item won't allow this. So that's why I need to understand your infrastructure by battery so I can get sense about how to talk with the It in order to deploy your system. So I'll give you one context here. Just like we have been working with another really large company, two very large companies in the enterprise space similar to yours in different domains, and they also have like a pretty stringent It team. So we have been able to work with them to deploy on their infrastructure pretty simple constraints with regards to VPC or with regards to downloading an external package. And all of those will not be there. Like, we'll work around the constraints of your It and will kind of work seamlessly with them to make that happen. So that is something you should not be worried about. But Nicole, do you want to share more around that so that concern at least is allocated? Yeah, for sure. So like you mentioned about the internal pipe package, of course there will be some security. And by the way, this is all when we get to that stage of deploying truefoundry on the platform, right? So far, we still have to validate if the fit in terms of the project that you guys are working on, what we are building, et cetera, is all good. So we have to spend some time there. But imagine that we get past that then exposing our package to be deployed on your internal pipe by going through the security reviews, going through the compliance reviews, et cetera, something that we have done a few times before. Our platform has already gone through stuff like VIP testing and stuff like that. So basically we have already gone through a bunch of the hoops in terms of It, security, compliance, et cetera. And also our team is flexible to work with your constraints as well. So if there are some other things that we need to take care of, happy to work together and make that happen. So I guess that's where we stand. If you had other specific. I need to understand your solution better. So can you share some details about the solution architecture or something like that? Because even like, if I on board you guys, I have to socialize with the It team. So they will ask me what's the solution? They need to understand what you guys are using with service like that. Okay, let me maybe spend like five minutes and give you an overview of the product itself. Okay. Just so you have a good mental map of what we are doing, how we are doing it, and if you have any more questions on that, we can actually take some time today to answer those questions and then we can get to some questions that I'm ragging I had for you. Is that okay? Okay. Yeah, sure. Okay. I'm going to keep it fairly high level given that this is a first call that we are taking. You get an overview of the product itself, right? Do you see my screen? Yeah. The way you should think about the demo is imagine that Merck already started to work with True Foundry. What would happen first in terms of like whatever installations and all. And then what would the data scientists or machine learning developers within the company, how would they interact with our platform? Right? So like, imagine recommended system, how would they interact with the platform? Those are two parts that I will show. So first thing is, let's say if you have already a Kubernetes cluster running within your company, that's what you want to use truefoundry on that is deployed through. The way that works is like you connect that cluster with our Truefoundry dashboard. Now, connecting up cluster itself does not do anything. It just tells us that there is a Kubernetes cluster that exists like this. But then what you would do is you would actually install a couple of helm charts on your Kubernetes cluster. And that's basically going to set up the infrastructure that is required by Truefoundry to run your machine learning models. And at that point, you will start seeing that this cluster is connected on the Truefoundry platform and it's available for the data scientists to be able to deploy their machine learning models via the Truefoundry platform. So that's pretty much like the setup. There's a couple of other things that you can set up. Like if you wanted to connect your docker registry or get and stuff like that, you could do that. But I'm going to skip all of that for now. Now imagine that this place is set up and I'm going to give you a quick overview of what your developer experience would look like. Right. Imagine you have some data scientists in the company that either want to deploy any services, which are like, imagine any API endpoint for preprocessing or postprocessing of your machine learning models. Or they want to deploy some jobs which could be like a training job or a batch inference job. So something that runs once spins up a machine would execute that piece of code and then kill the machine. And lastly, if you wanted to deploy a model where let's say you have a model file saved anywhere, like an S three or something, you just provide us the Uri of the model and we will just deploy that and give you an end point of the model. So these are the three things that a machine learning to represent deploy on the platform. They can do it directly from the UI. So, for example, if they wanted to deploy a model, all they do is on the UI, they tell us the name of the model, they will tell us a Uri of the model itself, and just hit Deploy. Okay, if they want to deploy a model. So can you show me an example of the model? What an example model looks like? Is that the question? Yeah. So in here, basically, we support different types of models. For example, let me actually show you how a model looks like. So, for example, let's say we have, like, whatever, a basic Churn prediction model here. So, like, this model itself, if you think so. These are all the models that are logged on our platform. We have version control of each of the models. Here. You see that the way this model looks like is it takes like a few of these inputs as arguments, right? Like, these are the features that this model takes as argument. And then the prediction that it makes is like a categorical prediction, for example, right? And then if you wanted to understand how this model looks like, you can actually look at the actual, whatever. This is a psychic learn model. It is saved using a pickle format, for example, right? And then you can obviously download the entire model if you wanted to and stuff like that. Basically, we can also track some important things like metrics and stuff. I'm just trying to understand the workflow. So data scientists can write anything in jupyter notebook and then what they need to do. Okay? So I think the way this conversation is going is we are practically giving, like a full demo of the platform in some way. I'm happy to do that, but I think usually the only problem in giving, like a full pleasure demo without us understanding some of your requirements is we end up covering, like, all functionalities of the platform that may or may not be relevant. That's why we generally like to personalize the demos for the problems that people are facing. But in this case, because you're curious, I'm going to give you a little bit of this workflow. So, for example, let's say a data scientist wrote, like, one training script in their Jupiter notebook. This training script is very simple. They read their data, they instantiate a classifier and the trainer model, right? Now, let's say they want to run this particular training script on our platform, okay? So there are two different ways in which they can do it. Number one, they can directly have this training job deployed from their Jupiter notebook. So basically, like, this service boundary that you're seeing is true as our SDK that a data scientist would put on their machine. And then they write like, these five lines of code. So they need none of these, actually. They just write these five lines of code and when they hit a job deploy it will directly deploy this particular training script on our platform. And they will be able to track that on the dashboard here. Okay, so they can actually see this on the dashboard here. I see. Could you go back to the notebook? There's this. Like, be the same script. That the data scientists wrote here, and they just. File. There are also ways on the platform where they don't need to dump it to a file and they can directly deploy like a function as an end point as well without actually writing it to a file. We also have that API. But how about the data if they want to connect with a database? Yeah, for sure. So remember that this is like a vanilla Python script, right? So in this case, they are getting the data from this read CSV, like a CSV file that's hosted on GitHub. Practically, you can actually implement a simple thing like read data from that function and we would be able to read that. And we also have full permission controls as well built into it. So if you wanted to provide, read or write access to the data scientist about a certain database or whatever, you could do that on the platform as well. I see. Okay. So what kind of service do you need to deploy this? Sorry? What kind of the service? You said you need a Kubernetes, right. How large is the cluster? So that really depends on the kind of loads that you want to deploy on the model. Like, we have a couple of infrastructure elements that we need to have deployed on the Kubernetes cluster. So, for example, we need a postgres database and one file system itself. So that's what we need. Like you're deploying on AWS. If you're deploying on an AWS cloud, then we need S three. If you're deploying on GCP platform, the minimum requirement is this one. So usually some of the Kubernetes customers that we have worked with are like nine CPU and 3GB of Ram in terms of sites, just to make sure that we have enough things to deploy the infrastructure that we need to run all these systems. You use the apex provided. Kubernetes. It usually depends on the type of usage. So I think without actually understanding the kind of usage of the platform, it's actually really hard to provide the cost because is it constrained on CPU? Is it constrained on GPU? Is it constrained on number of developers? How many models are you deploying? You charge by usage or you charged by user. So user is one metric, but we also have different levers on the number of applications that you are deploying on the model. It's not necessarily about how much CPU are you using, we charge based on that. But like, number of applications that you're deploying, number of models that you're deploying, the size of your set that you're dealing with. So there are a few factors that we need to consider. So it's really hard to give up charging. Okay. I need to have a rough idea about how much it costs. We need to report the budget. How big is the team. Which have copied 50 I think at least 50 people developer at least 50. Okay, got it. Let me just think once. So if we did not assume anything, if you had to really guess based on how many models are these developers deploying and stuff like that. If we really had to just index on that one number and give you an estimated price point, that would be roughly in the range of 200K for deploying for that many number of developers? Two hundred k per year. Okay, that's based on what? Based on users or usage. That's the only information that we have. So like if you had to guess a price based on that, we would say something in the range of 200 kwh. It can be more or less depending on the usage. Okay, so you need Kubernetes because our It teams, they don't like Kubernetes. We mostly use service tool. Can you not using communities instead of serverless? We can support serverless. So basically, Jeffrey, at this stage, as Nikon mentioned, there are some organizations we are working with Q and It's requirement is there. There are some organizations where people are asking us for new things. So if serverless is a requirement, we can definitely build on top of it. But we'll need a little bit more understanding whether of this are all models going to serverless? One question on the serverless, when you say serverless, what is it running like? Do you mean serverless? Like lambda serverless or running it on? We can use Lambda glue, job orchestration tool like Step function, Airflow, those are what people frequently use in our organization. And if you I don't think anybody use communities. We can do Far gate Fargate is something that is already getting used on our platform. Okay. Is there a way like we can have like trial version that people can test it? Absolutely, yes. We can also spin up an account for you that you can try the platform out. Get a feel of how the platform like deployments and all work on the platform. Absolutely, we can do that. Yeah. When you say open up account, it has to connect with your server. So if you wanted to just try out the platform, we generally recommend using not using any sensitive data for the trial itself. Right. You probably don't want to use any very sensitive patient data or something. Then you can directly do it on our cloud, like with some public data sets to get a feel of the platform. That's a very quick way of trying. We can open up like a user account for you. If you wanted to do more immersive testing of the platform, like trying out, then you could also experience deploying our platform on your cloud or something and testing it out there. But usually that process is a little bit longer and we recommend trying it out on the public platform. I see. In the long term, my understanding is that you would not want to use like public cloud for training your machinery. Models of the sensitive data that you deal with and everything would probably need to be by design within the ecosystem. Yeah. Okay, so what kind of information you need? You said you want to understand better of what yeah. I think you mentioned number one, that is like you are using AWS as a cloud. First of all, two things, that is how is your team structures? You mentioned you have 50 to 100 people. Do you have like a lot of data scientists who do a lot of experimentation but don't deal with like actual productionization of these models? Or do you have ML engineers who do like both kind of stuff like a platform team? We'd love to understand your team structure and then also would love to understand about what is production for you. Like when you deploy deploy models, what does deployment mean? What kind of models are getting deployed? Where are they getting deployed? Would love to understand the deployment workflow as well. So yeah, if you can start with these two questions. So, as I mentioned, there are three products. So for the product project, so they have entire product team like data scientists, engineer, MLPs and they build a model by yourself and also deploy the model by themselves. They use mostly firm data like step function, like Airflow, good job, those things. And then model deployment. Sometimes they use Sage maker and then for the technical analytics, we sort of want to deploy products as much as possible. If your platform can help us deploy their work, probably it's meaningful for us. For that technical analytics, they just write the script in Jupiter notebook and conduct analysis and then the slides put into a slice and send to the business stakeholder. So you can help them to maintain their work and also connect with we have internal asset management tool. Can browse the model, browse the model through internal website. I'm not sure the progress there I need to connect with them, but it seems like someone want to better manage those assets. It seems like your platform can connect with that asset management tool. Nice. Yeah. So actually I want to understand a little bit more. You mentioned about the technical analytics like where they write jupyter notebooks for creating a presentation for the leadership, right? Maybe help us deploy that. What do you mean by that? What kind of deployment there are you talking about? I mean probably just trigger the Jupiter notebook in a certain frequency. Sometimes there's a report that has to generate like monthly, weekly like that and that's probably one use cases. Understood. Okay, got it. And. The second thing is, like you mentioned about the asset management tools. Are you using like what are you using for your model and asset management right now? I'm not sure there's a team to do that. I will meet them next week to talk about how to collaborate, certain things for that. That's the internal engineer to sort of do this. I don't think they can connect with the model. It's just a place to put a link. There is a model name and it can link to the gift repository document like that. But it doesn't have a way to trigger the model. I see. Understood. Okay. So they don't have the full loop closing where the model itself is saved, but they can't actually trigger the model or get an API inference or something from the model. Yeah. Okay. Actually that's a good .1 of the other thing I wanted to ask is you mentioned that some teams use Stage Maker. Do you know which parts of Stage Maker are the teams using? Is it like more on the training deployment? Deployment. Usually they don't train on a Sage Maker, but they will deploy their training script using Sage Maker. So for the MBX, they will train the model, like once an update model and then use the back interest job to trigger the model. I see. Got it. Okay. For those products, I don't see any need for your platform. But for those ta work, they probably need some way to maintain their work and deploy put into the product phase. That's what suma want, I think. So just to make sure I understand this right, you're saying that for the training jobs that they run on Sage Maker, there is not value to be added from the platform, but basically managing your like, the model one place is something that we can add value. Yeah, managing those analytics work. Oh, I see. Okay. Basically I think some I want to build more like production life more work. Like those tape. Work is right now not getting productionized. You're saying Jeffrey? No, this ad hoc. And you want to get to a state where all of these are also productionized so that someone else access. Out of the 5200 members you mentioned, how much part of the team actually works on this technical analytics work? I think at least half of them. Half of them. Okay, fair enough. Understood. Okay. And curious to know about. I remember someone also referred to some projects like I think they had cryptic names, four of them. Which project? In WhatsApp group? I think the projects that you mentioned were like NBX CTAP. Yeah. Okay. If you want to pilot for this, I need to talk with C Tag and Pi team, see if they have the need. And also for MBX is very matured product. They have well maintained infrastructure. It's hard to break in. I think for C tub and Pi or bre. It's very new. But for BR e, it's a different story. It's not machine learning model. This is all business model, all the SQL. This is more focused on ETL part, but for the CPAP and Pie probably there is some opportunity there. I need to talk with some. Also out of time currently, but is it possible to have another call with you? We would love to understand a little bit more on the technical analytics part, like exactly what is happening, how many models probably. And then also if you are able to get some more information from CTAP and Pi and if need be, like we are also open to doing a more detailed presentation for this folks or folks in this team if that helps in some way. Like we kind of. Not in the merchant network, so I'm not sure, I don't think we can talk more of that part of the work. I can just tell you that they write into the notebook. Some of them are machine learning model. I think that's all. I don't even know the detail about what they are doing. The model won't be too crazy. It's not a deep learning model, it's just even simpler than machine learning model. In our work, the most heavy part is ETL part. The data is pretty noisy most of the time they spend based on the GP part, I can tell you, but I sort of understand your technology. But I haven't jumped into more detail about the infrastructure. But I need to talk with a different team and to see if they need this kind of tool. If you can, can you set up meeting, talk more about the infrastructure? Yeah, that would be more helpful. Yeah, I think we can do a second meeting where we can tell you more even about the product. Like I think we kind of gave a high level overview because and we can talk more about the infrastructure. Okay. One thing I'm curious how you make yourself unique. Like there are different amount of stuff like data to you or I heard different the Data dog or yeah, I don't remember the name. Yeah, so there's like a few different types of platforms, Jeff. Like data. Robot data IQ. This Amazon figure you mentioned Then we have data breaks, right? So we have all these different startups try to solve the problem. There are primarily two ways in which we make ourselves unique. Number one, which is we meet the data scientist that is a model builder in their workflow and try to make things very simple for them. So like if somebody wants to work on top of Jupiter notebooks, they could continue using Jupiter notebooks and deploy models. Jobs API endpoints directly from the Jupyter notebook using very similar looking APIs. So they really don't have to learn much more in using our tool. And when they do deployments using our platform, like a lot of engineering best practices that data scientists typically don't follow. So for example, things like tracking every change that you are making, everything version controlled, those things are taken care of by default so that it's much hard to make any mistakes as part of their machine learning pipeline. Right. So that's like the first most important value addition that our platform has. The second value addition is that if as a platform team owner so for example, let's say if you are the ML Ops architect in the company or you're leading the MLPs team within the company and you wanted to customize the platform for some of your own use cases. Because we understand that a lot of times the platform directly out of the box does not work for many diverse use cases and you may need to customize on top of our platform. So we have built out everything in an API driven way. That is if you want to certain things. It's also very easy to do that. And that complaints that we have heard that some platforms are actually maybe easy to use, but they're not customizable. Like, for example, Data Robot or data IQ. Whereas some platforms are customizable, but they're not very easy to use. So that's like a code differentiator. Yeah. Okay, sure. Yeah. I will talk about your project to different teams to see how they respond and I will let you guys know. Yeah, so I think it would be best if we set up like two action items from this meeting. Number one, of course you can set up a call with the CTAP and the Pie team and what kind of use cases that they have and you can basically kind of act as like a bridge between the CTA and Truefoundry right now. And the second thing, we can set up a follow up call where we can walk you through our infrastructure details, understanding of the product, because today we kind of just skimmed over it very briefly but happy to share. Is that necessary so that you also have more context on like when you go talk to different teams, you can actually add more color to the conversation. Okay, sure. Okay. If you can, can you send me how to quote your price? I need to tell someone if we're going to do that with seat above, I need to tell him what the cost is. Okay, yeah, we can send out some. Details, base cost structure, but there will be other variables that can come into play and we can work around that. But at least the baseboxing structure we can send it to. Okay. And if you want I can also talk to someone about it if that's helpful as well to facilitate some conversation on that side. Okay, but I need to discuss this with her and Pikke first, so I will let you know. Okay. When should we set up a follow up call? Like sometime next week? Do you think? Like Tuesday next week? You can check my calendar next week. I'll be in India. I'm traveling next week. Which part of India? And Mumbai. Okay. How long are you going to be there? One week. Actually, if you have time, we can potentially catch up. Like, I am based in India right now, so happy to kind of get in the first week. Maybe we can meet that. Well, it's not necessary, but through video chatting, I have more flexibility in Mumbai from Monday to Wednesday next week. Or you can schedule a call, like Monday to Wednesday. I have more time there. Okay, cool. I'll try to see if it's possible to meet in person. Otherwise, we'll set up something over the video at least to kind of go over the details of the product and the infrastructure as well. Okay, sure. Sounds good. Do you have any travel plans while you are in India? Like, can we help you plan your trip around here in any way? No, that's it. My colleagues already planned bunch of stuff. Do you want to party while you are in Mumbai? Mumbai has great parties. I'm not sure. I travel with Suman. I'm not sure what's his schedule. Oh, yeah. Suman is also coming to India with you? Yeah. I see. Okay, so Suman probably understands already, like, some of the local stuff here. Yeah, we have a bunch of India colleagues there. Oh, nice. That's very good. That's very good, Jeff. Okay. All right. I think this is great. Let's actually try to meet in person in Mumbai. We will try to coordinate something. All three of us are connected on WhatsApp? So we can try to finish figure something out. Okay. Okay, sounds good. Thank you, Jeff. Thank you for your time. Really appreciate. Thank you so much. Good one. Bye.