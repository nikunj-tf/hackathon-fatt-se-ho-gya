Hi, Beville. How are you? I'm doing well. I'm sorry, but somehow my Chrome is not detecting any camera connected to my computer, so I cannot switch on the video. I couldn't have it. No worries. That's pretty. All right. How are you? Which part of the the country you are located in? Right. So I'm in Canada, and within Canada, I am not exactly in Toronto. Very close to Toronto. It's called Brampton. It's also called, by the way, nice. The weather must be super cold. Yeah. This part of the year is usually cold, but fortunately there's not a lot of snow at this point of time. Otherwise, December and all the way up to March is very snowy. This year is better. How about you? So I'm based out of banglar. Weather is always pleasant here. I think you wear in Bangla, so. You know that for three, four years, right? So weather is always present here. Any point of the year. The traffic counters the weather. Actually. It is getting worse and worse by the year. I know. Hello. Hi, Vivek. Hi, Babo. Hey, Quinch. How are you? I'm doing very well, Babo. How are you? I'm doing well too, thank you. Where are you based? I'm in very close to Toronto. I'm in Brampton. Actually. Canada. Okay. Sorry. Very close to Toronto. Where did you mention the city is called? Brampton. Okay. Brampton. Okay, understood. Nice. Good morning. Nikkunj is the co founder and the CEO of the company. And he was based out of SF. Actually, he's based out of SF. Right now he's traveling in India in multiple cities, and in fact, he happens to take a bus in some time. So probably he'll be there in time permits. I didn't want to postpone this meeting because I wanted to go through it, and if time permission will. Great. Thanks a lot. Weake for sharing the background. Apologies, web. I think some mess up with the first timing happened, and I might have to leave, like, five to ten minutes before our call in. But that said, let me just give you a brief introduction about myself and also about the Foundry. And after that, I would love to learn a little bit more about you and also your work at Procore. Right, sure. So I personally come from a machine learning background. I used to be at Facebook, where I led one of the conversational AI teams building their virtual assistant product called Portal. And prior to Facebook, I used to lead the machine learning team at a startup called Reflection, where I got to build out a lot of recommended systems, personalization algorithms for the ecommerce industry, and besides that, build out a horizontal machine learning platform because we had, like, five, six different teams building ML algorithms. And it made sense to work towards developer productivity. So we built it out, scaled the system to roughly 600 million monthly active users. And the journey, I got a chance to see the Reflections journey from getting its first customer to these hundreds of ecommerce giants basically. So it was a very nice experience working there. And between Facebook and starting through Foundry, I did one more startup with my current co founders Abishikan and Rug in the talent space which got acquired by the largest HR tech player in India called InfoAge. So talk a little bit about my background. Sorry, Info? Correct. And all three of us on Ragabhishek and I went to Karakpur for our undergrad we are 2013 batchmates. I see that you went to Kanpur in 2006 to eleven. I was in an adult degree program. Understood. I see. Yeah. So I also have a lot of Kanpur friends because during my masters I got a chance to meet a lot of them at Berkeley. Yeah, you have a great background, great to see folks from fellow It is doing wonders. Thank you. Thank you so much Weber for the encouragement. Need all the good wipes to come in because during a startup it's not easy. I have been there, I have never been a founder but not similar story. Three of my It conquer seniors, they were just one year senior so pretty close and at that point of time I was fed up with life as like what's going on? Was I supposed to work on Excel seats for the rest of my life? So I approached them, I was like don't give money but I would like to work with you guys. So I have been there, the anxiety, the initial you'll get some little encouragement meeting VCs or meeting prospective clients and then a lot of times it doesn't go anywhere. I have experienced that part of as well as disappointment a lot of times. Honestly it makes this conversation much easier for people who have been there than that because like you truly empathize with how much startup meets in this phase of the product building and company building. Right. So thanks a lot for volunteering to help as well. No problem, happy to do that. Great. I can go over my background a little bit. I have tried a lot of different things in life after college because I wasn't sure what should I be doing. So I started with analytics then did software engine for a while and then joined the startup. That is where my machine learning journaling started. The startup was called Islands and it was a computer vision startup mostly focused on visual search, automated tagging in the usual computer stuff that you would see in the 2D space. After that did consulting for a while with Learn OpenCV if you guys might have heard of Sattamale and then came to Canada. In Canada I have mostly worked in the computer vision space so there was a startup here who are building video analytics solutions for construction industry actually both video and images and they were doing okay, they were not very successful but at least because the founders were very experienced. So it was a lean startup and they managed to survive COVID two. Luckily they got acquired by Procore. Proko as you know, is kind of jira for construction industry, all that. They do more than jira apart from the project management, they have financials and project estimation bidding, a lot of different steps in the whole workflow of construction industry. So that is how I joined Proko. I was working at industry and then Proko acquired us. Most of my life I have worked with startups. Proko is the biggest company I've ever worked with, although in two sense it is not a big company. It just crossed the face from a start up to a district company. So I have been on the applied machine learning side when I started the career, stayed there for I think six, seven years and then switched over to the ML optimal platform site. So right now, I'm in the ML ops team within pro quo. Lovely. Wow. So I think we are going to learn a lot from you in that case. I don't know man, you have been at Facebook. I can share the perspective of startup facing the challenges as well as a mid sized company, but I have not yet personally experienced the pain points of a huge organization. Got it. When you say startup, do you mean like Pro core from the startup to a mature phase? Vala organization is what you mentioned. Right? And startup as a very small startups. For example, in the they did not have their ML Platform team. What they did was they hired a single ML engineer. The scientist will write their code and that ML engineer will do his best in order to push that code to production. And when I joined they specifically hired me because they were having a very bad time managing their production workloads. Every other day was firefighting code getting crashed, services not scaling. They were having a lot of issues. I think indus raised up to series B, I'm not wrong. So startups who have crossed that phase of series A and series B because there is no direct benefit of, let's say investing in MLA's, founders do not prefer to do that and then when there is a need, then it's too late. So even startups like that can benefit from some early stage adoption of an optional platform. That makes sense here. So one of the things that we are seeing, webho is in the industry, similar to what you mentioned as well, that startups typically are very resistant to building out anything in house, of course, and also fairly resistant to using something external for ML Ops, at least so far. I think primarily being that the number of machine learning models that they put to production is so few that they're like we'll use something handwrite and we'll run the show until we don't absolutely need to solve for that. And based on that feedback, what we realized is that maybe focusing on the upmarket and the enterprise segment is actually better for us because that's when you have issues of scale hitting you and you're looking for more solutions like ours, basically. So actually I think the journey that you might have seen at Procore might be very relevant to the conversation as well. And maybe one thing if you can, and by the way, I can share just one quick minute of background about proof and so that you have some understanding on that, and then in that context, we can have the rest of the discussion. So if you think about the overall machine learning stack, web hub from the data and feature engineering to model training, deployment, monitoring, et cetera, truefoundry does not focus on the left of model. Okay? So that means anything features, data pipeline, et cetera, we don't focus on our primary focus of the platform is deployment and monitoring of machine learning models. And generally when we talk about deployment, we do multiple different types of deployment. You could do like batch inferencing real time inferencing API, endpoints gRPC, you could train and retrain your models so you can do a bunch of those things on the platform. And when we talk about monitoring, we again mean both your service level monitoring, system level monitoring, and the machine learning model level monitoring. So that like, is there any data drift happening, is there any concept drift happening? So being able to detect those things, essentially. So that's primarily how the area in which we are working more along the lines of operationalizing the model as opposed to adding value in terms of improving the model itself. Right. So that's the general focus for the company. And in that context, I think it would be very helpful if you can maybe give us some background on how is the team structured, like how many people in the ML Ops team, how many ML engineers versus data scientists, what type of models, et cetera. If you can give us some context, that would be very helpful. Yeah, sure. So because Proko acquired Indus and Indus had their data science team, a DevOps team, and the front end back end applications team. So that is why the current structure at Procore also kind of reflects that. So we have a data science team. I think there should be 13 or 14 data scientists and then four folks in. They call it ML Ops, but it's not true ML Ops, it's just the DevOps team and then five folks in ML platform. So ML Ops has five plus four total nine people. Oh, wow. Yeah. But you're saying the scope for that this ML Ops team is actually broader because it also does a lot of software deployment. Basically, it's like yeah, in industry, MLS is usually anything that data scientists, they don't do. For example, infrastructure scaling, monitoring, security side. But in Procore, ML Ops is broken into two teams one is called ML Ops, which purely handles DevOps SRE kind of stuff. For example, managing clusters, managing the code through TerraForm. And the ML Platform team handles, let's say, adopting new tools. So last quarter actually they have been using Airflow for a while, but last quarter we moved their flow to Kubernetes and help the team move their pipelines too. So ML Platform is doing the true ML Ops work and the other ML Ops team is just the DevOps team. Okay, understood. Got it. Okay. But to make it simpler, you can say it, it's a team of nine members which do both the SRE sort of stuff that is managing our clusters as well as managing clusters as well as cloud. So for example, few of them are very good with there are many AWS accounts at Procore. So you need to make sure that you do the BPC Peering and Security group. Sometimes it gets too complicated for the pure ML engineers. Understood? Got it. Okay, makes sense. And one other thing here, I would love to zoom into this complicated part as well, but just a couple of things before so I can collect some more context is what is the cloud that you are using? AWS. So proko uses AWS. They acquired level set. They use GCP. So mix of GCP and AWS. Machine learning happens primarily on AWS. Purely on AWS. So far as the Level Set team will start doing their machine learning. Plus Procore is also thinking of building a financial pillar. They'll also start doing some Actuarial sciences kind of work. So I don't know where that will happen. But as of now, 98% of machine learning is in AWS. Got it. And do you all use Sage Makers? They were using it one point of time. Interesting. I think they ditched because when Procore acquired Indus and at Indus we did not have enough money to go for, let's say purely managed solution. So we started building out on our own because the whole team also exists at Procore. So now either you fire PP or you or you just simply use what we already built at industry. I think this is one reason. The other was Sage Maker is good, but it does limit you. So any kind of solution that you accept from third party, it does limit you in one way or another. So Sage Maker gives you the ability that you can train your model and just you have the IPA endpoint, you can start consuming it. But what if I want to deploy the model in a certain way? What if let's say I want to contact the model and do any other extra thing that Sage Maker does not provide. So I think the ready to ready made solutions are not so matured yet that you can just simply start using them. And any company comes with their own baggage too. For example, Procore, they have a lot of baggage from the last ten or twelve years in terms of how many accounts do they have? Can they these accounts interact with each other? Can data move from one account to another? The usual stuff which starts happening as the company grows. That makes sense. That makes sense. And just one last question before I will leave. Do you all use Kubernetes? We do. Okay, understood. Yeah. Machine learning is everything is on Kubernetes. Procore was on EC, two instances but slowly they have started breaking it big hole Mongolia into micro services and they are moving to Kubernetes too. Nice. Got it. So Webbaum, really sorry to cut this call short, but just a couple of things I think we're sure has a few questions about how you currently deploy the pipelines and models, et cetera. So Vivek might touch base on that. But I would love to do a follow up call with you and dive a little bit deeper into the Sage maker issue that you mentioned, how you have built out a platform on top of Kubernetes. What type of models are you building? So I would love to learn a little bit more on that if we. Can set up a lot to check. Thanks a lot. Happy New Year. I will connect with you. Okay. Happy New Year. Have a safe. Take care. Bye. Thanks. Take care. Hi David. Quick background. I do not have anything around machine learning. I look after growth aspects at Truefoundry, but I happen to see the profile. And you mentioned you are from 2011 Kanthur. I have a good amount of friends from Kanfor. I am from Isandwad twelve, right. And there are like a few friends of mine, you know Hashith Kashyev and Rishav Raj and all those risha Raj. Very wellshev Raj was my junior, one year junior with me. And I know him very well. He would know me very well. He was my school friend from Patna, so I'm from Patna, so he was there. You happen to know Punkage? Not Punkage. Punkage and abhas. They were from computer science. You happen to know them. Bigger problem is IIT, I'm pretty sure you are all spoken from one of the It's. We do not know the actual names. We do know the nicknames that's on point. You're right. Got you. I know Proko very well because in my previous organization so I am in startup world. The reason that you mentioned right. I was in consulting, working with Euika Rawan and the world is moving super fast towards new tech, right? And in Eui you are working in Excel and you mentioned you were in consulting. So you know how things are, right? Problem or repurposed? So then I decided. I remember these two folks I mentioned, punkage and Avash. They were from CS eleven. So I know, I told him and he said I started something in Chennai, in SaaS and in manufacturing domain. Would you be interested? I took the next slide site out to Chennai, spent full day in Chennai and I liked the product. So that was also somewhat very niche, you can say like in manufacturing two refineries, like in a very niche manufacturing set up of manufacturing, refining and petrochemical. They were building solutions for them to manage their plant turnarounds. That happens. So I joined them and I started working with them, worked with them almost like four years and that was like very India centric business. We were catering to all these big players like Reliance Ioceron GCs and all the petroleum and petrochemical side of the world and that's when I thought that I time to move on to something newer, right? And that's when I stumbled upon Nick and Jen met him, nikunj truefoundry happened. So my journey in almost eight months only. But interesting to meet you and interesting to know about you. And you happen to be from that bash? Yeah, absolutely. I'm glad to talk to you as well. When you are on the other side of the table, it is easy to say no. And I have said no to a lot of folks whom I did not know personally because ultimately if my company is not willing to buy anything then I'm just wasting someone else's time. But you guys are from IIT. So there was, I would say, personal interest in talking and knowing what are you guys doing and what are you planning to do in case I can help, I would definitely help. And then the whole objective I think Abhishek reached out to you, abhishek who wanted to join this call. But then there is another firefighting which is happening. So it took his time and I jumped in and Nikon had to leave. So I'll tell you the whole objective that we are reaching out to a lot of folks in the industry who are associated in this domain. I'm helping with the profiles and he's sending we're using Fondale lead connection request through them only. So we want to know, as you mentioned right? There are so many of the shelf products, right? And some of them are good, some of them are not even matured and they come with their own limitations. And organization that you mentioned has their own packages, right? And this domain of ML Ops started in 2018 19 and is now moving super fast. What do we focus on is our main problem. We do have few clients. We are working with some big companies, we are working with few union startups. But there is no commonality between what we are solving for them, right? For some we are building deployment, although we are super focused on deployment and monitoring aspects. Monitoring we have recently started, but the whole idea is to get to know more from the users like you on what are the challenges that you are facing from the tools that you have been using. Most of the companies have been either using Sage Maker or something that they have built internally. Right? Right. As the technology progresses, the internal tool will eventually give way to some of the shelf. It should, because that's how people moved all of their workloads from onpremise servers to cloud. Right. To be honest, I do not have a clear cut answer to your question, but maybe I can just simply talk about the challenges team is facing right now, and that might give some clue. So deployment has not been very challenging, at least for me or my team, because I have been doing it for a while. And before indus, I never used kubernetes. So at that point of time, deployment was challenging to make sure that the server is up all the time. For example, you deployed something and it crashed, and you do not know that part of a problem is also solved by, let's say, when you deploy on a cluster. Of course there are other benefits, but this is one of the things, one less thing to worry about, I think, in deployment, it's not an ML off problem, but a specific issue that I have seen a lot of ML engineers faces. They have trained a model, now they do not know how to optimize it. I'm not saying it's ML opt problem. I'm just saying it is a problem that a lot of people don't know how to solve. Although the solutions do exist. For example, everyone knows that if you deploy your model on the Tensor RT runtime, it is significantly faster, but the entry barrier is too high. If you want to do it, it's not as trivial as, let's say, writing and training, model intensive flow. Every ML engineer knows that quantization will make the model faster. So quantization simply means that instead of doing the calculations in flow point 32, you do it in 60 or even eight. With TensorFlow and Pythars, it has become much easier as compared to, let's say, three or four years ago. But still, there is some barrier with respect to people using it, and it provide great benefits. I think these are the deployment related changes, but there are few tools available in the ecosystem. For example, at Procore we use Silden Core. Selden Core is the free, open source public version to deploy for the deployment. Initially there was, I mean, it took some time to deploy the first model, but after that it becomes a template, right? You have deployed one project, and that template can be used by restrict team. And because at Pro Core there was a DevOps team supporting how to deploy apps in Kubernetes, we were able to do it. Otherwise, that was also challenging for someone who has never deployed through charge profiles using Argo CD. So simply logging to a cluster and saying kubectl rent deployment is much easier. But if you want to do it in a systematic way, such that you deploy something you can roll back, you know exactly what you have deployed. All of this is a lot of work unless and until you have team supporting you. So I think that is also challenging. And I also think that not a lot of I mean in India, I'm pretty sure there are a lot of most of the companies adopt new tech very soon. But at least in North America, I have seen a lot of resistance with companies adopting a new technology. For example, Procore used Kubernetes, I think just probably four or five years ago. They got listed like last year. So it is still late. So I think if you ask someone do you face a challenge in deploying your model? They would say no. They can also deploy on an easy to instance, but having a structured way of deployment so that it plucks very easily with the rest of the best practices, whether it is observability model monitoring as well as let's say as companies grow bigger, they want audit capabilities too. Unless you have a structured way of deploying, you would never know, right? So just getting it done and doing it the right way, there's a difference. And I think that's where the challenge comes into the picture. You did mention you use Selden Core and you also mentioned the structured approach of deployment, which kind of makes sense. Now, has Selden Core solved that for you? And two questions. One is one this part, there are two separate components. Selden Core comes with its own set of features. You can use Selden Core or you can use Fast API or you can use, I think, Vertex. There are a bunch of tools out there. They come with their own set of features. We picked Selden Core because it seemed very close to what we were trying to do. Exactly. And selling Core makes life easier because we do not have to, let's say, implement the API from scratch. So just like we use Flask for building web apps because the framework comes with home setup features. The second part structured approach was once we decided that you want to deploy on Kubernetes, then for a given team which either does not have Kubernetes experts, I mean experienced, not experts, or their existing DevOps team is fully supporting them, then I think then only they'll be able to do it seamlessly. Otherwise it is a huge task. So the whole structured approach, it became easier for me and my team because the DevOps team was there supporting us all the time. I mean, they were fully dedicated to the AIT. Otherwise it is a challenge. Understood. And you still use the Free or the open source version of Silver Core or the Enterprise version, right? At Procore, when we were at Indus, actually, that is when we started using Silden Core. At Indus we didn't have money, but when we joined Pro Core, we got the support license for Selden Core, not the full Selden Enterprise, but we did not renew the contract and there are two reasons to it. Selden team is very good. In fact, in one of the calls their CTO came and we mentioned a problem that we are facing and he immediately went and fixed it on the GW. So the team is very good. But there were two reasons why we did not continue. First, I think that the team at Proco is decently, competent to fix any issues that we encounter with selling Core. And let's say if the selling team is taking too much time to solve them or we find other ways to approach the problem. The second problem was I think we raised four queries with Selden Core team in one year. I think four or five queries, they solved one and for the others they were not very concrete solutions. Either they said it's not in the roadmap or there are other issues at the end of the year what we decided that having that support is not giving its value and that is why we did not continue. I think there was also thought reason companies are very conservative these days in terms of spending money. So most likely my manager also wanted to cut any extra on US. Spending and that is why we did not continue. But there was never a thought around Enterprise, kind of because I understand support is basically using their open source version and you get a support which you mentioned, right, enterprise will come up with their own set of benefits, which roadmap kind of a situation where your problems lie could have been solved. Right. So was there any thought process of even looking into Enterprise aspect or just the cost? No, I think the main reason was because my current manager who is senior director at Pro Core and who was VP engineering in my previous startup which got acquired, he comes from a platform background, so he was very confident that we'll build a solution ourselves. And if, let's say someone has the time, money and expertise, the three things, all the three things time, money and expertise, then a lot of times building your own solution makes your life easier because you build what you need as compared to adapting to something that exists. Right? And most likely that is what for example, let's say if I tell you today that the python does not fit my needs and I have the time, money and expertise, I want to build another programming language. That may not necessarily be a good idea, thanks, but I'm talking about a space where the tools are not as matured. I think that's why we went with building our own stuff rather than looking for shopping for the one that fits our needs. Awesome. I think whether I've already overshot my time, but I will definitely love to have a follow up or to dive deeper on to two aspects. One, you mentioned Sage Maker and second, you mentioned our biggest competition, right? Sheldon, to. Be honest with you. And there is another third aspect, which is monitoring, which you touched upon slightly around observability and other aspects, but we did not dive deeper into it. And again, Nicole also wanted to speak with you. So any time that you would be comfortable next, let's say next week or any other time, happy to work as per your schedule and talk to you again. This time I'm mostly free throughout the week, but I would like to skip Monday and Fridays. Makes sense. How about Tuesday? Next Tuesday? Yeah, sure. 17Th, same time? Yeah, makes sense. I'll send you an updated calendar invite for our follow up call. But lovely talking to you and always great meeting someone from Fellow. We have so much mutual. Love to not touch base with you again. Thank you so much. I also prepare for the next meeting the two points that you raised. I'll come up with concrete examples. Thank you so much and have a great day ahead. Great week ahead. Love talking to you. Look forward to our next meeting. Good night. Good night. Thank you. Good day.