Hello? Can you hear me? Yeah. Hi, Nicholas. I'm able to hear you. How are you? Great. I'm good. How are you doing? Thank you. Yeah, I'm good. Is mine joining in? No. So he is actually caught up in another meeting. So he won't be able to join this call. But we can start. I can fill him in. Okay, perfect. And Nitish, is it fine if I record this meeting? Yeah, sure, go ahead. Cool. First of all, thanks a lot for taking time to speak, Nitish. So I'll just give you a quick context. Ankit introduced us. Ankit is a part of the same search batch that we are a part of his company. And we had some interactions and he was telling that he knows my unclosure and you might be doing something in the AI space and thought it will be good to connect given you are in the early journey of AI. And we are also pretty early where we are looking to work with folks who might be in their AI journey to help do machine learning deployments faster. So that was the context of this call. Literally what we want to do is learn a little bit about Tangent AI, how ML comes into the picture, what are the current use cases, where do you kind of foresee it going, what does the ML team look like and how you are doing things currently. And then we can also kind of give you an overview of what we are doing at Two Foundry and what we are looking forward to. So that is primarily the goal, apart from knowing each other, obviously. So that is how yeah, great. Sounds perfect. So I'm not sure if you got a chance to go through the Tangent website and how much you already know. So I did go through a little bit actually. Before that, it'll be good to maybe quickly do a round of intro. Like badal is also here. It's one of the founding architects at Two Foundry. Background for me. Graduated from Etikarakpur 2013, spent six years working with a hedge fund, first in India, then in US and Singapore, and after that built a startup in the talent space. We sold it to Info Edge. We were facing some issues in scaling it and we felt that we would like to build on the tech side. And that's where we kind of transitioned from entire to building True Foundry, where our goal is really to make machine learning deployment simpler for companies like my co founders, Avishek Nikon. They were at Facebook and they saw the internal machine learning platform that Facebook uses. And our thought was like, why can't any company adopt a platform, get access to such a platform from day zero? Why do everyone have to build it later on in their journey when they realize that things are breaking? Whereas it could be very seamless, could save time for the developers as well as some cost and so on and Buzz joined us right away in the journey as a part of the founding team itself, if you want to give a quick introduction that you all yeah. So I've been doing software engineering from past eleven years and as Andrag mentioned, I'm here working as an architect. Before joining Truefoundry I was with Phone Pay and before that I was with AWS for five, six years and there I have worked on building multiple AI platform like AWS Sage Maker, AWS Comprehend, AWS Code Group, and I have also worked on other engineering projects as engineering platform like Code Deploy and Device Form. I think. Nitesh, you were also at Amazon for some time. Were you in Natash? Yeah, so I was in this Amazon Now team which was called Piranha Now at that time and I have my friends right now in Charlotte who are working on AWS Hazemaker. Did they join recently or were they before were they there four or five years ago as well? No. So they are all promoted to SD Three s now. They have been there since more than five years. Everyone else has those yellow badges now, right? Yeah. Great to meet both of you. So I and Mang, you know, we have been we like we worked in our first organization together so that is back in 2010. So we started it with a services startup where we would build end to end apps for mobile and web, like from the design and the development part. And then we moved to a product called which was into this ecommerce and personalization data space which got acquired by Flipkart and then I moved to Amazon. My Ank started something in Fintech after that and then I have worked in QMat before coming to Tangent and then we started again working together and yeah, so I've been in the industry for like twelve years now and have worked on these different engineering side of technologies. Not a lot on AI side, but more on the general apps, DevOps front ends, back ends, services and all those things. At Tangent what we are building is that we are B, two B sales company and we Tangent ecommerce store owners and we started with the Beauty segment, Beauty and Fashion. But beauty is 90% of our customer base. So what we have done is we have built like an AI selfie solution for them. So we say that we are a zero party data personalization platform. So zero party is like someone giving you data explicitly, you're not just capturing from different websites or by tasting cookies and stuff like that. Right? So we have built a selfie solution for these store owners. And what we can do is that if a shopper comes to their website, they can click a selfie and we can tell what skin tone you are, what skin conditions you have on your face, what is the color of your hair, what type of hair, how damaged your hair is, and so on and so forth. We have around 150 data parameters which we can extract from a selfie. So based on this data, we add a personalization layer on top. So we can do a product recommendation, we can do a retargeting. And that is how we have been working with our clients majorly. We're still in beauty and AI has been a strong kind of selling segment for us, which kind of makes us stand apart from the competition that we have. And we are a little more niche, a little more targeted towards beauty industry. So there are other data collection platforms, but not everyone has this selfie thing as part of that. So we have had customers who had been trying to build these things with different tools, using three tools, but when we got introduced so we kind of replaced all of them with our solution. That is where our AI comes into picture. We have in house models where some models are used for skin conditions detecting, some models are used for hair segmentations and some models are used for facial recognition and all those things. So we have our in house Kubernetes cluster where we deploy all these individual models and individual containers and that is how containers are poor as a Kubernetes language, that is how we have been building. So the AI will be a part of our product, I think generally even when we go forward, it might not be like the main part, but from the entire offering will have some share of it. But it won't be like that. The product revolves around AI more enabler. Kind of a thing in some way. Enabler more like a talking point or selling point for the customers. Like a few things just to understand a little bit better like how big is the team currently at tangent and what part of it is the engineering team and then what part of that is say the AI team. And when I say the AI team, I mean like the data engineers, if at all, data scientists, MLes or even DevOps that are supporting them. Yeah, so we are pretty lean right now. We have just ten people here, AI researchers, we have a couple of them who actually build those models and DevOps and engineering and back end kind of things is something that I take care bulk of it and I pull in resources based on the time or the situation or the total overall quantum of work. Right. We are pretty lean and there's not a lot of operations that are involved in terms of processing processes for coordinating between people. That is how we assess it right now. Perfect. All ten people are well versed in machine learning or is it like few are more on the side of engineering and then fewer more on the side of machine learning? Yeah. So ten is the total overall headcount and AI researchers are just two so they don't put model in the production, they just train it and then other people help them out in putting it in production? No, they do it themselves. I collaborated with them. We came up with how we should deploy and where we should deploy and then I made the initial DevOps kind of thing. But then I have shared access to them and they do it themselves so I don't have to hand hold them because that is how we have been trying to put it in the team as a culture as well that we don't define the roles very concretely. So try to be more independent and do the work. That is great. Actually on the Kubernetes side, what made you choose Kubernetes over like plain AWS or something like that? Right. Ideally, our thought process was that we will keep on adding these models and some models could have more load depending upon the requirements. We thought that we will be having these in terms of small microservices and then when we were evaluating whether to go with Docker Swarm or Kubernetes, we thought Kubernetes is a little more sophisticated and easier to manage. So right now it is honestly it's like an overkill. I'll say before this we were just doing using teamwork sessions and run a server in that. But that is not very fail safe and there's little more fragile. I agree. So hence we thought eventually we have to go and it will keep becoming more complex if we do it later. We started with it right now. So we are not on AWS, we are on Azure. Okay. Irrespective of what cloud services you use, we choose Kubernetes because we wanted to manage all these microservices and orchestration smoothly. Understand. And you mentioned some devop portions, right. Where who creates the helm chart for these models? You mentioned that I presume that you created those helm charts and then they never get updated and you probably put them in the githubs and every time somebody commits it automatically gets deployed. Is it the case? Yeah. So in terms of automations, we haven't done that entire pipeline into automations because we do it a little more manually right now. Get there and when we talk about hencharts yeah. They are not updated very frequently. So any new AI model that needs to be trained and deployed, it takes like a good amount of time. It takes around a couple of months to really get it to a production quality. Two to three months. Right. So those Hinge charts are not updated very frequently. So that's not a problem right now. But yeah, going forward we might have to do that. Okay. So does your research engineer they have cubectl, they use Kubectl to push the data. And how the second part is how do they create docker image to get deployed? So we have few test machines where we use to just do any kind of scratch pad work. If I can say that. And after we have tested things on that separate machines, we actually create that image using a few scripts running on that same machine and then to Docker hub, and then from Docker hub we pull the images to the Kubernetes cluster. Okay, so this both part like running those scripts, which creates this docker, pulls this docker image in Docker hub. And the second part is doing Kubectl like helm deploy. So both of them, those commands are sequentially executed by research engineers. Yes. You got it. Okay. And you probably have a dev environment and like Dev workspace in the Kubernetes and the prod workspace funny you mentioned, we recently have recently made two separate environments. Okay. We were working on eggshells. We were directly messing with production. Nice. At one point. We added a little bit earlier because we are a platform company. Made more sense for us to add it later. But most of the startup do it like that. Only our first startup actually, we didn't have a development. Everything is to just get pushed directly. Exactly. Product development always takes the precedence over these things that we as a techie or an engineer, we always want to have, but we never get that priority in that picture. Got it. And I presume that the Jupyter notebook also lives on the same machine on which those scripts are run. Right. So we started using Jupiter notebooks initially pretty heavily, but then we right now use more of the normal Python files and code IDs. You use our local IDs and then we experiment and we push the code and get and use that code from there. So we using Jupyter notebook a lot for scripting, we use more of the command lines and but your image model I presume would be big. So you cannot train them on your local on your laptop. Right. And also the GPU requirements are not fulfilled on your local machine. We do it on the servers on the test machines, but we don't use Jupyter notebook a lot. Understand. So how do you use ID? Because is it like a desktop environment where you can access the remote machine? Like UI of the remote machine? Okay. When do you generally need GPU? Right, we need GPU when you have to train the model and then training inferring and then creating that image. Right. So we write the code on our local machine because that is quick, and we use our IDs, we pull in the requirements or the libraries, and we set up that locally. Whenever we have to train it, we push it to a repository, take a pull on the server and just press that train command. Understand? Got it. I presume that the model deployed in the production are CPU, like using CPU to run the inference or is it GPU? They're both summer CPU. Summer GPU. Okay, got it. And how do you create the services? Do you get to the real time traffic or do you cater to the batch or is it batch traffic? Batch jobs? No, it is real time, mostly. Like the product side of things. Mostly real time. Okay, so what is which inference? Like, do you use inference server or is it like simply wrap it in a fast API? Can you differentiate between the two? I'm sorry, I didn't so basically, let's say you train the model, right now you have to create a service out of it. So a lot of people, what they do is that they use like, let's say Pytotch lightning or tensor, like triton server or something like that to host the model and then write a separate wrapper on top of that, which lives in a separate microservice which call those model and then get the output. So your model and your services kills differently. Or some people do it like in the same Python file. You load the model in the memory, you write your transformation in the same file and you just create a single pipe like Rest API, either using Flask or using Fast. Yeah, got it. We don't found a need where we have to host them separately as of now. So we have right now thought of one model as an entire self contained entity where it can be inferred as well as it's a Rest service. So from outside we don't know whether that Rest service is using a model or whatever. It's a box. We haven't found a need where we have to do it separately. Maybe if in the future we feel that there's a need to split that thing and scale them individually, then we might. But right now it's the same one image that has both the model as well as the service. Understand? Sorry, go ahead, please. Yeah, so understanding what will be the pros for scaling it separately? Okay, so let's say you have a GPU, let's say you have a GPU model which takes a lot of GPU and then you have some transformation which happens on CPU, right? And then what happens is that when you get a request, you have to optimize the lot to make sure that your GPU is always at full capacity. And usually people are not able to achieve that because when a request will land, it will first consume some CPU and then it will consume some GPU. And since GPU are costly so what people do is that they take out the part like the model which runs on the GPU and then extract a separate service and they make sure that that service over saturates the GPU. Which means that your GPU is always running at 80% or 70% capacity all the time. And then on the CPU you are a little bit more relaxed because CPU are not that costly. You are like, okay, let it consume like 20 or 40% of the CPU, I'm fine with it. And if you get a lot of traffic and things like that. Then on this side, if you have Http connection pool, then you have some level of protection because if you set up auto scaling, then this may happen that from one GPU you might jump to four GPU. So there are a lot of problem happening because of the CPU and GPU happening on both. Yeah. If I hear you correctly, if it is combined and if we want to scale that service, we'll have to consume the GPU, we'll multiply the GPU consumption. Right, but if you take them out, we can postcale the service without also multiplying the GPU consumption. Sure, yeah, that makes sense. We haven't reached that problem yet. Okay. So yeah, maybe when we encounter that problem, we'll optimize it for that. Got it. And which framework do you use for writing the rest service? Is it Django? Is it flask or is it fast? We have been using Django. There is a Django service, but that doesn't have any relation with AI models. But we have mostly used either Flask or there's another Falcon server which is pretty light. Got it. Yeah, those are the ones which are like which infer the model and return the response. Okay. And how much is your cloud charge as of now? Is it very small? Yeah, it's like $1500 to $2,000 in INR if we have to say it ranges around 1.5 lakh. Got it. And I presume that you are getting cloud credits because at least it's startup rate. We have expired those. Okay. As you go, we got two years worth of free credits. We have exhausted them and now it is we pay what we use for. Okay. And do you see your cloud cost like going up from here on? Not a lot, because as you have already mentioned, right, that GPU is the biggest segment of the consumption and our product is not expanding very heavily on AI side and hence we don't foresee our costs increasing by a lot in next year or year and a half at least. Understand? No, just one question, one comment. It's good to see that you build the stack on top of Kubernetes site from day zero. When you talk to a lot of companies, they actually end up using the clouds and later on they face a problem and a challenge. When you have to migrate to Kubernetes, it's really good. So honestly, I think when you do it too early as well, it gets you more operation time, which you don't really require. But the problem is that you know that eventually you have to do it and then when you kind of prioritize it, then it becomes like a mammoth of a problem to really migrate. Kind of chose after a year and a half of usage that now let's move to Kubernetes or more sophisticated tool. Yeah, we have talked to customer who knows that if they move from Sage Maker to Kubernetes they will reduce 30% cost because it's a shared machine, right? One host might have like two, three models deployed on the same. But they. Are too big to migrate to. That is always a challenge once you grow to a point where revamping that entire thing is a very big problem. And it is also very risky sometimes because you are having active development here and then you want to migrate everything, this new thing and then you keep trying to chase that. Do you also have any monitoring of inference? Monitoring meaning all the inference data which is coming when you host your service, you might have to really label some sample of those data right, for the future use case. Because right now you're doing prediction but you might want to improve your model and things like that. So do you store that data somehow, somewhere? So for us, the data is majorly selfies and those selfies we store it similar to that s three in AWS. We have some these buckets or what do you call them, containers or buckets in azure. So we keep saving those selfies which is like the image data. They do not get auto labeled, if that is what your question was. Auto labeled or the model doesn't get auto improved. Sorry? And the model doesn't get auto improved. So we improve the models based on the requirements. For example, either our observation or our customers observation is that this model is not performing in these scenarios. So then we kind of do this small manual exercise of tagging that data first picking the right data and then tagging that data and then training it. Got it? But yeah, that doesn't happen. So we do this kind of exercise once in two months. Maybe we don't need that automation in place right now. Okay, and when you retrain your model, how do you do the model evaluation for the new model from the same data that we have saved? We just pick the test data at random and then evaluate. Okay, I see. What I meant is that live evaluation. So let's say you have one model version deployed on production and now you want to go to next model. So you just go and flip it to the new model. Or you just do a B testing, some sort of A B testing. Okay. We do the complete rollout. We don't do an A B test. We don't evaluate the model of one versus two. We do that at the time of testing. Once we are sure that the second model is better than the first, then we roll out and deploy it for the entire thing. Okay. And that is primarily based on the validation set which you are separately put and then just comparing the Roy score. Yeah, both some things are done automated and then there is a manual evaluation as well. So one is what machine says and then what human says and then we conclude that whether the model is actually better or not. Okay, and how does human evaluation takes place? Do you deploy the model somewhere and then somebody goes and test it? Yeah, we generally deploy it at a place for either the QA person to test or I and my cells also keep testing these models. So yes, we deploy it at the same test machine sometimes where we are also training it. So we have a couple of machines which we start and stop based on our requirement disposal. So we can just quickly spin a machine, deploy it, test it and then turn it off. Okay, so you don't do that on Kubernetes, you do it on some separate yeah, we might be doing that going forward since we have a different environment now. So we can deploy it there and test it, but so far we have not been doing that. Okay. Thank you, Nathan. Actually that gives a very good overview of how your system looks like and also it gives us opportunity to show you how we can help you out, how we can improve your experience with the Kubernetes. Because our system is also built on top of Kubernetes and we solve the problem of creating this helm chart and things like that. We simplify so that research engineers or machine learning engineers or any engineers doesn't have to, they just run a command and then everything gets deployed to create a test environment. They can just go on our UI and then create a new workspace, another copy the new copy on those machines and quickly test it out and then push the to production. So we have all this feature I'll let and write. Sure. Basically that's very helpful. We'll tell you as to how we are thinking of building the system and what we are building and love to hear your comments as well. And if we have time then we can showcase you demo of the platform today, otherwise we can showcase on another day like a more detailed demo. So basically the fundamental hypothesis is that ultimately people who are using data in some way today will start using more data tomorrow and there will be more companies doing that. And DevOps in general is a rare skill set. At the same time, ML Engineering is an even rare skill set. People are able to still build models today, but if you talk about being able to deploy, a lot of people are not able to do it. Or even if they do it, they don't do it in the best way. So they will kind of do an ad hoc implementation of it and then later on when the system starts killing, things start breaking or if you need like models start failing, you do not have a proper monitoring system to kind of see as to what was failing. So we thought that if we are able to build a deployment system that actually uses some of the best infra that is available today and on top of that, it allows you any developer to kind of get started in 30 minutes so that they can deploy either to a test environment or a prod environment, depending on what the organizational structure is. And once you deploy, you get access to monitoring by default. That is you are able to actually see some basic metrics for your models as to what they are doing and if there is any drifting data, you have ways to kind of interface where you can just go and debug things, right? And tomorrow as you scale you have functionalities for auto scaling. If you want to kind of do model traffic splitting wherein you have multiple models and you want to test it on different traffic, you have that functionalities and so on. So we kind of made some design choices as well. We started like okay, what do we build on? So we took Kubernetes as the main orchestrator for deployment. The idea was that all the complications that anyone needs is automatically supported by default. So our deployment stack is on Kubernetes. We support real time as well as batch deployments through a similar mechanism, wherein you can either do it from your jupyter notebook, you can do it from a cli. Like in your case, your team is using cli mostly, so you can do it from there, or you can even do it from a UI, wherein you can load like your GitHub repositories and so on. And if you have CI CD then you can just integrate it with your own CI CD like whether it's GitHub like Actions or Jenkins like whatever. So that's the route we took towards building it. Just I'll share a screen to show you some of the things. I'll not go into the overall Ppt because I think you already kind of get a sense of it. So basically the way we kind of do is for your inference function. You have a predict function, you just bring it to us. You kind of write a decorator like this at the top and then you kind of run through foundry deploy it will kind of create. You will be asked to choose a workspace which is similar to like a namespace in Kubernetes and will deploy it to that workspace and you have access control permissions in that if you wanted to do auto scaling enabling on GPU or CPU that is supported. So all you need to kind of do is you kind of enable auto scaling. The UI looks like something like this, like this is equivalent to a namespace for each namespaces. Like suppose there are two members in your team say if they wanted to work on test environment separately and then there is a shared production environment, then you can create multiple namespaces and you can allocate CPU, memory, et cetera. So that you are always sure that the cost will never exceed beyond a certain limit. So when you. Kind of do this allocation, you actually see what is the cost range that it can maximum info and within that your namespace restricts that. Beyond that cost will never be incurred on your site like estimate and within this you can deploy multiple services and so on. Then if you wanted to kind of for a model we wanted to kind of do a shadow testing, you can actually decide, okay, out of the traffic that is coming or the inference request coming, this much 20% should go to this one, the service, and the other 80% to the service. And it allows you to track that. There is a way where we are kind of thinking of also allowing serverless mode for cases where there is a burst of traffic and probably it will be more cost optimal to use that. And as you deploy you kind of get access to this code where you are able to see system monitoring by default and then some insights into cost as well is there. Apart from that, on top of the deployment, it obviously supports, as I was saying, monitoring. So you don't have to do anything like in your code. Wherever your model is there, you just write this log prediction line and it will start actually logging your predictions. And based on that you can actually see some of the stats or the feature health stats and so on. And you can also add alerts if needed later on. But all these parts are built in a way that if you didn't want to use monitoring, it's completely fine. You can just use the deployment piece of the platform and if you wanted to use monitoring, you can actually just use it with the same library later on. We are building this part, this is not yet built wherein you can actually run pipelines and deploy it and automate the training like when new data comes in. So roughly this is how the system is. We also build like a small part of the system which allows you to kind of log in all the experiments that your researchers are conducting so that at any point you have to go back to a particular experiment. All the models, all the runs, all the artifacts are locked there in. But again, this is just more than workflow extension to allow for that functionality. The code that we have built is still around the deployment infrastructure. Yeah, we'd love to see if there are any questions here for now. Otherwise what we can do is happy to answer questions once. Otherwise we can actually kind of try and showcase you like buzz. Do you think we can showcase a high level UI level demo for this? To get a sense of things? Sure, we can do that. Do you think you have time for that right now or do you want to do it later on? Like up to you. Okay, first of all, how much time. Will it take around I think a good demo will take around 20 minutes and questions. So it might actually be more. So maybe if you have questions right now, you can address that and then demo we can do in a Sequent call, if that is better. Yeah, I think that will be better. And I'll also get one of my researchers in that whenever we want to. I think that will be better than this is roughly the thought process. Now, obviously we are also very early stage niches. So companies, they are able to use and we want to see the ease. Our goal is basically if you are taking time to get started on deployment, it should not be a challenge. Managing a Kubernetes interest should not be a challenge. It should just happen at the click of a button. You should not have to spend your time. That's the major thing. And it should happen in a cost optimal manner. So, yeah, working with a few companies, trying to get understanding of their use cases and building around the product. So Scaroundly thought it will be good to connect to you as well and see if there's any way, if there's anything that you are actually feeling as a pain point that you are interested in kind of trying out something in an easy way and so on. Or by the way, Infra banned, it's available on the cloud. So basically upkeep Kubernetes cluster because it integrates. There's also a public cloud version, but a lot of companies do prefer the on cloud version. So we kind of give you a helm chart. You run that helm chart, it basically deploys on your Infra. And then there is a way like you just create like click and connect to your cluster. And then you can connect your cluster and then the system starts working. Got it. Cool. So if I understand two, three problems, one is the deployment of a model can be done and then we can have that A B testing, and then the cost will be optimized. And then there is the Inbuilt monitoring that we get along with it. Right, got it. Last name. But there's the Data Set management Car Tool. Right. Yeah. That is not necessarily a data set management tool. It's more like for tracking of your experiments. They say, I engineer today is working on data and they are running different models. Right. Today they have a version that is model one. Tomorrow they'll run more. There'll be a new business problem coming in. So all of this right now, I'm not sure where it's deciding, but basically this is a place where you just run a simple command like log model, log metrics, and it will start logging all of that into a single dashboard tomorrow. If you have to refer to, okay, what are the business things I tried or say your AI engineers to compare between ten different experiments they ran. And that part is taken care of but yeah, that is not the core differentiator. I just wanted to stress once maybe. I can show you a little bit. So in this, let's say you are training machine learning model then log your metrics, you can log your hyperparameter and then you will be able to see how your metric model improved over the paripoc and other than that we also allow you to basically log images. You can take few images, image samples and say what expected label and what you have predicted and things like that. You can log a live plot. So all of this is useful if you're let's say training a model two months later and then you can compare the current model with the old model and compare at more granular level than just comparing just like one metric. So instead of one metric you can compare all of different things like confusion metric and things like that. This caught my interest was that especially while training we keep tweaking these hyperparameters, right? And there are these multiple tuning buttons if I can say and then you go to something older then you try on that. So this is something which can be tried out at our end because other things I feel that are not that big a problem for us like the cost problem or deploying problem but these running different experiments, monitoring them and then building over that this might be an interesting thing to try out. So is it possible to just try this feature on our end? If you can send some guide on how to try this out, some steps on how we can install your tool, and if you can just give it like a small trial and see if this is something which is adding value for us or not, that will be great. Before demo. If we can just try this one feature out. Yeah, we can actually do that. Like puta easily up. We should be able to just share. The yeah, we can, but on the service side also. So here we support different things. Like you can create a new service, you can deploy a new job, you can even run a jupyter notebook on top of Kubernetes itself. Like on demand. Let's say. If you have multiple teams, you can like multiple people working. They don't have to set up a EC two machine. They can just click a notebook and then just spin up it. Spin it up and then finish it. And the same thing goes for the training job. You can schedule a training job for the future date, you can create a new training job and then you can just deploy a service. So we allow you to deploy so these are nothing but Kubernetes namespaces a namespace and then you click on the next and then either you can give a docker image or you can give a GitHub repository. So we integrate very well with the GitHub. You can link your GitHub repository and then pick your GitHub repository, you can pick your branch. And then either you can give which Python version and what is the command to run. Let's say if you have main Py, you can just simply give Python main py and then you can give how many replicas you want, how much CPU you want, how much memory. So we made it very easy. This is abstraction on top of helm chart. Got it? Understood. So let's say if you have machine learning engineer, they can very easily come and increase the memory, increase the CPU, use the GPU if you use the GPU, if you don't want to use the GPU. So you can do all of that. And we also provide advanced fields like okay, do you want to add a liveness probe? Right? You can also do advanced stuff as well. So we have abstracted out all of this to make it very easy for people to run service, run training job, and then notebook on top of Kubernetes itself. Got it. Interesting. Sure. That's a great value add for these people who are not very well versed with the deployment side of things. Like if your training engineers are separate than the people who deploy those models, this can really help them. Sure. Yeah. So it's completely built for machine learning folks to run on autopilot so they don't depend upon bother engineers that much in figuring out what is wrong. And one more thing was we also just a second. So we also have grafana. We also create grafana dashboard. So this you get out of the box, right? So this is like system like Grafana dashboard for system monitoring. I don't know how you guys are doing it right now, but here you can look your system metrics and things like that for the service which is deployed. Similarly, you can also look at the logs as well. So we have all of these things automatically build out for you. So on your Kubernetes, we will take care of deploying the Grafana and the Loki and then we automatically configure all of this behind the scene for you to monitor. Right, got it. Good to know about all these features. And please do share. If we can try out that one feature that I mentioned and then post that, we can probably schedule a full demo call sometime. Yeah, that will be good. I will share a link and documentation. So say, I think your AI engineers should be able to try that out. And then we'd love to actually showcase you the overall platform and even if it's something not usable. And it is good to get feedback from people because you have actually built things on Kubernetes. So we'll also love to learn, given your state, which part is actually even usable or because it does not matter. So it will help us also orient a little bit in calls with other folks, like for those who have adopted Kubernetes what could be a value prop that could be offered to them and so on. So I'd love to learn a little bit around that when we do the demo and few things. Sure, sounds good. Yeah, totally for it we can probably coordinate on what about it and then. We can yeah, thanks a lot Natasha. Thank you so much for your time. We'll send it out like just give us some time. I will send out the credentials for trying it out. Great, thanks and thanks. Thank you. Bye bye. 1 minute. Yeah, sure. Thanks, Matthew. Actually, bye bye. Just having team discussion. Recording of Kala Kubernetes use Karaf will be resistance high in case I'd say motherboard deployment will nathan interest in the kaya zero interest. Basically, this is a problem. Dalitaki engineering. Kubernetes engineering. We use curry. MLB use curry. So it seems like engineering ML don't use Career to logo or change CPU to manually increase. Or by the system. Asadikraiki similar state delta lookout. Nikata okay, actually user persona per discussion upon ham. Nikkun told you. Weekend weekend members. You know that CTO are in very short supply, right? Correct like people have business idea people but they're looking for CTO merajo college community. They reached out to me to abhun said discussion Karamabad exactly close naya parasaki network mayor two distance they can give like positive recommendation about each other. Those types already koi log person discussion. Discussion karma Donut decision making patani kidney time laga but hamadlab I am actively trying developer tool Bananga Bananga but abhi jitney merining true honda Bahati hard developer tools open source alternative exist karthija ideas field Masari open Source developer tool go aside ragdiya I am going with complete open mindset key business side while Logan Kikoi concrete problem so I am going like Malabai have to build tech as long as there is market traction and things like that. Discussion ganatha badma. Be saxon so miracle. Badal is an the key mother yejo tumblake dev tools difficulty but it may.