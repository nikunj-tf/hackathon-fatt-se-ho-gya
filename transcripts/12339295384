Am I supposed to follow up only? ashish I'm following up. Also, there was that one guy, shaker. Let me check. I'm not here. I don't have any message exchange with him. Basically, just check your email once. Anyway, we can look at this. Sure. Thanks. Nicole I just quickly introduced the team. In fact, Nikkunj was the one who passed on your number. He got it from the sequoia Founders group. Nikkunj is the co founder of Two Truefoundry. Sorry to interrupt. May I ask who gave you the number? Niconge actually have to check in the group. To be honest. I think it's a pretty old message at this point, so I don't know. We have a couple of groups. Generally what happens is there's a few areas where we are needing some feedback on. So we kind of put if there's any connect in this company. Sometimes people directly make intros. Sometimes they're like, I don't know well enough. But if you want, you can just reach out to okay. No, I'm just curious. Anyway, yeah, of course. So, nikun, you can go ahead and may all can also go ahead. Quick intros. Take care. Maybe I can introduce myself first. mandar. So I'm cofounder CEO at Truefoundry. I come from a machine learning background. So used to be at Facebook, where I built a lot of conversational AI solutions. Similar, it seems similar to what you all are building at. Have you heard of their product called Portal? So Portal, maybe before launch, I was working on their Portal product, basically voice assistant and all. And prior to Facebook, I was leading the machine learning team at a startup called Reflection, where we built out a lot of recommended systems for the ecommerce industry. And we served to companies like Disney, banana Republic, Gap, et cetera. I did my masters at berkeley and that's how I moved to the Us. Since then I'm generally based on the Bay Area and currently traveling to Bangalore, by the way. And before that, I was doing my undergrad at iit Karakpur, where I met my now for Bishik as well. So that's a little bit about myself. chinmay, you want to go ahead? Yeah. Hi. mandasa. This is chinmay. I graduated also from It post that I work with mckinsey and Company as a management consultant and joined Roof Truefoundry about six months back here, I'm working the founder's office and I look at product, customer development, et cetera. Thanks guys. It's a pleasure to meet you. So I'll just quickly introduce myself. My name is mandar, and I have been in the AI products space for the last two decades. So, yeah, I've worked across the industry and academia, worked across multiple functions, research and product and data science. So right now, over the last few years, I have turned into a product AI person. And I used to be at ibm before I joined twenty four seven. And I headed ibm's AI services department globally, about 500 people, huge portfolio there. So yeah, that's about it from my side. Let me know how I can be of help. Actually, I know I haven't been very prompt responding to messages. I'm dealing with a few things at home which might occupy more of my time over the next few weeks. But I will eventually respond to your messages so I can tell you that. Anyway, let me know how I can be of help. What do you want to talk about today and exactly how would you like me to help you? Right. So that I have to be honest is not yet clear to me. I can take that. mandar. Just 1 second. mandar did you get a chance to briefly look at the hypothesis document? I did, I saw the document the very same day that you shared it and I think I have forgotten most of it. Okay, fine. I just want to check. Sorry. Sure. Basically just a brief introduction. akshay. akshay truefoundry.com startup like we are operating for a little over a year now. We have built out a platform that helps machine learning teams deploy and monitor their Ml models. But we are fairly early in our journey and we are trying to figure out a niche for ourselves because as you know, this is a fairly competitive space. Right. There's a lot of companies building out. Now in this context, there is one niche that we are currently trying to validate, which is building out such platforms for companies that are by design multi cloud that are already multicloud or hybrid cloud basically. Okay, so the idea being from our perspective that out of box editions like Sage Maker, Vertex don't work for them because they need to build and deploy models across different clouds. And the kind of platform like paths that we are building on top of kubernetes, we have built it out in a very cloud agnostic manner. And is that a reasonable target segment for us or not? That's what we're trying to validate now this is where we're trying to talk to some of the AI technology and product leaders and understanding where the landscape is because chances are that we might be completely off in our estimate of the market, right? So that's where we just want to be real and get some feedback. So we thought that we'll reach out to you if you have seen whatever your experience has been in this context, we learned from that and also just generally learned some other problems that you have seen in the area. tucky it just helps us define our pitch and the product as we move forward. Fair enough. Okay. I think the niche that you are specifically talking about, ml ops in the hybrid multi cloud environment right. That's I think the headline for what you're targeting, right. To my money, that's a good tool to pursue. Right. Because like you say, if you pick each individual cloud service provider, say Gcp gcp has got weights and biases. They've got vertex So Ml Ops on Gcp is more or less a solved problem. Plus they have other managed services using kubeflow where they can set up a custom Ml Ops pipeline for you, right? So that's possible. Same thing is possible with AWS sage Maker azure. Ml does the same thing. But what if I have deployments across all of these different layouts plus for good measure on trend, right? So certainly that seems like a good market to address. I just don't know what is the total addressable market there, right? Yeah. And see, I'm a little skeptical on that front, okay? I'll be honest with you. I'm a little skeptical on that front because the whole idea of Ml Ops itself has not yet sunk into the enterprise. Right? Look, DevOps as a process has reached a level of maturity that is now beyond question, right? So when you think about DevOps everything ranging from creating tickets using jira to a sophisticated build and release pipeline, most things are today assumed to be necessary. You cannot see the same of Ml Ops just yet. We have tools like Ml flow kubeflow. In the open source world, we have enough data engineers and data scientists who are capable of implementing Ml of solutions. Yet my observation is in the large enterprise, you don't see a lot of Ml Ops adoption itself in the first place. Most enterprises, even to this day, Chat, gpt, Hype Train, most enterprises today are still bothered about creating the fancy AI models, the fancy Ml models, okay? And for the most part, it also seems like most enterprises struggle with finding the right use case for those models. It's like somebody in their lab has gone ahead and developed a really cool model and now these people are solution probleming. They are like, what problem do I solve with this model? So everybody stuck still in that, right? There are very few organizations which have reached the level of majority where they are saying, hey guys, we have these models in production today. Let's have a way of monitoring and tracking these models. If the customer comes and says to me, things did not work well last night, a, I don't want to take just the customer's word for it. B, I want to understand what that phrase did not work well mean, right? And I don't want to understand it just at the level of what was the accuracy, what was the precision, what was the recall, what does the mean reciprocal rank? What are the minimum average precision? I don't want to understand at that level mean average position? I don't want that. I want to understand at the business level, right? What business metrics did it impact? Right? For example, for a conversational AI company, because of whatever error in my model, how many conversations could not be contained within the chat bot and had to be escalated to an actual agent? Right? There are very few companies who have reached that level of majority that they are interested in measuring. That measuring the impact of business metrics, the impact of performance metrics separately. Right? In fact, because like I said, most enterprises today, they're still wrestling with the problem of putting their machine learning to work. If you go on and talk to any enterprise today, they will not be honestly able to tell you that they have a huge number of, say, deep learning models in production. Most likely they have sv and random forest in production, right? Which is not a bad thing. But they won't get off the Hype train. That makes sense. Especially the hypetrain that is now created with the llms and these extremely overreaching applications like Chat, gpt and bard, right? Enterprises are more and more likely to get sucked into that. No, that makes sense. We need AI. We need AI, right? How to operationalize AI how to deploy AI scalably, how to track AI, monitor AI It's not important. So most stuck there, that's point number one. Point number two is even organizations that have started using Ml Ops, and I'm not even going into the multi cloud hybrid multicloud area guys, right? I'm saying, even if it's just one environment on prem, or one environment with Gcp, okay? Simple case. Even in those cases, what Ml Ops means to those people is not very crisp. Right? So when we think about Ml Ops, there are a few different dimensions to it. One is, of course, your create, deploy, monitor, interpret. Right? That's pipeline. Right. And most people don't even get to interpret, explainability is nowhere on anybody's radar. Right? Nobody'S really at the point where they would like to understand why their model behaved the way it behaved. Right. So that sequence is one dimension. Right. Create the model, deploy the model, monitor the model, explain the model. That's one. The second is continuous integration, continuous deployment, which is something most organizations will understand. But there's a third element that you have to add to it continuous training, which means whatever models I build, their loss functions have to be built in such a way that they can learn progressively without catastrophic forgetting, so that I can use user feedback, the upwards and the downloads, what have you. And more importantly, I have to build a data pipeline to allow those upwards and downwards to flow into the system. Right? So that ci C is the cte. The ct part is lost on most people. Right. Other open area, in my opinion. Right. And then, of course, a third area, which is, I think it's extremely nascent at this point, pretty practically. There really isn't much of a market. There is scaffolding for monetizing AI. So, for instance, if I'm a company like coher, right, we have a whole host of Ml models which I'd like to sell as services. But do I have a scaffolding to say, even do a monthly billing a monthly invoice for my customer. Right. So that is the third angle of Ml Ops where you're thinking in terms of what was the usage. Right. The explainability part is about usability. The second part is how do you keep the machine running, the model running, running continuously. The third part of the usage, actual usage, there are a few different like this and most of these nuances, and I certainly don't mean to sit in judgment on these enterprises about this, but it seems that it's a pretty wide open area. Right. If you're not very careful, it will very soon seem like you are trying to boil the ocean. Ml Ops is not one problem. That's what I'm trying to do. Absolutely. No, this is very true. Thank you so much, mandar, for sharing this perspective. I think the more we talk, the more we talk to people, the more we realize that this space is actually very nascent, whereas it seems extremely competitive from one standpoint, like from the user standpoint is actually very nascenter. You were saying something sorry, interrupted. Yeah, on this. So you mentioned that a lot of companies aren't actually even using MLA, but we were trying to think of companies where this becomes like a necessity. And our hypothesis was that the company which is like serving software or software which has a sensitive data or has like data hosting norms, or the client usually in a lot of cases want to host the software on their own. We're thinking if there you want to ship like mlops and we understand like, the number of companies get further chopped down. But even if you could start there, do you think there is like a tendency in companies to go multi cloud? And what kind of reasons do you see? Is it more from a security reason, from a cost reason, resource availability reason? That's something we're trying to like understand. And actually one of the things here, like it would be great if you can also explain this in the context of also like, are you all multicloud? If yes, what's the reason? It's a trip, not what's the reason. You can also explain that context. Sure. But before that, I comment on what China was saying, right? There is no company that does not need mls. They just realize it yet. Right. Makes sense. Like I was saying earlier, they don't mean to pontificate. I don't mean to sit in judgment. I have myself been in situations where I know that I have to implement Ml Ops and I'm unable to because your business priorities simply never cease. Right. The urgent always keeps taking precedence over the importance. And so you are always in a frenzy to build these AI models and ship this and ship that. And you never get to a point where you are like, okay, let me now try and build a proper framework for monitoring and analyzing my models. So anyway, that's a separate remark. As for the multi cloud environment, right? So, yes, there are companies that operate in a hybrid multi cloud fashion, but these are, I think, extremely large enterprises. For instance, an amex I'm sure is across not sure. I know that they are across multiple clouds. Okay. And they have large companies like ibm and accenture managing their cloud apps for them, right? I can't think of any medium or small enterprise which is spread across multiple clouds. I think most people, most service providers, okay. So what I mean by that is there are businesses in the sectors like banks, financial institutions solving a problem in a particular vertical. Those are the companies that's one. And then there is a layer above them, companies that provide solutions to these companies at the bottom. So there are companies that build AI models for the financial sector, but these are just AI service providers. They are not the financial service, financial markets people themselves. Right. So if you're thinking about this bottom layer, the actual industry wallas, right? I think the big ones are likely to be multicultural and hybrid. Also, the small ones may just have started migrating to the cloud, and they are likely to have started doing it one by one. The next layer, which are the service providers, and which is where 24/7 also figures, right. We basically make it easy for consumers to talk to companies. We are those enablers. So we have the AI, we have the software, we have the bpo setup to help consumers do that. Now, service providers, enablers like our company will eventually want to go multi cloud, but then again, unless you're already a huge company like ibm, you're not likely to be already multi cloud, right? Most companies are likely to be. Do you guys not get request from your clients to host the models or something because of the sensitivity of the data? Sure. And we do have customers where they say, okay, so we would like you to use, we'd like you to host one or two models in azure and the rest in Gcp. For whatever reason, the data resides at one place, the model is at one place, or the data is sharded across multiple environments. It does happen. Right. But the setup of those services across multiple clouds is a one time thing. And it's not like there is a significant chunk of services that need to run on Gcp as well as azure, right? azure. We just need to run maybe a couple of things. That may be just my speech to text transcription engineers to run on azure. Everything else can be on Gcp. I'm just giving you an example. My guess is there's absolutely no data to back this opinion. By the way, I'm just doing some plain old punditry here. My guess is that most of the enabler solution providers are in that state where they know that they cannot just be on prem. They know that they have to migrate to the cloud, but they won't migrate to multiple clouds all at once. They won't bring in the multiple cloud readiness all at once. They'll do it one at a time. Right? Because it's difficult to convince customers to move to the cloud. And this is not true. Not just true of the financial services sector, it is true of other sectors also. Right. For some reason it depends on the individual's perspective. The CEO of a company somewhere, if he or she is of the opinion. That. Maybe putting our data on the cloud will open us up to is just that one belief that can stop an enterprise from moving to the cloud and doesn't even have to be a cio. Maybe if they did have a cio, maybe things would be easier. This could be a vp or a senior vp who has a particular belief and that becomes the organization's belief. So it is quite possible that an organization will say, let's just keep things the way they are. I don't want to break anything. If it is on your data center, let it remain on the data center. I don't want to change things right now. Getting that customer to agree to moving to the cloud is a challenge, and it's not just a technical challenge. Does your use case involve having any exposing the clients themselves to any kind of Ml observer? It will be like retraining or monitoring these models or something like that. Or is all of that handled by you guys? Because. All the responses that I have been giving you, I've carefully avoided being specific to 24/7 because it's proprietary. So I will again, without making it specific to that. Makes sense. What you expose to the customer depends on the kind of interaction model you want to develop, right? So for instance, if Ml Ops is going to get exposed to, say, data scientists in your client's company, then is the assumption that the people building the models are also data scientists in your client company through an automl kind of interface? It depends on that. So depends on what user persona you build your products for. Right. If the idea is that you will provide AI services to your client, but your data scientists are going to be the ones building these models, then the Ml Ops consumers mostly need to be your data scientists because they need to understand what's happening to those models. Right. But at the same time it makes sense to provide a view of the business metrics to the client so that they can see how much impact this AI model has had on their business on a day to day basis. Understood. So it's important to find the personas. Understood. That makes sense. And just to understand, do you find most of such companies having because, let's say even for single services, kind of thing, you are deploying on, let's say Gcp, and then a year, do you see a lot of these? Companies like the service companies making their own some kind of like a platform? Or is there something go to that you use to orchestrate these things across cloud? Is there a solution or is this like ad hoc on each time you go and run and figure out what to use in these clouds? Okay, so there is no solution, that there is no platform already available anywhere that you can just start using for the simple reason that you at least need to build your own reporting, you need to build your own dashboarding, you need to be able to define your own business metrics, right? Look, most mf engines will define precision and recall for you, right? But nobody will define a metric like, say, containment portion of conversations that started in the chatbot, stayed in the chatbot, ended in the chatbot, versus how many got escalated to an agent. Now, that's a business metric that a company like ours would be extremely interested in. And similarly, think of how many other business metrics there might be for different sectors. The end user will care about those metrics. They won't care about your precision and recall. And that is auxiliary information, ancillary information that's nice to have. They really want to know how much mess me up yesterday. Tell me that. Right. So the definition of the business metrics, the building of profiles for those business metrics, the building of my reporting and dashboarding for those business metrics, the user experience for those business metrics. Even if you pick any existing platform, there's a fair amount of application building that needs to be done on top of make it usable to your context. You are useful to your context. Understood? I understand this would be like for the interface with the client, you have to create a unique single view for them. But for things like for your own team, the workflow that they have to obey for, let's say on AWS versus Gcp, I would assume there is a difference between the two. Is that not a lot of overhead and the team adapts to deploying across, let's say, AWS and azure. Do you ever consider a tool which could have a single workflow? Because you said that this is. Yeah, look, like I said, I wouldn't mind considering a tool that integrates across these multiple platforms, right? But it has to solve the main problem for me. Even if my data scientists are the ones who are going to be using this Ml ops engine, not the client, data scientists still need to be aware of the business metrics. I don't want them working in silos where they are just concerning themselves with precision and recoil. Understood, right. I want them to have a view of the business metrics, what they need to have empathy for my customers. Understood. We have to build that blue anyway, what would be useful is a capability where I can define business metrics as plugins, right? I should be able to just by the way, here's a business metric that I'm defining, okay? Here's what it means to be able to declare the semantics of that business metric, define what it means, point out what data it should use in order to be computed. Right? Yeah. But I do all of this as a matter of configuration with very little code, as low code as possible. If there's a way to do that, then that will be really useful. Regardless of whether it is multiple platforms or not. The challenge today with Ml Ops is not that there are multiple cloud environments. The challenge is that very little is understood about mlps itself. Understood. Mandara. I know that one thing that you mentioned is some of the answers that you're giving is also generalized and not specific to. There's a few of these insights that you have given. I think it will really help us if you are able to articulate that with a few examples, real life examples that you're expensive, I don't know, in an anonymous if you're already doing that, or these are like a little bit more. I can either confirm or deny that. But I'm happy to talk to you about the context of 24/7 itself. Right. The reason I'm not doing that is because this is right now, an informal conversation. Sure. They contact me on WhatsApp? And it's not right for me to bring understood. Context of my business right away into this call. Right. Got it. Okay. But I'll tell you what, as it happens, I am trying to solve an Ml of problem in my team. Okay. Okay. And I'm talking to vendors about that. And I'm happy to engage with you also to understand how you can help solve that problem. Right. But that needs to be a separate call, and you need to set that up through my official email ID so I can bring in a few of my folks into the call. Right. And my official email ID is my first name, my last name at AI. So feel free to set up a call right. Sometime next week should work. But I want to tell you right away, the problem that I am interested in solving has nothing to do with multiple cloud environments or even the problem I am interested in solving is, like I told you, those two, three dimensions, right? One, how do I build that whole create, deploy, monitor, explain. Got it? Sure. You know what? Have all four of those in pieces. I just don't have them together in a pipeline. That's one dimension I want to build. The other dimension I want to build is the whole ci Cdct. Right. Then I also want to be able to build scaffolding so that one day I'm able to sell my services to other cx companies, other contact center service companies. So I need that Scaffolding to be able to drive usage. Right. So I want to solve that problem, that ecosystem. If I'm able to do this across multiple cloud environments, that would be great. But that's a problem for me five years down the line. Makes sense. Understood, right? If you're interested in working with me to solve that problem, let me know. We'll work together, right, with some of my extremely talented folks. Maybe we can talk about the feasibility of your solution. Maybe I can't promise anything that will talk. Of course. To be honest, I think that's not actually for us. We want both, right? Ideally, we want your insights as a leader, like this informal call that is happening where you're sharing your insights, working in the industry and learning from that. Because as you know that we are fairly early stages and learning this helps us a lot. And by the way, if this space is interesting to you, if this area is interesting, we also understand everyone's time is constrained. So we can also figure out to make things a bit more interesting from I don't know if you typically engage with startups in other more formal capacities as well. So we can figure something like that out that's on one end. The second end is potentially figuring out if there are problems that you're trying to solve at we could be of help in that aspect. We can obviously set up a call through your work email as well. But what I would appreciate, if it's okay with you, is before setting up a team call, like a call with other folks in the team, we sync up with you, and we try to understand a bit more what are the actual problems that you're trying to solve so that we can already know that is this a domain? That we can actually help him or not, so that we can save everyone's time. And if you're getting people together, we can actually customize the parts of the platform that are more relevant to them so that overall just more effective for everyone. Another quick question. Where are you based out of? In Bangladesh where I work, my office is in offices on outering Road. Do you know the adobe offices? Do we? Offices. Close to Marathon. It's a place called Khadovic nelly. It's between sarja for Road Junction and maratha. Actually live in kor mangala. Oh, wow. I also live in but it must be far for you, right? Yes, I don't have to go to office every day. I go to office like once a week. I see. Okay. So one thing is generally I'm based out of San Francisco, as I mentioned earlier in my intro. But right now I'm visiting Pancroad. So if you're also in the city, I would love to catch up in person with you. I can make my way too closer to your place and just replace office, whatever you prefer and we can grab a copy of something together. Yeah, sure. Let me look at my calendar and get back to. You, Nicole, because among the many medical emergencies that I'm dealing with at home, my son today, yesterday, has been diagnosed with viral gastroenteritis, and he's only five months. So my focus absolutely. Yeah. Let's keep talking on WhatsApp I should be able to take some time out this week for a cup of coffee. That's certainly possible. I just can't tell you right now which date. That's fine. No, mother, I have a seven month old, and I completely empathize with what you're like. Last month he had a bad stomach infection, and that got us on our feet throughout. So I completely understand what you're talking. About here, and I hope he's feeling better now. He is feeling better now. Things are getting better. But, yes, please do take care of things at home. We will just like and drop a message whenever things settle down a bit. We'll try to meet you in person, and we can thread. Yeah, so just hold on a second. Let me just see. Do you guys want to meet Friday afternoon? Friday afternoon we can come by. Actually. I have a decent chunk open on my calendar, actually. All right, let's make that Friday afternoon. If you can come somewhere near mg Road, that would be great. Sure. We can set a time. We can always refine it as we get closer to this. Let'S say maybe, I don't know, 04:00 P.m.. Chicken. Sounds good. We will just block that slot for our calendar, and we can always move it closer to the closer. And my gmail address is my last name@gmail.com. Perfect. Got it. Should I send you a note on your official ID? Like, we are happy. If you think that's better. Either way, it's fine. Okay, got it. What I'll do is just for ease of so I travel to Bangladesh. I'm actually based in bombay. I travel, like, every second or third week. I won't be there. Let me just create a quick WhatsApp group that will just make coordination easier, I think. Yeah. And then I can go meet mandar chinmay if you're free, you can join, too. But I would love to come by and meet you while I'm here in the city. Mandar yeah, absolutely. chinma niconji. I love that. Please, let's make time on Friday at 04:00. Lovely. Awesome. Thank you so much, mandar, for taking the time. Thank you so much. manda please take care. Bye bye. Take care. bye.