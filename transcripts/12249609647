And get your unmute. Sorry, I didn't realize. And I find, how are you? currently in Bangalore, Almost six years now. Where are you based Ankit? That's a nice nice generally. Yeah, you've been in Bangor for a long time? Yeah. Okay, long enough. Long enough, thanks. Are you awake? You wake. And get. Are you? Nice to see. Same here. Finally was called meeting. So many vacancies, but I like the way we persisted for this meeting. I went generally people drops the ball in between, if you are not able to for so long, somehow we could No, Thank you. Thank you for that. So Nikunja I'll set the contest book with Abhishek, he probably is caught up with some, you know. In-house firework. So, I I pretty much have them context and you are already there on the call, so I'll just start off and then maybe you can take it from there. So Ankit, thank you so much for joining and as he mentioned, we've been like, talking from a long time, you know, trying to figure out a way in which we can meet sometime. He was not available. Sometime Abhishek was and I've got up and even today it could have easily been reshape you but thanks for you being on the call. The objective here was mostly to understand the current pipeline at locus that Ankit and his team follows and on some some challenges What is the infra that here? Probably they are using some challenges that they are facing. And you know we wanted to understand that and ankit from our point of view. You know we are in a in our new stage working with a couple of enterprises in healthcare and other domain. We, we are looking forward to interact with more and more data leaders to understand what are the challenges that the industry, or the the fertility in general is facing, and where we can prioritize to build tools that will eventually, you know, give us some niche in the segment. As you know, there are like it's quite populated with so many players that are out there. So that's the objective, I hope. We'll try and finish it off in 30 minutes. Over to you Nikunj. Awesome. Thank you so much Vivek for the for the background, ankit pleasure to meet. You really excited about the call. So, I'll just give a brief introduction about myself, Ankit. So, I come from a mission. First of all like co-founder and CEO here, a true foundry. So work alongside abhishek, we attended undergrad together at Iits and Hallmates at work. So that's very nice to build the company together. And I generally like, you know, after that, I have been working in machine learning, so based out of San Francisco work and recommended systems at a startup called Reflection and then worked in conversation AI at Facebook. Can you hear me? Okay. I my video is freezing a little bit. Yeah. No, I can't hear you very clearly. Okay. Yeah. So what's your Facebook and conversation ai? And after that the three of us and Ragabishek and I did a startup together in the talent, space called entire that could acquired by infoage, and then we decided to work on through Foundry. so, Yeah, that's that's a short story about myself. I think Vivek already said the context for the call, I'll get maybe like, you know what we can do is you can share a little bit about your background and the type of work that you and your team is doing on at locals. And then specifically what I'm interested in is learning about some of the infrastructure elements about how models are built and deployed and also they developer workflow. That where are they prototyping? How well they're deploying the models like those are the two things that are particularly interested in asking so you can give an overview and then I'll ask more, follow-up questions. Got sharp. So let me start. So basically in locus we are into last mile logistics as you might have already knew it from the website If I'm not mistaken. Oh indusment logistics many use cases falls under them, you know data science I would not say machine learning. It's it's wrong to say only machine learning because there are so many optimizations that we do Which are not part of ML or AI, what was right? So they there it is. Mostly you can say it's algorithms workflow. It's it has nothing to do with machine learning. It's classic optimization. And biggest iPS that we have is under the optimizations framework. However, after I came here before approximately one and a half years back, we started building the Data lake. I mean we started in listening for the Data lake, it was always under the plan, but never got executed due to the priorities back. Then now that we have the data lake in place data, scientists are able to grab the data access it? And take the decisions based on that and then eventually use a the same data to build the models. Currently one of the use cases that the team is trying hard to improve upon is the GEO coding as a problem. However, there are so many small other use cases like transaction time. At the door prediction, the premium pricing for this lot. It started delivery. So what should be the price of a given slot if it is a prime slot for delivery with generally people, prefers to get delivered That could be some other business use cases like Because we are into B2B the value based rising. How do we you know, Define the value is pricing of also all the prediction of the john of a customer with not only a bit or not only suggesting the names, but also going beyond that with recommended actions to be taken. So, this are some use cases which are under development. There is a truly speaking. There is no model currently in the, You Know, production system. But there are so many under experiment within two to three months, I think there will be, at least two three models in the production workflow And which are the most prioritized models here. In terms of sorry, I didn't get the context a little clear. So should you mentioned you gave me like six seven different use cases for machine learning models. I didn't mentioned in a couple of months, two or three models will be in production. So which ones are these? Primarily around Geocoding. Short Text, You can set sort text, NLP related, because address is something which is not a huge text like unlike the paragraphs of text which you find in other domains. So anything related to short text is Right. something that we are currently exploring. So is it fair to say that like you know this this is like address verification and updation like for example like like You know Basically I give an address which probably is an incorrectly format or whatever incorrectly formatted you would automatically fix that format. Is that what is what does it mean by geocoding? If you opening in simple, terms is converting, the textual address into latitude and longitude now is the Huh. inputs are noisy. It cannot be done straightforward. There are so many preprocesses and Right. all that you do have to do. While you do that, you might have to standardize the address, you might have to spell correct. It you might have to call it out valid invalid and so on and so they are all sub ML use cases. Okay. Understood got it because I'm assuming that the actual JIO coding itself. If the address is correctly meant to specified, it's basically a deterministic problem, right? Using the Maps API. Yeah, so it said that way it is a straightforward if you have the perfect address. Character. Right? Even the component itself is a ML Okay, make sense here. problem there. So if I'll give you a reference here Three kids. in chat, we haven't build that but there is a similar thing built by delivery. You can see three tabs there, address standardization, validation, and geopoding API. These are all, you know, standard ML problems or you can say data science problem under geocoding beyond that. Also, there are some but there are some samples Understood. Representative problems. We got it right? Okay. No I think this makes sense. Cool. So this is very helpful. The second thing that I wanted to ask is you mentioned that you now have a data lake. What's the data lake that you're using? Currently we started with only storing the data in as file storage S3, if the load and everything that we want to get increased or there are some analytics, use cases that will down the line. Come they will explore. You know because we are on AWS of Of the natural extension is to use anything that is part of the ecosystem. Maybe if we go out of the AWS, maybe Snowflake was the choice. Once when we explored that. But then currently there is no plan to Go because everything in S3 is sufficient for now. So most of the data that you're talking about is the structure date or is it a lot of unstructured data? It's all structured here. I mean only unstructured one is the address because they're the next one, Makes sense. everything else would be structured on the Understood. Okay. And then the other thing is like, How is the team like, you know, composed like in terms of data scientists devops in for our Emily's? What's the structure of the team? Okay, so I mean under data science labs, we have one of the data engineers one or two of the data engineers, who takes care of the radio leak. Oh, odd to ones are the analysis. Rest of them are data scientists for the uses of the data. And Devops is there. However, MLS is taken care of, by few of the interested. I mean, data scientists, who are interested in handling anal, I see how many team. In roughly on this kind of projects which are pure data science, other than optimization, you can say, would be around six to seven only. Okay. Okay. See Six to seven data scientists. And basically develops is done by their money. So they only productionize or they plan to productionize the models. So currently there is nothing in production as such in terms of the ML models. So not sure how it will progress we have some plans but I don't it's little early to say that how it's kind of productionized we may directly never message sagemaker to start with this that kind of things, works out easier. I see. Okay. Understood. So, so so, so you have like, well, basically, this entire dslab reports to you, okay? Yeah. Okay, so you have one to two data engineer, one data, analyst, and six data scientists all like together Yeah. with the team basically. Okay. Understood I see and you're on AWS. Do you end up using Sagemaker? some some of the use cases, we do use, leverage, SPACEMAKER In this smaller version of the models. If you want to do pocs and all, we try to leverage something in the whole lab world as well. Okay. Understood so people basically use the Jupiter sorry like Google Collabs and like you know just experiment with the models there. Yeah. And I'm assuming that given that is structured data in the logistics. It's a, it's a, it's not a very large data set, right? It's not like tens of gigabytes of data or is it? Initially, that was the thought that it won't be so large, but then if you see the address is accumulated over years or You know, a multiple geographies across the globe, then it becomes a huge data set. So I mean, see I mean just simply giving you an example. Imagine that you want to create the embeddings of the addresses. all the addresses that you have, there are so many problems that down the line task can be anything, but if you just train the emittings, That itself has a lot of value and imagine you have your 10 10 million addresses, unique ones with some basic preprocessing done. So, now, downstream does can be anything but first challenges that, how do you deal with so many addresses? So that's to start with the first ML challenge that we have to solve. Got it. Understood. Okay, no this makes sense got it. So the the idea here would be like let's say once the data scientist is training, one of these models. Like let's say some of the NLP texting coding models etc. I was doing they might even use some pre-trained APIs as well instead of building something from scratch, right? Absolutely. Yeah. So it's little early to say right now oh, that what will be working out. We are trying both from this crash because my intuition here is Address has its own language. Unlike English and other languages, right? It has its own grammar essence, but Right. it has his own rules and all that you follow what geographic device it Through that, yeah. differs and all of that. So, the experiments are around that, only that should be try to train it from the scratch or Should we try to, you know, have the pre-trained version? Where at least the basic structure is like basic language structure is there in the model, versus you can just post process it using transfer learning Understood got it by the way, I don't know like this, This is one thing in this context with our work on this problem, a little bit before the address column. And one thing that I can share from my experiences that  character based character based embeddings actually work out better than would token based on weddings Yeah. for for these models. So I don't know if you're already trying that, if not just something to consider, Okay. Okay, and you can also intuitively Okay. imagine. You can also intuitively, hello. I'll make a note of this as an important input to me. And it's also like, you know, not very hard to intuitively imagine because like, you know, a lot of times people would put commas next to words and that kind of gets like, you know, the comma itself has a lot of significance, right? Like slash has a lot of significance, basically. So those things, basically, if you go character by character your your modest tend to perform better. By the way, in a lot of token based embeddings you would typically just remove those punctuation marks or whatever like so. Yeah, it happens, right? So I mean, you are right Currently the initial experiments that we did. Although they performed a little. I mean I don't have exact metrics on top of my mind but they perform a little better than the other rule-based approaches the and they were not they were talking based on produce. Character based The only I can learn He got it. from your argument. Here is so that this comma, this special characters makes a lot of significance in the address world, at least. Yeah. However, in the training of the previous angerdings, we had actually cleaned those things basically. Exactly. Yes. Yes. Which is our, which is the main thing. Yeah. Yeah. so, Make sense. Yeah, which I think? Alright. Thanks. Of course of course, a couple of other things. So are these going to be? Real-time models are always going to be batch models. Okay? It could be both in in certain natures like it depends like if there is a company, let's suppose an e-commerce company wants to leverage this model. Will upload the badge of addresses. And we'll wait for the results, whether it is valid invalid address. That could be one task second could be the use case that they have the while they are dispatching. The orders from Side. They want to just make sure that it is listed less. Let's say return to home ratio. So return to home base ratio. So in that case, they would like to just predict if the addresses fraudulent or not. Of shots, right? Right. So in that case, the model can be called in the online basis also. So it depends on the use case at the okay, understood end but generally the genericity of the model actually doesn't care whether it is online or batch. Thanks sense. Makes sense and does your team primarily use Tensorflow Pytorch? What type of libraries framework? So the team generally uses Currently fighters is heavily used. got it. Are you familiar with taught sir? So it is actually started with like somebody who started deep learning in the team was biased with by Torch and then everybody adopted that to started. So there was, you know, natural bias to the choice of technology there. However, in my past experiences, I have you highly used by George Models in other organizations. So then I also continued that because hosting that in the previous organizations helped as foster Or to be productionized on the those use cases. So then without much delay without, let's figure out those details later. It's first prove that it is working and then other things can fall in place later. Right. Right. So I think, I think for Pytots specifically like, you know, like, for serving pytorch models like people a lot of times people end up using like, you know, your standard Web servers, like whatever class or something, but like torch serve type of web server. Generally work better right border server generally work better. So that's asking if like you know you have you heard of thoughts of Do you plan to use thoughts of anything along those banks? Not at the moment, I would be very open and frank here. Okay. You've got it. So ankit in the next couple of months. Like What are the challenges that you see with respect to this entire like, model frameworks? Like, If you, if you had someone who is like an open potentially available to help in this aspect? What would, what would you ideally seek out help on? so, Currently. There is some transition going on, I have Unfortunately, how decided to move on? And you know, in a week of time, I'll be leaving from locusts. There will be somebody else taking up here from the existing team. So in that case I think challenges and everything maybe it will be better for you guys, you know, discuss with the one who will take it over from there and currently given the micro situation outside. I think the they want to be as you know, frugal as they can about their experiments bandwidth. Which we were doing the lodge in last couple of partners versus what we will be doing as an organization. So we'll be backing on the things which are going to pay a more Roy's rather than a long-term experiments tough As an organization that call is taken right now. So not all problems that I mentioned. On the street. Here will be opened up in the same time. The ones which are priority in terms of the business outcomes will be prioritized over everything that I mentioned, right. But it makes us understood. Okay. So I think this is very, very good to know about about the about the, like, you know, talking to other folks in general and like, in a prioritization and stuff, from your perspective, have you already decided Ankit, like, you know, where are you going and stuff? Like, is this or is something that you're going to figure out, basically? Hello some options. You still need to figure out the best possible from there. It's a it's not a bad state to be in to have a bunch of options and then deciding from deciding where you want to go. I hope I hope you find something nice and exciting for for the next next. Sure sure. Thanks. Thank you very much. Right. I think I will call about delayed and things, move different ways. So Makes sense. Yeah. Make that that makes. And I do know who is going to take over the your old basically. so, Hasso currently not somebody from my role for sure. It's going to be somebody in the within the team who is just a, you know, date dslee types, we will continue to eat because they want to be frugal right now. They don't want to expand the team too much. So, that's the reason I guess. Nobody is going to get hired for this position at the moment, maybe down the line, they might decide to do that. Nexus understood. Understood. No, I think this is very, very helpful. Thank you so much. Ankit for for walking me through this. Like one of the things that would love to do is keep in touch with you As you move on to your next role. I'm sure that you will. You probably are you going to continue to work in data science? Yeah I'm into data science. Only I generally like to build products in data science data related products, basically I generally not get biased by ML only stuff. Charlie. Yeah. Yeah. Like it's a tool to solve business problems. One of the tools to solve business problems, physically, Make sense Make sense. Yeah. What I can do is Ankit also give you a little bit of an overview of what we are building taki. You have some mental model of where we are and they can would love to keep in touch as as like, you know, each of us continue to move along in the journeys, right? No. So, Basically if you think about the data scientist journey from licking building a model, right from left to right? So they typically spend a lot of time and data and feature, engineering and then model training, hyper parameter tuning deployment of the model and monitoring of the model. So true foundry comes at the model level basically. So we don't deal too much with the data and feature engineering side of things. We do deal with model and beyond Basically, okay? And our focus is that any type of model batch inference, real-time inference async inference etc. We are able to quickly deploy that model without making the data scientists deal with infrastructure at all. Okay. So like we almost abstract away the infrastructure and technically a data scientists could get an API endpoint directly from the Jupiter notebook. But we also like, you know, integrate with like the best practices like Cicd and stuff like that essentially. So the main thing that we are solving for is obstructing away. Infrastructure in a data science, friendly using data science, Friendly APIs essentially, okay. And once you put a model to production using the platform, you can also get very quick monitoring model monitoring and data drift dashboards as well. So that like, you know, something is wrong in your model. You're quickly able to understand what's happening do a root cause analysis and stuff like So those are the areas that we are working on as we continue to move along in the product journey, we would love to like, you know, show the show the product demo as well to you and get some more concrete Yeah. feedback at some point. Yeah makes sense makes sense. You know, I think, I think that's, that's pretty much what I wanted to cover. If you have any questions, I'm happy to take that. No, I will definitely have questions once I I mean, I just opened while we were talking the website and everything now that I understand the objective here, I'll at least pass on it. I mean, whatever happens. I mean our journeys might be different but at least, I'll pass on this information to the team. At least they can keep their eyes that what's coming new and all of that down the line, they will be in the need of such things, right? So that I will definitely, second is Exactly. Yeah. wherever I am going, I'll be always in the data science world. So in that case, also it will be useful only. Lovely, awesome. Awesome. Great. Thank you so much, ankit for putting in the time and good luck with the next earlier. Thank you. Take care. Bye.