Just send me the LinkedIn profile. That's fine. I'll anyway set the context of before anyone. Hi, how are you? You're on mute, niven, we are not able to hear you. Can you hear me now? Yes, we can hear you. Hey hivin. Hello guys. Hello. I'm sorry, first time using this up here on my iPad. So I had some little problem with all this configuration and everything because I mostly use the slack. So I have my working configuration somewhere else. So I needed to put it in the work. Okay guys, nice to meet you. I'm sorry. Also one more thing. For some time last time I just forgot of the old obligations I have. So I mean most of the time I'm almost twelve or more hours working something. So I'm sorry for that. No worries. So I'll quickly set the context up. Unfortunately, Abisha could not join. But I have with me today anurag he's a founder as well with the firm. So Anurag, Abishe and these are the three founders batchmates from their graduation college. So they'll introduce themselves. But I'll just quickly set the context up. I took a download from Abishek just to ensure the session is productive. So basically Naveen has kindly agreed to help us in understanding the current process that he follows at Sugar CRM. Some of the challenges that he and his team might be dealing with day in, day out in terms of deploying the model into the production, what are the learnings that he has? These are some of the things that we'll be discussing today, focusing our conversation around that Nevada. Basically we are building a solution to enable the deployment of machine learning model really fast onto production with inbuilt monitoring into it and something which I think and Rag will talk a little bit about more. I am Vivica and I look after business development growth at Truefoundry. We work very closely with Anurag and Bishop on growth initiatives. Nice meeting here. Me too. Yes. First of all, I really appreciate you taking time for the call. What I would love to do is spend two minutes giving a brief introduction of myself and two foundry, including my co founders. And then I would love to spend some time learning a little bit more about you about Sugar CRM and the data science use cases plus what the current entries. So does it sound good from the context? Yes, of course. Yeah, please. Glad you had something. No, I just wanted to say as I already mentioned Abhishek, I cannot speak about anything that is yes, I cannot disclose any type of this level of information. This is something that I already say. I can told that this is okay. So I can speak about my experience in the sugar and outside of the sugar, in the science and so on, but only in not so specific cases. No, this information cannot be disclosed. Yes, yes, that is completely fine. So Niven like I am on Rock, one of the co founders at Co Truefoundry. Like my background is I did my undergrad in electrical engineering from Indian Institute of Technology Krakpur and then post that, spent six years working with a hedge fund called WorldPoint where I was using a lot of data for building trading strategies and trading models. During that time I spent between Mumbai, US and Singapore and I was trading around 600 million assets for WorldPoint. So got a really good sense of how to use data for building strategies. We used a little bit of data science but more things around data engineering and basic strategies. During that time I also started investing into startups myself and invested in 22 startups so far. Post that like when? In 2020. Me, Abyshek and Nikunj we're all in the same boat. Nikonja Abyshek were senior software engineers and lead machine learning engineer Facebook to bring a lot of experience on the technology side of things and how ML platforms are built together. Like Facebook internally uses something called an FB Learner for speeding up their machine learning pipeline and what we are trying to do is bringing a version of a bill Learner to every company around the world. The goal is to make it as less for companies globally to adopt ML and deploy ML models either to a test or a production use case just like it is in Facebook and with the best practices that are followed. So yeah, I mean that is a quick summary. We built and sold a startup in the talent space as our first startup to one of the big talent companies in India and through foundry we have been building for a little more than a year. We are right now a team of around 18 members full time most of it being the engineering team and primarily we are based out of our headquarters is in US. We have a team in India and we have few folks in Paris as well. Nice, this is nice story. I guess then you have some experience with all these people especially for the Facebook. This is glad to hear. I would definitely like to know more. Okay yeah. Naminga please go ahead. Thank you for introduction. So on my side, I work in the science for some time, more than eight years working on some first research problems, multiple I mean different ones from buying from artists perspective protein, protein interaction, structure, rotation, genetic and so on and so on. Then after my finalize my PhD I go out of the science. It was the last how much? Three, four years. I did some different job. One is some of them are high profile like one of those is for some company that work with Hollywood studios one that we try to predict how the movies will basically how much money they will make but only using the information. Even this information is disclosed to the public in any level. So even before you start shooting and so on. Different stuff then yes, I first started to work with note startup, then we go to the sugar working on the different levels. So I mean not to go in many details, there is almost very little thing that I didn't do in that time. Only thing that I didn't produce. I had the opportunity for working with the pictures but almost everything else I had some level of experience with it. Got it. Just quickly to a quick follow up question. So a lot of your work has been on the research side. What has been your experience in terms of putting the models that you are developing either into hands of a real user, either in terms of like maybe a test environment deployment or a real pro deployment or even for training like say bigger models like when you have to use virtual machines. I would love to hear a little bit about that. The problem is two level. First is that be research lab that I work on and at the time I also work on the server infrastructure basically maintaining all the things mostly with some help of the DevOps. But in the science this is a little bit different. The level of the distinction between the different role is much more blurry than you will see in the companies, especially big ones. Got it. So the two problems are always there. The scale and position of something. Okay, it was the time before Rves. So right now Averse definitely changed many things and many people are just doing the two things. Do you want to do something on the premise or do you want to do in the ives and that change industry as you already know and most people are just using that. I mean if you're a small company you're using probably OBS prices and everything. You all know that story. But I was from the time where you need to do something on the premise, there is multiple reasons for it. There is my work on also very projects that are connected to something that are of the national basically security issues. So it cannot go anywhere outside of the country and even if you provide some information it needs to stay on the protected servers and so on and so on. So there is a completely different story because you need to build your infrastructure from ground up security to the outside of the user who will use it, with which tunneling, how that will be introduced and so on. Of course that is the problem of the nodes and basically the problem can be scaled. Are you using just how big and how complex of your survey infrastructure are you using? Single node, multiple nodes and so on so on because most of the things that smaller companies and research labs can do is mostly smaller stuff. If you do not have the high level of the HPT computing and so on and so on and your labs are not using that. That mostly is single or probably two or three very much connected nodes. In small labs, the bigger ones you will have the infrastructure. I work in the France where we have basically all the people imposed their infrastructure. But then is the changing, do you want to train on it or just deploy? And that is the first question. Then there is the question of course how you will use the prediction and that sometimes they're even the more problematic than having the model itself. I had a different situation. I had the situation when we had 40 million predictions per day. Oh wow, that's now yes, that is the problem because it's not a problem. Training, even training is slower, you can faster the train the model that you need for the prediction. So then is the question how you will do that? Do you need to produce multiple models and then predict the power so the infrastructure on server if you put it how you will handle it without another question is maybe you want to put it on a mobile device. And then the whole, of course, different game changer because your model needs to be shrink. Neural network need to go completely floats. Need to change everything need to change because you don't just have the memory you don't have. The capacity for very long very long prediction timelines. And then also, if you're working in iOS, you have the gateway problems. 32nd predictions depending on which infrastructure you're using. Sometimes their gateway is just not enabling because all the process of deploying the data, transferring the prediction needs to be done under some timeline depends on what you're using. So it's completely different story now, I understand that it's easier now because of the OBS. So most of the people I heard some and I heard something, people are starting doing things and they're just using Rs. I'm creating specific configuration for you that can be done. But like I said, it all depends on what you are targeting. If you are targeting big companies, they will probably have their own infrastructure. The biggest one, the middle ones, another story. The small ones, maybe they have money, maybe not. So that I would do if I go that route. Awesome. No, I think that is fair. I think in terms of the way the infrastructure is built, I think bigger companies definitely build most of their infra with the authentication layers, with the right secrets management, with auto scaling and everything enabled, which then makes it simpler for them. But for midsize companies, I think it's still time where a lot of people spend time to build it, but are not able to build it or at the same time. Sometimes what happens is they do not have enough resources to build, like, you know, building. It needs, like, a combination of data, science knowledge, infrared knowledge, engineering knowledge. And sometimes it's not easy to find those engineers. So a lot of times we have seen people trying to either use something that is open source or something out of the box. So one question here is in terms of like the challenges you saw. Did. You also end up using sage maker by any chance or was it mostly AWS that you used? No, one of the things that I can say, we have the completely custom infrastructure. So right now in the sugar everything is built from scratch, everything. So there is no sage maker inside there and even, I mean outside from the even the libraries sometimes are completely rebuild if they're needed. So that is one of the side that I do not know what your target is, but this is the story when basically you just need to have your teams, you need to have data scientists, data engineers, architects, DevOps and this is all we have. So we basically for our going from the scratch. I mean if you need assembler, you'll go there, you build libraries, you build everything. So this is like another side, this is on the left side and the right side would be if you are a smaller team and you want to produce something, produce something fast, you are startup and you have some idea and maybe in that shoes then there is maybe help. Okay, I have the data science but I do not have the needs or level of the knowledge to completely do my own infrastructure. Then maybe that is the place that I understood you guys want to be positioned. Yeah, ideally I'll talk in more details of the product side, but the positioning is for two cases. One is people who don't have good infrastructure and they want to make it better and they want to accelerate machine learning faster. And then the second is people who have built systems. But probably a lot of the build out was fast and therefore not taking into account all the considerations led it to Cost or latency or secrets management or anything like developer speed. And they now want to either revamp it or integrate with something so that they can still speed up their pipeline. So these are the two targets primarily and we are still in very early stage of the journey. So we are working with a few companies even and at the same time looking to work with a few more with them of working very closely on specific problems that they might be facing. For example, one of the companies we are working with is facing specific problem around support of different frameworks and then having their entire system deployed on someone else's customers clouds. So working there. Similarly there's another company that was facing issues around building the right authentication system and then ensuring that the secrets are not exposed to the data center. So trying to work with them to improve the system and at the same time add value. So that's how we kind of operate. I wanted to take two more minutes to understand a little bit like whatever you can share on the without sharing proprietry as to how big is the team currently at super and then on the infrastructure do you end up using Kubernetes? Is there any challenge you have seen or you foresee seeing and what is the reason of buying versus building versus trying to adopt something out of the box? So this will be really helpful for me. Yeah okay so team about size of the team, I mean Sugar is the company how much? 700 something people. Team that is connected to AI I think more than 30 or more people yeah, sometimes even bigger than the company scale so like I said, the reason why we go with that level of the solution we go completely custom is the things that we do okay? Okay and the things that we do and I cannot disclose anything outside of something that you can find on our company is the protect team is doing is basically integrating level of the information of outside of the world different kinds of information, building specific pipelines just for that information and code them in very specific ways. Okay? Some of them are trade secrets. While we are doing that, feature engineering and everything. And then integrate them to provide our customers like. You can also find out basically different level of the use cases for our customers in the level of the predict. And most of the use cases are for the market, for the leads, for opportunity, for the advanced forecasting and so on and so on. So all that use cases have completely different pipelines on the different infrastructure because you are not having just one source of information, even not from the one single database of information. Now there you can guess how many how? Fast and how things can complicate become very fast complicated then you have the data protection from the customers everything that is done, how it's done so it goes on and then there is basically solution. So we build from the scratch our own AutoML modeling predicting everything else. So everything is done from the structure. There is multiple reason complete control of the system needs for the customization some things that we are doing are just on the level of getting your PhD on that. So we are researching things, but we don't have the time for PhDs. And some of these things are never published, but on the tutorial. Okay, so another thing is about cooperatives. Yes, we use them. I mean, companies definitely using that technology is using also Docker. I use Docker for some time also in my labs some of the people are providing that so yeah, most of these technologies are used I cannot go in more details there are multiple teams in the Sugar, they are using that for the multiple reasons I mean most of the DevOps and so on. I'm not directly involved in the why that is chosen, but I can say yeah, definitely. Okay, cool. I think I get a sense of, you know okay, one or two last questions and then I love to kind of share with you what we are building. And because I don't have a lot of information but maybe by sharing what we are building you can potentially see if there is any part of the product that might be useful or maybe give feedback on how we are building it as well. Either of those will be super helpful for us. So I wanted to understand if you do any sort of monitoring for your models in terms of like when I. Say monitoring, of course, everything and everything. One part we are having UI teams, multiple ones for different parts of the project. And also, of course we are having UI teams and our UI team is basically taking care of everything. So from MLS side there is the pipelines, they take care of every steps of the production and everything is being monitored show to the customer or you have even different ways, I mean, you're not showing to customers. There is internal reporting, there is external reporting, there is stakeholder reporting, different level of the knowledge to understand exactly what you are seeing. But like I said, everything is custom and everything needs to be because the solution, I mean I can go with machine learning or technologies from the little bit broader side. But the problem is the problems we encountered doing this road are very specific and the solutions was it's not something you can go and find on the net. That is the problem. But most of the things is not you just implemented, you cannot implement it because it's not work. Your data are specific. I mean you can apply some of the rules, but you need to devise many, I mean many different and that is a little bit goal to the customer. Of course it's bothersome, it's problematic, you waste so much time. But then it is what it is. That is also the reason why we have so big team. Yeah, so I totally understand the reason for custom, but I have one question that is when you say custom, an event like for the model building site, the custom I totally understand because the kind of models you are building are very different. But once a model has been built, after that the operationalization process I'm guessing will still be common to a lot of other artists. Right? Because ultimately after that it's basic engineering. Yes, that is correct. That is correct. With some cabins also because there is multiple cabins there where you will store your predictions. And what we are providing, we are not providing single solution, we are providing out ML solution or ML solution to our own customers. So we are company that is providing ML solution not only for us but for other customers. And that is why we are leads in the CRM world because right now currently as the middle I mean in the size but still our AI solution to other customers basically providing them as our state of the art and on the part at least what anyone else is doing. And that is the complexity also there. So not only we are building that, there is no single pipeline. So for every customer we are providing this resource and there is the storage, there is the show where it goes first what you want to show and there is different use cases. It's not single thing. You are not predicting single things. Okay? You're not building chat bots. Now you want to output chat and where there is a solution and prediction are used by the multiple different scenarios. So do you have the storage and then you have the shared storage between your own storage and the customers and so on. I'm just trying to explain why complexity I totally understand. I think I get it. So one clarification niven is we as a company are not building the model side of things. We basically plug into anything that other companies are building. Like say for example, you might be building different kinds of models and we totally understand that it is a need to build those because we cannot build the models. The amount of data access that you have is completely different. What we do is only once the model has been built, the entire infrastructure for productionizing. The model which involves say shipping it maintaining shared, ensuring that the cost is lower. So in case of yours, I'll give an example, you might have a case where you might be deploying the same model but the same model is trained for different customers on different data and then there are thousands of customers. So there are two options. You can deploy thousand models as 1000 services or you can do a deployment into a single service and then do dynamic loading of that. So how do you choose between the two and ensure that okay, cost wise it's minimum but at the same time there is no interaction between data of one customer versus another. So that's probably an optimization problem which is more on the operationalisation side and something that a lot of other companies also face, for example. So just trying to tell you that maybe, I think maybe there was a mismatch in the understanding. So we are just trying to be on the other side. Yeah, okay, perfect. Okay, cool. So Devil, if you have five minutes, what I can do is I can quickly show you a high level of the platform and then please yes, please. How much? 30 minutes. Okay, I have I. Let me try to speed this and so something quickly. So are you able to see my screen? Yes. Yeah, this is at a high level still, but at least it will give you a sense of what we are building on event. Okay, so basically we are a machine learning deployment platform built over Cuba networks with the aim of speeding up development workflows while providing them full flexibility and with full security and control for the internet. So on one side suppose there are developers like Data scientists, ML engineers and on the other side there is infrastructure to ensure that both the sites have the right access to the system. So what that means is basically for developers we enable single click deployment to make the deployments fast. We make it easier for developers to learn by providing Python SDK which is something that they understand. We ensure that across the stack SRE best practices are followed like the CI, CD, Auto, Scaling, secrets Management, Authentication all by default without you having to build it or without developers having to care for it. And finally, everything is on top of your software engineering workflow that is built on top of Kubernetes. So that way your infertility is just maintaining a single pipeline rather than maintaining double pipelines or increasing their work. So if you look at the product, the product has three different like has the following workflow. So first is for the infrared, the DevOps team where they create a secure development environment for the ML team by easily connecting to their own cloud, ensuring that they can allocate resources to the ML team and ensuring that the platform has guardrails that prevents them from doing mistakes or ensuring that costs are not overrun. And I'll show you how this happens through the video here. Basically the main thing is it makes it very easy to connect to your own cloud and you are able to provision workspaces clusters for your team to work on. Then the next part is model deployment which is by the developers. So once a developer has tested out a model and now they want to deploy it, they can actually deploy very simple functions including preprocessing functions to postprocessing functions, they can deploy models which are real time batch, pipelines, anything. Again ensuring that the best practices are followed. We also enable like traffic splitting. So for example, if you have to launch a model to production, you don't have to launch the entire model, you can launch it to say 1% of the traffic and then after that scale it automatically based on performance. So that functionality of traffic splitting or Canary testing and federal testing is available by default as well. And then once you deploy your model with a single line of code, you get access to system monitoring, model monitoring which is model performance drift in the model and ensure that you are able to debug and have full visibility to what you have built. Any questions so far? Yeah. So how you are detecting drift of the model? So drift we use like a proprietary algorithm. Basically it tries to earlier we're using KL divergence etc. But now we have shifted to a more proprietary algorithm. It works primarily for more structured data. It does not work very well for unstructured data, but we are able to predict if there is a drift in the data as compared to say wait. How will even detect drift in unstructured date? In unstructured we do not do because that is something that is still a topic of research. So we are not doing like monitoring is not the main thing our platform is built for. Our platform is built more for the deployment monitoring. We are enabling for structured data only as of now, for unstructured data as of now. At least we are not aware of how people have sold it and we are not doing research on that right now. Okay, so when you said diversions of what you are looking for the so you're monitoring divergence of what exactly? Yeah, we are looking at the feature drift and the data drift. So features like you might be calculating a lot of features on top of your existing data. Right? So we measure the drift in the distribution of those features. Okay, yeah. Why do you want to do check if any divisions or what? Because if there is a difference between what the input data input feature distribution was, which was at the time of day. Yeah, I understand that, but this is exactly the reason why I'm asking for that solution. So divergence, you can do without different models in their predictions, but distribution is something else. That is what I want to clear out. I didn't understand you completely on the start what you exactly want. So outside of the distribution, what else you're looking for in the model? Outside of the distribution? Yeah, because you have at least four forms of the date, some of them are or can be detected by the distribution. So distribution is just one thing and your model can drift even if your distribution doesn't change. So how will that. So actually for that to be honest, we'll have to ask the technical team that is implementing this and I'm not aware of the full details, but I can get back to you. I think we measure concept drift as well, but I'm not aware of the details of the implementation. So I'll have to go back to the technical team and ask. I believe you are referring to something like a concept drift, right? It depends. The problem is even in the literature the terms are a little bit of the messes maybe. Yes, but what I'm referring is there can be situation, at least there is the four different situation drift. Some of them include distributional changes. But even if distribution changes happens, it doesn't mean that your model predictive performance will be lower and then that means you need to time series of it and so on. So when you said that I wanted to hear about more of the drifter detection because that might interest me. Okay, but I get some of the answers. Yes, I think we can go into a little bit depth of that. I can have a shake or someone to kind of sense their more details on that. That is completely fine. Basically. Now let me show you like take three minutes to showcase you the platform once are you able to see my screen? Yes. So basically I'll quickly kind of show you and this is just a kind of a small version, but basically we can dive into details later on in another call. So this is the place where the insert team or the DevOps team comes and connects their cloud. So you will be working on probably again, I don't know which cloud account you use, but suppose you are using Kubernetes and behind the hood you are using AWS. Then in the Kubernetes you can create a cluster on your AWS account, you have admin member privileges, you can configure your base domain, you can create your monitoring dashboards, you can configure the type of machines you want to provide access to our blacklist or whitelist. And then you can add the cluster. And then the cluster will be added. Once you add a cluster, the infrastructure can create smaller workspaces for the data science team with resource constraints and limits, so that the data science team never exceeds it. It can also be different environments, like a test environment, fraud environment, depth test environment. And then you have resource limits like CPU limit or memory limit. You can also further have cost restrictions here, so that no one exceeds the cost here. The cost tab is not there. We are going to add that and then collaborators. Again, full access control is there for the developers. So once this is said, basically the infrastructure is allocated to the developers and then the developers are ready to start working on a deployment model. So how that happens. Any questions so far? Otherwise I'll go ahead. No, I cannot. Okay, so I'm showing you the deployment via the UI, but the same is possible over a CLI or through Python as well, using either Python or YAML basically. So you can deploy services, jobs, models, even pipelines is something that is coming. Suppose you have to deploy a service. All you do is select a service. You select one of the workspace in which you want to deploy it. You can deploy from your source code directly using GitHub, or you can deploy from your docker image. Suppose you are deploying for your source code. You give the GitHub URL. If you have the docker file, you can give it. Otherwise you kind of simply select Python built back and give this override command. If you enter the part two requirements, we automatically create your docker file. You can select the ports, you can select the resources, you can configure your environment variables like secrets management, etc. And this is the ultimate YAML spec file that is generated which can be used later on. Once you click the submit button the model is live along with like your metrics which is the system metrics, your logs so that you can debug if something is going wrong. And then if you go deep into the model further you can see different versions of the model that are deployed and if you want to go to an older version you simply click redeploy button and then it will move to an older version. So literally you don't have to go back to the infrastructure and everything. And similarly like this way you can also deploy your training job and you can deploy like a model here, even deploying model we don't have to deploy like from a source code. You can deploy from an existing model registry that you are using by simply adding a line of code as there. And once you have deployed, the monitoring is like this once you basically add a line of code to your model you are able to see your metrics like predictions, actual precision recall, you know, log loss, etc. You can also measure the distribution of the data and how it is changing between actual and prediction. You can compare it across two different timestamps so that you can see if there is any change in distribution again. And then further you can see drift. If there is a drift, it will throw an alert to you. You can calculate drift by features as well and then at the same time you can go back to the audit and then you can dive deeper and you can also kind of configure and see alerts et cetera. So roughly like this is at a high level the platform. There are a lot of things underneath it but I wanted to just show you an overview so that you get a sense of what it enables. For the developer. The main goal is as a data scientist or ML engineer, you don't have to depend on the inter team and you still have independence and you are able to quickly deploy and test models. That happens in the best with the best DevOps practices. Okay, that's good. I understand a lot of the things have been built in house. I would love to kind of do a call wherein we can talk more about monitoring as to how we are implementing it and then if there is something you feel can still be worked, not from a model side which is completely your IP and you will need to do it yourself, but more on the operationalization side. I would love to kind of potentially figure out a way if there is any challenge you feel can be seen and if not that is completely fine, but just want to have an open discussion around that. Okay, you know how we will do it because it's already 15 minutes to six. Yeah, this is good, you can send me and I will give you answers in how much? 15 days from now. I can see what else is there any use for you guys? To be very honest, I fear not so many. But if there is something we can use, if there is something maybe we can speed up, I will give you that answer. That is the best thing I can do. Okay, that is helpful. That is completely fine. And one more question. Is there someone from the infrared team as well we can talk to? Like purely infrared team who kind of manage the resources and all by chance. I need to check out. Can I give you that? Okay. This is information. If you cannot find it or people don't want to talk with you, I cannot help it. Basically, it cannot happen with my green light, I mean, anything, and it's not mine. There is multiple people included in decision making issues. So if anything happens, needs at least five, four of us on a little different level of the authorization to happen. So it will just not help you. Any talks, you can get some experience, but we are extremely strict on how the information we can provide everything we can it's on the site. Anything else, our sales team can help. So, yeah, that is my official mail. You have my mail in the LinkedIn, so you can use I already provide a bishop email, so you can use that email. That's where we are having conversation, right? Yeah, please use that. Yes, that's it. Okay. I'm sorry, I'm not sharing my company meals. There is multiple reasons. We are having extremely strict procedures. I will not see it because these mails will be stopped. And I mean, my professional mail is something I use only for intercompany communication. So if anything else, you can use Gmail. Okay, thank you guys. Thank you so much being very much. That is completely fine. I really appreciate it. We'll send across the resources. If there's anything you can do to help it, otherwise, it was great chatting anyways, and thank you. Really appreciate your time. Thank you guys. Bye.