Hey, how are you? Hey. Hi, I'm Robert. I'm doing good, how are you? I'm good as well. Thanks a lot for taking time for the call, sir, I appreciate. Where are you based out of? I'm based out of Texas actually. Dallas, Texas. Got it. What do you guys from the area? So actually myself and Avishaik, who is my other co founder, we are based in Bangalore. Our third co founder, Nikkunji is based in Sfidia in the US. And the rest of the team is distributed primarily. It's still bulk is India, but there are a few folks in US and Europe. I see. Yeah. So see, that basically just give me 1 second. I just wanted to call Abhishek so that he can join in. Sure. Yeah. So I think Abhishek is also here. Awesome. So Sinada, basically I'll just set the context. I think you already have some context from Nikhil. But basically we were chatting with Nickel about how the research group works and he did mention that one of the things that really matters is how we optimize for the cloud cost because there's a lot of usage of GPUs, et cetera on the research side and there's a potential, like what we were building as a product. I'll give you a brief. And he told that there is a potential usage of the product from a perspective of how we can use it for optimizing the allocation of research infrastructure costs. And for that he told us that would be like a good person to kind of dive into as to how we are currently managing the GCP infrastructure, how we are optimizing the cost there, what are the initiatives in plan and so on. So I wanted to dive into that primarily during this call and get your thoughts. Yeah, sure, definitely. I'm happy to share our current set up and then how we are managing our infrared GCP. Maybe I can share a couple of slides, just one or two, like how we are, the current flow. That will be good. Maybe we can start with like a quick introduct to introduce ourselves as well. Sure, definitely. All three of us actually graduated from It correct in 2013, batch in India and then went very different pathways. So I went to work with a hedge fund called Worldcoint where I was looking after building a lot of trading strategies using data and then went on to trade them as well. So I was doing portfolio management and risk optimization for them where I managed around 600 million in assets. I spent like four years between us, three years between us and Singapore and before that, like three and a half years in India. And during that time started to interact with a lot of founders, wanted to build something of my own. Invested in a few startups myself as well and then from 2020 continued on the startup journey, left my job and then Aishik and Nikunju are on the same board. So we all came together, we built our first startup in the talent space solely to Infoge and then over the last one and a half year we are building Proof Foundry. The goal is really to build like a cloud agnostic platform that optimizes for how you allocate and provision resources on the training side of things and then also compare the models that you are building and you are able to choose which the right model is and then from there, moving those models to production in a reliable and cost effective way with the right AB testing infrastructure. That is kind of the overall layer we are building. So there is obviously like the research in trial location component and then there is the production management component and the serving layer as well. With Salesforce like we are talking timely on the research side as of now. And the goal is to kind of bring something like what salesforce internally had like an instant platform and then companies like Facebook and Google have their own internal ML platforms. So wanting to provide a very seamless developer experience for other companies as well and build it in a very deep way so that it's scalable and reliable. So that's like a very short brief and we'll talk about more towards the later part of the call that's el Sinathia. Sure, definitely. Thank you. Thank you very much for the introduction. Nice to meet you. I graduated from It correct for 2013 Computer Science and then worked in Facebook for around five and a half years. Worked on different teams like the Distributed Caching System team was leading the Mobile Performance team and was eventually leading the video's organization at Facebook. And then I returned into quit my job, moved back to India and then currently we worked on a talent startup that is acquired by Info Age here and currently working on Truefunction. Awesome. Yeah and Nickwin is like same batch, like he worked more on the ML side with a company called Reflection in the Valley and then was the lead ML Engineer at Facebook. Brings a lot of experience on the ML side of things and right now we are a team of like around 18 folks so still early in the journey, working with a few enterprises and trying to find our way into others. Taking help from folks like Nikki, yourself and others in the journey. Sure, I mean really great stories to hear. Actually I can go with myself, so myself. So I'm working as a Research Infrared Engineer for the Salesforce research team from the past four to five years. So our team basically we provide all the info needs, whatever the infrastructure team needs. So we provide with them and then we connect them with the different teams within Salesforce and also to the external vendors if we have to use any. We are responsible for managing the capacity, budget and everything into the infrastructure for the current research team. Okay, got it. Perfect. Cool. I think before salesforce, where were you? Just to kind of get yeah, sure. Before this I was working with PayPal. Okay. Yeah. So I was working in the CSV team over there, nothing related. From there, I was working mostly on GCP, but GCP for CSV, like GCP. Okay. And before that time I was doing Masters here. I went to Minnesota State School. Great to hear. Cool. I think we can dive into and would love to hear about about maybe starting with the workflow of research, what the infrastructure looks like, what are the things your team takes care of, what is like a pressing need and then we have a list of questions after that that we can go. Sure, definitely. So, as you guys know already, I mean, we heavily rely on GCP for all of our infrastructure needs at the moment. Is it fine if I record this? It's for internal purpose and nothing, but only if you are comfortable. If not otherwise I'll not. Yeah, I'm sorry. Because I might. Okay. Yeah, this is fine. So within GCP, we actually heavily rely on Google Kubernetes engine because the way it provides auto scaling and also the way we can provision resources, whatever we need. So that's how we basically use this for provisioning all of our infrastructure. So before this, our research team was using AWS and there we have they were just using the city instance. I mean, they are provisioning their own instances and they are conferring each and everything manually, all their packages and whatever they need for the infrastructure. From then we wanted to move to GCP and take advantage of Kubernetes engine. And then we want to make the provisioning automatic. And also the resource team here, they also have more control over there, what kind of resources they can provision, like they can provision whatever GPUs, whatever kind of GPU they need. And also the different types of CPUs they can provision with a simple YML file. Okay. And then for storing our data sets, of course you are using tons of data, I mean TVs of data for doing the pairing. And also we'll also be storing multiple checkpoints, so multiple model checkpoints. So for that we are using Cloud File store. This Cloud File store, definitely they have really high throughput and high hopes. So these file stores gets mounted to the Kubernetes pods, whichever researchers spin up. One question you mentioned high throughput and high. I hope so. Okay, got it. This file stores are being used for that. And then these are really like close to 50 to 100 TB. So that's how the high scale capacity this file store have. And then you mentioned 100 TB. Yes. 5200 TB. Yeah. So that's the magnet scale this file store can scale up to. We even wanted to use more than that, but that's limited as of now on the GCP at the moment. That's one thing. So of course, we have two different clusters. One is Resource Cluster, which is mostly used for training, and the Demo Cluster, which we actually serve the API endpoints to the different teams within the salesforce, and then probably some demos to the external public during research conferences and stuff like that. So they look almost same. These clue clusters look almost same, except that we'll be using Kubernetes Services and Kubernetes English controllers to expose our models to external users. This might not be much significant, but we just use cloud storage during our data backups. Like, if you want to back up any of our model checkpoints or stuff like that, we just use Google Storage and coming to the flow. I think. You have any questions here? Yeah, I have some questions, but you can go to the floor and then I'll ask altogether. Sure, definitely coming to the next slide. So this is our typical YAML, looks like. So this is what researchers use, and then they submitted to the Google Edition. Basically, they just specify the image they want. So this is the primary thing. I think we should make a note here. So basically they have all the packages they need, all the different Pythons packages or whatever. I mean, Python packages, different Python packages they have. They'll be building it within this image. And again, this image is built using G Cloud commands as well. So we use Gcloud Build command to build this image and then and then push it to the GCP Cloud Registry. So I think it's similar to Docker Registry but specific to the GCP. So they'll be pushing it there again for the command. Most of them, they just start this container or Pod in a debugging mode. Like they just use Sleep Infinity or Sleep Ten Days or 15 days, and then they directly log into the pod and then do some initial testing and then start the training. Mostly you can use it. Yes, that's right, exactly. This is more like a training job running command, right? Exactly. But you're not using the Job object in Kubernetes. You're just provisioning a Pod with Sleep and then starting the training job there. It's kind of two ways. It's just a preference on the researcher. Actually, some of them that directly use the training command within the YAML itself, they use the Job step to start the training. And some of them, they just use the Sleep Commander, and then they get inside and then start it. Okay. And then again, as I said, they can ask for whatever resources they want. In this case, they can just ask for two GPUs and then how much CPUs they can use and memory they can use. And also we have one more parameter I think that might be missing in the same way. So they can specify what kind of GPU they need, like a 100, B 100 or K 80, whatever they need. They can just specify additional fill in the sample. And then they can just submit a Kubernetes unit, which will take care of presenting that. I spoke in a previous slide about the persistent volume. So this is how they mourn them. Basically, we have two different persistent volumes. One is the private persistent volume, and also one is the state persistent volume. So they can mod how many persistent volumes they want on their parts. And then they can specify it right in this ML or something like this. So they can store the data sets and also monitor points onto this. And once the YAML is ready, they just submit this to the Google Google engine and then it will automatically take care of provisioning the compute based on the limits they specified. And then that's how it will start the Pod on the workload. Any questions here in the pod? Shina. I guess there must be some wastage, right? Like a data center starts the podcast, starts the training job, and when the training job is over, the Pod is still running. It's still occupying the request resources at least, right? Right. If they are going to use sleep command, yes, that is right. That is another problem. There will definitely be a waste if they are going to use a sleep coming. Do you also host notebooks on this cluster or they don't work on notebooks. How does that work? They do, actually. So basically they install the Jupyter notebooks on this port itself, and then they port forward the pods to their local host. I see, they know all of this. You have taught all of them commands? Yes, we have all the documentation related around this. And then they have this. And also when we have a Remote Visual Studio code, they can even connect their Visual Studio or intelligent to these pods. And then they can directly write the code in the visual studio. We have that. The reason you have to do it is because the data is monitored on the shared volume and that is accessible only on this cluster. They can't operate on it locally. So that's why they have to always operate via Pod in Kubernetes, right? That is right. That is right, yeah. The shared volumes are there actually on GCP and we won't be able to local laptops. What is the ingress controller you're using for the other demo clusters? It's GCP. Native English controller. Actually. We do not use controller always. If there is a need for Https only, then we go with invoice controller. So most of the workloads right now we have just demo purposes. I think we just use GCP load balancer service within Kubernetes. I think we have a load balancer service and then we just expose you to that. You're using GK autopilot or GK Standard? This is GK standard. GK standard, okay. Yeah, that's a good production. We have multiple load pools. We configured multiple load pools within the GKE. Of course, for a one on that even within a GPU we have multiple machine types. Let's take an example of a 100. So for a 100 GPUs we have five different machine types. Like one GPU, two GPU, four, eight and 16. So we call this multiple node pools. And then we always set the auto scaling limit, I mean minimum limit to zero and then maximum limit to maybe depending on reservations or whatever we have. Of course, every time a researcher submits the YAML, they definitely should wait for maybe five to ten minutes for a note to get provision and then get spinned up on that. And where do the researchers track this progress? Like how much let's say sometimes they provision less memory. Right, so it will crash like the logs metrics. Everything is done using cubestl logsityl. Yeah, they can do either with cubes in GCP itself, in the GCP console itself we can track the memory usage and also the logs. Okay, the Stackdriver thing yes. Maybe renamed the cloud monitoring. Yeah, everything is being monitored there. Okay. We are using something called VandB, I mean Waits and Basis. So I think that is experiment tracking. I guess. So that's one more thing we are using at the moment. Wait, is hosted internally? No. It'S a public cloud internally. But I think we have a private server hosted by the Vandyb team. Inside the salesforce cloud. No, it's not hosted inside the salesforce cloud. It's only for you guys. They have hosted something. Yes, we have our own Apex and our own domain for the Vandybn then. So it is being completely managed by virtual Basis team. Just the access is being maintained. Understood. I have a few questions basically from your perspective, how does the request for allocation of an infrastructure come? Or is it like people just request to YAML? Like at what point does your team step in beyond these resources? You have to take permission or is it just open like you have provided this insight and then the researchers can request for any amount of no, actually. I mean for CPU and memory, if it's just a CPU request, we don't have limitations. But if for GPUs we limit them to use maximum of eight GPUs for each researchers, they can't get more than eight GPUs and then we limit that using quotas. In Kubernetes, of course we have an object called quotas and then we use that to limit that one namespace. So if they need more than that, they need managers approach, we might need some approval from their manager and also the project impact that is going to have with this GPU. Basically, as you said for you, because there are a lot of researchers where do you kind of see this entire location? How do you get into visibility of okay, what cost is actually real used costs versus what is unutilized and how do you maintain those? That's what I just want to get a sense sure. Actually even within the GCP itself. I think right now we are using Data Studio for tracking all this usage. So there we can monitor them on a day to day basis, like how many GPS use these guys are using and how much they are costing. So those dashboards actually they can also give you like on a cost basis, like how much this user has spent on these GPS. So it will also give the cost not just the GPU numbers, but it will also give the cost be it CPU, memory or GPU. So it will give the complete whole picture of a particular researchers. Basically we are using it's actually completely managed by GCP again. So we just integrated a BigQuery data set into GKE. So basically all these metrics get pushed to that BigQuery data set and then we just use that data set to we just feed the data set to Google Data Studio and from there we basically track all this information. Okay, got it. Did you have questions around this workflow? Otherwise I can share the set of questions and we can go over them. One by one as well. Yeah, you tag the namespaces by team or developer. How do you get the cost per developer of our team? So we create namespace. Each researcher has his own namespace. We do have team namespaces, but very few are probably two to three of them, I guess. Does Google give you namespace level costing in Kubernetes? I know that open cost, cube Cost, these guys were there. Yeah, they do actually. Maybe I can share some. Yeah, they do actually on Data stream, we can do that. On Data Studio. You can go and see the namespace, level costing per namespace and everything. That is right. Yeah, of course. Before that we need to configure a data set. We need to enable GKE metering, I guess in the Kubernetes engine, whichever you want to monitor. So then we can enable that and we can create our own dashboard. They really have a great example. Okay, yeah, we can share the dock link. It will just be great to kind of go through it. 1 second. Sure. Got it. So you don't have to use cube cost et cetera, because the Data Studio kind of does pretty much the cost allocation part in terms of namespace level, right? That is right. Yeah, this is the only thing we are using at the moment like the GKE. Okay. From a perspective of salesforce and for your team, at what level do cost really matter when you have to track it? Is it just at the name of this level for researchers, do you have to also kind of aggregate it, look at it at teams level or say project level? And how does that mapping kind of work? Like, is there a structure in which you do that mapping as well? Yeah, it does actually. We usually do it based on the project level. Project level and also the conference levels. Like we have multiple conferences like ACL, Em and LP so even we make allocations based on that as well. So if it's a really high impactful project, we try to give more priority to that. There is a potential use case if there is a potential use case for that project to get integrated into any of the salesforce projects. So we will be giving first priority to that project. And of course especially during the summer, so we get a lot of incomes and also some of the times like November or December, so those times are basically busy for our researchers where they have to attend multiple conferences and they submit their research papers. So that's when we have more GPU usage than the normal. So at that time we try to allocate more budget in those months compared to the rest of the months and also during the summer of course, as I said, because of the internet. Okay, understood. And then in terms of the overall cost part, what is the rough breakdown of costs? Like in terms of say GPU, CPUs, networking database? Do you have a sense there or majority is just GPUs and others are pretty small. Yeah, actually the majority is GPUs. I'm not wrong. Probably I would say 60% to 70% of them goes to GPUs. 60% to 70%, definitely. And then maybe another ten to 15% of CPUs and memory. And then the rest of the stuff like the storage, even the storage, I think storage itself takes like 15% to 20% overall cost, whatever we are maintaining. So that's the breakdown. But apart from GPUs, we use another SKU called TPUs as well, tensor processing units. I think these are specific only to the GCP at the moment. That's the new skew which we have started using recently. I mean we have been using it from last three to four years, but from last one year I think more and more researchers are getting interested in that and then even now I think we probably in future I think that is going to be our major. TPU. That might be a problem. Okay, got it. In terms of the usage patterns that you see among research teams, what is the usage pattern that you generally observe? And does the inter automatically take care of shutting it down? Auto scaling say researchers can look it up to eight GPS. Do they actually ask for it and then not use it? Like situations like that also common. Want to understand more detail of the usage? Sure, definitely there are definitely some ports or GPUs that are not being used and then they just keep running them. So initially we had a problem like some of the resources they just use sleep Infinity here and then they just keep on running the parts even if they don't use. The part gets still running even if they don't use. For that we created some automation and then we basically created a basket and we delete all the Sleep Infinity parts on a daily basis. So if they want to use the power, they need to specify specific time frame, like maybe sleep one day or sleep two days or three days. So that is one strategy we are using at the moment. But they can still use like they can still do sleep 30 days of holidays. So for those kind of workloads so right now, to be honest, we are doing it manually like we are if there is any pod that is running for more than 15 days. So we are basically manually checking the pod usage if there is any memory usage for the past one week or past three days. So again we just use the GCP console and then from there we can track the memory usage over the past one week or something like that. So that process is currently manual, like to check the utilization for the last three to four days. So then we will be deleting those spots or maybe inform the user to shut it down. Okay, so that's one way. Okay. And of course sometimes we have a resource especially in case of if a pod is requesting for eight GPUs or 16 GPUs itself. So those are kind of high demand resources in our team. So in those cases we are planning to implement something like do not run anything for more than seven days. So if anything is running for more than seven days or ten days. So we are planning to build it automatically so that it can get allocated to some other researcher who is actually waiting in line. So that is one more strategy we are planning. You have reserved GPUs? Yeah, we do. Probably that's another thing we can discuss. So we have reserved GPUs and we have commitments. Especially right now, I think we have close to I mean almost 90% of our GPUs are under reservations or under reservations are under committed usage discount. So we get close to whatever the least price you see in GCP, also GCP. So we get at least less than 50% of that discounted rate to us. Again, we regularly check our dashboards and we track our dashboards and based on the usage we basically place the additional reservations or commitments we have. So almost 90% of our usage is covered under this reservation discounts or commitments. So in that case, like scaling it down will not make any effect on the cost, right? No, of course. Yeah. But the only reason we try to maintain the auto scaling limits is like we want to know what kind of resources they are using, I mean, what kind of machine types they are using so that we can make changes to the reservation. Yeah, so that's the only reason we want to enable the auto scaling. And we have reservations. Do the researchers get to see the cost? They do actually. The dashboard which I was talking about previously, they have access to that, so they can track their cost and also they can track how much resources they are using. Okay. Do they actually go and see do you think they see? I don't think so. Not really, to be honest. They just see the overall usage, like how many GPUs they are using. I mean resources, but not the actual cost. I don't think so. Probably managers. Maybe managers might be the managers might be seeing it, but not the actual. Got it. On the question of this one, this reserve GPU thing, I was wondering the amount of reservation at any point, what is the limit by which you overshoot the reservation? Say, for example, you have deserved like 20 GPUs with Google, but what is the peak usage? Does it ever reach like two x of Deservation? Or it's always within the reservation? Definitely not two x for sure, but maybe it's 30% to 40% more than what we're talking about in November, December, that's when our usage peaks. So definitely during that time and we go our reservations definitely 30% to 40%. During normal hour, during normal business days, I think we are definitely probably 10% more than what we have. So generally your reservation should be at the 80% level of the average usage you see, and then you're expecting that even if people are not using, then the remaining 20% additional capacity will not burn you costs. So that is generally the optimization, I'm guessing. Yes, that is right. 80% to 90% more than that. Okay. We also have a problem with these reservations. Probably one problem with discussion, I guess. So basically the reservations, especially the GPU reservations, I think with CPU reservations we are fine. I mean, if you reserve 1000 CPUs or 2000 CPUs, you can spin up whatever machine type you want in GCP, and then the reservation get applied automatically. But in case of GPUs, that's not the case with GCP at the moment. So if you reserved, let's say if you reserve one eight GPU mission, so you should be using it only on the eight GP machines, but not eight one GPU missions. Hope you got that's one of it. I mean, it's hard to predict what kind of machine type they are using, so that's where we might get even. We have reservations, so that's where our costs get wasted. There probably like 10% or something like that. So that's the ballpark one. Okay. Got it. When somebody requests for GPU, it's not like two people are reusing the same GPU machine. No, it's not, actually. That's the reason we created a multiple load pools, like each and GPU type on the different load pools. It's not on the same one. Other thing is in terms of like for the projects, for the projects and the ROI of the project, like, do you end up mapping the cost to the actual ROI, how significant that is, and who. Then decides, okay, which projects are useful, which are not useful and what does that impact? What does that have impact in terms of the resource allocation or for your team in general? Yeah, sure, definitely, as I said previously, so we allocate resources based on the product impact. So as of now, we don't really have many products that are actually integrated into the salesforce production or something like that. So we don't really have the numbers on Roa, like how much we can monetize this particular project. But definitely there are really few high impact projects which are going to get integrated into the salesforce which we are going to monetize to the salesforce customer. So those kind of projects are definitely we are we allocate more resources and then get the approval from our leadership. But not really. Right now we don't have any one mapping of ROI on a particular project. Okay, that is not there. And then in terms of like you mentioned about two or three things that you do to kind of nudge people or shut down resources in certain use cases or sleep infinity, is there like a major project in place to kind of just optimize for this cost or that has not been a concern. I just want to understand that for you. Yeah, right now we don't have anything in plan for that other than shutting down the notes which are running for more than a week or 15 days. So that's the only plan we have at this moment. But other than that, for the cost optimization, I think we are not really concerned with them. Okay, got it. Cool. I'm trying to think if I missed any question, do you have any other questions in terms of this part? No, nothing from my side. Okay, got it. Basically what we can do is we also had a few questions around security. But basically when we were discussing with Nicholl, he mentioned that we sold our platform, which kind of allows management of the infrastructure, easy provisioning of namespaces, workspaces across researchers and teams, and then managing and getting a view of the cost for each of these and then also tracking like a layer on top of that. And then for researchers to run the researcher environment where they can easily kick off a training job, compare runs and so on. Kind of a thing we were discussing with a potential POC that could be there in terms of basically the intra team and the co who manages the budget of their search group, in terms of seeing, like, can we create more visibility if possible, or can there be certain things in best practices to nudge people, to kind of optimize for cost? So around that like wanted to maybe showcase you what we have been building. And this is still early phase, so for us also it's a lot of learning from you all, but I would love to kind of hear your perspectives there. And then there were a few questions around if we have to think of the POC, what perspective we should think about. Given you work most closely here, is there something that will be most beneficial, if at all, or wanted to kind of use the remaining call for that part? Sure, that's it. We can go over to. Yeah. Is my screen visible? Yeah. Cool. So. I'll just go over the infrastructure of things first. So this is where you can basically connect all the clusters. As you mentioned, you have a demo cluster and a research cluster. You can attach the two clusters and this cluster is not connected. So it's showing up, is disconnected. This cluster is connected. What connected means is basically you go ahead and add a cluster. It can be on any of the clouds. Okay. You can map any ingress. Also if you want to map ingress like star, dot, let's say start Mlspool.com. Okay. Whatever, whoever is deploying something, they will only get sub domains of this thing. This can be internal IP also it can be an internal domain that is available only under VPN. So you can also do that. You map this, all your clusters are here, basically. And then what you can do is you can go and see all the workspaces of the cluster. So these are all the namespace in the cluster. Okay. Here is where you basically see how much is being used for every single what is the usage, what is the allocated, what is the limit? So when you create data workspace, you can define like CPU, memory, storage limits, GPU limit will also come here. So you can define how much, as you mentioned, like eight GPUs you are allowing. So you can do that and you can also do access control. So if you want like one workspace to be visible to only one researcher or one team, you can only add those people so they can only see those same spaces. They cannot see anything else. Okay. Yeah. And we also show you like if somebody has allocated something and they're not usaging. So we'll try to show you that. We also try to show you the cost right here. So you can see the last month, last week, last hour, and even the developers can see that then. So they will know that how much we have spent and how much was allocated and things like that. Sure. And one thing to note here, do you have an option to maybe allocate something like that? I mean, passister storage to the stage. You want to mount a certain volume. You want to allow mounting only a certain volume to this namespace, right? Exactly. Yeah. So we don't have that now, but that can be added. What we have is, as of now, we do have this thing, service accounts. So I think you don't need service accounts because you are mounting it as a volume. But if you want to give that access to certain namespace, access to certain other infrastructure like service accounts, maybe like a GCs bucket or maybe some other Google Vision service or things like that. You can attach that service account, okay. To that part, to that port. And this is where you can basically define what kind of instances you are allowing each namespace to use. Okay, so even on a name level you can define that I want to use, I want to give access to GPU to this researcher. This researcher has access to the bigger GPU machines or not bigger GPU. So even on a per name, since you are able to allocate that, okay, this researcher only has access to, let's say T three machines. Okay? Makes sense. So once the researcher basically gets you have allocated it and the researcher basically plays around this domain. This is the deployment page. Basically, this is where they can deploy services, jobs or machine learning models if they have directly. So Jobs is pretty much what you were saying regarding that 1 second. I'll see if I can show you a good job example. So Jobs is basically what they are running as a job, long running job. So this is where they can just create a job. If you want to deploy a job, we have a CLI way to deploy a job. And also if they want to deploy it from the UI, they can also do that. So they can select the Git repository from where they want to deploy the branch. If they have written a docker file, great. If they have not written a docker file. They can also give us a Python command packages to install whether they want to trigger the job manually or they want to run it on a schedule so they can enter the conjure schedule. Also right here. Any environment, variable secrets they want to use, the resource limits they want to use, and we know how much is left in their workspace. And we also try to show them an estimate of cost regarding how much they're requesting. Got it. And where do these jobs run? Is it on your own infrastructure or do we need to connect any chances for the CI to run. These jobs as these training jobs? Yeah, not the training jobs, but the actual CI part, like downloading the report and creating the docker images and stuff on the Council cluster itself. But you can attach any other CI pipeline we offer integration, Google code build you can integrate with and it will build the image there and then it will push it to the Kubernetes cluster. So that also is possible. Okay. Otherwise it will build on the cluster itself. Okay. This is our demo cluster. Basically, if you want to deploy it quickly, a service like a quick demo to show to the business team or anything like that, you can just quickly go here, select the refer that you want to deploy the port on which it is available. This is where you get to decide the endpoint based on what you have configured on the intro site. If you have given start MLS.com, they will only be able to select among the two domain name and if you want to do pathwaysearchresearcher two that also is possible. Okay. And again they can target a certain instance type to deploy their workloads, things like that. And one more thing that we had was this thing. So this is the part where they can create templates of jobs so anybody can trigger it with customer argument. Let's say they created a template that allows them to train from like 1 July to like 15 July but they want to run a training job that suddenly they just want to run another job which trains from like let's say 15 July to 30 July. So they just need to change this and create a trigger job. Okay? And the moment they do this basically all the runs will be there and then they can also log metrics in the job which they can see right here. So they can see like pretty much they can do they can compare the compare the metrics that happened in different jobs and everything right here. Okay? We do plan to show the cost estimate also right here for every single service and job. So that is something that we are working on but volume out is something that is very good idea that we can add that will actually be important. I guess for you. I wish I could maybe talk a little bit about what else is what we are thinking of on the cost side. And. Cost side is pretty much like we try to show you the cost of getting a detailed cost estimate from GCP so that has pretty much all the data. This one is just to expose the data out to developers on a daily basis so that they get to see and we do want to do a few things like before creating the job we kind of try to show the estimate even before you deploy the job. Okay, so developers know that okay, if I'm asking source so much like this is what I'm going to incur. Sure. So this is where we try to show the cost. So that is also something that we are working on like showing the cost previously to the developer and clear jobs part will be handled really well this one because these machines will shut down the moment job ends so there will be no waste days regarding the when they want the shell access and all. So for that what we are working on also is like a pure developer environment. So one more thing will come here which will be take a note or a photo shell. So what they can do is when they start it behind out we will also create a pod but they can mark like kill my pod after certain amount of seconds of inactivity, right? We will mark kill my thing after like ten minutes of inactivity and inactivity means any request to that machine. So then the automatically died on after ten minutes. But all the data will be saved on a peak on a persistent volume. Okay? So when they come back up, all the data will be there. So that way there is no cost to waste also and they are able to work seamlessly. So that is something that we are also working on. So that will solve your the shell access thing, basically. Got it. That makes sense. And also regarding the showing about cost per user even before spinning up the job, I think that's a really good idea, I guess. And also based upon the company's deals with the cloud vendor so I think it might vary between company to company. Whatever the list price which is being shown in the GCP outputs, that might not be the actual cost which are entering because of our existing contract. Probably that could be the one more factor you guys might want to consider, I guess. Yeah, if we get that exact amount, we can show but otherwise we can. Show. Directional value basically we will basically show that okay, this is like more than this and things like that for every job and also they will be able to see for every single one that they have, they will see the cost right here. Training takes how much cost. 20 days of training takes how much cost. So that graph they can see basically developers themselves got it. And then we wanted to kind of have a dashboard synagogue which is basically exposing the costs across different functions. So for example across projects or across say individuals or across teams or division, across CPU, GPUs and all of that. And then directional trends, any indicators, red indicators that overshoot of cost on a particular day as compared to normal and things like that. So that dashboard we are thinking of building and that is where we are also kind of looking at a design pattern and that's where I had the chat with Nicholl. So there is like the infinite side of the platform but this is the part that we are generally focusing on to kind of see if there could be a way in which we can potentially use salesforce as one of the design partners to kind of help build out an outside value. So I wanted to understand from you, like your team, because you look at the interest rate, is there anything that your team has as a target in terms of cost management or you have as a target in terms of cost management? That is one question and then the second is in terms of the platform, the way we are thinking like do you foresee like these are certain parts where it could be more valuable to focus on which is currently missing in the GCP overall environment, for example. Yeah, definitely for the cost management, one thing I would think of is like we already discussed about the unused resources, I think I wish I had a good point about that. If there is any inactivity for maybe one to two days or something like that, that's one kind of feature I think we want to integrate with and see where we can reduce our overall cost. So that's the one thing we want to focus on. Coming to the GCP right now, the kind of model which we are using, I think it's really efficient, I guess the team, but of course, the only thing which I mentioned previously, like we had to tie the reservations to the machine types rather than the whole. So if we can resolve that kind of issue, I think that will more optimize our cost. I mean, we can effectively use all of our reservation 100%. So that's one thing we are currently not getting from GCP. Yeah, actually we are trying to add this to action GPU support. You don't need to allocate one machine per developer, right? So you can allocate like partial GPUs, so that way that problem will get solved. And then one more thing I forgot to show you is basically the developers can see what they're doing, like Jupiter, and they can see it right here. It just crashing the Kubernetes event. So every developer does not need to run Kubernetes to understand how to operate those things. Right? So on the allocating GPU machine to different research objects, we actually did have that previously. The reason we do multiple GPU machine types is let's say we have eight GPU machine and then one researcher wants to use only four GPUs on there. So for eight GP machines, if you talk about View 100, for a GP machine, you can get a maximum of like 64 CPUs and maybe 60 GB of memory Ram. If this particular researcher is requesting four GPUs and maybe 40 CPUs and maybe 200 GP of spam. So, okay, that eight GPU machine gets allocated to him, but remaining four GPUs get wasted. So other researcher, if some other researcher is using, if he wants to use another 200 GP of memory, he won't be able to get that onto that machine. So this is a problem we had actually. Even though we define the limits, we try to enforce them. Like for one GPU you need to request a maximum of this amount of Ram and this amount of CPU. Even if we enforce that, sometimes some of the projects, they might need more CPU. So that's the reason we shifted from that model to the individual machine types. But I think that could be a good feature, I think, to have in your design as well. For a single resource, you can get a maximum amount of this. So maybe that could be a good option to include I guess. In the resource. What do we actually let you define? We don't have a relationship that okay. For this amount of CPU you are allowed this amount of GPU can define for CPU memory, GPU, I guess limits if you create it in the order of the ratio in which most machines are whenever you're giving namespaces, given the order, the same ratio as the machines are configured. So that usually allows for more efficient utilization in most cases at least. That's what we used to do at Facebook to avoid that proportionate ratio balances. Right, got it. So we used to do that to make it more optimal. Like a few other questions that I had was one like you mentioned about, one is the research cluster, the other is the demo cluster. So the demo cluster, these people, the researchers just host these demos and is there a lot of resource consumption that happens there as well or is it mainly that is going into the search cluster? Probably I think less than 5% might go up. So that is not really anything to optimize at all. Right, yeah, most of the time we use only maybe one GPM to post a demo or something like that. Okay. But I think definitely there is more focus on applied research now. So I think we are going to host more and more demos, probably from 5% to 10%. Okay. Who are these demos exposed to? Like these are exposed to the end clients of Salesforce or is it for internal use case only? No, this is only for internal use cases only. Probably we integrate this with other clouds within salesforce, like maybe a service cloud or sales cloud. The client will be using this Sales product, but they use whatever the API they consume internally. These are never really exposed directly to the end client. For this demo they have to create a pod, a deployment, a service, all this tech. Right. How do they like you give them the template? No, for the demos. Right. We have a CSV pipeline. We are using Jenkins at the moment. So they just need to give the repo like whatever you are showing. So they just need to give the GitHub repo link in the Jenkins and then they can specify how much memory we have parameters configured there, like how many CPUs you need memory and you need GPS. You need whatever is in the docker file. You just build and run the command in the rocker file. That's right. Exactly. Okay, understood. And also of course the service even the exposing that demo to endpoint, exposing the end point, that is taken care by the denial server itself. We have predefined helm templates. So basically it will have a deployment ML and also the service YAML are also English YAML. So basically it will be using that. Understood. Cool. Yeah, I think that is all. Two. Other things I wanted to ask if we kind of as a startup think about hopefully working with salesforce in any capacity. Is there a potential thing that you see from this perspective of the research in front perspective like what direction we could potentially talk to say if we are talking to the folks here. Or. Do you think generally the systems are overall well sorted and generally hard to kind of just want to understand? Yeah, within salesforce I think to onboard there is a huge process, kind of process we have to go through. I think we need to definitely piece this idea. I think probably for your team. I think if the emphasis is more on cost optimization, I think that might be a good selling point. I guess the cost optimization is more on the cost optimization optimization side. Okay. Because visibility it seems you already have like a good. Actually. Thanks a lot. I really appreciate few more questions that I'll shoot over email but really helpful to kind of get the thank you so much. Thank you so much. Thank you, thank you.