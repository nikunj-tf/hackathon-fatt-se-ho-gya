Actually. Sure. On mute in case IBM audible. Yeah. You are audible? Yes. Oh, great. I just want just one quick question. Are you in India time zone? IBM in Sgt time zone. Okay. You're based out of Singapore? Yes. Right now I'm in Singapore. Generally, I'm based in Singapore. Okay. Yeah, I forgot to ask then this was scheduled and then since it was accepted, I thought it's good. Okay. Because I think Calendar talked about those open slots, right? Yeah. So basically just give me one moment. Okay. Just waiting for Abysheet to join. Sure. How you IBM? Good, how are you? Good. Ashes. You're based out of which place? Singapore. Okay. Yeah. Actually, IBM based on Goa, but yapunion Goa. But primary Goa. Basically, we started to go off started Go office like four months back. So we have already office in Mumbai Pune and now started in Goa. So I look after that office apart from other things. Yeah. Sounds like quite an interesting place to work from Asif. Yeah, it's a good place. Yeah, a good place. Absolutely. Good quality of life in general. Right. And good quality of food. We are struggling with traffic all day. Yeah. It restarted. Right? True. That is just to set context for this call, like Bothek and myself, be a cofounder. At co founder Simon Shu is another cofounder all of us. And we have been building in the machine learning space, making it easy for companies to do their deployments in a scalable way. So pretty much you can think of it like a platform that companies build customer development. We are making that easier for us by providing our platform on top of which companies can build further if they want to. And the stack is built on top of Kubernetes, so it supports cloud agnostic, use cases and so on. So with regards to that, I wanted to connect with regards to knowing about Turtlemint a little bit more in terms of what the use sales for ML, what is the current state of the ML, if there are challenges you're facing and any particular goals that you are trying to solve over the next few months right now. And then from there, I wanted to get into a few more questions and then take it from there to tell you more about how we are thinking. And there could be any way in which we could potentially partner. In the early stage of our journey, we are still building and developing, so we need people who have actually seen this genuine partner with us in terms of expecting value on where we can learn and show our product for this. Sure. I think glad to be connected. Absolutely. I think this envelopes as we know it, I mean, it's very crucial, critical, and lot is happening in the space, in the startup space as well. It's a pretty hot space for startup to be in. So I'll share, I think the question you asked where we are near term thing primarily I look at that function at Turtlemint and also I'll have a couple of questions because you mentioned it's committed, so I was just wondering, is it Kubeflow based? Is it based out of Kubeflow? No, it's not based on queue flow under the pipeline side of things. We currently don't do pipelines, but when we integrate pipelines like QFlow or Airflow or Prefect, one of these choices will go with or based on what customers need. So we'll go with one of those pipeline things, but not directly based on people. Got it. Okay, maybe I'm sure you'll have some way to present high level architecture or something, right? Whatever is presentable, what is best for it and we can take it there so quickly. One thing we didn't do is probably introductions, so maybe that we can do. This the first call. Not that we shane to complete this call, we'll have a subsequent call as well. Sure. I joined Turtlemint late last year through Equation, so my startup call Physics Systems got acquired better being in software product more than 20 plus years now worked with large enterprise as well as startup and their own startup. The startup I built before Turtlemint, Equation was primarily into cloud analytics space wherein we built a product to integrate data from any sources to any cloud of choice. So meaning for data scientists, data analyst who can use it, like to integrate it and then derive insights. So yeah, there's a choice of cloud, there's a choice of data at the source and it also does ML. You can do ML because it's a pipeline, right? You can do ML on top of the data, right? It was done. We used Gong for performance reason and that was a good journey, three plus years and then it was always a small team and then that got acquired along with IP and product by Turtlemint is often tech and before that it's large enterprise experience and some startup experience at Turtlemint primarily joined to start off data science, data engineering. So it's not that it's not there, it was there, data Science was little and Data Engineing was there to some extent. Of course we are primarily based on AWS stack, but we use a good amount of open source we built it not that everything is managed because it's cost effective as we know and build data science. We have a good data science team really coming from a good tier one colleges across India. And then Data Engine also is strengthened and plus also there's a limit of blockchain there, which is not relevant here, but that also exists. So that's what my focus is on. And in data science specifically, we are solving multiple problems, something like some straightforward problems using CV NLP, which are very straight forward. Right there you deal with really improving performance of the model. But then there are like some open problems around finance. It's a fintech company, right, is a fintech company primarily focusing on insure tech. So there are certain open problems also which are there, which are kind of business centric, highly aligned to business, but there is little ambiguity and then you try CTO kind of take it forward and solve it, right. Those things exist. Yeah. So Ben, primarily in terms of technology, it's pretty much statistical like in Data science, statistical things are there. Then the core ML algorithms are in picture, deep learning is in picture through Nlpcv reinforcement, something we already have Poland, pretty much everything exists and yeah, AWS shop pretty amazing things have come out. Primarily we are applied so that way a lot of things are getting into production which is happening. It's aligned to business, that's how it's aligned. The team is aligned. It's aligned to business, right? Yeah. And it's vertical, so it's meaningful interrogation and quickly for Turtlemint, as you might be Amar, it's a fintech, but the major focus is insurance. So that way it's insure tech but there's also element of investment through mutual fund. But that is like a small part. The majority focuses on insurance and primarily pioneered be to be insurance through agents. So there's a flagship app on Android place where you can find a call tournament pro using which the brokers can run their business. It pretty much helps you run your entire business. Right. A lot you can do, it has a miniate and all that exist actually on that platform. And then data science plays a role as to the priority standard problem site recommendation. Standard problem site recommendation using CDs are some of the standard problems as we know. And then there are certain newest problems which we are trying to also crack. So a few things she's like a quick introductions for me and I wish both of us patch Metro Mighty, but I wish he spent most of his time in Facebook in the US where he was kind of software engineer first and later on let the video team there. So spent six years there. I work with a hedge fund called World Fund first in India and then spent three years between US and Singapore. More on the finance side like doing portfolio optimization and so on. I actually met the founders of Turtlemint Payback so know them briefly, but it's great to see like the Turtlemint journey sitting up so well and it's becoming one of the largest ones in India. So that's great to see. Good to hear about portfolio optimization thing you mentioned. Yeah, just curious, did you use reinforcement learning by any chance? There not me, but there are few folks who are housing, so I was not using a lot of ML, IBM using Heuristic stuff, but people were using a lot of ML. Like there are few teams that were based on MLM. Got it. So few things you mentioned you are on AWS and you're using Kubernetes. Could you give a sense of what is the current team size overall and what is the data science team like, how big is the data science team? And then in that, how many models do you currently have for the different use cases that you mentioned? Like how many models do you have currently? And out of them, like, how many actually do you kind of end up deploying or is actually deployed? Yeah. So maybe I can't answer everything. I understand your intent and IBM absolutely supportive of the journey you're cracking into. Absolutely supportive of it. But then I can't share all data, so I please understand, but then absolutely benefiting this conversation. Absolutely, I'll do it. I think team wise is a smaller data science team in any organization. If you look at it, it's less than ten single digit. Okay. Mainly I focus on quality and quantity. I'm strong believer of it. It is there. Right? I mean, overall settlement, it's 2000 plus employees, right, out of which hardly 200 or 300 engineers. So you can understand it's close to a unicorn company. So that way you understand, right? I mean, basically then you can extrapolate data team will be like 15 plus. Not too much, not too big. It's very small but focused people working right combination of some seniors, junior, but yeah. And data science, if you look at it right, I mean, in fact a lot of people pick during college days now they get good hands on with being open source around it. So that way in the last year they have done a couple of internship project and they're really good at just that you need to go to right college, talk to them and I think that there's a good hit ratio. Yeah. My point was basically small team like Flipcard data science is a 50 year understand it's not too big given the Flip size of Flipkart. Right. So datta general data science or data team here? Data science, I mean both data science and arranging small, right? Yeah, that's how it is. I've heard some big companies also 20 plus in that range. Generally that's how it kind of if you Shane, a ballpark number right around that number, it will toggle I believe for postman also something like 2025 maybe. I think that's how it is. But yeah, generally that's how it is. And in terms of model thing. So. Yeah, model is like I mean, basically the idea has been applied like you shane applied. It not on the paper though. I know that you can write papers on XIV like Arcs IV and all that, right. But yeah, it's like the emphasis has been on putting moderate in production, which we have been doing generally as a company. We are KT, right? So like services are deployed using KTS EKS, either managed or managed both for the same thing applies to machine learning. So basically we deploy services using gets deployed on pods and you can scale them then, right? So that thing is in picture and then that's how through Japan gets into production, right? So those things exist, right? And then there's a backing data pipeline, right, all that exists. Right. So you are applying on Caters properly few companies. Okay, yeah, maybe that's I think somewhere technology based accordingly companies can make a choice. But Katie is obviously as we know, Katie is very important and that is like a building block, right? A very asif building block of deploying a service sep. The thing would be at juncture of a company typically they could just do solve business problem. Let's not worry about scaling using KTS which is fair, right? And I've heard this also in some good talks they don't care, they use PHP only and they just remain on PHP for many years. Do we know we cloud counter question, right? But yeah, that still could be existing. Data scientists in Kia requires learning curve of writing Amar and things like that. How is that process today? Like a data scientist deploying or they hand over the code to ML engineers and then they take over. So data scientists is data scientists as we know right, they will come from maybe non CS background, I have it and they don't understand as we see soft changing like you worked at Facebook Meta, there's an element of software engineering also, right, which they don't really understand well. So that way they are not the one responsible of course, but then it's like combination of density or maybe SRE site relevant engineering what Google calls right? It could be combination. So SRE team could sep up the general infrastructure, right, or guideline but I would say deranging team is well positioned to handle it. At my level, I have seen both worlds. So the way I put it is Datta engineering is centric, right? And of course it has a bit of analytics as well, but not a good amount of analytics involved. But then there's and on the other side is data scientist primarily on modeling and then there can be a messaging in between, right? It's a fusion of understanding and structure and then understanding some email modeling so that's where you can think about it and then the rules will evolve in that line. But you cannot expect data scientists to be writing YAML soumen maybe not who could make the cut? Not necessarily make the cut and I don't think you need to go that far to make that cut, right? Rather they beyond data side, there are a lot of other challenges exist in terms of ambiguity and cracking it. So to answer the Datta center, not so much it is on data engineering side. Is it mostly batch infrastructure like the handling? Or do you also do real time. Both inline and batch both? Not on the Android, not on the end device yet. That could happen with optimized modeling, but not yet. But we'll get there. Yes, understood cool ashes and the development as of now data scientists use do you use anything like Sage Maker or purely a covenant shop? Not yet sage Maker it was tried and then it will be because AWS is not preferred but it's a vendor where it's hosted and sales maker and maybe combination of ML flow you can think cloud can be one way. I would like to see pro founded definitely the offering and how do you differentiate or maybe what is it and what's your roadmap? Definitely you would like to hear but yeah. I mean Sage Maker is something because it's like off the shelf you can quickly try it out but Kubeflow we are aware of QFlow it is more data engineering centric and data science centric correct and then there take a note of other new age I'm sure you must be tracking take a note of new age players which have come one or two more promising rate which has come in this field. Yeah, those exist but that's like open source and then there you basically see a team as you know right? A team backing it team who is there to do that? I think that's what matters cloud France startup and who are the people behind it and then that's how you make the cutout, make it easy to try it out and go forward. I have one question actually assist you like in the current like real time as it is badge that you're doing are you actually seeing any problems that the team is facing? Like yeah. Not today because it's like frequency is good but then generally as we know right as we move along this line. I think Chris ML observability will play a crucial role as things move along as we know right ML ops and there are a variety of ways CTO solve it today there's one a method but it can be more of a security method as we move on because that will be required not now but maybe after three months. Six months down the line right those things will become start becoming not operationalizing. Let's not call operationalizing is not a big challenging thing but yeah, general observability of I think you might have seen Aria, right? It's also one of the big competing thing in this piece they have X AI offering, they call them observability but yeah, that's something you can have a look at it that's also something interesting but then yeah, generally as you grow, as we know standards are standard in them it's like a function of data. There are ways in which you can at least still manage it by building model or maybe there are ways to actually handle it so that you don't go really off track. There are ways to do it right, I mean that we can do but generally as you take it to the next level, definitely these tools will become important which can provide a middle observability in terms of drift happening or maybe drift happening in terms of giving feedback. Correct. Those things, they will become important and then like a sophisticated tool could be helpful. Right. I'm not saying something new here. We know about this already. Right, got it. No, I totally understand that. Basically the question we are trying to ask is, is there something that already is say a problem you are already seeing where maybe you are already looking for some results? Is it more like okay, more from a scaling perspective and more from a longer term perspective that you feel that a tool like an ML of integrated thing will be used? Both. I would say both. Like I won't allow something like sophisticated. Yeah, it's like new tools to try out. Because that definitely exists. That not exist and that will happen. But yeah, and then long term also both things are existing because we can't claim right. I mean IBM successful with ML model. Okay, it's not that, right? Basically, I mean, how long it's like duration. Right? So to see it in action for long duration, of course, that's how we are seeing it. And we are making it applicable directly in the product. But then generally over time you observe. It's not like one of one month, two months, it's like over time or six months, one year you observe. Right. And then only you will know a lot of these things with data. Okay. I wouldn't just put it like a futuristic only let's not make that statement right now. Yeah, it will be like you existing also. Absolutely. Why not? Cool. Do you have more questions? Otherwise maybe might be useful is just to give a session overview. I can maybe start with a high level overview. Surge Week we can start with actually we'd love to first try to tell you what we are trying to build. Surge Week. Love to hear your general feedback in general domain and what have you seen and how do you think it can be useful or how it can add value. Since we have seen basically the whole end is like I saw pretty advanced systems and I was at Facebook. Every engineer was fully empowered to take the whole project to delivery and show the impact. And if it doesn't show an impact, the project, everybody has autonomy in the system. And while it is completely secure, it's not that I can go there are systems in place that prevent me from doing bad stuff or big systems. But there is enough autonomy that I have. And when I came outside, like I was dealing with cloud and all those things, I felt like it took me like five days to do the thing that took me 10 minutes back in Facebook just because the platform was so soft. And that's the value we wanted to create. That every company should have access to that advanced infrared that you can just go CTO things in 5 minutes and then focus on the business logic rather than focusing on Op stuff. That's the mission with which we started. Ashish and I really want to give that experience. So would love to help us. If you can help us get in that mission and deliver that to the world that would be really cool. Sure, absolutely. Yeah. Okay awesome. When you started just quickly if you want to share or maybe you're going to cover this like when you started off and where you are in the journey and maybe that will be helpful. Okay, sure, I can do that. So basically we started around October last year. It's roughly twelve months since we started, but a few months I spent just talking to we talked to 120 different companies globally of different shapes and sizes to understanding the Shane, the kind of challenges that they face in their ML journey. So that combined with what we have seen at Facebook as a part of the platform that they have led us into kind of building that okay. This is what we want to build from a deployment platform perspective that should be able to support a company in its earlier stages but at the same time be able to provide all the toolkits that are needed as the company's sales and go through multiple use cases as you are mentioning multiple use cases of ML like bad use cases. Real time deep learning models and so on. So as you evolve, I'm sure you do not want revamping your entire. Inter. One thing will be generally you see this happening more and more like Kate has not seen much option. Then maybe it will become mainstream based on the nature of company, a person who is driving it, right. It also matters. But then generally like we see AI at the back playing role enabling as a secondary use case or as a secondary like we used to say data secondary storage or secondary use cases. Not like OLTP use case primary and the data path. Something similar AI like AI helping business from back but then they'll become front also. That will happen. You are driving through AI more and more so it becomes a driver's seat. That also will happen with more and more it as we move along in the next few years. So that way it's highly relevant. Yeah, sorry, please go ahead. Once a high level overview Ashish and then also dive into specific use cases that relate to deployment just to kind of align us to what we are building in the code and why IBM happy to answer questions along the way. Sure. So first like just an overview. If you look at the ML workflow, this is what it consists of pretty much data gathering, analysis, feature engineering. Then you train your model two serving model monitoring and then you would want a loop that is completely automated where the feedback from one thing is flowing into your retraining pipelines and accordingly deploying new models at the same time. So from a perspective of two foundry we majorly focus on the model serving infrastructure along with enabling, monitoring, automated for you so that you don't have to worry about it. So this is the part that we focus on. We do not necessarily build on this part of infrastructure initially so the core things that we try to address is to ensure that models go into production in a fast way. So instead of saying that companies say it can be faster and at the same time to enable that the experience of the developers would be comparatively fast as well. And the most important thing is like specialty for companies of the type of settlement like as you scaler as your number of models go up, as there is more scaling required all those practices are tied there in the system from the get cook. So this around the principles around scalabilities and stability is something that we have tried to build into the platform, right? A lot of these companies like Facebook, Google invest into platforms to help them leverage HML and our goal is to kind of enable that. So if you look at the team. The team consists of like me. Nikunjabishek and then there are other members from companies like Amazon. Project Reserve Postman. Some who have seen the system that the company and some also from the software engineering and then soft perspective and taking that into account. We have been trying to build this. So primarily based in Bangalore and so. US headquarters so someone works from us. Or like in the yes. Then one of our team members is also in Paris but the rest of. The team is majorly in India and all the KGB. Yes. Okay, got it. And you're the three founders yes and you started last year. If I may ask, are you funded or how is it like yeah, so. We actually are funded by Sequoiacap and we also have a US investor called ENIAC and then Anthony Goldbung is the founder of Cagel and a few other anil investors are there in the journey as well. Okay. So basically just wanted to kind of mention this. Right that the code design principles around which we have built we ensure that we use Git wherever possible. Ensure complete reproducibility of things. We try to make it self serve for data scientists and MLS to be able to do most things but in companies where there is a workflow that DevOps is doing we completely support that entire thing takes care of access control and logging so that this becomes a specific point when you go at the company said and this is taken into account. Everything is API driven the infrastructure we Shane tried to build in a reliable way and we use cube and it said and we also try to optimize for the cost by giving you insights around that so that as you scale you are able to actually take the right distance to enable you to lower cost. Got it? Yeah. Right now just taking it at a high level is the system. The major part of the system as we said is built on top of Kubernetes on the back pendo like it uses different things like the form for infrastructure code integrates with the CI CD pipeline that you are running on and exposes a layer for the DevOps to be able to see all the models. Be able to manage the access control and resources for the team and so on like the entire deployment happens like for everything we have built it supports both the YAML way as well as the Pythonic way so depending on who in the team is using it like the infrastructure supports both. But the second thing is a Pythonic or Python. Python. Okay, so you mean directly from Jupiter's, not book you can deploy? Yes. Have you developed some rapper on Jupiter's notebook to deploy or like some commands too or you call local command something, you install a package and do it. You install a package and do it. Okay. And that you call the command from the Jupiter and it deploys it basically. You can think of it as the Python code generates the YAML so you don't need to understand how to write YAML. It doesn't know how to write YAML. Right. Understand? Python So it's like you do Python, you write Python API behind the word generates the ML centre CTO cooperate datta. Centers is IBM writing in Jupyter book my model and my model is written I have used standard libraries right in jupyter and now you tal about you focus on two things serving and monitoring. The intent is to now deploy, I'm sure a little bit angle of deployment in a pod and expose the endpoint right to serve right through your code, right? Right, is that right? So then as a data scientist, once I'm done writing model, I'll call some commands to deploy maybe one or two commands to deploy it to production. Is that how it is? Yes. Okay, correct. Okay. Once I've written the model, tested it, everything is done. My model is good to be deployed to staging for example. Correct. Then you just call what one specific command which will be like from your package which will actually take care of model which is built and then put it to the endpoint server and expose it or something like that. We basically build we generate the docker file for you, build the docker image, we automatically push it to Kubernetes and we get the endpoint. So all that is automated. So data science does not need to learn anything they'll just do this one command and the end point is up and again the staging environment they can quickly share with the back end team that they can start integrating and do much faster rather than bring. Three teams in the middle. Okay, and what kind of model, what's the artifact like for you to start creating a docker image, like any restriction on the model, because the model can ben done in a variety of forms. So we support all the standard types, like TensorFlow, Pythons, Xboost, those standards are supported. If you need a custom preprocessing logic, you pretty much write a predic function in Python and you just tell us that this is my function that netmeds to be deployed. And then we will do everything around it. Like we take the requirements that we see whatever is in your current machine in the repeated notebook, whatever dependencies are installed, we automatically take those versions. We automatically pass that and your code to the docker file and we generate the docker file and build an image and everything. So if it runs locally, we make sure that you're done on the server, that's the value prop, basically. Okay? And locally the user generally my user will be running only a plain jupyter or there's no collab point here, right? I have to be on my own. Local Jupiter, any Jupiter node, it can be collaborative collaborable, right. Even if it's collab Google account, it's all still it'll work. But then on that server you need to have your package installed, which will package it. But that is as simple as. You have a package Python package. It's a prerequisite for doing it and that you represent. After I'm done, at the end, I'll call that command something I call some CLI of you. Okay? Also, it's a python. You can do a CLI also service fontployee, or you can do package service fontry, which can ben servicefunded deploy in Python. Okay. The functions I can call and then it gets executed. It will deploy it. And how do I know it is deployed? Or like some status UI and everything. That will show you, even the command will then deploy, takes some time. We are building the image, so we stream the logs. You can sep the locks. There is a UI also will show that it's currently building and when it finishes, you. Got it? Understood. So that's a deployment part and that it gets exposed as a rest API in point. Correct. Okay. We have democracy that we can show. You sure you're not using scaler or anything here. We will use sales under the hood. But CASER will only do there's a problem with sales. CASER will do like okay, if I have a standard TensorFlow model or those things, those will go. But there is any pre processing logic you need or post processing logic you need, you have to deploy them as again separate services. So one model becomes three microservices. One is a free processing service, one is a model server, and one is the post processing service. Right. So data scientist has now write three docker files and all that stuff. It becomes very complicated that way. Right. Okay. Are you just curious and maybe something important? Are you contrary into queueflow? We don't contribute to QFlow, but we do contribute to casers. Okay. Because sales is the component that we really kick. Flow is a pipeline sep of things. I meant entire thing. I meant all those three, four things which comes along with QFlow, the completing rate. I mean, they have multiple offerings. When you open the UI UI, right. Kisser is there. And then there is a katib is there. It's not easy to use. I mean, even for India people, it's actually quite complicated. We're trying to make it like data scientists will never be able to like it's very difficult to understand. Yeah, I understand. It's like a system person or people who have done data infrastructure, they will understand. This. Goes so deep into covenant's concept that you really need to understanding the space. Be able to use case, sir. Correct. Yeah. Do you have anyone in your team working who has worked at Google? No, not at Google. I would suggest get feedback through whatever channel you can. I'm surge week KGB so you can get or maybe I think the person sitting in US. Ask him. Good. To get data on the queue flow side of ecosystem. Right. A lot of check ins have stalled. It is not going it's not going well. Of course, Google understanding the space. That's why they have vertex here. That's how they are looking to get money. Right. Which is not wrong. But then because their child which became such a big thing. Normally Google is famous for it building technology. My point was good to hear that you are contributing. That's why I asked that question. But also be vigilant and watchful about these data points. Okay? Right. Because ultimately it's like this. You should own it. Then. Strong dependency is KS. So that is a strong dependency. Not a strong dependency of us. Because we phone conference server also. We use a certain ML server also behind the hood. So it's basically Ben ML servers. Everybody's pushing like free opens. And there's a new ML open source server coming every day. Yeah, we just find the best option for the user. And what do you support them today for ML serving? ML serving, like right today, if you ask me. We have the simple parts API thing that you San Jose, your model in this fast API. That option is there that we've already done. The model server part is what you're working on that you bring a TensorFlow model. We suggest that. Okay. What is the traffic? Whether you should choose triton or you should choose TensorFlow server. These are the two options on TensorFlow. So, basically, every framework has like a couple of model serving options and it changes. So, for example, triton only supports TensorFlow and Pythons. Not exe boost, not. Do you plan to open source? Maybe too early to ask. I don't know. But you have thoughts open source. I have thought yes, we're not against open sourcing. At some point we might ashish. That is a decision we still need to take for the initial company we are working with. At least we tell that the whole board will be available to you. That is not a problem. And you have both SaaS and hosted. Model, yeah, yes, right. Because that's okay. You can take the binaries and you can deploy not on your cloud but on the customers cloud, correct, exactly. Okay. What would be is doing it in your cloud very important to you? That is something which is very tricky thing. I understand data is critical, right? I mean, like when you do with ML ops, I mean just think about it. Data going to other cloud sensitive data. Third cloud we don't know here I think one cloud is okay. Third cloud we don't know. We all talk about Pi and like all these things happen, right? And then you script is like a model and the data will be of course available to model it. So I think it's understand the point from your side as well. But maybe I shane to live with both. There'll be customers who like small to medium size. I don't want I can afford to take a risk because I want to get to introductions like cloud usage. Right. And there'll be someone like CDs will not go to public. It's not right. It's not required really? AWS within that cloud is okay. Because of things are governed by that law rules and all that people understand there all those things are you got it? Any extra data is trickier, right? Egress is one, but security will be most number zero, I would say Egress of course cost is critical, but then security will be number zero item. Right? Because IBM not saying it will never happen. I'm not saying that, but yeah, I mean it's a journey, right? So it will be hosted. It should be like you take the bits, take the bits and then deploy it and then it's like you install it on premise and then you control. Of course there'll be some cookbook, you'll do it, get book something but you'd say these are things to do and then they will happen. Of course you'll have some UI to visualize things, right? Correct. I saw things somewhere lafana, you talked about something. There are some UI to visualize what's happening, right? Yes. So actually not able to cover it. Do you have more time or do you want to kind of schedule another? Maybe we can take to a logical conclusion because definitely we can schedule one more sep what will be required at least a good idea, right? I mean, because let's take it to a logical checkpoint in the sense that maybe we can spend five more minutes easily. But if you can tell we talked about where you are at what stage you are in. Okay, I'll just maybe quickly walk you. Through a few things, right? Like just where we are. So basically as I was saying that the model deployment is one of the major parts and then it comes with model monitoring and you kind of scale and you need things like traffic splitting that is kind of also supported here. Okay then just wanted to use one. More thing, model monitoring. How do you monitor model? What is used for monitoring model? How do I monitor the model here. When you say how do you monitor basically what we do is we kind of do both system level metrics as well as the ML level metric. So in system level it's more like resources monitoring and so on. And in ML monitoring it's basically your data drift, you data set featured drift and kind of null data sets, performance of the models and so on. How do you visualize this? You have your own we have our. Own UI like something around Chris. So you'll have a Tal where you'll see model. Okay. And then it'll kind of show alerts as well. So it will actually send you alerts on Gmail back and if you're using pager duty then we can integrate with that. And what alerts are supported like key. Alerts you can mark if your water drifted greater than some threshold, if some features drifted greater than some threshold, if some data Renault values percentage is greater than some threshold, quarter accuracy is dropped below 90% configurable alerts. Okay. And this is available today? Yes. Okay, so you talked about serving we talked about that flow, right. You can do it through command line that is there. And then the other thing you talked about was monitoring, right? So that both things are available. Yes, in serving, like basically some of the things are in the process of build out. Like for example Chris Shadow trafficking thing is yet to be built out. But yes, suppose you have a cluster, then we can ship it CPower Helenstart today you actually just install it on your cloud and then you can connect it with the cluster and post that whatever models you are deploying, if you want to create different environments, say test environment, production environment within that, you can do that. Someone can do that. It will allow control of it and the data scientists can say deploy and point to a test environment and then we want to move to production environment that whoever in the team is deploying. They can do it in the production environment. And this is supported for both realtime as well as batch use cases. So suppose it's a training job also they can actually deploy a training job if it's just a batch use case. You want to kind of run a model and dump it to a database and then read from that. That can be done. And as you do this it will connect to the monitoring, it will start. Showing so regarding this monitoring, you talked about the alert, right? So there will be a way to set the alerts, the example Abject talked about. And once you have a breach, then you learn notification. Then can you act on its example, then retrieving the model building again so. That happens that we have two we are building on. So I'll show you once on the feedback loop. So this retraining pipeline. So basically you can write a pipeline that you keep checking, that you can execute every day. Check the drifter than the grip, then go and train the model, deploy the model. And if you write it where you write it, this is like so this. Is the pipelines part. That is, you don't have the pipelines part yet, that you have a series of tasks and then you execute one after the other. But we'll ben building the pipeline. If you have any pipeline system, I'm guessing you have data integrity. So they must use something like airflow or correct? Yeah, those things are standard. Just write in a simple airflow script. That will do it. You already provide the case for you have a hook, right, wherein this is breached. And so invoke this job right, or whatever it is, you can give us. A web book to invoke. So you can deploy a quick service using our platform again that we can invoke whenever there is there. And the moment Chris is invoked, you can model and provide again. Okay, so till the popeye is there, you're saying you have a web book? Yes, we can fire a web. Yeah, exactly. It's like a Poland doing lambda. Right. And then event driven. That's what I asked. Like you should have event driven because you know something got breached. Yes, you will have a level of tolerance site and all that and you invoke web and that you can then write it code to retrain if required, for example. Yes, exactly. So that's very custom. So we vivek it to the clients, what they want to do on that. And how do you go about it serving exist, monitoring exist, and then there's a basic way to trigger the trigger. That's the housing. Right. And then you said one year you've been doing this. Any deployment like beta, alpha or someone using, I'm sure they'll ben. Yeah. So there are three companies ashes that we are working with. Two of them are using the deployment piece as a POC. One of them is starting to use the monitoring piece as well. And then there are a few individual users as well who are doing the deployments, like simple deployments on the small public version that we had launched out. But we have shifted focus to company side because that is where we see value majority. So that also allows us to build the platform better because the use cases in individual cases, Qovery use cases. So in a company site like the use cases are better so we are working with teams that are actually in the journey where they feel that over a period of time they will need this platform so we can get them started instantly. Even your deployed services can be very easily migrated on top of your own cloud and then as in when your features and even if you need some custom features, we have built it for some companies. Like this monitoring alerts thing was built based on demand of one of the companies. The pipeline thing we have added to the roadmap because of the demand from one company. So we are actually working with companies in the early like basically who can also help us in terms of knowing their features. So people who want to have a longer term stable platform, we kind of hear their things and we can continue CTO build out along with shipping out our platform. So that's the Shane where we are in. What is the language you use to code the platform? Like, I'm sure Python is one and it's an open source tool which uses KTM is okay, data form is okay. But then any specific other languages which are used from performance point of view. All these TF seven plus plus so that is standard we use our platform does not come in the it's not that same models are running on our code. We are doing the party deployment that is written in TypeScript. That part actually doesn't need to be performance because they're basically just handing it over to KX to do the actual deployment. Okay. Yeah, about model drift also that is okay. Deployment is okay. Like. Modern depth is also we capture the metric like you log the metrics we capture and then it's mostly data engineering where we go over the metrics. And see which ones are almost near real time, right? Yes, that is based on the SLA you will do it right and then that also is like scripted. You mean then because yeah, as of. Now we do every half an hour. She's like we don't have any use case where people need that okay. Drift is because you need half an hour to analyze. Also if drift is happening right because you collect over the last 30 minutes, even 30 minutes is less in some cases people want to do because soumen people have spikes every afternoon, like doing sweet they never order the place in afternoon spikes. So they want to do it on a daily basis. Some people even want to do it on a weekly basis. The last week, my model so we have not encountered many use cases when people really need it to be like that means there's a drift Qovery second or every minute. Yeah, that's okay. I agree. Correct in those cases also based on the problem we're solving, there are ways to analyze it even if I can afford to a false negative, it's stated right? Those things are already upfront stated right. That way those things are always in picture like credit card fraud or maybe the transaction fraud. I mean, those kinds of things. Okay, so, yeah, I think that's a good information. I think almost out of time. I need to get to other meetings. But yeah, maybe we can have follow up. Absolutely. But what could be covered? Like some tech vivek could be covered as appropriate. What you can share? I got a highly good idea. I mean, definitely it helped where you play role, what you're understood. We can go like the platform overview right now. We just showed you high level from the site, so we can actually show you how the screen that will give you more context as Chris and then we can cover some part of the technical overview, basically. What do you want to cover basically in the technical? Yeah, basically understood. It's a big area. Right. You talked about your focus area that I got it serving monitoring and also there was I thought there's no feedback, but there's an element of feedback which is critical actually. So that exists as basically talked about. Right. And maybe a little bit more in terms of I think we started doing what kind of drips you can have. Right. I mean, some of these things are maybe in chad of how can you visualize what you can get and maybe if you have some thoughts in terms of issued pipeline, what are your next road map you're building on. Maybe those things also become very critical right. For these things. Right. What you have today, basically what you can use out of the box. And then what we are building next three months, six months that will be useful to share, which I believe will be useful. Changes will be useful. Right, of course. To know how you're headed. Right, that makes sense. Okay, perfect. Maybe I'll see if I can pull in maybe a senior person or so to give feedback and share thoughts. Okay, that will be good. I cloud love to kind of focus you and what I understand you actually do want something where you can play, at least where you can experiment and see which platform could work well so we can showcase you and if it in any ways seems like something you'd like to do a POC with, something like happy to support anything there CTO make that happen. Yeah, absolutely. It's a huge area. It's like a big area. There's a variety of it. Also this being a fusion of data science and system engineer, not many people know about it properly. Also you understood right now you're building it for data science, which totally makes sense because you don't need to know what is KT and what is it. I mean, I also talked to them. Absolutely. I don't expect a lot on Pod and storage and PVC and don't need to know about it. We know underneath these things are required I mean how do you store it? How do you access when you deploy it? What are the privilege? What is the IBM role you're giving? Right? What is the inderjeet storage you're using that way PVC everything really becomes meaningful, right? But you hide those things right as you move on that way it's a big area, huge area. Good that you are focused that you are focused on the strict thing. But that's the way startups should be. Ruthless notation. When do you want to connect us? I think next week sometime next week will work. Tuesday, Wednesday, something like that. Tuesday, Wednesday let's see we can catch up but let's do it sometime next week. Yeah, that is fine. Wednesday, something like that. What time? Afternoon should be okay, we might change it a little bit here and there but maybe three to four, something like that. Okay, I'll put it then for three to four. Okay, thanks. If you have any sample models data critical, nothing is you private data. If you have some use case I would love to see how quickly we can deploy it on our system. Okay, you mean like the given model is given that far we can't go until there's lot of NDA and all that things like the other company not in this space for the discussion. I think everywhere that will come, right? I mean you cannot see this is like discussion of course it's right. I mean I'm supportive of startups. Absolutely. We are also people like people in the startup they understand it so they are supportive but generally as you know see this insurance finance is a highly regulated field compiled also that way a lot is regulated right and generally it will be like that right. We discussed of course in the right but then when you get to next level of engagement there'll be NDA something with that will come CTO me without that you can always do the next step. It will ben good to keep it whatever appropriate you feel like sharing which can benefit and give roadmap idea and these are things which value which you can get. Okay. I would suggest also I'm sure you must have done it maybe you can do some moon charting right when you compare you with competition, right? Not now. Maybe someone who is handling product can do it. It will be helpful as you move along those things will be important as you move along slowly, slowly in parallel that kind of gives you comparison for now I know like three experience ML Flow, Kubeflow, Sage Maker what it can be somewhere those things are known. Right but generally that will be helpful as you build it because anyway you focus on your part that's your strength and there you can create a try to differentiate. Yeah, right, but yeah, I think let's take it that route because then it's like then there's a second out right of IP and EA all that right. Which will come into picture which you can bypass, which is very fair actually. Any discussion of that sort will go through that route which is mutually beneficial, by the way. Right, that is definitely okay. Yeah. Like the way I said I talked about initially the bigger of the kind of problems you're solving so that I think gives idea about kind of problem right. I mean being sold so I can talk some of the problems as well again but I think that gives definitely good idea as to what is in each of the problem because we know you also know right. It's a competition problem, you know, what is it doing and what it could be doing. A problem like OCR, we know what kind of things it can solve for. Right. Okay, awesome. Thank you so much. I just really appreciate an invite also and we'll look at some of this. Bye.