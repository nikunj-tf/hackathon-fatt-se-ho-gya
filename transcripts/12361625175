Thank you. Hello. Hello. Hey. Hi. How are you, Peter? I'm doing good, thank you. How about you? I'm good. How do you pronounce your name? I just want to be sure that. Well, it's going to be easier if you use English versions, Peter, so I think it's much easier. Yeah. Okay, got it. Cool. Hey, Peter. So first of all, thanks a lot for the call. What I wanted to do on this call was we have been talking to Novartis, we talked to who is the director of AI and wanted to get some more insights around the need for multicloud at Novartis. What are the challenges there and things like that. Also understand the workflow from a perspective of TML engineer, like the hands on side of the things as well. So that is the primary goal. What we can do is maybe we can quickly start with a brief introduction and I can tell you a little bit about us and then would love to hear about you and then take it from there. Does that sound good? Yeah, sure. Sounds good. Okay, cool. So I'm one of the co founders at Truefoundry. Truefoundry is a company that we started one and a half years ago, along with my two other co founders, nikunjana Vishik, and we have been building for one and a half year now. The primary goal is to enable companies that are on multi cloud architecture to build good, flexible, machine learning deployment platform on top of that and solve for other parts or pieces of the problem that comes with deployment, which could be related to security, authentication, supporting different types of models, training, managing cloud costs and things like that. So that is where primarily our focus has been fitted. And while we are kind of talking and working with a few of the enterprise companies, we are trying to enhance our knowledge in the multi cloud space and trying to understand more about what companies are doing to kind of solve for multicloud challenges. Why are they even going towards that and what impact does it have from a developer perspective? Right, so that's primarily a quick deep. Right now we are working with around three enterprise companies, similar sizes as yours, and have a few pilots that are also on way. So I wanted to take this call to kind of understand more about the ML at Novartis. A big background about myself. I used to work with a hedge fund called WorldPoint, which is an asset management firm based out of us. Built a lot of trading strategies, they are using a lot of data and then did portfolio management for them as well. Then left my job, started my first startup in the talent space, sold it to Info Edge, which is a talent company, big talent company in India. And then we started cook. Truefoundry. Vishek and Nikkun were both at Facebook, where they built software and infrastructure systems for ML. So they bring a lot of experience on the AI side and Shinma is a part of the product function, looking after how our product will shape as well. Hi Bridge, nice to meet you. Yeah, likewise, nice to meet you. Okay, so I can tell a little bit about myself. So character work as an emloss engineer in Novartis, as you know, and previously I had been working for several years in banking industry mostly, but also in another pharma company, Roche, which is one of the Novartis competitors in pharma industry. So I know pretty much quite well the problems of such big companies. From the technical perspective, our solutions I would say are not super sophisticated. So I work mainly with AWS solutions. My job is basically to deploy the code to build CI CD pipelines as well as to orchestrate something like using, for example, Step Functional AWS. So from technical perspective, it's navigate superpency. We don't build like it's not a tech company, so we basically operate on some sales data in order to predict something like time series predictions and stuff like that. We don't use like at least I don't know nothing about it. We don't build any big deep learning models for computer revision, for NLP and something like that. From technical perspective, it's not complicated but well, when it comes to the challenges, I would say the challenges are exactly the same as in the all big companies I have been working with. So basically we are using different tools and different teams are responsible for each tool or each tool set. And then the problem is usually when you need to orchestra something because the responsibility is shared across multiple teams and if you want to aggregate something like use several data sources, you need to find proper people, ask for permissions and so on and so forth. There is no like a single hub when you can see the whole tool set or the available solutions. And sometimes different teams build exactly the same thing in parallel because they don't know that someone else is building that at the same time. That's the main challenge, I would say, at least for me, because. Peter, I have a few things it'll be great to kind of understand a little bit like you are an ML engineer. How many ML engineers work closely with you and is there like an organization or a function that you are serving? Like you said, you work with AWS Solutions, but is there like a business or that you are particularly kind of reporting to? Who ultimately do you kind of what is the organizational structure like for you? As I said, it's very complex. So I work with several different teams, I cooperate closely, mostly with two ML engineers, but also with around ten software engineers and probably 20 data scientists, plus 20 or more people responsible for different kinds of architectural permissions. It's at least 100 people. That's why I said it's challenging sometimes. To find personnel platform team or how does it work? Is there like a central platform team or every use case or a business unit has like a separate platform team or MLPs team? When it comes to envelopes, probably different team when it comes to platform, I guess probably as well. Well, I'm quite sure that it's like that because I've seen in different projects some completely different tool sets. So there is no orchestration between. So the tool set I have and maybe the solutions I'm building right now are being developed in parallel by different inputs in different ways. So we don't share, let's say, code or solutions across departments, at least I'm not aware of it. Got it. It might change. So it heavily depends on the department you are talking to because in different department they might have completely different tools, completely different challenges. It's a huge company. So probably which you belong to, Peter, maybe is there like a marketing organization or is it like, say a drug discovery or is it like the precision medicine or is there a particular department that you are aware that you fall under? Well, I cooperate mostly with finance department, but I'm an external contractor, so when it comes to my department, it's completely different than there. But I support mainly finance, one of the finance teams because it's your team. So, as I said, mainly time series predictions and things like that, that's what we have. But yeah, when it comes to drug discovery, I don't even know where they located. Got it. Understood. So one question I have, Peter, is when we were looking at the JDS and also when we talked to we know who kind of leads the strategy for A. Like he was mentioning that you all use both AWS and SEO. And in the GDS, we saw that the ML engineer position, there's a requirement to kind of understand Kubernetes. So when you say you work with AWS solutions, do you kind of ultimately take your models that are being built and deploy on top of EKS and that is where you kind of build the orchestration thing? Or is it like royal? Personally, I don't have admin access to EKS. I know there is an EKS cluster, probably a lot of them, but for some reason someone said that I should not build PKS cluster for our purposes. No one knows why, but it was set. And personally, I'm using Sage Maker jobs, mostly lambda functions, ECS as well, but we don't deploy into ETS. But I know there is an ETF cluster, very big one, but I have no idea what's there. So if they want ML engineer, if you it's absolutely possible. However, as I said, probably there are like hundred or more ML engineers like me, but I don't know them. Okay, very interesting. Are you aware of internally, like, say the other engineers, do other people also end up using Sage Maker quite a bit or like the rest of the company at least there are many things they use more of, say AKS or AKS. Do you have a sense there? Probably they use everything. That's my guess. Okay. As I said, we don't share the solutions between departments. So definitely they use ETS. Some people use ETS, sage maker everything. So the tool set is somehow defined by department, but usually it's arbitrary decision. I would say somewhat selected a tool set. And just to be consistent, we use the same tool set. It doesn't mean that it's the best tool set. For example, I would choose for a particular use case, but just to keep in line those solutions. We use the same tools, but it's always like that in big companies. Understood. Just trying to understand. Peter, you mentioned that there are redundancies that get created because different teams work in Silos. We also understand there is the central data science effort being made to have a uniform platform and like a uniform repository of all the things. Are you aware of that initiative and do you see it solving this problem of redundancy? Or do you think it's fine to use different tools and different teams? Well, it's the first time I hear about it. It would probably help to some extent, but as I said, I'm not aware of it. So I don't think it's like for the whole company. Maybe it's for a few teams, but definitely not for the whole Novartis. I don't expect that. Got it. Peter, just trying to understand, in your interaction with the MLE, what point is the model deployment and productionization the responsibility of MLE's? And when does the DevOps team or the ML Ops team take over? Like, do they give you the bare code? The model file docker is containers. And where do you. My responsibility starts from code repository, data science code. They test it on their environment, they push it to repository. And from that point I take it. You kind of take the code that is there and then you kind of deploy it completely. Are there real time models also that you are deploying currently or is it mostly batch models? Yeah, currently I have mostly, as I said, time series prediction. So those are the batch models that you need to predict like monthly, weekly or something? There are some plans about real time models as well, but I don't know many people. At least most of these models that you work on with the finance team, they would be used for an internal consumption. Right? And not like serving in an app or something which is like externally facing? No, those are like some confidential data. So we need just that predictions and somewhere to business people. Understood. And do most of the models get deployed? Like you was explicitly with AWS, right? So internal functions are through AWS. Is it that internal functions like what do you mean exactly? The cloud that is used by the different teams is internally AWS the cloud of choice. Or you also do like something like on Prem or something because you said the data is confidential. Well, no data are confidential, but it's not like top secret. But those are like some sales data. So they are confidential, but not such confidential that access is very limited. So we use cloud mostly. Personally, I don't use anything on Prem, but it doesn't mean that no one does it because I don't know exact structure, because we have a kind of hybrid cloud, so we have some local DNS server as well. So there are different types of connection with WS. Sometimes if I connect to something, I don't really know if it works on EC two or it works on some on premise server. And then the other members that you work with that you mentioned two to three ML engineers, like do they also use Sage Maker jobs or do they use something else? Yeah, those are people like those that work with me, so we use the same tools. Okay. Is there any challenge that you are seeing in the overall workflow? Like how much time does it take for you to today take a code from the job repository and then deploy it as an inference job on Sage Maker? And then what are the additional responsibilities that come to you there, Peter? Well, in general it's immediate. There is a CSV pipeline that takes the code, run the test, deploy the docker, and run it on Stage Maker. So it takes some minutes to deploy that code. And the execution itself, the badge job, the part, the training process depends on the model. It takes some time, but as I said, those are time series prediction of super sophisticated models. So usually the overall time it's not a problem. Okay. Do you have a sense of what these data science folks use? Do they also use the Sage Maker notebooks for their model building or do they kind of do on local environments? Or what exactly is the. Depends what they prefer. There are several options. They can work on local machines. We have some Sage Maker notebooks, but just to have them in case when someone needs much more computing power. There is also some remote environment for data scientists where they can SSH directly from Visual Studio and execute the code remotely. Okay, got it. And at any point in time, like, how much ML models is your team supporting? Right? Like, what is the number of total models that you are generally managing for this data scientist now? I have few thousands. Few thousands? Yeah. But as I said, they are very small models because every model is responsible for some single time series. Okay, is there a place where you can easily go and check? Okay. For example, for this project, these were the 20 models. And then if you want to go back to an old model or things like that other data scientists can see themselves. They don't want to do it just because it's time for this prediction. So the latest data are usually the most relevant ones. So if you take all the model, it's not accurate anymore usually. But do they have a way to kind of see all their models in one place, which is like the latest version? So suppose a data scientist worked on 50 different models in the past. You mean like model registry or something? Yeah. No, I didn't build it because I didn't get such requirements from them. As I said, they don't want it sold. Okay, got it. I think get a sense and then once you kind of host it on Jupiter note, sorry, sage maker Jobs, does the intra team at any point come into the picture or that is primarily the part that you handle, like with CIC, is there anything else that is a part of your workflow? Well, sometimes, unfortunately, from time to time, I need to ask him for some additional permissions. But in general, I try to do as much as possible on my own because it takes sometimes several months in order to get approval, to use something additional, or to extend, for example, service quota for particular service. So usually it's faster to build a workaround rather than get some permission. Okay, got it. So understand the workflow. Now, I have one question, Peter, for you. Like, you have been at Novartis and earlier you mentioned that Ross, like, you have seen the multicloud environment. Like, do you have a do you get a sense internally or even from the work that there is a need to move to multi cloud or do you feel that, okay, staying on one cloud is fine, and if you have a sense there, want to understand as to why this companies really want to move there? Well, from my perspective, it's easier to have everything in one cloud because, well, first of all, the services are aligned with each other. It's easier to communicate between AWS services or Azure services. And if you have something on Azure, something on WS, it's always a mess. You need to have a kind of on premise network as well in order to migrate stuff between those clouds. And the reason why they use that is usually very long migration. So I've seen that in many companies. For example, someone decided that we don't want to use Azure anymore. But if a lot of services are there, they set up AWS and they migrate something and it takes like three years, four years, the migration. So that's why they have multi cloud environment, because it takes several years to migrate everything. And sometimes someone realizes when they migrate, like 50% that migrating this another 50% is so challenging and so time consuming that it's easier to keep it like 50 50 on both clouds. Okay, that's the reason. It's not like someone decided, let's have 50 50 on Azure and AWS, it's usual migration and it's not so easy to migrate everything. That's very interesting. And do you think specifically at any company, like was this the case at Ross? I've seen that in at least three companies. All of them were like very big companies, one of the biggest in Europe. So that's what I can tell you. It's a very common example, by the way, in Roche, when it comes, Roche have totally different approach than Novartis. So in Novartis, as I said, I have some tool set and I need to follow it. And in Rush was completely different. In every project I have totally different tool set. So for as an example, in CITD, I was using like Bamboo, Jenkins, Silk CI and GitLab CICD in Rush for different tools, for different projects. I believe they still have Azure and AWS and on premise servicer, so they have everything. How is it different from innovatives? You're saying that you are told to use Sage Maker, so you have to do everything on Sage Maker. I wanted to know what kind of let you kind of use Sage Maker. Like why Sage Maker when there are other tools that are better? Good question, good question. Because as I said, someone decided that let's use Sage Maker. Like, I don't know, three years ago and now people don't want to migrate everything. So we stick to Sage Maker. And also some to avoid the situation, I told you about to have like 50% on this and 50% or something else. And then there is a need to maintain everything. That's the idea. Got it. And generally, like, who is the person you think who kind of takes this decision for you? Do you have a sense of who is the decision maker? General, that's a very good question. That's a very good question. And I don't know, and I never knew in any of my companies. Usually if you ask someone, you can mark my work. If you ask someone a big company, why do you use this? Oh, it's not my decision, it's someone else. I see, okay, so it's more like a legacy thing. Someone from Top Has, Poland. That's why you just stand. If it were your choice, you'd probably choose something else. Yeah, but in your perspective, Peter, does it seem to have any merit across things like compliance, et cetera? Even if you guys have on Prem, is it easier to have like a multi cloud thing which also runs an on Prem? Do you see any variable from compliance or security or anything for a multi cloud system? Well, from security perspective, probably difficult to handle it. However, I'm not security experts. Hard to tell. Well, in general, I believe that the simplest structure of the network and of the cloud the better. But of course it's difficult to keep that. I think. I don't have any questions. I get a sense of the workflow and also the overall what view you have in terms of that. Like Chinman did you have any follow up questions? Otherwise we will take two minutes to just tell Peter about what we are potentially doing. Yeah, no I don't think I have any questions. Again. Brief Peter. Yeah so Peter, basically I just wanted to give you an overview of what we are building at Proof only. So like Nikunjan Abhishek were at Facebook and at Facebook internally there was a platform called FBI Lender which they used to use which was like a platform built internally which they used to use for testing out models and then deploying it to production and deploying with the best practices. Like you will go through an A B testing and slowly kind of do traffic from one of the models and prod towards new model that you have built out and then slowly finally traffic at the final level. And while this is done like the system also allows you to do basic monitoring. So when we actually were building our first startup we had to build machine learning models for matching candidates to jobs because we are building in the talent space and that becomes a requirement like a lot of candidates coming to our platform then which job do you prepare it to? So we build out those models and then when we had to kind of integrate those models into our web app it kind of was a big challenge. Like we had to understand cloud systems. We tried to use together a number of open source tools but a lot of them were not reliable. How do you kind of really get a good reliable system? And then it took us more than a month to build it out and that's where we realized that probably this space still does not have the maturity yet as we see in tech companies like Facebook and all and that's where we started building two foundry with this the system in mind. So we are a platform right now we are built on top of Cuban networks. We kind of support single cloud as well as multi cloud. So, for example, if your workloads were on AWS, we kind of take an ECS cluster will deploy there on your cloud so that data does not flow out, and post that the workflow is generally that a developer can use the tool to kind of quickly kind of commit code to a test environment or deploy code to a test environment. And from there, like someone who is maintaining it or has the responsibility of ensuring these models go to prod, like say, someone like you can easily kind of promote those models from a test to a prod environment. If you didn't want to expose this to the data centers you can still take the models that they have committed to the gift repository and do the entire productionization yourself. So there are different levels of abstraction built out on the platform to allow for this. And then in order to ensure that there is full visibility for the teams, there is access control built out and we kind of have a model digital so all your models can be logged into that so that the team can easily search and all. And then you as a person who is kind of maintaining this model, so you have a view of all the models in one place, including different versions and all. So basically, taking care of those aspects of the pipeline, do it in a very simple way. So we don't ask you to change the code, we don't ask you to do anything complex. Basically it's like a wrapper. You write on top of it and then you just run it. So we doctorize everything. So that's basically the way we have built it. The goal was to build it very seamless and provide a really good experience. Okay, your target users are going to be data scientists or more like DevOps ML Ops people. So mode we are targeting the ML Ops people. So our goal is like there are two types of things we have seen. There are companies where we have seen that ML Ops folks are actually taking the responsibility of taking the models and then deploying it, in which case they are doing that for every model. So they'll either use that tool as you are using Sage Maker, right? So they'll either use a tool like that, in which case they can use our tool to help them enable them to do that. There are some companies in which the ML engineers build functionalities which allow the data scientists to at least go further. Like in your case, say they are going to the code repository. Suppose you take a step ahead where from the code repository they kind of post a simple model to a test environment. Now, there are some companies where that happens. In that case you can use our platform and build on top of it and expose a few APIs that you specifically want data scientists to use. So basically the control is on the hands of the ML engineer or the DevOps person, whoever is in charge of this. And they can use it in the way they feel fit or they can expose it to the data scientists that they are supporting. So that's the way all the philosophy. Around which we are okay, I see. However, if I were you, I would target more data scientists as our users because a lot of data scientists I have marked would like to use cloud in more native way. They would like to use Kubernetes for example. But for them it's still very challenging while for DevOps people it's a more natural way of working Kubefubernetes because they know Kubectl and tools like that. But for data scientists, if you tell them oh, deploy that through Kubectl, it's too difficult. So if you give them graphical user interface when they can click something and deploy to Kubernetes. They would like that. Probably. In some cases, people are using like data scientists are using, but we have so far targeted the ML team. But I think this is a good idea that we can instead target data scientists because they'll find it more intuitive, because they'll not have to do anything, and they can just use the UI and request. So that's an interesting idea. There are like at least five data scientists per one DevOps or MLS. So user pool is much bigger than okay. That is also true. Yes. Okay. But one question I have, Peter, is then in case of all right, like, a lot of these companies do not want data scientists to deploy. So how do you kind of go about that. Deploy? As I said, we take the code from code repository. They don't touch AWS, that's the thing. But they would like to it's more. Like an aspirational thing. So you're saying you go to data scientists and put it like an aspirational thing that they can use? Yes, exactly. So that could be a good starting point for them. Because now, as I said, it's a big step starting from laptop and now go directly to cloud. It's not so easy. There are lots of people willing to try that interesting. Do you have friends who are data scientists would want to deploy? Even like, do you want to try out the tool offline to kind of try and see as to what the tool does? Then we can try and expose the tool to you. Maybe we can create an account and love to kind of get feedback on that. Okay, sure. I can try it on my private machine because definitely I will not get permission for that. Yes. Okay, well, we'll do that. We will kind of set up an account. We'll send you an invite and will shoot an email with it. I would love for you to try it on your private side and see what the utilities and even tell us, like, feedback, if these are the places where we think you think we can improve potential. Okay, great. Okay. Thanks a lot, Peter. Great talking to you. Thank you. Have a good day. Bye.