Mainly anytime you are building a model, even if you have to spin up training resources and compare ten web models, different versions and then test workspace. Secrets. Management, authentication in a way it's usable and not a black box. System, and at the same time, basic monitoring out of the box. System monitoring. You can push the logs through there basically roughly platform Kubernetes super built as of now, but individual cloud accounts net overall at a very high level, obviously. But team member. And combination will be like around 1617 data scientists Songwe and ML engineer songwe okay, right, mostly sorted in a veiki mostly so we use data bricks for all our interactive computation purposes. Then for deployment we use again Kubernetes. So I'm looking pipeline model builder so you need to just extract one file, put that file in a code base and then just run a pipeline. Multi cloud. They pull the data, they basically run whatever things that they have to do. They try to take at model file format, model format then we take that and finally selected it will compute the feature. It will be easier for us to execute and offline. Maybe we recompute features. Now we are building features. And then. We put it on. So pipeline pipeline. But you are not. Launching then with respect to teams so most of the teams are basically endpoint generator and whoever is the engineering corresponding engineer team they have to integrate that APA and they have to use it. Is there like tests the environment? Okay, it's got flow castor. Generally dev one QA we do it so we basically push it and check for a few users even before it works to there like model evaluation coffee process. Okay. Mostly business teams who have also some statistics background they also understand these things. So they evaluate models for their business case, they see how it works for their vertical and then they try to give a go ahead and model evaluation phase. Then they have some questions. It's quite normal thing. Okay, when do you do the model evaluation phase? Generally when you are in the dev environment. No, even before we go to dev like we generate all this course backscode scores for all the users, whatever predictions are to be done, zero prediction coupon we try to basically give them the analysis that is there. But it's not a model hosted name although it's more done. It's more like a data bricks but that data. We only fetch it from data lake. And things are not but is it live data? Like basically live testing few users. When we go to Prod for upload we call it Shadow. It runs in shadow. Then we do an analysis. Is everything in live fine monitoring drift was a checker even before we check it, but on the fraud as well we check it and then we basically switch it on to Prod mode. Okay, so basically it's more like shadow traffic. Shadow copy banner you are able to test kick out and if it runs well, then you expose to exposed to prod. Once we deploy to Broad, everything will be taken by engineering team. Pipelines one. Or how to take it to Shadow, how to take it to a few people. Once you deliver a model, it's mostly dev. Effort from your side is done. Just that you need to monitor and see through that key. It is correctly implemented. Logistics will be handled by mostly engineering teams. Post you deploy. Our job is to basically provide an endpoint for that model. Okay, I see. Drift type model, drift measurement, similar types. We were doing it, and we had some standard metrics to measure and in general, other business metrics. So sorry, models, pipelines get triggered at the end of the day, and every day we get a report real time at the end of the day. We get a report at the end of the day. Maybe performance metrics and drift metrics. Let's take the usage case of lending. Right. So data bricks we have built pipelines where in which every day that model gets evaluated. Model so harder than a model retrain. We have that capability every day. That model will be retrained and acceptance criteria, it goes to prod pipeline. We trigger from DataBridge, okay? And it pulls that. Pickle file from docker Bundra docker image basically downloads and then basically lookup file, feature list file it downloads, then it will containerize that through docker image bud. And while this is going into prod from the already model to this model basically measures your data drift and tells you when you should retrain. It serves for any kind of model. Generally this is well set, like the. Process and everything processes. We'll have to basically do some kind of hacks there one of the primary use cases for us is we will not see results today for anything that we do today lending use case may specially right even for jawala use case maybe incidents use case maybe results results come with a lag to us. Six months, twelve months lag to us, we get results. So even intermediate monitoring that we do, but mostly data. We generally use that for our model training for most of the models. Okay. Right. So now, Baramana Pale tech systems will be completely different. Arts are different. Engineering systems will keep on improving. So their data models and how they store the data will basically also change. Right? So now when that is changing your pipelines have to adjust to those change to basically ingest that data. Okay these. Kind of issues we face and could issue and basically then one of the biggest challenges we need point in time data right? That is the important challenge we need point in time data that is one of the major challenges engineering teams then we have to go see and make sure they are implementing that data pipeline correct data EMR we are thinking of wherein we can run this standard daily jobs on EMR rather than on database. Okay, got it. Database separated pipeline used the volatile at least you are trying to sift out tucky, cost and Kubernetes like resources management. Which team is consuming which resources? There is some tags that will be assigned to every resource that is spawned. Okay. It will be a deployment portal on which so when you are deploying you will have access to your team's resources you can deploy against your team. Then you can see what are all the parts that are of the services that are running in your team and then you can search them. Got infrared. You don't have to daily do anything for that but automated. But infrared is responsible for those things. Okay. And cost visibility? How is the cost visibility in the system? Like terms of running the models and. Also every day and last seven days last week. What is the cost that your team has incurred? So it has been an incremental process. But infra team is really good here. Like in terms of everything they have built a pipeline in general even the visibility to things. Right. So navi in a way is very data driven company even for any business metric. Everything is published to slack for everything. There is a dashboard out there on tableau or superset or metabase which you can go and just check that. So data visibility is like too much here. Okay nice. This is super good here. So automatically everything is automatic. Mostly training, deployment training kale not for. Deployment. And GPU instances be on top of databricks. Okay, got it. And then what about distributed training by. Chance be perceptor in the near future. Right now we are dealing with lot of image data that we'll be dealing. We are thinking we might have to figure out some distributed training. Okay, got it. We are doing a python deployment. It is sometimes flask, sometimes bend to ML. Okay then few of them we do with scala. Wherever we can do with scala, we do with scalar only we convert into PMML and do with scala yoga. Especially when neural network complex model. So we go ahead with bend ML. There old models are there few which are on class KPM Columbia framework we use. Okay. As an open source mainly I think. Okay, got it. Nice. The model servers as such. Do you. Use like sort of a data dog, new Delhi graphics. It computes everything but software engineering, team monitoring, system monitoring, they use graphana and Prometheus. Understood. This is super helpful. Very helpful to understand the whole pipeline actually to be honest I would love to get feedback also and next week sometime platform. Maybe I'll try to move things some things around and tell you next week. That will be really good. Sure. Thank you so much. You have been here for two or. Three years right now we may have here since one and a half years. Okay. And you oversee the entire PUDA data science. Yeah. Okay. Got it. Nice. Cool. Yeah. Bye. Thank you so much. Bye.