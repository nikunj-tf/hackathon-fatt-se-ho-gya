{"prompt": "What are the different levels at which access control can be added to the platform? \n\n###\n\n", "completion": " uuid: 12044422040 Access control can be added at the cluster level, workspace level, and individual service level.\n"}
{"prompt": "Can access control be added at the deployment level? \n\n###\n\n", "completion": " uuid: 12044422040 Yes, access control can be added at the deployment level.\n"}
{"prompt": "What APIs are exposed for logging metrics and data? \n\n###\n\n", "completion": " uuid: 12044422040 APIs for logging parameters, data, and metrics are exposed.\n"}
{"prompt": "What is the Model Registry? \n\n###\n\n", "completion": " uuid: 12044422040 The Model Registry is a feature that allows for easy logging and deployment of models in different versions.\n"}
{"prompt": "Where can models be stored? \n\n###\n\n", "completion": " uuid: 12044422040 Models can be stored either on the cluster's cloud or on the user's cloud.\n"}
{"prompt": "What is the pricing structure for the platform? \n\n###\n\n", "completion": " uuid: 12044422040 The platform charges by the number of users, with a minimum of ten users at $150 per user per month. Pricing can be discussed and adjusted based on individual requirements.\n"}
{"prompt": "What is the next step after the call? \n\n###\n\n", "completion": " uuid: 12044422040 The next step is an internal discussion on Friday, followed by a larger team demo and setting up trial accounts after defining objectives and a start and end date for the trial.\n"}
{"prompt": "Who is speaking in the context? \n\n###\n\n", "completion": " uuid: 11189924245 Niquinh.\n"}
{"prompt": "Who is Yogesh? \n\n###\n\n", "completion": " uuid: 11189924245 The person being spoken to.\n"}
{"prompt": "What is Niquinh asking Yogesh in the beginning? \n\n###\n\n", "completion": " uuid: 11189924245 If he should call back later or if Yogesh can wait for ten minutes.\n"}
{"prompt": "What does Yogesh say in response to Niquinh's request to wait for ten minutes? \n\n###\n\n", "completion": " uuid: 11189924245 They can join the Google call together in ten minutes.\n"}
{"prompt": "What type of companies is Yogesh referring to when he says 'companies like CVS'? \n\n###\n\n", "completion": " uuid: 11189924245 Corporate American companies.\n"}
{"prompt": "Who is Yogesh targeting for his business? \n\n###\n\n", "completion": " uuid: 11189924245 Large companies that do not have much machine learning expertise.\n"}
{"prompt": "What is the goal for Yogesh's startup? \n\n###\n\n", "completion": " uuid: 11189924245 To work closely with five large companies to solve their initial use cases and prove value.\n"}
{"prompt": "What does Yogesh say is the most important aspect for the startup to be cautious about? \n\n###\n\n", "completion": " uuid: 11189924245 Constantly being in touch with the executives at the top level and having a spokesperson to generate revenue and long term business.\n"}
{"prompt": "What is True Foundry and what problem are they trying to solve? \n\n###\n\n", "completion": " uuid: 11564066567 True Foundry is a startup in the machine learning domain, helping companies build out ML platforms. They are solving the problem of making machine learning developers more productive by providing internal tools for frequent updates and cutting edge technology.\n"}
{"prompt": "What is the main challenge with deploying ML in the fintech industry? \n\n###\n\n", "completion": " uuid: 11564066567 The main challenge with deploying ML in the fintech industry is explainability. Fintech companies need to have a clear explanation of their ML models to regulators in order to use personal information in decision making.\n"}
{"prompt": "How is the team structured at Lending Club for building and deploying models? \n\n###\n\n", "completion": " uuid: 11564066567 There are separate teams for building and deploying models at Lending Club. Data scientists build the models and pass on requirements to data engineers who deploy, test, launch, and maintain the models in production.\n"}
{"prompt": "What is the focus of ML models at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 The focus of ML models at Lending Club is primarily on risk. Alternative data is a nascent area they are currently exploring for underwriting models.\n"}
{"prompt": "What is an example of alternative data at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 An example of alternative data at Lending Club is bank transaction data, which is currently being explored for underwriting models. However, the challenge is generating signals quickly enough, as runtime needs to be in milliseconds rather than seconds.\n"}
{"prompt": "What is the broad objective of the call? \n\n###\n\n", "completion": " uuid: 10881905922 To understand the ML process and pain points and get to know each other.\n"}
{"prompt": "Where is Vivek based now? \n\n###\n\n", "completion": " uuid: 10881905922 He is based in Bangalore.\n"}
{"prompt": "What is True Foundry and what are they building? \n\n###\n\n", "completion": " uuid: 10881905922 True Foundry is a startup building a platform for machine learning teams. They focus on model deployment and are working with design partners.\n"}
{"prompt": "How is Freshworks' ML team structured? \n\n###\n\n", "completion": " uuid: 10881905922 Freshworks has a monolithic code base with a separate team maintaining infrastructure. Their ML team operates with a layer that abstracts the application from the ML service, and ML services are specific to each account.\n"}
{"prompt": "Where are the models stored for inference? \n\n###\n\n", "completion": " uuid: 10881905922 Models are stored in an S3 model registry for inference.\n"}
{"prompt": "What is the main focus of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 10881905922 The main focus is on model deployment, enabling teams to deploy and monitor their machine learning models quickly.\n"}
{"prompt": "How does Freshworks guarantee performance for as many models as possible? \n\n###\n\n", "completion": " uuid: 10881905922 They have a custom-designed app with caching built in that ensures calls for a particular inference from a particular account meet certain SLA parameters.\n"}
{"prompt": "What is the problem with losing clients and how do they want to approach it? \n\n###\n\n", "completion": " uuid: 10323043378 They want to understand the problem and how it is hurting the clients, and also know how the clients have attempted to solve the problem prior to showcasing the capabilities of their product. They will try to have a personalized demo based on the client's specific use case.\n"}
{"prompt": "What is the plan for the demo and what will be sent beforehand? \n\n###\n\n", "completion": " uuid: 10323043378 Before the demo, they will send a document for the client to agree to the setup. During the demo, they will showcase how their platform can add value to the client's existing tools and solve the specific problems they are facing.\n"}
{"prompt": "What are some key questions they want to ask the client during the call? \n\n###\n\n", "completion": " uuid: 10323043378 They want to understand if deployment time is a problem, if the client is using ML Flow and if not, why, how much time batch inference takes, what existing tools the client is using, what business problems they are trying to solve, if they are being crunched on time, and if they are looking to hire more data scientists.\n"}
{"prompt": "What are some comparisons they can make to differentiate their platform from others? \n\n###\n\n", "completion": " uuid: 10323043378 They can discuss their expertise in Kubernetes and how it offers more flexibility for deployment over Sage Maker, as well as the potential cost savings compared to other platforms. They can also focus on specific areas where they excel, such as feature store management and data-driven monitoring.\n"}
{"prompt": "What is the plan for follow-up after the call? \n\n###\n\n", "completion": " uuid: 10323043378 They will keep the client in the loop by sending updates and seeking feedback. They also want to build a community of data scientists for feedback and suggestions on how to improve their platform.\n"}
{"prompt": "What is the context of the conversation? \n\n###\n\n", "completion": " uuid: 11189840489 A conversation between two people, Amar and Nicole, discussing Amar's platform and if it fits the use case for Dozee, including running hyper parameter tuning jobs and running models on the cloud.\n"}
{"prompt": "What are some of the issues with the current model training at Dozee? \n\n###\n\n", "completion": " uuid: 11189840489 The current process of running and training models is done on local machines, some jobs take a long time to run, and there is a desire to save and organize results remotely.\n"}
{"prompt": "What is the purpose of the Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189840489 The purpose of the Truefoundry platform is to provide a cloud-based solution for machine learning tasks, including running and training models, and organizing and visualizing results.\n"}
{"prompt": "What is the deployment process of a model on the Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189840489 The deployment process of a model on the Truefoundry platform involves writing a script to deploy the model, specifying dependencies, and setting up a job to run the script on a remote machine.\n"}
{"prompt": "What can be tracked and visualized on the Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189840489 Metrics and outputs from multiple runs and models can be tracked and visualized over time on the Truefoundry platform.\n"}
{"prompt": "Who is the CTO of you.com and what is his background? \n\n###\n\n", "completion": " uuid: 10784174762 The CTO of you.com is Brent and he co-founded it with Richard a few years ago. He worked with Richard at salesforce for about four years, doing research in AI, transfer learning, multitraining, and large language models. He has experience with chainer PyTorch alpha testing and GPUs.\n"}
{"prompt": "Who is involved with Builders Fund and how do they relate to you.com? \n\n###\n\n", "completion": " uuid: 10784174762 Pete from Builders Fund met Richard when they were both at salesforce and they worked on different projects together. He is now an advisor for you.com.\n"}
{"prompt": "What is Truefoundry and how does it work? \n\n###\n\n", "completion": " uuid: 10784174762 Truefoundry is a platform built on top of Kubernetes that supports machine learning developers to help them deploy their models to production. It supports real-time and batch model deployment, and provides service monitoring, logs, and basic monitoring for deployed models. The platform sits on top of either public or private clusters and allows easy provisioning and management of resources across different teams. It enforces best practices and supports CI/CD. The platform makes complicated things like traffic splitting and shadow traffic easier as well.\n"}
{"prompt": "What is the background of the founders of Truefoundry? \n\n###\n\n", "completion": " uuid: 10784174762 The founders of Truefoundry are Karen, Mia, and Nikhunj. Karen graduated from the Indian Institute of Technology, Pin, India and spent six years working in hedge funds. Mia and Nikhunj have backgrounds in machine learning, with Nikhunj building the platform for Reflection and becoming the lead ML engineer for Facebook's Portal team. They all left their jobs in 2020 to start Truefoundry.\n"}
{"prompt": "What is the platform used by you.com and what kind of work is done? \n\n###\n\n", "completion": " uuid: 10784174762 You.com is built on Azure and uses data bricks, ML flow, and Kubernetes for deploying services or models. The models are mainly built using PyTorch, and there are pipelines that use TerraForm. Engineers and the ML Ops/DevOps team deploy the models, while the data scientists are mostly responsible for data analytics work.\n"}
{"prompt": "What aspect of ML Flow did the speaker use in model building and tracking? \n\n###\n\n", "completion": " uuid: 11354404149 experiment tracking piece\n"}
{"prompt": "Was the experiment tracking aspect of ML Flow effective? \n\n###\n\n", "completion": " uuid: 11354404149 Yes, it worked pretty well.\n"}
{"prompt": "Why did the speaker and their team move away from using ML Flow? \n\n###\n\n", "completion": " uuid: 11354404149 To reduce maintenance overhead and free up time.\n"}
{"prompt": "What was the reason for wanting to move towards a managed service like SageMaker? \n\n###\n\n", "completion": " uuid: 11354404149 To further reduce overhead.\n"}
{"prompt": "Did SageMaker provide an adequate experiment tracking interface? \n\n###\n\n", "completion": " uuid: 11354404149 It was a little clunky and the team is still figuring out how to fully replace ML Flow.\n"}
{"prompt": "What practices important to SRE does the speaker's team implement, and how do they do it? \n\n###\n\n", "completion": " uuid: 11354404149 The speaker mentions CI/CD, authentication, and secrets management, which are implemented through GitLab, SageMaker, and other systems.\n"}
{"prompt": "What is the speaker's company building? \n\n###\n\n", "completion": " uuid: 11354404149 They are building a deployment platform for ML models.\n"}
{"prompt": "What is the core feature of the speaker's deployment platform? \n\n###\n\n", "completion": " uuid: 11354404149 The ability to quickly and easily deploy models while also following SRE best practices and running on the same infrastructure as software.\n"}
{"prompt": "How does the platform ensure reproducibility of models? \n\n###\n\n", "completion": " uuid: 11354404149 The platform provides a model registry for versioning, but users can also track versions in the deployed tab.\n"}
{"prompt": "What is the purpose of workspaces in the speaker's platform? \n\n###\n\n", "completion": " uuid: 11354404149 Workspaces are smaller groups for developer teams to work on, each with resource limits and proper access control.\n"}
{"prompt": "What did Cinema do before joining Found? \n\n###\n\n", "completion": " uuid: 12361625352 Cinema worked as a management consultant at McKenzie for IT.\n"}
{"prompt": "What is Pritika Groal's role at Medtronic? \n\n###\n\n", "completion": " uuid: 12361625352 Pritika Groal is leading data sciences and digital innovation at Medtronic, part of diabetes organization.\n"}
{"prompt": "What challenges are faced regarding unifying the workflows? \n\n###\n\n", "completion": " uuid: 12361625352 Challenges include misalignment of the process, differences in the integration to the development cycle, and differences in tool sets.\n"}
{"prompt": "What are the challenges faced for scaling and deployment of models? \n\n###\n\n", "completion": " uuid: 12361625352 Challenges include ensuring that resources are not wasted, and a pipeline is set up to follow FDA guidelines strictly.\n"}
{"prompt": "What is data identification and why is it necessary? \n\n###\n\n", "completion": " uuid: 12361625352 Data identification is separating personal identifiable information (PII) from the rest of the data to prevent researchers and analysts from accessing PII. It is necessary to follow privacy regulations.\n"}
{"prompt": "Who does explainability for models currently? \n\n###\n\n", "completion": " uuid: 12361625352 Currently, most models rely on SHAP values. They are still exploring a good system for explainability.\n"}
{"prompt": "What happens when a model needs to be retrained after going beyond set limits? \n\n###\n\n", "completion": " uuid: 12361625352 The model falls back to the previous version.\n"}
{"prompt": "Are the models for direct customer facing on the hardware or on the cloud? \n\n###\n\n", "completion": " uuid: 12361625352 Currently, they are on the cloud. They are exploring edge computing to get on mobile devices.\n"}
{"prompt": "How is the monitoring done for models when they are on devices and there is no connectivity? \n\n###\n\n", "completion": " uuid: 12361625352 One approach is to run some part of the feature on the device and use cloud for learning and optimizing parameters. Heuristic-based algorithms can also be used to detect patterns on the devices.\n"}
{"prompt": "How are you doing? \n\n###\n\n", "completion": " uuid: 11942347136 I'm good, how are you?\n"}
{"prompt": "Who is Lucky and when will he join? \n\n###\n\n", "completion": " uuid: 11942347136 Lucky is someone who will be joining the conversation and the speaker is texting him to join in a few minutes.\n"}
{"prompt": "What is Anrag's background? \n\n###\n\n", "completion": " uuid: 11942347136 Anrag is one of the co-founders at IIFL Truefoundry. He graduated from IAT Karakura in 2013 and spent seven years working with a hedge fund called World Fund.\n"}
{"prompt": "What is the goal of True Foundry? \n\n###\n\n", "completion": " uuid: 11942347136 The goal of True Foundry is to make it easier for data teams to get access to a better platform for testing out and deploying models in a scalable way to production with the right security, with the right authentication and with monitoring in building.\n"}
{"prompt": "What is the size of the Data Science team currently at IIFL? \n\n###\n\n", "completion": " uuid: 11942347136 The team has 4 members currently.\n"}
{"prompt": "What is the current workflow for data to modeling to batch computing to prediction? \n\n###\n\n", "completion": " uuid: 11942347136 The current workflow is to perform extensive exploration data analysis around the data, build models that can be posting and bagging models, and dump the scores in their old database. Prediction is done on the saved models.\n"}
{"prompt": "What kind of API traffic do they expect to see once the models are deployed? \n\n###\n\n", "completion": " uuid: 11942347136 They expect around 10-15 API hits per minute.\n"}
{"prompt": "What are some of the necessities from a deployment platform? \n\n###\n\n", "completion": " uuid: 11942347136 The deployment part should be taken care of, there should be a dashboard for tracking performance and failures in API calls, metrics for tracking population stability index, AUC k or characteristic stability index, and intelligence around retraining the model.\n"}
{"prompt": "Is there a timeline for deployment or solutioning? \n\n###\n\n", "completion": " uuid: 11942347136 There is currently no timeline, but they are exploring possible ways to work towards a solution.\n"}
{"prompt": "Can you provide a demo of how True Foundry works? \n\n###\n\n", "completion": " uuid: 11942347136 Yes, a simple recorded demo can be shown, and a more detailed demo can be scheduled for a hands-on experience with code repositories and deployment processes.\n"}
{"prompt": "What is the goal of the platform? \n\n###\n\n", "completion": " uuid: 12361625352 To help companies make their ML very simple and manage the entire workflow, from training to deployment and monitoring.\n"}
{"prompt": "What tools does the platform integrate with? \n\n###\n\n", "completion": " uuid: 12361625352 It integrates with Docker registry, GitHub, and Bitbucket, and can also integrate with Gitlab.\n"}
{"prompt": "What are workspaces in the platform? \n\n###\n\n", "completion": " uuid: 12361625352 Workspaces are environments within a cluster that set limits on the maximum amount of resources that a team can use, and can also have different access controls and service accounts attached for data access.\n"}
{"prompt": "Is the platform built on Kubernetes? \n\n###\n\n", "completion": " uuid: 12361625352 Yes, the entire platform is built on top of Kubernetes.\n"}
{"prompt": "What is the benefit of using the platform's access control feature? \n\n###\n\n", "completion": " uuid: 12361625352 It allows for setting different roles for different users in different clusters, ensuring that resources are used efficiently and securely, and also enables allocation of workspaces and service accounts for different teams and projects.\n"}
{"prompt": "What is the punditry focused on? \n\n###\n\n", "completion": " uuid: 12339295384 The punditry is focused on enabler solution providers and their migration to the cloud.\n"}
{"prompt": "What is the challenge in convincing customers to move to the cloud? \n\n###\n\n", "completion": " uuid: 12339295384 The challenge in convincing customers to move to the cloud is not just technical, but also involves individual perspectives and beliefs.\n"}
{"prompt": "What kind of interaction model influences the exposure of Ml Ops to clients? \n\n###\n\n", "completion": " uuid: 12339295384 If Ml Ops is going to be exposed to data scientists in the client's company, then the assumption is that the people building the models are also data scientists in the client's company through an automl kind of interface.\n"}
{"prompt": "What is the main challenge with Ml Ops? \n\n###\n\n", "completion": " uuid: 12339295384 The main challenge with Ml Ops is that very little is understood about it.\n"}
{"prompt": "What problem is the speaker interested in solving? \n\n###\n\n", "completion": " uuid: 12339295384 The speaker is interested in solving an Ml Ops problem involving building a pipeline for create, deploy, monitor, explain, the whole CI/CDCT, and scaffolding to sell services to other contact center service companies.\n"}
{"prompt": "Where is the speaker based out of? \n\n###\n\n", "completion": " uuid: 12339295384 The speaker is based out of San Francisco, but is currently visiting Pancroad.\n"}
{"prompt": "What did Ansul say when asked how he was doing? \n\n###\n\n", "completion": " uuid: 11354404149 Ansul said he was good and doing well.\n"}
{"prompt": "What was the name of Ansul's co-founder based in the SF area? \n\n###\n\n", "completion": " uuid: 11354404149 The name of Ansul's co-founder based in the SF area was Nikkunji.\n"}
{"prompt": "What is the goal of True Foundry according to Ansul? \n\n###\n\n", "completion": " uuid: 11354404149 The goal of True Foundry is to bring what they saw at Facebook in terms of the ML platform there to every company around the globe.\n"}
{"prompt": "Who is the primary user of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11354404149 The primary user of True Foundry's platform is the ML developers who are building the models.\n"}
{"prompt": "What is the secondary user of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11354404149 The secondary user is the intra engineer or the DevOps team or the platform teams in companies who would want to have a full view of what is going on in the resources, in the infrastructure that they have allocated.\n"}
{"prompt": "What kind of models is Prove building according to the conversation? \n\n###\n\n", "completion": " uuid: 11354404149 Prove is building models for identity authentication work that relies on signals from the device to help determine the level of risk and other factors related to behavioral biometrics.\n"}
{"prompt": "What is the main problem Prove is trying to solve? \n\n###\n\n", "completion": " uuid: 11354404149 The main problem Prove is trying to solve is how to become more efficient in their ML development process.\n"}
{"prompt": "What tools does Prove use for ML development? \n\n###\n\n", "completion": " uuid: 11354404149 Prove uses Sage Maker and AWS for ML development, with the ML team owning the infrastructure and using hosted notebooks in Sage Maker for easy prototyping.\n"}
{"prompt": "What challenges do projects face when deploying ML models on device according to the conversation? \n\n###\n\n", "completion": " uuid: 11354404149 Projects face challenges related to model size and privacy, as well as figuring out how to optimize the model for on-device performance and determining the right deployment framework such as TensorFlow Lite.\n"}
{"prompt": "Where in India are you based? \n\n###\n\n", "completion": " uuid: 12044331076 My home is in Lucknow, so right now I'm in Lucknow.\n"}
{"prompt": "What type of place is Charity, where you live? \n\n###\n\n", "completion": " uuid: 12044331076 Charity is a very fancy neighborhood, with a lot of good buildings and concrete walls.\n"}
{"prompt": "How long have you been living in Dubai? \n\n###\n\n", "completion": " uuid: 12044331076 I have been living in Dubai for almost 4 and a half years.\n"}
{"prompt": "How does the Dubai tech salary compare to other regions like India, Europe, and the US? \n\n###\n\n", "completion": " uuid: 12044331076 The Dubai tech salary is comparable to the US because there is no tax, and maybe a little bit less than the US.\n"}
{"prompt": "What cloud platform do you use to build your ML platform? \n\n###\n\n", "completion": " uuid: 12044331076 We use AWS and EKS to build our ML platform.\n"}
{"prompt": "How many people are in the platform team? \n\n###\n\n", "completion": " uuid: 12044331076 There are around 8-9 people in the platform team who work on different parts of the platform including machine learning, experimentation, feature store, and injection platform.\n"}
{"prompt": "What is your definition of experiment tracking? \n\n###\n\n", "completion": " uuid: 12044331076 Experiment tracking is basically tracking the version and parameters of models during experimentation.\n"}
{"prompt": "What tool do you use for experiment tracking? \n\n###\n\n", "completion": " uuid: 12044331076 We use ML Flow for experiment tracking, with a custom layer on top of it.\n"}
{"prompt": "What did the speaker share about their team? \n\n###\n\n", "completion": " uuid: 11655736677 As a team, they are comprised of Vishik, Nikko, and the speaker who were all batchmates at IIT Kharagpur, and they left their jobs to build something in the talent space to help companies hire better talent. They later sold that company to Info Edge and started working on building tools to reduce the time for ROI on machine learning, artificial intelligence, and analytics initiatives.\n"}
{"prompt": "What does the speaker want to know about Kotak's initiatives? \n\n###\n\n", "completion": " uuid: 11655736677 The speaker wants to know about Kotak's different digital initiatives, how AI and ML has been shaping those initiatives, and whether there are any opportunities for improvement when compared to other companies.\n"}
{"prompt": "Is there a central data team at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 Yes, there is a central team that works with different business units.\n"}
{"prompt": "Is there any challenge on the data side at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 No, there are significant opportunities for them to scale up and become better, but they do not face any challenges presently.\n"}
{"prompt": "What is the central data team responsible for at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 The central data team's main responsibility is to ensure that data is available in a manner in which it can be consumed on the fly, but not necessarily focusing on building all use cases coming out of it.\n"}
{"prompt": "What are the tasks involved in the data science process described? \n\n###\n\n", "completion": " uuid: 10346094649 Tasks involve cleaning data, doing feature engineering, building model, testing model, deploying model, and batch inferences and monitoring for data leakage or performance degradation.\n"}
{"prompt": "What challenges is the team facing in building neural network models? \n\n###\n\n", "completion": " uuid: 10346094649 The volume of work involved in building 400 multi-level, multi-classification models with neural networks is a challenge.\n"}
{"prompt": "What format is used to hand over Keras models to the engineering team? \n\n###\n\n", "completion": " uuid: 10346094649 Keras models are saved in the saved model format of TensorFlow.\n"}
{"prompt": "What is the process of updating features in the model and deploying them? \n\n###\n\n", "completion": " uuid: 10346094649 The data scientists add the feature, retrain the model, update the scripts in GitHub, and then the process flows through the production automatically.\n"}
{"prompt": "What tool is used for monitoring the models built? \n\n###\n\n", "completion": " uuid: 10346094649 It is assumed that Sage Maker is used for monitoring since everything is done in the environment.\n"}
{"prompt": "What is the game of operationalizing models, according to the speaker? \n\n###\n\n", "completion": " uuid: 11354404209 To monitor the models for drip data response and different monitoring activities and trigger a new AutoML bill if needed\n"}
{"prompt": "Why did the speaker ask about the stack built around Sage Maker? \n\n###\n\n", "completion": " uuid: 11354404209 To understand why Sage Maker was chosen and if building the ML deployment layer over Kubernetes was considered\n"}
{"prompt": "Where are the models that the speaker is referring to typically built? \n\n###\n\n", "completion": " uuid: 11354404209 Internally, but for Fortune 500 customers, the models can also be built by the customers using tools like Sage Maker and GCP\n"}
{"prompt": "What is the purpose of the platform built by the speaker's company? \n\n###\n\n", "completion": " uuid: 11354404209 To reduce time to value for ML models and provide scalability to allow quick ML model deployments with the flexibility for developers to build on top of it while ensuring right security and other requirements for the industry\n"}
{"prompt": "Which companies does the speaker suggest to target for their platform? \n\n###\n\n", "completion": " uuid: 11354404209 Chip or health manufacturers who are not hardcore IT companies and not at the level of Salesforce or ServiceNow\n"}
{"prompt": "What suggestion does the speaker give to improve the growth story of the platform? \n\n###\n\n", "completion": " uuid: 11354404209 To get data scientists out of it and enable business users to run AutoML pipeline parallel to the experimentation pipeline\n"}
{"prompt": "What does the speaker plan to do after scheduling the demo of the platform? \n\n###\n\n", "completion": " uuid: 11354404209 Take feedback and learn about challenges and use cases, but partnership with companies like Pega is not possible at the present stage of growth\n"}
{"prompt": "What is the speaker's opinion on hiring and managing a data science team? \n\n###\n\n", "completion": " uuid: 11354404209 It is a long and difficult process, and enabling business users to run AutoML pipeline parallel to the experimentation pipeline can offset the cost of maintaining a data science team on the company's side\n"}
{"prompt": "What is Richard's role at Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 Richard is responsible for all tooling around ML ops at Wayve.\n"}
{"prompt": "How did Richard learn about Pro Foundry? \n\n###\n\n", "completion": " uuid: 10441289250 Richard learned about Pro Foundry through an email newsletter alert.\n"}
{"prompt": "What kind of models does Wayve work with? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve works with models that deal with image and video data.\n"}
{"prompt": "What is Richard's biggest time sink in the pipeline? \n\n###\n\n", "completion": " uuid: 10441289250 Richard's biggest time sink is having a tight feedback loop of bugs occurring on road deployment and fixing them effectively.\n"}
{"prompt": "Does Wayve use open source tools for building their pipeline? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve mostly develops their tools internally due to the lack of off the shelf products for the autonomous driving industry.\n"}
{"prompt": "How many people are on Wayve's ML engineering team? \n\n###\n\n", "completion": " uuid: 10441289250 Around 60-70 people on Wayve's ML engineering team, which comprises around a third of the company's employees.\n"}
{"prompt": "What is Wayve's approach for building autonomous vehicles? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve's approach is focused on entering machine learning for this problem area, developing off internal fleets and retrofitting vehicles with their technology.\n"}
{"prompt": "What kind of data monitoring does Wayve do? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve mostly monitors for major data distribution shifts, data drift in the model and major bugs that occur on road deployments.\n"}
{"prompt": "Does Wayve export data out from the vehicles for further analysis? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve ingests offline data from the vehicles for analysis on further retraining.\n"}
{"prompt": "Is there a live update from the models in Wayve's pipeline? \n\n###\n\n", "completion": " uuid: 10441289250 No, there are no live updates from the models for Wayve's pipeline as the model is directly deployed on the vehicle itself.\n"}
{"prompt": "What kind of problems are you working on and what are the challenges that you are currently trying to solve? \n\n###\n\n", "completion": " uuid: 11354403948 The current focus is on building the tools for data scientists to efficiently process data for machine learning tasks. The challenge lies in building an efficient data pipeline from the database to the analytic machine to allow for sampling and feature engineering. We also need to consider distributed training and parallel computing for scalability.\n"}
{"prompt": "Who are your target customers and what is the application of machine learning? \n\n###\n\n", "completion": " uuid: 11354403948 Our target customers are data scientists who have knowledge of machine learning and encoding. We provide a Python library to import and then they can train and deploy their own models on their own infrastructure. Our next phase is to provide a cloud infrastructure to train the models and provide verticalized solutions for specific use cases like fraud detection and recommender systems.\n"}
{"prompt": "Are you planning to be cloud-agnostic or focused on one specific cloud provider? \n\n###\n\n", "completion": " uuid: 11354403948 We are planning to be cloud-agnostic and have already deployed our database on the big three cloud providers. We will prioritize which provider to integrate with first, most likely GCP.\n"}
{"prompt": "In the first phase, how does the library integration work with the client's infrastructure? \n\n###\n\n", "completion": " uuid: 11354403948 In the first phase, clients would need to have their own infrastructure for training and deployment. The Python library will be provided to the clients so they can import it and then they would train and deploy their own models on their own infrastructure.\n"}
{"prompt": "What kind of timeline are you looking at for deploying machine learning models and hosting them? \n\n###\n\n", "completion": " uuid: 11354403948 The first phase is already complete with the Python library provided to clients. The next phase of providing a cloud infrastructure to train the models and building hyper-parameter tuning and parallel computing capabilities will take at least half a year. Verticalized solutions for specific use cases like fraud detection and recommender systems will be a parallel focus.\n"}
{"prompt": "What is the speaker's plan for December 7th? \n\n###\n\n", "completion": " uuid: 12150828333 The speaker starts working full time on that day.\n"}
{"prompt": "What is the idea behind the speaker's startup? \n\n###\n\n", "completion": " uuid: 12150828333 They are trying to build a YouTube-like platform for comics using generative AI.\n"}
{"prompt": "What is the speaker's goal for a universe of models? \n\n###\n\n", "completion": " uuid: 12150828333 They want at least 40-50 models that can serve the universe of comic creation.\n"}
{"prompt": "What is the speaker's plan for allowing users to fine-tune their model? \n\n###\n\n", "completion": " uuid: 12150828333 They plan on allowing it but are still figuring out the commercials.\n"}
{"prompt": "What is the speaker's multi-cloud strategy for hosting their product? \n\n###\n\n", "completion": " uuid: 12150828333 They use a multi-cloud Kubernetes strategy with multiple nodes in a single Kubernetes cluster.\n"}
{"prompt": "What is the speaker's plan for model versioning? \n\n###\n\n", "completion": " uuid: 12150828333 They plan on building a detailed pipeline to reduce manual parameter tuning.\n"}
{"prompt": "What is the role of the control plane in the speaker's infrastructure? \n\n###\n\n", "completion": " uuid: 12150828333 It helps to talk to the Kubernetes control plane and allows for cluster instance types to be decided automatically across namespaces.\n"}
{"prompt": "What metrics can the speaker auto-log in their system? \n\n###\n\n", "completion": " uuid: 12150828333 They can log CPU, module type, and image metrics.\n"}
{"prompt": "What is True Foundry's role in the speaker's deployment process? \n\n###\n\n", "completion": " uuid: 12150828333 They can allow for the deployment of two services as a canary and can change parameters for each service.\n"}
{"prompt": "How much of the GPU does each model take up in the speaker's system? \n\n###\n\n", "completion": " uuid: 12150828333 They have three models that share the 16 GPU memory and all three are shifted into the GPU at once.\n"}
{"prompt": "What is the process of migrating code to creating images or writing Python files? \n\n###\n\n", "completion": " uuid: 11354403912 The DevOps team handles this process, and developers help in deploying all the services.\n"}
{"prompt": "What is the process for promoting from one environment to another? \n\n###\n\n", "completion": " uuid: 11354403912 Staging is promoted to UAT, and from there to Production. The pipeline has already been automated and there is nothing to coordinate.\n"}
{"prompt": "What cluster is the code copied to when deploying in a different environment? \n\n###\n\n", "completion": " uuid: 11354403912 The code has to be copied to a different cluster because everything is different, such as branches and code. Staging may have code which is not supposed to be delivered, so it cannot be promoted to UAT.\n"}
{"prompt": "Is BitMarket or GitHub used for resource provisioning and deployment? \n\n###\n\n", "completion": " uuid: 11354403912 Both are used.\n"}
{"prompt": "How is secrets management handled? \n\n###\n\n", "completion": " uuid: 11354403912 Google Secret Store is used for some services, and something else is used for others. Secrets management is automatically ingrained build.\n"}
{"prompt": "What is the process for developers to deploy to the workspace? \n\n###\n\n", "completion": " uuid: 11354403912 Developers individually deploy services or Cron jobs to this workspace, which can be scheduled or triggered at their leisure. The deployment to the workspace is very simple and can be done through a YAML configuration or UI without the help of DevOps or infringement for the Kubernetes YAML.\n"}
{"prompt": "What is the workflow for data science? \n\n###\n\n", "completion": " uuid: 11354403912 Instead of TML, it exposes the Python way so that data scientists can do it. There are complexities that come into the platform in terms of doing monitoring at the level of data science rather than just system-level monitoring.\n"}
{"prompt": "What is the concept behind the platform? \n\n###\n\n", "completion": " uuid: 11354403912 It is built agnostic to software engineering, and allows you to connect to a GKE account with authentication, access control, and choice of machines. Once connected, you create different namespaces or workspaces for your different teams which come with resource constraints, and allow you to control access.\n"}
{"prompt": "What is the role of DevOps in the platform? \n\n###\n\n", "completion": " uuid: 11354403912 DevOps acts as a security layer and comes into play if anything breaks or if there is a change in a final approval. If you are okay with your developers directly pushing, that is also fine.\n"}
{"prompt": "What is the benefit of the platform? \n\n###\n\n", "completion": " uuid: 11354403912 The platform comes equipped with monitoring logs, secrets management, CI/CD integration to GitHub bit bucket, authentication systems, and rollout to production in a canary shadow testing manner. All of these come by default with the system.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12361625175 The primary goal of Truefoundry is to enable companies that are on multi cloud architecture to build good, flexible, machine learning deployment platform on top of that and solve for other parts or pieces of the problem that comes with deployment.\n"}
{"prompt": "What is Peter's position at Novartis? \n\n###\n\n", "completion": " uuid: 12361625175 Peter works as an ML engineer in Novartis.\n"}
{"prompt": "What are some of the challenges that Peter faces in his job? \n\n###\n\n", "completion": " uuid: 12361625175 Peter faces the challenge of redundancies that get created because different teams work in silos, making it difficult to aggregate data from different sources. They share no code or solutions across departments, and different teams may build the same thing in parallel.\n"}
{"prompt": "How many ML engineers work closely with Peter? \n\n###\n\n", "completion": " uuid: 12361625175 Peter works mostly with two ML engineers, but he also cooperates with around ten software engineers and probably 20 data scientists.\n"}
{"prompt": "What tools do Peter and his team primarily use for deployment? \n\n###\n\n", "completion": " uuid: 12361625175 Peter and his team primarily use AWS solutions, such as Sage Maker jobs, Lambda functions, and ECS.\n"}
{"prompt": "Does Peter work on real-time models as well? \n\n###\n\n", "completion": " uuid: 12361625175 Peter is working mainly on batch models for internal consumption. However, there are some plans about real-time models as well.\n"}
{"prompt": "Does Peter's team use container orchestration tools like Kubernetes? \n\n###\n\n", "completion": " uuid: 12361625175 Peter is not aware of any use of Kubernetes by his team. He personally has no admin access to EKS, but other teams in Novartis may use it.\n"}
{"prompt": "How many ML models does Peter's team support? \n\n###\n\n", "completion": " uuid: 12361625175 Peter's team supports a few thousands of models, but each is responsible for some single time series, and they are usually very small models.\n"}
{"prompt": "Does Peter face any challenges with permissions or services quota? \n\n###\n\n", "completion": " uuid: 12361625175 Peter mentions that it takes several months to get approval for some additional permissions or to extend service quota for a particular service. So, he tries to do as much as possible on his own and builds a workaround rather than getting permission.\n"}
{"prompt": "Does Peter see a need for multi-cloud at Novartis? \n\n###\n\n", "completion": " uuid: 12361625175 Peter feels it's easier to have everything in one cloud, and he has not seen any clear need for multi-cloud at Novartis. In his experience, it's easier to communicate between AWS services or Azure services.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11185249388 The purpose of the call is to discuss Truefoundry, a machine learning platform the speaker is building and learn from others who are solving similar problems.\n"}
{"prompt": "Who is Bobby? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby is the person who the speaker is talking to on the call, who is a co-founder of the speaker's company.\n"}
{"prompt": "What is the speaker's role in the company? \n\n###\n\n", "completion": " uuid: 11185249388 The speaker is the CEO of the company.\n"}
{"prompt": "What is the company that the speaker sold? \n\n###\n\n", "completion": " uuid: 11185249388 The company that the speaker sold was called Reflection and it was in the HR tech space, which was later acquired by Infoyage.\n"}
{"prompt": "What is Netomi using machine learning for? \n\n###\n\n", "completion": " uuid: 11185249388 Netomi is using machine learning for a variety of things including customer care, conversation AI, and for things like recommending products for upselling and cross-selling.\n"}
{"prompt": "What are some of the challenges the speaker faces with real-time scoring of machine learning models? \n\n###\n\n", "completion": " uuid: 11185249388 The speaker faces challenges like real-time scoring being slower than running a simple database query, and the need to bypass governance challenges for optimal operationalization of machine learning.\n"}
{"prompt": "What problems did you face when getting everyone on board? \n\n###\n\n", "completion": " uuid: 11488154639 Individual pairing with data scientists to get dependencies installed correctly for their chipset.\n"}
{"prompt": "What solution did you find to solve these problems? \n\n###\n\n", "completion": " uuid: 11488154639 Dockerization.\n"}
{"prompt": "What tool did you use for experiment tracking? \n\n###\n\n", "completion": " uuid: 11488154639 Sage Maker and Cloud Watch dashboards.\n"}
{"prompt": "Did you use ML flow for experiment tracking? \n\n###\n\n", "completion": " uuid: 11488154639 No.\n"}
{"prompt": "What is the process to update a dependency with Dockerization? \n\n###\n\n", "completion": " uuid: 11488154639 Update the dependency, run Docker compose build, push it to PR, and once approved, everyone will have it on their local development environment.\n"}
{"prompt": "What is the current deployment tool used? \n\n###\n\n", "completion": " uuid: 11488154639 Team City for CI, and CD pipeline that talks to AWS to upload new docker images.\n"}
{"prompt": "What was the package you created to define the steps in the Sage Maker pipeline? \n\n###\n\n", "completion": " uuid: 11488154639 A package that essentially wraps whatever code you want to execute out of the Sage Maker pipeline, allowing you to slot in any docker image or custom code into any number of steps that you define in Python SDK.\n"}
{"prompt": "What solution are you currently using for machine learning deployment? \n\n###\n\n", "completion": " uuid: 11488154639 Sage Maker.\n"}
{"prompt": "Are there any issues with deployment? \n\n###\n\n", "completion": " uuid: 11488154639 No, deployment is not a problem. There is a CI pipeline set up already.\n"}
{"prompt": "What is the platform you are trying to build on top of Kubernetes? \n\n###\n\n", "completion": " uuid: 11488154639 A platform like Sage Maker on Kubernetes.\n"}
{"prompt": "Who is on the call with anderson? \n\n###\n\n", "completion": " uuid: 12150677061 Akshaya, a member of founder's office and Nikkins, who is from KGP 2013 batch.\n"}
{"prompt": "Where did anderson spend most of his time at KGP and why? \n\n###\n\n", "completion": " uuid: 12150677061 He spent most of his time at RK because KK and Anish were at RK. He knew them from school.\n"}
{"prompt": "What channels are they using for outreach and what themes have they worked on? \n\n###\n\n", "completion": " uuid: 12150677061 They are using LinkedIn primarily and also outbound messaging, referrals etc. Some themes they have worked on includes multi-cloud ML, case studies, platform themes etc.\n"}
{"prompt": "What is the importance of identifying the budget owner in a company? \n\n###\n\n", "completion": " uuid: 12150677061 Identifying the budget owner is crucial as they are the ones who would sign the checks and have the incentive to reduce costs. If the functional load of the initiative is not able to make the case and put through the budget, then it's difficult to solve the problem.\n"}
{"prompt": "What should be considered before getting into a sales meeting with large enterprises? \n\n###\n\n", "completion": " uuid: 12150677061 It's important to establish who the data engineering head reports to and where the budget comes from as well as the interplay between the CDO and CTO.\n"}
{"prompt": "Who got a conflict and won't be able to join? \n\n###\n\n", "completion": " uuid: 11354404209 Mata had a conflict and won't be able to join.\n"}
{"prompt": "Who is one of the co-founders at True Foundry? \n\n###\n\n", "completion": " uuid: 11354404209 The speaker is one of the co-founders at True Foundry.\n"}
{"prompt": "What did the speaker work as at World Fund? \n\n###\n\n", "completion": " uuid: 11354404209 The speaker worked as a portfolio manager managing around 600 million in assets for World Fund.\n"}
{"prompt": "What was the first company that the speaker and their colleagues started? \n\n###\n\n", "completion": " uuid: 11354404209 The speaker and their colleagues started their first company called Entire where they were helping companies hire technically with a talent.\n"}
{"prompt": "What is the goal of True Foundry? \n\n###\n\n", "completion": " uuid: 11354404209 The goal of True Foundry is to help companies speed up their machine learning pipelines and make it easier for developers to deploy models fast while providing automated monitoring and the entire right security framework.\n"}
{"prompt": "What is Pegas AI infrastructure used for? \n\n###\n\n", "completion": " uuid: 11354404209 Pegas AI infrastructure is primarily used for marketing and customer service, and also optimization of business process automation.\n"}
{"prompt": "How big is the data science team at Pega? \n\n###\n\n", "completion": " uuid: 11354404209 The engineering and data science team together could be around 50 people.\n"}
{"prompt": "Who does Pega primarily target for their cloud instances? \n\n###\n\n", "completion": " uuid: 11354404209 Pega primarily targets large and data sensitive companies like banks for their cloud instances.\n"}
{"prompt": "How does Pega reduce latency in their ML Ops for real time marketing use cases? \n\n###\n\n", "completion": " uuid: 11354404209 Pega is trying to see if they can provision Sage Maker into a VPC and then have that latency reduced down to sub ten milliseconds.\n"}
{"prompt": "What is the goal of enabling business users in building models? \n\n###\n\n", "completion": " uuid: 11354404209 The goal is to remove data scientists from the picture and enable business users to build models easily by pointing out the data and what they want to predict.\n"}
{"prompt": "What are some benefits of using the platform for running jobs? \n\n###\n\n", "completion": " uuid: 11189840489 Saves infrastructure costs, provides remote logs for visualization, displays system level metrics, and provides version control for deployments.\n"}
{"prompt": "Can you run jobs locally instead of using the platform's machines? \n\n###\n\n", "completion": " uuid: 11189840489 Yes, it is possible to run jobs on your local machine and track results on the dashboard.\n"}
{"prompt": "Is the platform a good fit for every use case? \n\n###\n\n", "completion": " uuid: 11189840489 No, the platform is being used selectively to ensure immediate value is added for users.\n"}
{"prompt": "What kind of companies are targeted by the platform? \n\n###\n\n", "completion": " uuid: 11189840489 Companies facing challenges with their current solution or have a need for a new solution.\n"}
{"prompt": "What is the purpose of the newsletter? \n\n###\n\n", "completion": " uuid: 11189840489 To provide updates on the company's developments and to share relevant content with readers.\n"}
{"prompt": "Can you provide an example of a possible newsletter topic? \n\n###\n\n", "completion": " uuid: 11189840489 The use cases of OCR text summarization as a team-developed software.\n"}
{"prompt": "What is the only way to scale the data according to the context? \n\n###\n\n", "completion": " uuid: 11185249388 Cache the data.\n"}
{"prompt": "What service is used for caching the data for runtime? \n\n###\n\n", "completion": " uuid: 11185249388 Redis Elasticsearch.\n"}
{"prompt": "What type of server layer is used for the models? \n\n###\n\n", "completion": " uuid: 11185249388 Fast API.\n"}
{"prompt": "Has the team tried using any model servers like TF Server or Todd Serve? \n\n###\n\n", "completion": " uuid: 11185249388 No, the team has not tried using any model servers.\n"}
{"prompt": "How is the machine learning team structured? \n\n###\n\n", "completion": " uuid: 11185249388 There is a DevOps team that handles network and container setup, data science team that does ML Ops with the help from the DevOps and data science vertical teams.\n"}
{"prompt": "What are the steps involved in building a custom model at DMV? \n\n###\n\n", "completion": " uuid: 11185249388 Select a model type, select what aspect of risk you are looking for, provide the required data from s3 bucket or purchased DNB data, wait for the model to be deployed and get data science metrics to evaluate the model.\n"}
{"prompt": "What is the cost for operationalizing machine learning for a startup like Netomi? \n\n###\n\n", "completion": " uuid: 11185249388 No more than $100,000 for two people in India.\n"}
{"prompt": "What is the main source of revenue for the product according to the context? \n\n###\n\n", "completion": " uuid: 11185249388 The real money is in the peak of a database and insurance companies who may want to pay for building their own models using DMV data and deploying it on the DMV site.\n"}
{"prompt": "What is the priority for the company according to Bobby? \n\n###\n\n", "completion": " uuid: 11185249388 The priority is to build models and think about new ways of doing things.\n"}
{"prompt": "What is Bobby's feedback on potentially working with tools to optimize dev workflows? \n\n###\n\n", "completion": " uuid: 11185249388 It has not been a priority currently but he would be happy to provide feedback and try it out later.\n"}
{"prompt": "What is the speaker's location? \n\n###\n\n", "completion": " uuid: 11575824756 The speaker is in Fenton, Michigan.\n"}
{"prompt": "What is the speaker currently doing? \n\n###\n\n", "completion": " uuid: 11575824756 The speaker is traveling to India.\n"}
{"prompt": "What is the speaker's role at Groundspeed? \n\n###\n\n", "completion": " uuid: 11575824756 The speaker is a data scientist at Groundspeed and is involved in ML engineering and ML apps.\n"}
{"prompt": "How does True Foundry differentiate from ML Flow? \n\n###\n\n", "completion": " uuid: 11575824756 True Foundry focuses on the deployment aspect of ML models, manages infrastructure, and handles inference monitoring, while ML Flow's core strength lies in experiment tracking and project packaging.\n"}
{"prompt": "How is the Data Science team organized at Groundspeed? \n\n###\n\n", "completion": " uuid: 11575824756 The Data Science team consists of one person, the speaker, who works on enhancing the extracted data and building predictive models.\n"}
{"prompt": "How are the models deployed and hosted? \n\n###\n\n", "completion": " uuid: 11575824756 The models are containerized and deployed as separate endpoints on Kubernetes. The Data Science team is responsible for creating the helm charts and making the PRs that go into the helm repository, while DevOps manages the deployment process and infrastructure.\n"}
{"prompt": "What are some pain points in deploying models? \n\n###\n\n", "completion": " uuid: 11575824756 One pain point is transitioning from developing models locally to deploying them, which involves translating code from notebooks into PY files and incorporating it into the service. The team is working on alleviating this pain point with a pipe approach that involves packaging the model code into pipi packages.\n"}
{"prompt": "What is the main focus of this demo? \n\n###\n\n", "completion": " uuid: 10455870769 The main focus of this demo is on the deployment piece of the machine learning workflow.\n"}
{"prompt": "What are the two ways in which people typically deploy their models? \n\n###\n\n", "completion": " uuid: 10455870769 People typically deploy their models either as an API entrypoint or by dumping the results to a database.\n"}
{"prompt": "What is the core problem that Truefoundry is trying to solve? \n\n###\n\n", "completion": " uuid: 10455870769 Truefoundry is trying to solve the problem of managing all aspects of model deployment in one place.\n"}
{"prompt": "How long would it typically take to launch a feature change on Truefoundry? \n\n###\n\n", "completion": " uuid: 10455870769 It would typically take around 15-20 minutes to launch a feature change on Truefoundry as long as it's not a completely new data pipeline.\n"}
{"prompt": "Is infrastructure a concern for users of Truefoundry? \n\n###\n\n", "completion": " uuid: 10455870769 No, infrastructure is not a concern as Truefoundry offers abstractions that allow users to move much faster than they would by operating raw Kubernetes.\n"}
{"prompt": "What is the front end feature? \n\n###\n\n", "completion": " uuid: 10611764602 The context does not provide a clear answer.\n"}
{"prompt": "What kind of productionization is being discussed in the context? \n\n###\n\n", "completion": " uuid: 10611764602 Productionization using sage maker endpoints.\n"}
{"prompt": "Has the team faced any challenges in serving the front end system? \n\n###\n\n", "completion": " uuid: 10611764602 Yes, challenges like making the model responsive and optimizing other factors.\n"}
{"prompt": "What is the desired response time for front end system? \n\n###\n\n", "completion": " uuid: 10611764602 The desired response time is within milliseconds.\n"}
{"prompt": "What is the performance goal for the front end facing feature? \n\n###\n\n", "completion": " uuid: 10611764602 The goal is to achieve a P9 of 45 milliseconds.\n"}
{"prompt": "Who does the deployment for the front end facing feature? \n\n###\n\n", "completion": " uuid: 10611764602 The ML engineer handles the deployment.\n"}
{"prompt": "Is there a custom deployment made for each model? \n\n###\n\n", "completion": " uuid: 10611764602 No, the deployments are standard.\n"}
{"prompt": "What is the data platform journey of the ML and data science team described as? \n\n###\n\n", "completion": " uuid: 10611764602 The team is at a stage of proving the ROI and transitioning into optimization.\n"}
{"prompt": "What is the difference between Truefoundry and other ML platform offerings? \n\n###\n\n", "completion": " uuid: 10611764602 The differentiation lies in the developer experience, cost advantages, and ability to be multicloud.\n"}
{"prompt": "Where is the Truefoundry platform hosted? \n\n###\n\n", "completion": " uuid: 10611764602 The platform can be hosted on Truefoundry's own infrastructure or in the customer's VPC.\n"}
{"prompt": "What is Airflow and have you used it before? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker says they haven't used Airflow.\n"}
{"prompt": "What did the platform team do to make it self-served and how long did it take them? \n\n###\n\n", "completion": " uuid: 10784174762 The platform team laid out best practices to make it self-served and it took them 1-2 months with a team of 2-3 engineers.\n"}
{"prompt": "What is the purpose of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The purpose of the platform is to provide a self-service platform for companies from day one, so they don't have to build it.\n"}
{"prompt": "What is the admin level view of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The admin level view of the platform allows you to allocate different parts of the cluster, limit workspaces, and see who is using what, as well as providing cost estimates and insights.\n"}
{"prompt": "What is the developer's view of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The developer's view of the platform allows them to access a service catalog, trigger jobs, view logs and metrics, and create new services or jobs by choosing a workspace and repository.\n"}
{"prompt": "What frameworks are supported by the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The platform supports all frameworks, including Psychedel and Python, and can automatically Dockerize services if necessary.\n"}
{"prompt": "What other features are being added to the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The platform will support model deployment, GPU acceleration, a choice of machines and deployment strategies, and pipeline deployment.\n"}
{"prompt": "What is the speaker's goal for working with other companies? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker wants to work with more advanced tech companies to mature the platform further and improve it.\n"}
{"prompt": "What questions does the speaker suggest asking to evaluate the usefulness of the platform? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker suggests asking about pain points, time and effort needed to switch to the platform, and whether it is the right time to experiment with something new versus focusing on other priorities.\n"}
{"prompt": "What is the next step for the speaker and the team at the end of the conversation? \n\n###\n\n", "completion": " uuid: 10784174762 The speaker will arrange a follow-up meeting with the lead engineering and DevOps person on the team, and would like to learn about more pain points for the ML team to better present the platform.\n"}
{"prompt": "Where is the speaker based? \n\n###\n\n", "completion": " uuid: 12428314989 The speaker is based in Santa Clara.\n"}
{"prompt": "What time is it? \n\n###\n\n", "completion": " uuid: 12428314989 It's 1130.\n"}
{"prompt": "Why did the speaker choose that time? \n\n###\n\n", "completion": " uuid: 12428314989 It's the only time the speaker could find since the others are in IST.\n"}
{"prompt": "Where are the others based? \n\n###\n\n", "completion": " uuid: 12428314989 The others are based in India.\n"}
{"prompt": "What are the two major parts that the speaker wants to cover on the call? \n\n###\n\n", "completion": " uuid: 12428314989 The two major parts that the speaker wants to cover on the call are understanding the ML structure at Docusign and discussing multi cloud.\n"}
{"prompt": "What is the product that the speaker's team has built? \n\n###\n\n", "completion": " uuid: 12428314989 The product that the speaker's team has built is called Optical Foundry.\n"}
{"prompt": "What is the goal of Optical Foundry? \n\n###\n\n", "completion": " uuid: 12428314989 The goal of Optical Foundry is to create abstractions for developers so that they can do everything necessary to take models that they are training on local notebooks or wherever to actual real use case.\n"}
{"prompt": "Where is the speaker's startup registered? \n\n###\n\n", "completion": " uuid: 12428314989 The speaker's startup is registered in the US.\n"}
{"prompt": "Where is most of the team located? \n\n###\n\n", "completion": " uuid: 12428314989 Most of the team is located in India.\n"}
{"prompt": "Why is most of the team located in India? \n\n###\n\n", "completion": " uuid: 12428314989 Tech hiring is cheaper in India.\n"}
{"prompt": "Has the speaker ever seen a business reason to support multicloud? \n\n###\n\n", "completion": " uuid: 12428314989 No, the speaker has never seen a business reason to support multicloud.\n"}
{"prompt": "What is the reason that companies would rather not use a managed infra offering? \n\n###\n\n", "completion": " uuid: 12428314989 Most companies prefer to have their systems internally and not be dependent on a managed infra offering.\n"}
{"prompt": "What is the market like for Kubernetes adoption in India? \n\n###\n\n", "completion": " uuid: 12428314989 The market for Kubernetes adoption in India is quite behind, with very few companies adopting it.\n"}
{"prompt": "What is the goal of Banadia? \n\n###\n\n", "completion": " uuid: 12428314989 The goal of Banadia is to take care of everything in terms of the platform image so that the system can be deployed to any client.\n"}
{"prompt": "What is the charter for Junior? \n\n###\n\n", "completion": " uuid: 10611816710 To provide end-to-end infrastructure support for the ML/AI team at Junior, which involves improving the developer experience, post-deploy monitoring and selecting training sets, platformizing all of their orgs, optimizing the cost to run the models, and building a model store for all data points.\n"}
{"prompt": "What are some challenges faced by Junior in terms of their ML/AI processes? \n\n###\n\n", "completion": " uuid: 10611816710 Some challenges faced by Junior include improving the developer experience, building a model store, optimizing the cost to run models, and monitoring the image-based models.\n"}
{"prompt": "What is the company's current usage of Sage Maker? \n\n###\n\n", "completion": " uuid: 10611816710 The company is heavily using Sage Maker operators, which includes training operators and processing operators.\n"}
{"prompt": "What is the purpose of Sage Maker Operators? \n\n###\n\n", "completion": " uuid: 10611816710 Sage Maker Operators are used by the company to train and process their models quickly and efficiently.\n"}
{"prompt": "What is the objective of building a model store? \n\n###\n\n", "completion": " uuid: 10611816710 The objective of building a model store is to collect all the required data points in one place and derive model lifecycle insights, version updates, and model evaluations results.\n"}
{"prompt": "What is the biggest challenge in getting everyone on the same platform at Junior? \n\n###\n\n", "completion": " uuid: 10611816710 The biggest challenge is to convince everyone to switch to a unified platform instead of using their own existing infrastructures and processes.\n"}
{"prompt": "What are the challenges in monitoring image-based models and how can they be solved? \n\n###\n\n", "completion": " uuid: 10611816710 It is difficult to detect drifts in image-based models due to camera changes. Research effort is being made to automate this process. Solutions can also involve optimizing models for specific hardware like Arm and incorporating signals to automate retraining pipelines.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12339399214 To discuss Truefoundry, Nick's background and the challenges Dr. Anish is facing in data science at Doctor Edison.\n"}
{"prompt": "What is Nick's background? \n\n###\n\n", "completion": " uuid: 12339399214 Nick comes from a machine learning background, used to be at Facebook where he built out a lot of conversational AI models for them. Prior to that, he was at a startup called Reflection based in the Bay Area. And he did his masters at UC Berkeley and undergrad there too. Between quitting Facebook and starting Truefoundry, the three of them did one more startup in the talent space that got acquired by Info Age.\n"}
{"prompt": "What challenges is Doctor Edison facing with regards to data science? \n\n###\n\n", "completion": " uuid: 12339399214 Availability of clean data which has been some bit of barrier for them to deploy a few of these models as well. Governance with regards to reviewing the efficacy of the models and improving the models over time.\n"}
{"prompt": "What is Truefoundry? \n\n###\n\n", "completion": " uuid: 12339399214 Truefoundry is a platform to help analytics and machine learning data science teams to operationalize models and their data pipelines.\n"}
{"prompt": "What is the cost of setting up a POC with Truefoundry? \n\n###\n\n", "completion": " uuid: 12339399214 $5,000.\n"}
{"prompt": "How can they set up a POC with Truefoundry? \n\n###\n\n", "completion": " uuid: 12339399214 They need to define a scope of the problem and then they can take one of two directions \u2013 either a lightweight POC or a more integral POC with their DevOps team.\n"}
{"prompt": "How is Truefoundry different from DataRobot? \n\n###\n\n", "completion": " uuid: 12339399214 Truefoundry has built out a tool where they can take the data that is segmenting it and working out what are the most common failure areas in the study. So they can recommend different problem areas and corresponding fixes that helps improve the model. Some part of this has already automated in the tool that data scientists can do by themselves.\n"}
{"prompt": "What is the cost of doing a POC with a very small check? \n\n###\n\n", "completion": " uuid: 12339399214 It doesn't matter so long as there is one check associated with the POC.\n"}
{"prompt": "What is the next step for Dr. Anish? \n\n###\n\n", "completion": " uuid: 12339399214 He will discuss the scope of the POC with his data science team and bring it up to the leadership team to figure out logistics. He will also meet with Nick in-person while he is in Hyderabad.\n"}
{"prompt": "Can you hear me well? \n\n###\n\n", "completion": " uuid: 12428091307 Yeah, I can hear you.\n"}
{"prompt": "Who is Nikon and why did he avoid the call? \n\n###\n\n", "completion": " uuid: 12428091307 It is not mentioned.\n"}
{"prompt": "Who is Jimmy and where does he work? \n\n###\n\n", "completion": " uuid: 12428091307 Jimmy works in the founder's office at 200 and has been there for about six months. He mostly works in product and customer development and sales. Before this, he worked at McKenzie as a management consultant and did machine learning in IT. He is mostly interested in NLP.\n"}
{"prompt": "What is the central team structure of data science at Proof? \n\n###\n\n", "completion": " uuid: 12428091307 There is no central team for data science at Proof. The team is mostly associated with the business units and the use cases that have been identified. Each use case has a separate engineering team associated with it.\n"}
{"prompt": "What are the two main themes of business use cases at Proof and are they product specific? \n\n###\n\n", "completion": " uuid: 12428091307 The two main themes are process discovery and document processing. These come under one substructure, but each of them has a separate engineering team associated with them. They are product lines and features.\n"}
{"prompt": "What is the True Foundry platform and what is their main competency? \n\n###\n\n", "completion": " uuid: 12428091307 The True Foundry platform is an ML platform that is cloud agnostic and they specialize in model deployment and everything after that, including scaling, EB testing, and monitoring models in production using data drift tracking and concept drift. They also provide a unified framework to deploy models across clouds.\n"}
{"prompt": "What are some of the core competencies that True Foundry has over open source ML platforms like ML Flow? \n\n###\n\n", "completion": " uuid: 12428091307 Some of the competencies that True Foundry has over open source platforms include role-based access control, secret management, security layer API authentication, and scaling and provisioning resources for managing Kubernetes for the scaling or parallelization of training with GPUs.\n"}
{"prompt": "Does Proof provide a self-hosted version of their platform for clients who are not comfortable sharing their data? \n\n###\n\n", "completion": " uuid: 12428091307 No, Proof does not provide a self-hosted version of their platform. They provide pre-trained models for clients who are not comfortable with sharing their data.\n"}
{"prompt": "How does Proof automate the processes for their clients using robotic processor automation? \n\n###\n\n", "completion": " uuid: 12428091307 Proof automates processes like manual data gathering and processing for tasks like onboarding employees or verification of uploaded files against data using process discovery via screen recording on a laptop.\n"}
{"prompt": "How does Proof deal with data from clients who don't want to share it? \n\n###\n\n", "completion": " uuid: 12428091307 For clients who don't want to share their data, Proof provides a local deployment of their software on the client's system and sends pre-trained models and bots back to the client for inference only. There is no continuous training or retraining happening from the client's side.\n"}
{"prompt": "Who is speaking in the conversation? \n\n###\n\n", "completion": " uuid: 12336402979 Lida and the other person (not specified by name) are speaking.\n"}
{"prompt": "Where is Lida spending some time now? \n\n###\n\n", "completion": " uuid: 12336402979 Lida is spending some time in India.\n"}
{"prompt": "What was the other person's experience at Kora? \n\n###\n\n", "completion": " uuid: 12336402979 It is not stated in the context.\n"}
{"prompt": "What cloud setup does Kora use? \n\n###\n\n", "completion": " uuid: 12336402979 Kora mostly uses AWS, but has a small footprint on GCP.\n"}
{"prompt": "What is the reason Kora is using GCP? \n\n###\n\n", "completion": " uuid: 12336402979 Kora uses GCP for training a particular model using TPU and for using some of Google's ML API for image and text processing.\n"}
{"prompt": "What do they use for ML workflow orchestration? \n\n###\n\n", "completion": " uuid: 12336402979 They mostly use their in-house platform built on Kubernetes.\n"}
{"prompt": "Do they use Qflow? \n\n###\n\n", "completion": " uuid: 12336402979 No, they don't use Qflow.\n"}
{"prompt": "What do they use instead of Qflow? \n\n###\n\n", "completion": " uuid: 12336402979 They have their own in-house platform built on Kubernetes.\n"}
{"prompt": "What language do they use for building their oxidation workflow? \n\n###\n\n", "completion": " uuid: 12336402979 They use Python, which is the preferred language in the ML domain.\n"}
{"prompt": "Do they provide a UI for developers to visualize the logs? \n\n###\n\n", "completion": " uuid: 12336402979 Developers can view the logs from the airflow UI.\n"}
{"prompt": "What is the point made regarding an alternative NIC being developed? \n\n###\n\n", "completion": " uuid: 12044330588 That the National Security Center or government is considering coming up with an alternative NIC called Digital something.\n"}
{"prompt": "What is the main issue with deployment environments for models? \n\n###\n\n", "completion": " uuid: 12044330588 The deployment environment cannot be controlled, even if it's on the cloud; making it difficult to ensure that models will work on specific devices.\n"}
{"prompt": "What is the goal of the reference ML platform being developed? \n\n###\n\n", "completion": " uuid: 12044330588 To provide a base of integrations for customers, ensuring reproducibility, auditability and model observability, tracking and metric logging.\n"}
{"prompt": "What are some challenges associated with deploying models across different cloud platforms? \n\n###\n\n", "completion": " uuid: 12044330588 Coordination with the government agency's tech stack, the absence of self-managed clusters or Kubernetes clusters, and difficulty in getting access to the necessary clusters.\n"}
{"prompt": "What is the current approach to developing environments for machine learning scientists? \n\n###\n\n", "completion": " uuid: 12044330588 They take a dedicated compute for a project and spin it up for the project's lifetime.\n"}
{"prompt": "What was the agenda of the call? \n\n###\n\n", "completion": " uuid: 12150677061 To discuss the sales outreach and get feedback from Amit.\n"}
{"prompt": "Who are the target personas for the platform at True Foundry? \n\n###\n\n", "completion": " uuid: 12150677061 Data scientists and ML developers within a company, however, the decision maker is usually the head of the platform or data engineering team.\n"}
{"prompt": "What are the two segments of companies True Foundry is targeting? \n\n###\n\n", "completion": " uuid: 12150677061 Upper midmarket (100 million to 1 billion in revenues) and enterprises (1 billion+ in revenues), both of which tend to invest in ML.\n"}
{"prompt": "What is the primary channel used for outreach at True Foundry? \n\n###\n\n", "completion": " uuid: 12150677061 LinkedIn.\n"}
{"prompt": "What is Amit's advice to Anurag? \n\n###\n\n", "completion": " uuid: 12150677061 To study the zero to one sales approach of companies similar to True Foundry, such as Cubo DRUMO, Neo, four J data bricks, and reach out to former employees for their insights.\n"}
{"prompt": "What was the reason for being on mute during the call? \n\n###\n\n", "completion": " uuid: 10097842831 In case IBM was audible.\n"}
{"prompt": "Was the person audible during the call? \n\n###\n\n", "completion": " uuid: 10097842831 Yes.\n"}
{"prompt": "Where is the person based out of? \n\n###\n\n", "completion": " uuid: 10097842831 They are based in Singapore.\n"}
{"prompt": "What is the main focus of Turtlemint? \n\n###\n\n", "completion": " uuid: 10097842831 It is a fintech company primarily focusing on insure tech.\n"}
{"prompt": "How big is the data science team at Turtlemint? \n\n###\n\n", "completion": " uuid: 10097842831 It is a single digit team, less than ten people.\n"}
{"prompt": "What technology stack does Turtlemint use for machine learning? \n\n###\n\n", "completion": " uuid: 10097842831 They use Kubernetes for deployment and are primarily on the AWS stack.\n"}
{"prompt": "How is model deployment handled at Turtlemint? \n\n###\n\n", "completion": " uuid: 10097842831 Deployment is handled using Kubernetes pods and services.\n"}
{"prompt": "Does Turtlemint use Sage Maker for machine learning? \n\n###\n\n", "completion": " uuid: 10097842831 Not yet, but they have tried it in the past and may combine it with ML flow in the future.\n"}
{"prompt": "What challenges might arise as Turtlemint's machine learning processes grow? \n\n###\n\n", "completion": " uuid: 10097842831 ML observability may become a crucial challenge in the future as operations become more complex.\n"}
{"prompt": "What did he find interesting? \n\n###\n\n", "completion": " uuid: 12336403532 The crosscloud hypothesis.\n"}
{"prompt": "Who are Nick and Abhishek and what do they do? \n\n###\n\n", "completion": " uuid: 12336403532 Nick and Abhishek are co-founders at Truefoundry. Nick has a machine learning background and has worked with Facebook and Reflection. Abhishek graduated from It and worked in Facebook before doing a startup of his own.\n"}
{"prompt": "What is Frank's current role at VMware? \n\n###\n\n", "completion": " uuid: 12336403532 Frank is a chief technologist at VMware and does outbound work such as presenting at conferences and talking to customers. He also helps with strategies for patent applications and talks to engineers and principal engineers to create a better product or strategize in a better way. His main focus areas are resource management and machine learning.\n"}
{"prompt": "Which cloud platforms does VMware use? \n\n###\n\n", "completion": " uuid: 12336403532 VMware uses primarily AWS, Google, and Azure for their clouds as well as their own analytics platform that runs internally.\n"}
{"prompt": "Does VMware use Kubernetes? \n\n###\n\n", "completion": " uuid: 12336403532 VMware uses Tanzu internally for Kubernetes, but they also allow other Kubernetes platforms on top of their hypervisor. Frank also mentioned that data scientists themselves prefer Docker containers over Kubernetes.\n"}
{"prompt": "Is there a common engineering layer that spans across different business units? \n\n###\n\n", "completion": " uuid: 12336403532 No, each business unit at VMware has their own goals and deliverables, and they use their own sets of tools. There is an office of the CTO that communicates inter business units for a common strategy.\n"}
{"prompt": "Does VMware have a machine learning platform team for their business units? \n\n###\n\n", "completion": " uuid: 12336403532 No, there isn't a machine learning platform team at VMware for their business units. However, they have specific services like Wavefront that data scientists can use.\n"}
{"prompt": "Should we mail them? \n\n###\n\n", "completion": " uuid: 11656830384 Yeah did already.\n"}
{"prompt": "What did the person say when they couldn't hear? \n\n###\n\n", "completion": " uuid: 11656830384 Yeah, I'm saying I mailed him already.\n"}
{"prompt": "What did someone ask Chinmay to do? \n\n###\n\n", "completion": " uuid: 11656830384 Can you quickly share a couple of questions that you are asking on the monitoring thesis dockingba board rest or the domain directly to you or in the dock, whatever.\n"}
{"prompt": "What are some of the questions Chinmay was asked to share? \n\n###\n\n", "completion": " uuid: 11656830384 What is the current way? What is the change that we will bring sikh MATLAB what is the change in their life that we'll bring with our product or what is the value that we're seeing?\n"}
{"prompt": "What is the problem they're trying to solve for customers in terms of model training? \n\n###\n\n", "completion": " uuid: 11656830384 People would keep retraining models even if it's not necessary or people would just not retrain. Assuming the data is not drifted but the data has drifted basically take care of housing use case how frequently should we retrain the model?\n"}
{"prompt": "What is the second idea they have to solve for model performance regression? \n\n###\n\n", "completion": " uuid: 11656830384 just generally detecting your model degradation basically, right?\n"}
{"prompt": "What is the third thing they're working on for model performance monitoring? \n\n###\n\n", "completion": " uuid: 11656830384 generally if you think about the overall model performance monitoring most of the companies set up an engaging statement like model performance is like you do like an offline evaluation and online joy model performance real time there's usually no performance tracking statement just. Go out of performance.\n"}
{"prompt": "What is the use case for the drift problem that is important to solve? \n\n###\n\n", "completion": " uuid: 11656830384 fraud detection.\n"}
{"prompt": "What is the target customer segment for the product? \n\n###\n\n", "completion": " uuid: 11656830384 consumer focused companies and large enterprises.\n"}
{"prompt": "What is the purpose of creating a template? \n\n###\n\n", "completion": " uuid: 11656830384 to help differentiate the exact customer persona that they are trying to target.\n"}
{"prompt": "What is the platform built using? \n\n###\n\n", "completion": " uuid: 12044331076 The platform is built using Kubernetes, Argo CD, and various integrations such as Streamlit and Jupiter Notebook.\n"}
{"prompt": "How do data scientists deploy models using the platform? \n\n###\n\n", "completion": " uuid: 12044331076 Data scientists can deploy models using a Python SDK or a UI that allows them to click a button and deploy the model for specific use cases like cities or fleets of cars.\n"}
{"prompt": "What kind of ingresses do you use for real-time models? \n\n###\n\n", "completion": " uuid: 12044331076 We use an ingress layer to forward traffic to the thousands of spots running on Kubernetes, allowing data scientists to deal with real-time models in a more efficient manner.\n"}
{"prompt": "How do you manage resource requirements for models of varying intensity? \n\n###\n\n", "completion": " uuid: 12044331076 The cluster is managed by the infrastructure team, but the permissions to play around with the clusters are given to the data scientists. Horizontal port scalar is used to create scale based on CPU and memory usage.\n"}
{"prompt": "How is permission control managed for different users and their respective projects? \n\n###\n\n", "completion": " uuid: 12044331076 The platform has authentication and authorization integrated into the UI. Data scientists log in with Open ID connect and are given a guest role. Permissions are elevated based on project assignments and data set ownership.\n"}
{"prompt": "What are the core problems the company intends to solve in the future? \n\n###\n\n", "completion": " uuid: 12044331076 The company is currently focused on the adoptibility of the new platform. Future plans include trip detection, hyperparameter tuning, and model monitoring, all of which are still in the planning phase.\n"}
{"prompt": "What is Truefoundry's vision? \n\n###\n\n", "completion": " uuid: 12044331076 Truefoundry was developed to solve operationalization problems surrounding machine learning models. After talking to various companies, the team realized that only a few dozen companies in the world could afford to build the kind of platform they were building.\n"}
{"prompt": "What is the process for deploying machine learning models at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Build code in SAS or Python and use a converter to convert the code into Java code. The code is then deployed and results are compared for validation and testing.\n"}
{"prompt": "What is the split between the data science team and the data engineering team at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 For every data scientist, Lending Club has three engineers.\n"}
{"prompt": "What would be done with extra data scientists on the team? \n\n###\n\n", "completion": " uuid: 11564066567 The extra data scientists would be put towards the marketing side of things to find ways for things like multitouch attribution.\n"}
{"prompt": "How frequently are the models updated at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 The models are updated at an annual view for the credit side and every six months for the marketing side.\n"}
{"prompt": "Is model explainability a concern at Lending Club and if so, how is it handled? \n\n###\n\n", "completion": " uuid: 11564066567 Model explainability is not a concern because tree-based models are easy to explain. The decision tree nodes have approved the client outcomes.\n"}
{"prompt": "What are some of the tools used for experiment tracking and deployment monitoring at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Optimize and Heap are used for A/B testing and session tracking. All the tools are on the cloud, stored on AWS Redshift.\n"}
{"prompt": "What is the process for monitoring data drift at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Data drift is checked every month by looking at the production output. If the drift is outside of the range, the previous version is reverted back to and root cause analysis is done.\n"}
{"prompt": "How did the founders decide to start True Foundry? \n\n###\n\n", "completion": " uuid: 11564066567 One founder experienced the problem of hiring and started a company to solve it. While building that startup, he came across the problem of machine learning model building and deployment, which led to the creation of True Foundry.\n"}
{"prompt": "What motivated Ravi to leave his job at McKinsey and join an early stage startup? \n\n###\n\n", "completion": " uuid: 11564066567 Ravi was interested in combining his interest in machine learning with his business expertise from his time at McKinsey.\n"}
{"prompt": "Can Ravi make introductions to his network for True Foundry? \n\n###\n\n", "completion": " uuid: 11564066567 Ravi suggests scanning his LinkedIn network and making a list of cold leads to approach, from which he can make a warm introduction.\n"}
{"prompt": "What is the context about? \n\n###\n\n", "completion": " uuid: 10245510764 A conversation between a group of people discussing an ML platform\n"}
{"prompt": "What is the name of the ML platform being discussed? \n\n###\n\n", "completion": " uuid: 10245510764 Truefoundry\n"}
{"prompt": "Where is the speaker currently located? \n\n###\n\n", "completion": " uuid: 10245510764 Indonesia\n"}
{"prompt": "Where will the speaker be going back to after three weeks? \n\n###\n\n", "completion": " uuid: 10245510764 South Africa\n"}
{"prompt": "Who is Uri? \n\n###\n\n", "completion": " uuid: 10245510764 One of their ML engineers\n"}
{"prompt": "What are they planning to show Alyssa? \n\n###\n\n", "completion": " uuid: 10245510764 A demo of the Truefoundry platform\n"}
{"prompt": "What is the focus of the platform? \n\n###\n\n", "completion": " uuid: 10245510764 Deployment side of things\n"}
{"prompt": "What are some of the features that are still in development? \n\n###\n\n", "completion": " uuid: 10245510764 A lot of features and other things\n"}
{"prompt": "What can be seen in the integration tab? \n\n###\n\n", "completion": " uuid: 10245510764 Clusters that can be connected to\n"}
{"prompt": "What are workspaces? \n\n###\n\n", "completion": " uuid: 10245510764 Separations within the cluster where you can deploy different things\n"}
{"prompt": "What is the importance of resource limits? \n\n###\n\n", "completion": " uuid: 10245510764 To make sure that a particular service does not take up more than a certain amount of the resource that are available\n"}
{"prompt": "How can a job be triggered? \n\n###\n\n", "completion": " uuid: 10245510764 Manually or on a schedule\n"}
{"prompt": "What is a function service? \n\n###\n\n", "completion": " uuid: 10245510764 It takes any function and converts it to API\n"}
{"prompt": "What is Iris data set? \n\n###\n\n", "completion": " uuid: 10245510764 A data set that contains four parameters\n"}
{"prompt": "What is ML Foundry? \n\n###\n\n", "completion": " uuid: 10245510764 A library from Autofound\n"}
{"prompt": "What is the log model feature of ML Foundry? \n\n###\n\n", "completion": " uuid: 10245510764 To log model objects so that you don't have to write custom codes to store your artifacts and can just use the log model command.\n"}
{"prompt": "What is the platform that is being discussed? \n\n###\n\n", "completion": " uuid: 11354392885 The platform being discussed is a Kubernetes based ML deployment platform.\n"}
{"prompt": "What is auto node provisioning? \n\n###\n\n", "completion": " uuid: 11354392885 Auto node provisioning is a recommended feature on AWS and GCP where a node will be automatically joined to the cluster when someone tries to deploy on a specific cluster.\n"}
{"prompt": "What is the reason for reusing hardware in their approach? \n\n###\n\n", "completion": " uuid: 11354392885 They reuse their hardware again and again to avoid incurring costs for provisioning new hardware every time. They have found that GCP's pay on demand provisioning is not reliable for GPUs.\n"}
{"prompt": "What is the reason for using triton as the multimodal server? \n\n###\n\n", "completion": " uuid: 11354392885 Triton is the only open source multimodal server available that provides efficient deployment and inference graph.\n"}
{"prompt": "What is OCR? \n\n###\n\n", "completion": " uuid: 11354392885 OCR stands for Optical Character Recognition, and they have recently been working on this model for efficient deployment on their platform.\n"}
{"prompt": "What did Peter mention about being late? \n\n###\n\n", "completion": " uuid: 10881877574 Running two minutes late.\n"}
{"prompt": "What was the age of Peter's baby? \n\n###\n\n", "completion": " uuid: 10881877574 Four months.\n"}
{"prompt": "How many kids does the person speaking to Peter have? \n\n###\n\n", "completion": " uuid: 10881877574 Three.\n"}
{"prompt": "What was the person speaking to Peter's previous work experience? \n\n###\n\n", "completion": " uuid: 10881877574 Leading one of the conversation AI efforts at Poland and building personalization algorithms for the ecommerce industry at a startup called Reflection.\n"}
{"prompt": "What is the goal of the machine learning platform that Truefoundry is building? \n\n###\n\n", "completion": " uuid: 10881877574 To make it easy for internal platform teams to build on top of and scale up their platform while minimizing resources needed to continue building internal dev tooling.\n"}
{"prompt": "What are some challenges in machine learning experimentation that the person speaking to Peter mentioned? \n\n###\n\n", "completion": " uuid: 10881877574 Speed of testing models, visibility of experiments conducted, and iteration speed and quality.\n"}
{"prompt": "What is the person speaking to Peter's approach to reducing the cost of experimentation? \n\n###\n\n", "completion": " uuid: 10881877574 Building a platform that captures learnings and applies them from one project to the other while providing enough flexibility for teams to build whatever they want on top of the platform.\n"}
{"prompt": "What is the first thing that needs to be set up when using Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 The cluster setup.\n"}
{"prompt": "What types of machines can be added to a workspace? \n\n###\n\n", "completion": " uuid: 10443270777 CPU-based or GPU-based machines.\n"}
{"prompt": "What is the advantage of using Kubernetes in Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 You don't have to spin up clusters every time and can have a shared cluster.\n"}
{"prompt": "What is the difference between a service and a job in Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 A service is a long-running service API endpoint or model demo, while a job is a model training job or batch inference.\n"}
{"prompt": "How can a developer manage their applications in Truefoundry You? \n\n###\n\n", "completion": " uuid: 10443270777 They can manage their services, jobs, and deployed models with version control.\n"}
{"prompt": "Can a developer easily rollback to a previous version of a service? \n\n###\n\n", "completion": " uuid: 10443270777 Yes, with one click they can redeploy the previous version.\n"}
{"prompt": "What types of metrics and logs can a developer view for their service? \n\n###\n\n", "completion": " uuid: 10443270777 Metrics dashboard, log search filters, and log management.\n"}
{"prompt": "What types of models does Truefoundry You support and how are they deployed? \n\n###\n\n", "completion": " uuid: 10443270777 They support online inference models and batch offline modules. For offline modules, you run a service that pushes data to S3 and then stores the data in some database.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12362155036 To discuss about the startup in the ML infra domain.\n"}
{"prompt": "What is Nikunj's background? \n\n###\n\n", "completion": " uuid: 12362155036 He comes from a machine learning background and has worked in Facebook and a startup called Reflection prior to True foundry.\n"}
{"prompt": "What is Chinmay's role in True foundry? \n\n###\n\n", "completion": " uuid: 12362155036 He works in the founder's office and mainly helps with product sales and customer development.\n"}
{"prompt": "What is the structure of the machine learning team in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 The machine learning team is part of Merlin, which handles all the AI work in Zycus. It has AI, Java, UI and deployment teams along with product managers and data analyst team.\n"}
{"prompt": "What is the cloud setup in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 For lower environments like QC and release management environment, the data center in Mumbai is used. Staging and production environments are on AWS.\n"}
{"prompt": "Where is the data stored in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 Data is mostly stored in S3 and some data is also stored in MongoDB or SQL. They also have their own location like storage and data lake.\n"}
{"prompt": "Do they use Sagemaker in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 No, they do not use Sagemaker in Zycus as they prefer to use their own environment for their AI development.\n"}
{"prompt": "What is the deployment process for the models in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 The model is put into a repository, maintained with the model version and some configuration file. It then goes into the actual instances where it has to be used and before deployment, some benchmarking is done.\n"}
{"prompt": "Do they use any ML Ops tool in Zycus? \n\n###\n\n", "completion": " uuid: 12362155036 No, they do not use any ML Ops tool in Zycus as there is no expert in the company to start off with containerization for Docker and Kubernetes.\n"}
{"prompt": "What was the reason for Simon's absence? \n\n###\n\n", "completion": " uuid: 9984747349 Simon was in the hospital for something related to his baby for checkup treatment.\n"}
{"prompt": "What is the goal of the startup Netaling? \n\n###\n\n", "completion": " uuid: 9984747349 To make it simple for data scientists and ML engineers to deploy models to products in a faster way.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 9984747349 To understand Commerce IQ's ML stack and the challenges they face on a day to day basis.\n"}
{"prompt": "What is Commerce IQ's solution mostly based on? \n\n###\n\n", "completion": " uuid: 9984747349 Sage maker and they automate those pipelines.\n"}
{"prompt": "How do they store the model? \n\n###\n\n", "completion": " uuid: 9984747349 They store the model on S3.\n"}
{"prompt": "Is any of these models being used or called in real time? \n\n###\n\n", "completion": " uuid: 9984747349 No, they do a batch processing.\n"}
{"prompt": "How is the model improved in iterations? \n\n###\n\n", "completion": " uuid: 9984747349 By giving some manual inputs and there are clashes between the classification.\n"}
{"prompt": "How does Commerce IQ track models? \n\n###\n\n", "completion": " uuid: 9984747349 For the existing mature sales estimation model, they don't need to keep track. But for the classification model, they are making version two and will track them for improvement.\n"}
{"prompt": "What is the platform the speaker is introducing? \n\n###\n\n", "completion": " uuid: 9984747349 It is a platform to deploy models in various ways including endpoints, services and pipelines.\n"}
{"prompt": "Are both Pythonic and YML ways supported? \n\n###\n\n", "completion": " uuid: 9984747349 Yes, they are supported.\n"}
{"prompt": "What made you choose this problem statement to solve? \n\n###\n\n", "completion": " uuid: 12339422352 There were three events that led us to believing this problem is still unsolved. The first was building a horizontal level platform and realizing once a company goes beyond a certain scale in machine learning, things need to be platformized for efficiency reasons. The second was working at Facebook and noticing the amazing features of their platform that trivialised building, deploying, and maintaining models. The third was building our own machine learning models while doing another startup and realizing that doing it with existing tooling still involves a lot of pain and does not get far enough as machine learning matures. We believe it's important for machine learning to follow the same paradigm as other software in the long term and for good practices like version control and automatic rollbacks to be maintained.\n"}
{"prompt": "What is the direction in which you believe the problem has still not been solved? \n\n###\n\n", "completion": " uuid: 12339422352 We believe that machine learning needs to follow the same deployment paradigm as other software instead of a completely parallel setup. Also, good practices like version control and automatic rollbacks need to be maintained to avoid machine learning becoming unmanageable as it becomes more mainstream.\n"}
{"prompt": "What is the infra that here? \n\n###\n\n", "completion": " uuid: 12249609647 Probably they are using some challenges that they are facing.\n"}
{"prompt": "What are the challenges they are facing? \n\n###\n\n", "completion": " uuid: 12249609647 Ankit did not specify any challenges in particular.\n"}
{"prompt": "What are some of the use cases that Locus is focusing on? \n\n###\n\n", "completion": " uuid: 12249609647 The team is currently working on improving geocoding and have other use cases like transaction time, premium pricing, and value-based pricing.\n"}
{"prompt": "What is geocoding and what are some challenges in dealing with it? \n\n###\n\n", "completion": " uuid: 12249609647 Geocoding is converting textual address into latitude and longitude. It requires preprocessing like standardizing the address and spell correction.\n"}
{"prompt": "What is the team structure at Locus? \n\n###\n\n", "completion": " uuid: 12249609647 There are one to two data engineers, one data analyst, and six data scientists.\n"}
{"prompt": "What libraries and frameworks does the team primarily use? \n\n###\n\n", "completion": " uuid: 12249609647 The team primarily uses PyTorch.\n"}
{"prompt": "What is the data lake that Locus is using? \n\n###\n\n", "completion": " uuid: 12249609647 Locus is currently storing their data in S3 file storage, but they may explore using other tools in the future.\n"}
{"prompt": "Are the models primarily batch-based or real-time? \n\n###\n\n", "completion": " uuid: 12249609647 It depends on the use case, but the model can be used for both batch and real-time predictions.\n"}
{"prompt": "What type of data does Locus primarily work with? \n\n###\n\n", "completion": " uuid: 12249609647 Locus works primarily with structured data, although the address is the only unstructured data that they deal with.\n"}
{"prompt": "What problem is Truefoundry trying to solve with their platform approach? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry is trying to expedite the time to value from machine learning models so that they can deliver business impact more quickly.\n"}
{"prompt": "What approach is Truefoundry taking to build their platform? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry is taking a platform approach similar to what has been seen at Facebook and with other leaders outside of Facebook.\n"}
{"prompt": "What is the scope of the ML developer in the model development lifecycle? \n\n###\n\n", "completion": " uuid: 11984272003 The ML developer is responsible for playing around with the data, determining the domain knowledge, selecting which algorithm to use, and selecting which features to use.\n"}
{"prompt": "Where is Truefoundry available? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry is available in two modes: a public cloud mode for trying out the platform with publicly available data and a private cloud mode where the entire platform is deployed on the customer's cloud.\n"}
{"prompt": "Who manages Truefoundry's cloud operations? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry's managed service provider handles all cloud operations, including 24/7 support, infrastructure provisioning, and project management.\n"}
{"prompt": "What other potential ways of engagement does Truefoundry offer? \n\n###\n\n", "completion": " uuid: 11984272003 Truefoundry has on-boarded angel investors and is willing to share more details with interested parties. They are also willing to meet in person to discuss potential opportunities.\n"}
{"prompt": "What is the potential issue with the GPU and CPU usage when deploying services? \n\n###\n\n", "completion": " uuid: 10097873824 The GPU may consume more capacity compared to the CPU.\n"}
{"prompt": "What is the level of protection provided by the HTTP connection pool? \n\n###\n\n", "completion": " uuid: 10097873824 The HTTP connection pool provides some level of protection when setting up auto scaling.\n"}
{"prompt": "Which Framework is used for writing the rest service? \n\n###\n\n", "completion": " uuid: 10097873824 They have mostly used either Flask or Falcon server.\n"}
{"prompt": "How much is the cloud cost? \n\n###\n\n", "completion": " uuid: 10097873824 The cloud cost ranges around 1.5 lakh or $1500 to $2000 in INR.\n"}
{"prompt": "Are they currently receiving cloud credits? \n\n###\n\n", "completion": " uuid: 10097873824 No, they have already used up the two years worth of free credits.\n"}
{"prompt": "Do they anticipate their cloud costs increasing? \n\n###\n\n", "completion": " uuid: 10097873824 No, as they do not foresee their costs increasing by a lot in the next year or year and a half at least.\n"}
{"prompt": "What is the advantage of building the stack on top of Kubernetes from day zero? \n\n###\n\n", "completion": " uuid: 10097873824 It simplifies the DevOps process and allows for easier migration to Kubernetes in the future.\n"}
{"prompt": "What is the main orchestrator for deployment? \n\n###\n\n", "completion": " uuid: 10097873824 The main orchestrator for deployment is Kubernetes.\n"}
{"prompt": "What is the main functionality of the platform? \n\n###\n\n", "completion": " uuid: 10097873824 The platform provides deployment, monitoring, auto scaling, model traffic splitting, and cost optimization functionalities.\n"}
{"prompt": "Is there a way to run pipelines and automate the training? \n\n###\n\n", "completion": " uuid: 10097873824 The team is currently building a way to run pipelines and automate the training when new data comes in.\n"}
{"prompt": "What is the team size of HDFC Credilla? \n\n###\n\n", "completion": " uuid: 11984272003 There are 20 people now, out of which 15 are full time and five contractors part time, etc.\n"}
{"prompt": "Where is the office of HDFC Credilla located? \n\n###\n\n", "completion": " uuid: 11984272003 The office is located in MG Road, Bangalore.\n"}
{"prompt": "What is the focus of HDFC Credilla? \n\n###\n\n", "completion": " uuid: 11984272003 The focus is on bringing a lot of ticket option in the current organization.\n"}
{"prompt": "What is the in-house engineering team size of HDFC Credilla? \n\n###\n\n", "completion": " uuid: 11984272003 The in-house engineering team size is around 50 members.\n"}
{"prompt": "What is True Foundry? \n\n###\n\n", "completion": " uuid: 11984272003 True Foundry is a startup building a horizontal machine learning platform to support the operational needs of other teams.\n"}
{"prompt": "What was the conversation about? \n\n###\n\n", "completion": " uuid: 11354392663 The conversation was about the ML pipeline in Platinum and the challenges faced.\n"}
{"prompt": "What is EKS? \n\n###\n\n", "completion": " uuid: 11354392663 EKS is a Kubernetes-based service provided by Amazon Web Services.\n"}
{"prompt": "Do the data scientists do the deployments? \n\n###\n\n", "completion": " uuid: 11354392663 Yes, the data scientists do the deployments.\n"}
{"prompt": "How do the data scientists deploy their models? \n\n###\n\n", "completion": " uuid: 11354392663 They would provide pickled models.\n"}
{"prompt": "Are the models hosted as endpoints or batched? \n\n###\n\n", "completion": " uuid: 11354392663 They are hosted as live predictions on request, but they are mostly made for batch predictions.\n"}
{"prompt": "What was the problem that Platinum faced a year ago? \n\n###\n\n", "completion": " uuid: 11354392663 The state of the prototyping instrument was very problematic, so they had trouble retaining people over it.\n"}
{"prompt": "What did they do about it? \n\n###\n\n", "completion": " uuid: 11354392663 They put a plaster on it immediately rather than doing some kind of long overhaul.\n"}
{"prompt": "What is the current challenge of Platinum? \n\n###\n\n", "completion": " uuid: 11354392663 They are currently scaling up the two to three minutes machine learning data sets that they deliver, and the processes don't scale very well for that.\n"}
{"prompt": "What is the purpose of the platform being built by the startup? \n\n###\n\n", "completion": " uuid: 11354392663 The purpose of the platform is to enable data scientists to train and host models in a scalable way.\n"}
{"prompt": "What are the two concrete actionables that the startup proposed to Platinum? \n\n###\n\n", "completion": " uuid: 11354392663 To showcase their platform to Platinum and see if there is a use case for it in their prototyping teams, and to hear from someone from the infra team and see if the platform could help solve the introduction challenges.\n"}
{"prompt": "What is the ideal team composition for managing the entire pipeline? \n\n###\n\n", "completion": " uuid: 10097841502 A data science team with basic engineering skills is able to manage the entire pipeline.\n"}
{"prompt": "How does the platform deploy models? \n\n###\n\n", "completion": " uuid: 10097841502 The platform allows you to deploy models in various ways such as an EML way or a Python way from your CLI, notebooks, or UI. It automatically creates an endpoint, deploys it on your Kubernetes cluster that includes auto scaling and cost insights.\n"}
{"prompt": "What types of models can be deployed on the platform? \n\n###\n\n", "completion": " uuid: 10097841502 Different kinds of models can be deployed such as real-time models or batch-based models.\n"}
{"prompt": "What is the default monitoring provided for the system and ML on the platform? \n\n###\n\n", "completion": " uuid: 10097841502 The default monitoring provided on the platform includes system monitoring for usage of CPUs, memory, resources, and more. The ML monitoring includes monitoring data drift, feature drift, feature importance, and performance degradation.\n"}
{"prompt": "How are alerts set up on the platform? \n\n###\n\n", "completion": " uuid: 10097841502 Based on the monitoring data, alerts are sent based on the customer's preferences and flow to their email and slack for notification.\n"}
{"prompt": "Is Airflow compatible with the platform? \n\n###\n\n", "completion": " uuid: 10097841502 Airflow is part of the platform's roadmap, but it has not yet been shipped in the product.\n"}
{"prompt": "What are the factors looked for during tool evaluations? \n\n###\n\n", "completion": " uuid: 10097841502 Factors looked for during tool evaluations include ease of versioning and experiment tracking, resource monitoring, user-friendliness of the UI, continuous support, and relevancy for the next five years.\n"}
{"prompt": "What is the team composition in terms of location? \n\n###\n\n", "completion": " uuid: 10097841502 Most of the back-end team is based out of India, while offices are in San Francisco, Redwood City, and London. The Redwood City office is mostly sales and marketing, and the front-end team works mostly in the UK.\n"}
{"prompt": "What is the team's approach to platform building? \n\n###\n\n", "completion": " uuid: 10097841502 The team approaches building the platform with principles of scalability, best-in-class infrastructure, and user-friendly developer workflows for seamless use.\n"}
{"prompt": "What is the invitation to use the platform? \n\n###\n\n", "completion": " uuid: 10097841502 The speaker invites the listener to try the platform for their personal use case and provide feedback, possibly leading to further exploration and potential service for the listener's team.\n"}
{"prompt": "What command is used to initiate training in Python? \n\n###\n\n", "completion": " uuid: 12428091307 Python command to initiate that training.\n"}
{"prompt": "Who takes care of creating and killing the VM during Vertex model training job? \n\n###\n\n", "completion": " uuid: 12428091307 The Vertex training job takes care of creating and killing the VM.\n"}
{"prompt": "Where is the model stored after training in Vertex? \n\n###\n\n", "completion": " uuid: 12428091307 The model is converted into PB and then stored in the model register of the Vertex.\n"}
{"prompt": "What kind of reports the data center can create with the data? \n\n###\n\n", "completion": " uuid: 12428091307 The context does not provide enough information to determine it.\n"}
{"prompt": "What is Label Studio used for in object detection? \n\n###\n\n", "completion": " uuid: 12428091307 Label Studio is used to scan through unauthorized data for determining its quality without worrying about it.\n"}
{"prompt": "Who handles the packaging and image making for on-prem deployment? \n\n###\n\n", "completion": " uuid: 12428091307 The infrastructure team takes care of packaging and image making for on-prem deployment.\n"}
{"prompt": "What problems does Truefoundry solve in ML Ops? \n\n###\n\n", "completion": " uuid: 12428091307 Truefoundry tries to empower developers, provide monitoring dashboard, and make promotion from one environment to other easier.\n"}
{"prompt": "Is Flight ex deployed on any on-premises? \n\n###\n\n", "completion": " uuid: 12428091307 It is unclear whether Flight ex is deployed on any on-premises as per the context.\n"}
{"prompt": "Who is the contact person for DevOps or ML Ops in Flight ex? \n\n###\n\n", "completion": " uuid: 12428091307 Nico is the contact person for DevOps or ML Ops in Flight ex.\n"}
{"prompt": "Who is Matt as mentioned in the conversation? \n\n###\n\n", "completion": " uuid: 12428091307 Matt is the director of the speaker in the conversation.\n"}
{"prompt": "What is the goal of the pipeline described in the conversation? \n\n###\n\n", "completion": " uuid: 12339423649 The goal of the pipeline is to optimize multi-cloud deployment environment for best output and low cost.\n"}
{"prompt": "What parts of the system have not been built yet? \n\n###\n\n", "completion": " uuid: 12339423649 The cost optimization across cloud and AB testing automation retraining have not been built yet.\n"}
{"prompt": "What is the recommended focus of the company? \n\n###\n\n", "completion": " uuid: 12339423649 Specialization for one vertical may make more sense in general.\n"}
{"prompt": "How does the company interface with new people? \n\n###\n\n", "completion": " uuid: 12339423649 The company does customized demos.\n"}
{"prompt": "What is the main area of focus for this AI system? \n\n###\n\n", "completion": " uuid: 12339423649 The major focus is multi-cloud deployment environment which is more systems-oriented.\n"}
{"prompt": "What is the team using for managing the intra for research? \n\n###\n\n", "completion": " uuid: 12339423649 There is no orchestration layer like Kubernetes being used. Every developer has their own choices to make.\n"}
{"prompt": "How does the team manage the resources for on-prem research? \n\n###\n\n", "completion": " uuid: 12339423649 The team buys new servers for research which is cheaper than going on cloud.\n"}
{"prompt": "What are some tools used for data extraction from social media and web? \n\n###\n\n", "completion": " uuid: 10128442512 There are tools available but they are either not very accurate or they are very costly.\n"}
{"prompt": "What are some challenges faced while searching for the right customer on social media? \n\n###\n\n", "completion": " uuid: 10128442512 The challenge often arises while finding the right customer on social media due to profile matching.\n"}
{"prompt": "Does Credibly work with vendors or use internal systems for data extraction on social media and web? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly is currently doing data extraction internally by leveraging the API already available from social media platforms such as Facebook and Google.\n"}
{"prompt": "What is the tiering system for Facebook API? \n\n###\n\n", "completion": " uuid: 10128442512 The Facebook API has different tiers - a free version, a mid-tier version, and a premium version that gives access to all the data.\n"}
{"prompt": "Does Credibly build their own data science or machine learning models? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly has a couple of models for their underwriting process which they mostly develop internally but have also subscribed to a vendor called Data Robot.\n"}
{"prompt": "Why did Credibly subscribe to Data Robot? \n\n###\n\n", "completion": " uuid: 10128442512 Data Robot enables faster model building and greater transparency in performance monitoring, and Credibly found this to be of great value.\n"}
{"prompt": "How does Data Robot pricing work? \n\n###\n\n", "completion": " uuid: 10128442512 Pricing for Data Robot is based on the time period and there may be limitations on the server side.\n"}
{"prompt": "What is the approximate budget Credibly pays for Data Robot in a year? \n\n###\n\n", "completion": " uuid: 10128442512 The information on this is not available, but they were negotiating with a competitor called Aquarium and were quoted a price of about $400K or $500K.\n"}
{"prompt": "What are the names of the two people mentioned who were at Facebook? \n\n###\n\n", "completion": " uuid: 9984644130 Nikhunja and Aviate\n"}
{"prompt": "Which companies did the rest of the team come from? \n\n###\n\n", "completion": " uuid: 9984644130 Gojek, Amazon Reserve Postman\n"}
{"prompt": "Who is the founder of Kegle and Abyssia, and what was his role at Facebook? \n\n###\n\n", "completion": " uuid: 9984644130 Anthony, he was the first creator of the FP Learner platform within Facebook for productionizing of models\n"}
{"prompt": "What is the goal of the platform? \n\n###\n\n", "completion": " uuid: 9984644130 To enable teams to get models to production faster and reduce the time to value, allowing more time to focus on building different models rather than worrying about infrastructure and coordinating with different teams\n"}
{"prompt": "What are the design principles that the system adheres to? \n\n###\n\n", "completion": " uuid: 9984644130 Everything is API driven, treated as GitHub in terms of configuration, self serve, access control, cost insight, reproducible\n"}
{"prompt": "What is the central infrastructure of the system? \n\n###\n\n", "completion": " uuid: 9984644130 The deployment infrastructure\n"}
{"prompt": "What are some of the deployment use cases shown on the system? \n\n###\n\n", "completion": " uuid: 9984644130 Deploying a model as a fast API, training job, batch inference, model with artifacts, multiple microservices\n"}
{"prompt": "What is the monitoring system used by the platform? \n\n###\n\n", "completion": " uuid: 9984644130 The system monitoring provided by the platform itself\n"}
{"prompt": "Can the system schedule batch jobs or training jobs? \n\n###\n\n", "completion": " uuid: 9984644130 Yes, it is supported and can be accessed through the beta product\n"}
{"prompt": "How can the platform be used to update models? \n\n###\n\n", "completion": " uuid: 9984644130 Training can be scheduled and tracked through the platform's experiment tracking system, and a manual approval loop can be triggered to deploy the new model, with capabilities for automated retention being developed\n"}
{"prompt": "What is the process for monitoring the performance of automated models? \n\n###\n\n", "completion": " uuid: 12150845733 The process involves setting aside certain cases, monitoring outcomes through a dashboard that tracks both model outcomes and human outcomes, and continuously monitoring performance to determine if adjustments need to be made.\n"}
{"prompt": "Who has ownership of the model deployment setup in an organization? \n\n###\n\n", "completion": " uuid: 12150845733 The data engineering team takes ownership of the deployment setup, while the data science team specifies the requirements.\n"}
{"prompt": "What is the approach that the startup takes in working with enterprises \n\n###\n\n", "completion": " uuid: 12150845733 The startup takes an enabler approach, working closely with the data engineering or platform team to understand requirements, build custom solutions, and integrate end-to-end workflows. They seek help from advisors, accept angel checks, and build out more custom integration as needed.\n"}
{"prompt": "What are some of the differentiators of the startup's product? \n\n###\n\n", "completion": " uuid: 12150845733 The product is multi-cloud, supports custom plugins, and is developer-friendly, making it easy to deploy models in a reliable and scalable way. The architecture is built to allow flexibility and support different workflows depending on use cases.\n"}
{"prompt": "What value drivers does the startup offer to CTOs or SVPs of Data in an organization? \n\n###\n\n", "completion": " uuid: 12150845733 The startup's product can increase the productivity of team members, allowing for reliable and scalable model deployment. It offers flexibility and customization, enabling the solution of specific problems. It also provides multi-cloud support and is developer-friendly, making onboarding quick and easy.\n"}
{"prompt": "Who is introducing themselves on the call? \n\n###\n\n", "completion": " uuid: 12339422352 Jimmy is introducing himself on the call.\n"}
{"prompt": "Do they have a product already or are they still trying to figure it out? \n\n###\n\n", "completion": " uuid: 12339422352 They do have a product and platform, and they also have a few customers.\n"}
{"prompt": "What is Liquin Bhajaj's background? \n\n###\n\n", "completion": " uuid: 12339422352 Liquin Bhajaj comes from a machine learning background and has worked at Facebook and Reflection before co-founding Truefoundry.\n"}
{"prompt": "What cloud provider does Make My Trip use primarily? \n\n###\n\n", "completion": " uuid: 12339422352 Make My Trip primarily uses AWS as their cloud provider.\n"}
{"prompt": "Who writes the Airflow jobs for the model deployment? \n\n###\n\n", "completion": " uuid: 12339422352 The ML engineer or data scientist writes the Airflow jobs for the model deployment.\n"}
{"prompt": "What is the hand off process from the machine learning team to the intra team that's managing it? \n\n###\n\n", "completion": " uuid: 12339422352 The hand off process involves using a standard recipe for deployment and making changes as needed for the specific model.\n"}
{"prompt": "What platformization journey is Truefoundry on? \n\n###\n\n", "completion": " uuid: 12339422352 Truefoundry is working on platformizing multi-arm bandit, making it more accessible for non data scientists.\n"}
{"prompt": "What is the main issue with productionizing the projects at Novartis? \n\n###\n\n", "completion": " uuid: 12044422255 The issue is actually even getting to the production stage, and there has been a big reorganization happening since last year, due to which over the last three years since the organization was set up, they have not been able to show a very good return on investment in the sense that they have been showing proofs of concepts and showing Oh, hey, look, I can apply ML models to come up with new, interesting molecules.\n"}
{"prompt": "Who took over as CEO of Novartis and what was his promise to the shareholders? \n\n###\n\n", "completion": " uuid: 12044422255 In 2018, Vas Narasimhan took over as CEO of Novartis and he's been promising his shareholders to go big on data and digital, as a part of which he set up a chief CEO office and a central team was formed.\n"}
{"prompt": "What are the different applications of data science at Novartis? \n\n###\n\n", "completion": " uuid: 12044422255 The applications of data science currently revolve mostly around the research part, but they have promising opportunities to automate things like legal writing, supply chain and manufacturing, but the problem there is more with the data management side of things.\n"}
{"prompt": "What is the main challenge faced by Novartis in deploying ML models at scale? \n\n###\n\n", "completion": " uuid: 12044422255 The challenge faced by Novartis in deploying ML models at scale is that people don't trust the data or it's in too many different systems or there are too many constraints because of geographical boundaries and different regulations in different places.\n"}
{"prompt": "What are the tools used by Novartis for data management and ML? \n\n###\n\n", "completion": " uuid: 12044422255 Novartis uses data bricks, glassbox, and legacy tools for data management and ML, and they are trying to move some of the legacy tools to newer platforms. The structure is diverse, and there is no central infrastructure as such. The different business pods are doing AIML in different ways.\n"}
{"prompt": "How is the research infrastructure at Novartis managed, and how are models deployed and maintained at scale? \n\n###\n\n", "completion": " uuid: 12044422255 There is not much clarity on how the research infrastructure at Novartis is managed, but for the central team, they use glassbox primarily, and the data pipeline is built using GUI with little bit of coding here and there. The challenge faced by Novartis in deploying ML models at scale is that the business side doesn't fully see the promise yet, so the focus is on solving the right business problem, and there is no proper data management in place.\n"}
{"prompt": "What is the goal of the call and how long is the scheduled time? \n\n###\n\n", "completion": " uuid: 9984644130 The goal of the call is to understand each other's business, explore the possibility of potential partnership and see how Truefoundry can provide a solution to Nexus. The scheduled time for the call is 45 minutes.\n"}
{"prompt": "Who are the participants in the call, where are they based and what are their backgrounds? \n\n###\n\n", "completion": " uuid: 9984644130 The participants in the call are from Truefoundry and Nexus. Truefoundry team is primarily based in India, with some team members in the US, Singapore and Paris. The team members are from the founding team of Truefoundry, with backgrounds in portfolio management and building startups. The Nexus team is based in Singapore and is part of Standard Chartered Bank's eniacventures arm. The Nexus data science team consists of three members- data science lead, senior data scientist and data science analyst.\n"}
{"prompt": "What are some of the topics discussed in the call? \n\n###\n\n", "completion": " uuid: 9984644130 The topics discussed in the call include quick introductions, understanding of each other's businesses, exploring potential partnership, understanding machine learning use case and challenges, understanding data science team's background and use cases, understanding the deployment stack used by Nexus, understanding challenges faced in deploying models, understanding future use cases and challenges faced in building a scalable ML platform team from scratch.\n"}
{"prompt": "What problem is Truefoundry trying to solve and at what stage of the ML cycle do they come into the picture? \n\n###\n\n", "completion": " uuid: 9984644130 Truefoundry is trying to solve the problem of enabling data scientists to take model to production in a faster way and do it in a way that is scalable, cost effective and with some basic monitoring that is in built. They come into the picture in the model serving stage which is basically the deployment piece of the pipeline.\n"}
{"prompt": "What are the examples cited of companies investing in ML platform teams? \n\n###\n\n", "completion": " uuid: 9984644130 The examples cited of companies investing in ML platform teams are Facebook, Google, and Uber.\n"}
{"prompt": "Where is the person based? \n\n###\n\n", "completion": " uuid: 10238582319 In India.\n"}
{"prompt": "Where is their home located? \n\n###\n\n", "completion": " uuid: 10238582319 In Punjab.\n"}
{"prompt": "Is the person part of a remote team? \n\n###\n\n", "completion": " uuid: 10238582319 Yes.\n"}
{"prompt": "Do some team members still join the office? \n\n###\n\n", "completion": " uuid: 10238582319 Yes, a few.\n"}
{"prompt": "Is joining the office mandatory? \n\n###\n\n", "completion": " uuid: 10238582319 No, it's not mandatory.\n"}
{"prompt": "What is the person's background? \n\n###\n\n", "completion": " uuid: 10238582319 Machine learning.\n"}
{"prompt": "Where did the person previously work? \n\n###\n\n", "completion": " uuid: 10238582319 At Facebook.\n"}
{"prompt": "What are some of the projects the person worked on? \n\n###\n\n", "completion": " uuid: 10238582319 Conversational AI.\n"}
{"prompt": "What did the person build at Reflection? \n\n###\n\n", "completion": " uuid: 10238582319 A horizontal ML platform.\n"}
{"prompt": "What is the mission of the company? \n\n###\n\n", "completion": " uuid: 10238582319 To bring Facebook-level systems to all companies.\n"}
{"prompt": "What type of customers does Mathew have? \n\n###\n\n", "completion": " uuid: 10238582319 State agencies in the United States.\n"}
{"prompt": "What are some of the problems with working with state agencies? \n\n###\n\n", "completion": " uuid: 10238582319 Data privacy, model hosting at scale, data and model resiliency.\n"}
{"prompt": "What are some of Mathew's products? \n\n###\n\n", "completion": " uuid: 10238582319 AI products for clinical trials, intelligent document processing.\n"}
{"prompt": "Do the pharma companies use generic models? \n\n###\n\n", "completion": " uuid: 10238582319 No, they use custom models.\n"}
{"prompt": "What is used to deploy and scale the machine learning models? \n\n###\n\n", "completion": " uuid: 10238582319 Kubernetes.\n"}
{"prompt": "Does Mathew use multi-cloud? \n\n###\n\n", "completion": " uuid: 10238582319 Yes, since customers have different cloud preferences.\n"}
{"prompt": "How is resource allocation handled? \n\n###\n\n", "completion": " uuid: 10238582319 Engineers access their own AI servers before handing off to DevOps team.\n"}
{"prompt": "Are there permission controls on the machines and models? \n\n###\n\n", "completion": " uuid: 10238582319 Yes, there are various permissions and authentication controls.\n"}
{"prompt": "What is the speaker's attitude towards receiving the task of providing kwh? \n\n###\n\n", "completion": " uuid: 11189924245 It's like peanuts to him and he doesn't need to worry about it up to 200-300 kwh.\n"}
{"prompt": "What is the concern the speaker would have if he signs SW anytime? \n\n###\n\n", "completion": " uuid: 11189924245 He needs to have a work for that, which he currently doesn't have.\n"}
{"prompt": "What would make the speaker forget about the conflict of interest? \n\n###\n\n", "completion": " uuid: 11189924245 If the other person offers to do his chatbot and everything.\n"}
{"prompt": "What is the first thing the speaker proposes to start with for the chatbot business? \n\n###\n\n", "completion": " uuid: 11189924245 Starting with the chatbot business itself.\n"}
{"prompt": "Is the speaker sure that the proposed chatbot business is aligned with the other person's product line? \n\n###\n\n", "completion": " uuid: 11189924245 No, he thinks it's not aligned.\n"}
{"prompt": "What does the speaker offer to do for the other person? \n\n###\n\n", "completion": " uuid: 11189924245 Help him to get his foot into CVS and introduce him to people.\n"}
{"prompt": "What is the significance of CVS in terms of IT staff and expense? \n\n###\n\n", "completion": " uuid: 11189924245 CVS has 26,000 IT staff, which is a $2 billion plus expense every year.\n"}
{"prompt": "How many data scientists does CVS have according to the speaker and what does it indicate? \n\n###\n\n", "completion": " uuid: 11189924245 CVS has around 600 data scientists, which the speaker thinks is too many and indicates something wrong with their hiring.\n"}
{"prompt": "What is the speaker currently hiring for? \n\n###\n\n", "completion": " uuid: 11189924245 The speaker is currently hiring a lot of individual contributors at a senior director level, paying big bucks for that kind of talent.\n"}
{"prompt": "What does the speaker think is important when they place someone into CVS? \n\n###\n\n", "completion": " uuid: 11189924245 There needs to be one person who's their favorite superstar and who can code fast to take things to the end state.\n"}
{"prompt": "What is the first use case proposed by the speaker and how much money does he think it can make? \n\n###\n\n", "completion": " uuid: 11189924245 The first use case proposed is around drug performance analysis and the speaker thinks it's a billion dollar plus product they can build.\n"}
{"prompt": "What is the second use case proposed by the speaker and what is it focused on? \n\n###\n\n", "completion": " uuid: 11189924245 The second use case is focused on predicting drug shipment delivery times and improving customer satisfaction.\n"}
{"prompt": "Has work already started on any of the proposed use cases according to the speaker? \n\n###\n\n", "completion": " uuid: 11189924245 No, the speaker is the person pushing for these use cases and needs to convince others to prioritize them.\n"}
{"prompt": "When is the speaker available for another call to discuss the use cases further? \n\n###\n\n", "completion": " uuid: 11189924245 The speaker is available on Friday after 5:30pm EST and will send an invite for a call.\n"}
{"prompt": "What does Carlos ask and what is the response? \n\n###\n\n", "completion": " uuid: 11488124534 Carlos asks if he can be heard, and the response is yes.\n"}
{"prompt": "What do Carlos and the other person discuss after confirming the audio is okay? \n\n###\n\n", "completion": " uuid: 11488124534 They discuss their whereabouts and travel plans.\n"}
{"prompt": "What is the other person's profession and what team do they manage? \n\n###\n\n", "completion": " uuid: 11488124534 The other person manages an ML team and manages the back end team.\n"}
{"prompt": "What is Truefoundry and how long has the other person been on an entrepreneurial journey? \n\n###\n\n", "completion": " uuid: 11488124534 Truefoundry is a startup and the person has been on an entrepreneurial journey since quitting Facebook.\n"}
{"prompt": "What is the focus of Truefoundry and what are they building? \n\n###\n\n", "completion": " uuid: 11488124534 Truefoundry is building a platform similar to the predictor service at Facebook for companies that want to build and deploy ML models.\n"}
{"prompt": "Which cloud providers do they use and why do they use two different ones? \n\n###\n\n", "completion": " uuid: 11488124534 They primarily use AWS, but also use Azure for speech recognition because of a strong partnership and technical capabilities.\n"}
{"prompt": "What is the context of the conversation? \n\n###\n\n", "completion": " uuid: 11656830826 The conversation is about the location, weather, and backgrounds of the speakers, as well as their work in the machine learning industry.\n"}
{"prompt": "Where is Beville located? \n\n###\n\n", "completion": " uuid: 11656830826 Beville is located in Canada, very close to Toronto, in a city called Brampton.\n"}
{"prompt": "What is the weather like in Brampton? \n\n###\n\n", "completion": " uuid: 11656830826 The weather in Brampton is usually cold during the winter months, with a lot of snow from December to March, but this year has been better with less snow.\n"}
{"prompt": "Where is the speaker based out of? \n\n###\n\n", "completion": " uuid: 11656830826 The speaker is based out of Bangladesh.\n"}
{"prompt": "What is the speaker's experience in machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 The speaker has a background in machine learning and previously led a conversational AI team at Facebook, as well as worked on personalization algorithms for ecommerce at a startup called Reflection.\n"}
{"prompt": "What is Procore? \n\n###\n\n", "completion": " uuid: 11656830826 Procore is a project management software company focused on the construction industry, offering solutions for financials, project estimation, and more.\n"}
{"prompt": "What is the speaker's role at Procore? \n\n###\n\n", "completion": " uuid: 11656830826 The speaker works on the ML Ops team at Procore, which handles infrastructure scaling, monitoring, and security, as well as adopting new tools for machine learning workflows.\n"}
{"prompt": "What cloud does Procore primarily use for machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 Procore primarily uses AWS for machine learning, while their acquisition, Level Set, uses GCP.\n"}
{"prompt": "Does Procore use SageMaker for machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 Procore previously used SageMaker for machine learning but has since built out their own platform on top of Kubernetes due to limitations with ready-made solutions and the need to customize deployment and contact methods.\n"}
{"prompt": "What is an end point in this context? \n\n###\n\n", "completion": " uuid: 10881905922 An end point is a model application.\n"}
{"prompt": "Does every model created serve as an end point? \n\n###\n\n", "completion": " uuid: 10881905922 No, not each model itself is an end point.\n"}
{"prompt": "What creates a single endpoint for the product? \n\n###\n\n", "completion": " uuid: 10881905922 The service that was built creates a single endpoint for the product.\n"}
{"prompt": "What are the parameters used in the endpoint? \n\n###\n\n", "completion": " uuid: 10881905922 The parameters used are the account name and certain other things.\n"}
{"prompt": "What does the account name tell us in this context? \n\n###\n\n", "completion": " uuid: 10881905922 The account name tells us which model to use in which context.\n"}
{"prompt": "What tool is used for tracking experiments? \n\n###\n\n", "completion": " uuid: 10881905922 ML Flow is used to track experiments.\n"}
{"prompt": "What kind of metrics are tracked in ML Flow? \n\n###\n\n", "completion": " uuid: 10881905922 Metrics such as accuracy, improvements in search or classification, and drifter are tracked in ML Flow.\n"}
{"prompt": "Is the model registry used in ML Flow? \n\n###\n\n", "completion": " uuid: 10881905922 No, the model registry is not used in ML Flow.\n"}
{"prompt": "Which companies are focused on drift tracking? \n\n###\n\n", "completion": " uuid: 10881905922 Fiddler is a company that is focused on drift tracking.\n"}
{"prompt": "What is the primary importance of the company at this point? \n\n###\n\n", "completion": " uuid: 10881905922 At this point, getting things up is of primary importance.\n"}
{"prompt": "What would the speaker do differently if they were starting today? \n\n###\n\n", "completion": " uuid: 10881905922 If they were starting today, they would look at using Fiddler or Tuhu and using what Databrick has.\n"}
{"prompt": "What is a challenge in maintaining a multi-tenant system? \n\n###\n\n", "completion": " uuid: 10881905922 Managing these hundreds or thousands of models depending on the number of customers is a challenge in maintaining a multi-tenant system.\n"}
{"prompt": "What is the speaker's take on building a vector database? \n\n###\n\n", "completion": " uuid: 10881905922 The speaker believes that it is best to take something from outside and use it instead of building a vector database.\n"}
{"prompt": "What is a concern around sending data to a third party? \n\n###\n\n", "completion": " uuid: 10881905922 Sending data to a third party is not permitted by a larger syntax and is legally difficult to differentiate.\n"}
{"prompt": "What technology was used that caused pushback from customers? \n\n###\n\n", "completion": " uuid: 10881905922 One technology that was sending some metadata outside of the customer thing caused pushback from customers and had to be changed.\n"}
{"prompt": "What is the major challenge for machine learning in healthcare according to the context? \n\n###\n\n", "completion": " uuid: 11577360522 Multiple versions of the truth exist.\n"}
{"prompt": "What is the difference between feature-based models and deep learning models in the pipeline? \n\n###\n\n", "completion": " uuid: 11577360522 Deep learning models do not need feature definition.\n"}
{"prompt": "What tools are used for monitoring the models? \n\n###\n\n", "completion": " uuid: 11577360522 Grafana is used for visualization of metrics on Azure logging metrics, and models on Grafana for model performance.\n"}
{"prompt": "What kind of ML models are deployed in the customer environment? \n\n###\n\n", "completion": " uuid: 11577360522 Stateless models are deployed in the customer environment.\n"}
{"prompt": "What is the plan for ML ops adoption for the company? \n\n###\n\n", "completion": " uuid: 11577360522 The company plans to adopt an ML Ops platform in 2023 for consistency in engineering, infrastructure, quality, quantity, and monitoring.\n"}
{"prompt": "What is the team's comfort level with Kubernetes? \n\n###\n\n", "completion": " uuid: 11577360522 They are comfortable with deploying Kubernetes clusters and services, but are not yet using Kubeflow for model deployment.\n"}
{"prompt": "What is the main workflow of the platform? \n\n###\n\n", "completion": " uuid: 12361625221 The main workflow of the platform revolves around deployment multi model and everything. Basically, you can store for each customer. You can probably create probably a model registry here. These models are basically saved here with different versions. If you want to deploy these models, let's say you've already saved the models, then when you want to deploy, it's up to you based on the use case, you might want to deploy it as a real-time service or you might want to deploy it as a batch inference.\n"}
{"prompt": "How do you deploy models in the platform? \n\n###\n\n", "completion": " uuid: 12361625221 If the model is already saved on the system and you want to deploy, you choose the namespace where you want to deploy. These are the list of all the models that you have, and then you select the models that you want to deploy. You can also select if you want your selected models to target GPU or a certain type of CPU machine. Then you can click on deploy where it will create a service. If you want to deploy from Hugging Face model directly, you can give us the Hugging Face link and we'll automatically deploy it.\n"}
{"prompt": "Is everything driven by API in the platform? \n\n###\n\n", "completion": " uuid: 12361625221 Yes, everything in the platform is driven by API, and all the APIs are exposed that can be integrated into the layer for the customer. So all the UIs are not exposed, just the APIs. At the end of the day, everything is a REST API and we also provide our Python SDK.\n"}
{"prompt": "What is the pricing model on the platform? \n\n###\n\n", "completion": " uuid: 12361625221 We charge customers on the basis of the number of users. For now, our pricing has been USD 300 per developer per month. But we can think of a simple blanket pricing that can work for you all.\n"}
{"prompt": "What are the items that will be deployed on the customer's cluster? \n\n###\n\n", "completion": " uuid: 12361625221 Control plane will get Argocd, Argowork, Istio, and if you need auto-scaling, we need Prometheus. Workload cluster will get Argocd, Argowork, and Istio. If you need long-term persistence logs, you can use Loki; otherwise, you can continue using Azure. Elastic search is also available. Prometheus is optional and only necessary if you need auto-scaling.\n"}
{"prompt": "What is the ML flow? \n\n###\n\n", "completion": " uuid: 10881905316 ML Flow is a tool for tracking experiments and managing and deploying models.\n"}
{"prompt": "What happens when you try to log anything nonscalar with the ML flow? \n\n###\n\n", "completion": " uuid: 10881905316 It fails.\n"}
{"prompt": "What does the Truefoundry platform offer to solve the issue of logging nonscalar values? \n\n###\n\n", "completion": " uuid: 10881905316 The Truefoundry platform offers additional data logging functionality for non-scalar values.\n"}
{"prompt": "What is the name of the service deployed on the Truefoundry platform to demonstrate how to write FastAPI code? \n\n###\n\n", "completion": " uuid: 10881905316 The service deployed is a FastAPI service.\n"}
{"prompt": "What is the name of the endpoint that shows the three functions deployed as part of the FastAPI service? \n\n###\n\n", "completion": " uuid: 10881905316 The endpoint name is 'multiply', 'normal', and 'uniform'.\n"}
{"prompt": "What is the resource you need to pass to the service deployment code to specify the GPU to use? \n\n###\n\n", "completion": " uuid: 10881905316 You need to pass the resources parameter to the service deployment code to specify the GPU to use.\n"}
{"prompt": "How can you identify the model to use in the deployment of the Iris service? \n\n###\n\n", "completion": " uuid: 10881905316 You can identify the model by its fully qualified name (FQN).\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12044422255 To learn about the overall machine learning pipeline at Novartis, with a focus on how the multi-cloud comes into play and the challenges associated with it, and to introduce themselves to each other.\n"}
{"prompt": "What is the speaker's background? \n\n###\n\n", "completion": " uuid: 12044422255 He graduated from IAT Karakpur in 2013, worked at a hedge fund called Worldcoint, held two roles in the CEO office and as a portfolio manager, managed $600 million in assets, invested in startups, built a startup in the talent space called Entire and sold it in 2021 September, and then started building True Foundry.\n"}
{"prompt": "Who are the speaker's co-founders in True Foundry? \n\n###\n\n", "completion": " uuid: 12044422255 Vishek and Nickel are his co-founders. Vishek worked at Facebook for six years, and Nickel worked at Reflection and Facebook, where he led the AI team for Portal.\n"}
{"prompt": "Why did the speaker start True Foundry? \n\n###\n\n", "completion": " uuid: 12044422255 The speaker started True Foundry because in his first startup, they had difficulty with deploying models in a reliable way into their website and integrating it. It took them more than a month to understand the cloud systems and then piece together open source.\n"}
{"prompt": "What was the speaker's focus at IBM Research Debt? \n\n###\n\n", "completion": " uuid: 12044422255 The speaker's focus at IBM Research Debt was to work on the problem of reliability, specifically to have some sort of coding over data to protect data in large systems and prevent data loss while at the same time reducing the overhead in terms of cost.\n"}
{"prompt": "What was the main challenge faced by the traditional automotive industry with deploying ML models? \n\n###\n\n", "completion": " uuid: 12044422255 The main challenge faced by the traditional automotive industry with deploying ML models is that the industry does not list all the requirements in the beginning and they have a constantly evolving system that needs to be updated over the air.\n"}
{"prompt": "What is True Foundry's focus? \n\n###\n\n", "completion": " uuid: 12044422255 True Foundry's focus is to provide a machine learning deployment infrastructure on the cloud, to run a seamless training infrastructure and deployment infrastructure over the cloud.\n"}
{"prompt": "Can the session be recorded? \n\n###\n\n", "completion": " uuid: 12044422255 Yes, the session can be recorded.\n"}
{"prompt": "What are the services deployed in production that are sitting under some namespace? \n\n###\n\n", "completion": " uuid: 12428091030 Let's say the services that are deployed in production.\n"}
{"prompt": "Do data scientists have any access to those services? \n\n###\n\n", "completion": " uuid: 12428091030 Yes, they do have access, but to their own namespace.\n"}
{"prompt": "What metrics were being logged for measuring data drift? \n\n###\n\n", "completion": " uuid: 12428091030 There were no drift monitoring metrics being logged before onboarding Selden.\n"}
{"prompt": "Why did they onboard Selden? \n\n###\n\n", "completion": " uuid: 12428091030 One reason was for drift monitoring, but also because Selden provides features beyond just model serving.\n"}
{"prompt": "How did the process of initiation of a new software procurement start? \n\n###\n\n", "completion": " uuid: 12428091030 The machine learning engineers proposed the idea of drift monitoring, spoke to coworkers, manager, product owner, and data scientists, and after everyone liked the idea, it went to the higher-up for final approval.\n"}
{"prompt": "Did they evaluate any other vendors besides Selden for model monitoring? \n\n###\n\n", "completion": " uuid: 12428091030 Yes, they also evaluated Evidently.\n"}
{"prompt": "What is the main purpose of the system they have built? \n\n###\n\n", "completion": " uuid: 12428091030 The system is built on top of Kubernetes and supports all three clouds. It has workspaces for training and production, allows logging of offline metrics, has version comparison, integration with CI/CD for auto scaling, and monitoring for drift and predictions using the same stack.\n"}
{"prompt": "What is the primary reason for onboarding Selden? \n\n###\n\n", "completion": " uuid: 12428091030 Drift monitoring.\n"}
{"prompt": "Which workflow management systems have they worked with? \n\n###\n\n", "completion": " uuid: 12428091030 Airflow 2.0 and Argo workflows.\n"}
{"prompt": "What do they plan to do during the next demo call? \n\n###\n\n", "completion": " uuid: 12428091030 They plan to show a demo of their platform and learn from each other.\n"}
{"prompt": "Who did the person speak with on phone? \n\n###\n\n", "completion": " uuid: 12339423649 Siddharth\n"}
{"prompt": "Who is the uncle mentioned in the conversation? \n\n###\n\n", "completion": " uuid: 12339423649 Not specified.\n"}
{"prompt": "What are the two teams mentioned by Siddharth? \n\n###\n\n", "completion": " uuid: 12339423649 AI team and Empora.\n"}
{"prompt": "What questions has the person not sent to Siddharth? \n\n###\n\n", "completion": " uuid: 12339423649 Multicloud questions.\n"}
{"prompt": "What is Truefoundry's motivation behind the call with Stryker? \n\n###\n\n", "completion": " uuid: 12339423649 To understand the problems faced by companies that are multicloud by design, and to understand their demo pipeline.\n"}
{"prompt": "What is Stryker's current AI structure like? \n\n###\n\n", "completion": " uuid: 12339423649 Stryker has formed a central AI hub, which includes an AI research group, AI systems group responsible for deployment and monitoring, an AI application team, and a bit of analytics.\n"}
{"prompt": "What is the goal of the model building process in Truefoundry's system? \n\n###\n\n", "completion": " uuid: 12339423649 The goal is to go from building a model to deploying it to production, including basic monitoring.\n"}
{"prompt": "What happens after the researcher finishes a training run in Truefoundry's system? \n\n###\n\n", "completion": " uuid: 12339423649 The system will automatically shut it down and return all the logs needed to select and launch it, deploy it to a test environment, or create a basic front end demo.\n"}
{"prompt": "What kind of logs are getting generated? \n\n###\n\n", "completion": " uuid: 10439869350 The logs being generated are used for metrics dashboards, everything, lambda, API.\n"}
{"prompt": "Where are the logs being pushed to? \n\n###\n\n", "completion": " uuid: 10439869350 They are being pushed to something like Grafana.\n"}
{"prompt": "What is the planned usage of Kaan? \n\n###\n\n", "completion": " uuid: 10439869350 Kaan is planned to be used because there is a user layer written in Java that needs to go on Promises.\n"}
{"prompt": "Where is the monitoring happening currently? \n\n###\n\n", "completion": " uuid: 10439869350 Currently, monitoring is happening on CloudWatch and laptop tracking.\n"}
{"prompt": "Is the current monitoring ML monitoring? \n\n###\n\n", "completion": " uuid: 10439869350 No, the current monitoring is not ML monitoring.\n"}
{"prompt": "Are there plans for ML monitoring? \n\n###\n\n", "completion": " uuid: 10439869350 There are currently no plans for ML monitoring.\n"}
{"prompt": "What kind of testing is done for deploying a new model? \n\n###\n\n", "completion": " uuid: 10439869350 There is currently no use case for testing different models with different percentages of traffic.\n"}
{"prompt": "How is the roof platform built? \n\n###\n\n", "completion": " uuid: 10439869350 The roof platform is built to make it easy to deploy models in a scalable way and offers other functionalities to complete the flow of a data scientist or ML.\n"}
{"prompt": "What is the major benefit of the roof platform? \n\n###\n\n", "completion": " uuid: 10439869350 The major benefit of the roof platform is that it integrates training and deployment workload on the same service or box, resulting in cost savings.\n"}
{"prompt": "What is the primary use case being looked for at this point? \n\n###\n\n", "completion": " uuid: 10439869350 The primary use case being looked for is experimentation with the roof platform in terms of tracking and comparing different versions of models.\n"}
{"prompt": "What is one of the use cases for the platform? \n\n###\n\n", "completion": " uuid: 10439124882 The platform is primarily used for monitoring data drift and distribution drifts between training and actual data in industries such as real estate, pharma, and tech.\n"}
{"prompt": "What is the target audience for the platform? \n\n###\n\n", "completion": " uuid: 10439124882 Industries that are not very tech oriented and do not have their own data science team, or those who only have one analyst or data scientist are the target audience for the platform.\n"}
{"prompt": "How long does it take for data scientists to start using the platform? \n\n###\n\n", "completion": " uuid: 10439124882 Data scientists can start deploying on the platform within a matter of a couple of hours, making the onboarding process less than a day.\n"}
{"prompt": "How does the platform differentiate from others such as Sage Maker? \n\n###\n\n", "completion": " uuid: 10439124882 Unlike Sage Maker, the platform is user-friendly and not a black box. The platform is easy to use and provides users with the necessary support they need, even if something goes wrong.\n"}
{"prompt": "What is the target strategy for the platform? \n\n###\n\n", "completion": " uuid: 10439124882 It is initially better to have a few, slightly bigger customers for the platform to evolve and make it easier for smaller customers to use it and then distribute it to multiple industries.\n"}
{"prompt": "What is the UI like for deploying a model? \n\n###\n\n", "completion": " uuid: 10439124882 The UI for deploying a model is straightforward and only requires selecting the source, repository, name, and branch, and then clicking deploy.\n"}
{"prompt": "Can the platform accommodate data of different types? \n\n###\n\n", "completion": " uuid: 10439124882 Yes, the platform has a schema for every model that allows data scientists to define the features and associate a type with them. An error will be thrown if the data type does not match the schema.\n"}
{"prompt": "How can the platform be used for model training? \n\n###\n\n", "completion": " uuid: 10439124882 The platform allows data scientists to deploy a model training job by writing Python code, and they can trigger it to run on the infrastructure with one click.\n"}
{"prompt": "What is the purpose of the model registry? \n\n###\n\n", "completion": " uuid: 10439124882 The model registry serves as a central repository for all versions of the model that users have retrained, making it easy to keep track of them.\n"}
{"prompt": "How many versions of the model can users keep running on the platform? \n\n###\n\n", "completion": " uuid: 10439124882 Users can keep running all versions of the model on the platform.\n"}
{"prompt": "What does the speaker mention about heavy computations? \n\n###\n\n", "completion": " uuid: 11185249632 Do it on your own machine or your own database.\n"}
{"prompt": "According to the context, what is the process of running a computation on a specific server? \n\n###\n\n", "completion": " uuid: 11185249632 You can just point to all those servers and make a connection.\n"}
{"prompt": "What does the speaker say about pushing computation to Data IQ? \n\n###\n\n", "completion": " uuid: 11185249632 For big data sets, it's a bit of a trouble.\n"}
{"prompt": "Which industries can benefit from AutoML models according to the speaker? \n\n###\n\n", "completion": " uuid: 11185249632 Retail, ecommerce, and OTT companies\n"}
{"prompt": "What does the speaker say about the cloud providers' AutoML solutions in comparison to their platform? \n\n###\n\n", "completion": " uuid: 11185249632 From an economic standpoint, the AutoML guys provide some of these, but just because something is free doesn't mean it works.\n"}
{"prompt": "What does the speaker suggest at the end of the conversation? \n\n###\n\n", "completion": " uuid: 11185249632 The speaker suggests testing their platform by taking any of their models or even basic models and trying to see if they are actually able to use the platform to deploy and if they like the process.\n"}
{"prompt": "What is being discussed in the context? \n\n###\n\n", "completion": " uuid: 11317793541 Control plane installation and service deployment, building infrastructure for Dream Eleven platform, overview of data pipeline and distributed training.\n"}
{"prompt": "How many ML models are deployed in the environment that is being discussed? \n\n###\n\n", "completion": " uuid: 11317793541 Around 10,000.\n"}
{"prompt": "What is the role of Bharat in the project? \n\n###\n\n", "completion": " uuid: 11317793541 Building the entire infrastructure from the ML side.\n"}
{"prompt": "What is the goal of the project for Dream Eleven? \n\n###\n\n", "completion": " uuid: 11317793541 To give a detailed overview of the platform from a technical and product perspective, including AB testing.\n"}
{"prompt": "What is the focus on regarding the CI CD system? \n\n###\n\n", "completion": " uuid: 11317793541 Making the system robust from an engineering perspective for scale.\n"}
{"prompt": "What is the request count for Dream Eleven? \n\n###\n\n", "completion": " uuid: 11317793541 10 million requests by 1 million users daily.\n"}
{"prompt": "What is the topic of discussion for the 5-10 minutes overview? \n\n###\n\n", "completion": " uuid: 11317793541 The stack being used for the data pipeline and distributed training.\n"}
{"prompt": "What is the time limit for the call? \n\n###\n\n", "completion": " uuid: 11317793541 The call needs to be wrapped up in 5 to 10 minutes.\n"}
{"prompt": "What did the speaker say they wanted to do on the call? \n\n###\n\n", "completion": " uuid: 10611764294 The speaker wanted to get to know each other a little bit, learn about Maggie a bit, understand the stage of the current data science project at Amagi, and dive into a little bit of the pipeline and infrastructure.\n"}
{"prompt": "How many co-founders did Anirudh have in his previous startup? \n\n###\n\n", "completion": " uuid: 10611764294 Anirudh had two co-founders in his previous startup named Abhishek and Nikung.\n"}
{"prompt": "What is Amagi primarily into? \n\n###\n\n", "completion": " uuid: 10611764294 Amagi is primarily into cloud-based transcode or cloud-based content delivery solutions.\n"}
{"prompt": "Is the ML pipeline mostly batch or real-time processing? \n\n###\n\n", "completion": " uuid: 10611764294 The ML pipeline is mostly batch processing, and there are a few upcoming use cases where live content will be processed in real-time.\n"}
{"prompt": "What tools does the team use for infrastructure allocation? \n\n###\n\n", "completion": " uuid: 10611764294 The data science team is independent and can spin up any instance they want. They primarily use spot instances that are reasonably priced.\n"}
{"prompt": "What does the speaker want to learn more about in a follow-up call? \n\n###\n\n", "completion": " uuid: 10611764294 The speaker wants to learn more about the monitoring and automated retraining pipeline, and dive into more details of Proof Foundry as well.\n"}
{"prompt": "What is the context of the conversation? \n\n###\n\n", "completion": " uuid: 11354403489 A discussion between two individuals about their work in machine learning and data science.\n"}
{"prompt": "Who is involved in the conversation? \n\n###\n\n", "completion": " uuid: 11354403489 Two individuals, possibly working in the field of data science or machine learning.\n"}
{"prompt": "What is the seniority level of one of the individuals? \n\n###\n\n", "completion": " uuid: 11354403489 The junior individual is not very junior, but is not a decision maker.\n"}
{"prompt": "What is the focus of the conversation? \n\n###\n\n", "completion": " uuid: 11354403489 They are discussing how they can potentially add value to the machine learning pipeline of companies that use data science and machine learning.\n"}
{"prompt": "What is Netradyne? \n\n###\n\n", "completion": " uuid: 11354403489 A company that produces products for monitoring roads and drivers, which uses deep learning models.\n"}
{"prompt": "What are some of the features of Netradyne's products? \n\n###\n\n", "completion": " uuid: 11354403489 Detection of road signals, lanes, and driver drowsiness among other facial expressions.\n"}
{"prompt": "What kind of products does Netradyne have? \n\n###\n\n", "completion": " uuid: 11354403489 They have three different products, including NVDI based products and Qualcomm based products.\n"}
{"prompt": "What deployment pipelines do Netradyne's products use? \n\n###\n\n", "completion": " uuid: 11354403489 For Qualcomm based products, they use a pipeline provided by Snappy while for Nvidia, they use Tensor RT.\n"}
{"prompt": "Is the conversation being recorded? \n\n###\n\n", "completion": " uuid: 11354403489 No, it is not.\n"}
{"prompt": "What is the purpose of the call today? \n\n###\n\n", "completion": " uuid: 9133766297 To understand the problems that the team is trying to solve and figure out if it's a good time to potentially showcase what Trufoundry is working on.\n"}
{"prompt": "What types of models is the team currently working on? \n\n###\n\n", "completion": " uuid: 9133766297 The team is currently working on lead scoring, retention scoring, supply chain optimization, and product recommendations.\n"}
{"prompt": "Are these models already in production? \n\n###\n\n", "completion": " uuid: 9133766297 One of the models, lead scoring, is already in production. Supply chain demand distribution is also in production and the other two models are currently in data engineering phases.\n"}
{"prompt": "Who is currently working in the data science team? \n\n###\n\n", "completion": " uuid: 9133766297 There are four people actively working on the data science team: Nigen, Priyank, Shaans, and Sri Lank. There are two other people, Rohan and Kayhan, who are working on the communications platform and data engineering pipelines, respectively.\n"}
{"prompt": "Does the team have separate engineering support for taking models to production? \n\n###\n\n", "completion": " uuid: 9133766297 It's a hybrid approach. Depending on the need for product help and individual bandwidth, the team either provides data and relies on back end engineers or completes models end to end themselves.\n"}
{"prompt": "What was the context of the call? \n\n###\n\n", "completion": " uuid: 10611764602 The context of the call was to understand upSTOCK's ML needs and infrastructure.\n"}
{"prompt": "Who was the first hiring of the data tribe at upSTOCK? \n\n###\n\n", "completion": " uuid: 10611764602 The principal ML and data engineer was the first hiring of the data tribe at upSTOCK.\n"}
{"prompt": "What kind of use cases is the ML team working on at upSTOCK? \n\n###\n\n", "completion": " uuid: 10611764602 The ML team at upSTOCK is working on use cases such as associate partner incentivization, trading nudges, loyalty programs, RFM cohort, churn detection, sentiment analysis, personalized watch list, revenue forecast models, CLDP prediction, and customized cycle value.\n"}
{"prompt": "What platform is upSTOCK built on and what ML tools do they use? \n\n###\n\n", "completion": " uuid: 10611764602 upSTOCK's platform is built on Kubernetes and the ML team uses Sage Maker extensively, while the data engineering team uses Blue ETL.\n"}
{"prompt": "What is the migration process for upSTOCK to Kubernetes? \n\n###\n\n", "completion": " uuid: 10611764602 The migration process for upSTOCK to Kubernetes is already underway, with more than 50% of their tier one services already migrated.\n"}
{"prompt": "What is the workflow for a business case going from product manager to model production at upSTOCK? \n\n###\n\n", "completion": " uuid: 10611764602 The workflow for a business case going from product manager to model production at upSTOCK involves a discussion between the product team and the data strategy team to determine the best approach. Afterwards, there is an exploration phase to determine the model, data, and pipeline, followed by a standard deployment strategy with feature generation job scheduling.\n"}
{"prompt": "What was the difficulty the speaker faced with Zoom? \n\n###\n\n", "completion": " uuid: 10439124882 Clicking on the bottom because they were using Zoom instead of Google.\n"}
{"prompt": "How did the speakers know each other? \n\n###\n\n", "completion": " uuid: 10439124882 Debug was one of the speaker's seniors at Idi Krakpur and also a customer to their earlier startup when he was running Slintel.\n"}
{"prompt": "What is the goal of Two Foundry? \n\n###\n\n", "completion": " uuid: 10439124882 To create an easy-to-use platform for data scientists and ML developers to deploy models to a final state in a scalable way without relying on infra teams and making it not a black box.\n"}
{"prompt": "What are some of the features offered by Two Foundry? \n\n###\n\n", "completion": " uuid: 10439124882 Monitoring, scalability, and open access to allow building on top of the platform.\n"}
{"prompt": "What industry is Two Foundry currently targeting? \n\n###\n\n", "completion": " uuid: 10439124882 They are currently doing a horizontal approach and are open to any industry, but it might be beneficial to narrow down to one.\n"}
{"prompt": "What is one example of a specific use case that companies might target in their platforms? \n\n###\n\n", "completion": " uuid: 10439124882 Imbalance classification, such as in the fraud domain, which can be one of the hardest problems to solve.\n"}
{"prompt": "What is the speaker's opinion on auto training? \n\n###\n\n", "completion": " uuid: 10439124882 She is not a fan of auto training and believes that good models should be responsible for it and that it's important to monitor the models and understand when to retrain them.\n"}
{"prompt": "Who handles the deployment of models in the speaker's previous companies? \n\n###\n\n", "completion": " uuid: 10439124882 In her previous startup and in PayPal, there was a separate team of data engineers that handled the production deployment.\n"}
{"prompt": "What is the speaker's opinion on feature engineering? \n\n###\n\n", "completion": " uuid: 10439124882 She believes it is critical and that having a good pipeline for feature engineering is more important than building a model, as the model is only 5% of the work. She also mentioned that it is important to tailor feature engineering to specific use cases.\n"}
{"prompt": "What was the speaker's role at PayPal? \n\n###\n\n", "completion": " uuid: 10439124882 She was a data science leader.\n"}
{"prompt": "What is the process of building a model like? \n\n###\n\n", "completion": " uuid: 11655736993 It involves spinning up training resources, comparing web models, testing the workspace, secrets management, authentication, system monitoring, and basic monitoring out of the box.\n"}
{"prompt": "What tools are used for interactive computation and deployment? \n\n###\n\n", "completion": " uuid: 11655736993 Data bricks are used for interactive computation, while Kubernetes is used for deployment.\n"}
{"prompt": "What is the pipeline model builder used for? \n\n###\n\n", "completion": " uuid: 11655736993 It is used to extract one file, put it in a code base, and run a pipeline for multi-cloud use.\n"}
{"prompt": "Who evaluates the models and when is this done? \n\n###\n\n", "completion": " uuid: 11655736993 Business teams with statistics backgrounds evaluate models during the model evaluation phase, which is generally done before the dev environment.\n"}
{"prompt": "What is the process of deploying a model to production? \n\n###\n\n", "completion": " uuid: 11655736993 The engineering team handles the logistics once a model is deployed, while the data science team provides an endpoint for the model.\n"}
{"prompt": "What is data drift and how is it measured? \n\n###\n\n", "completion": " uuid: 11655736993 Data drift is the change in the relationship between the input and the response over time. It is measured by comparing the predictions of the model over time with the actual results.\n"}
{"prompt": "How are new data models ingested by the pipeline? \n\n###\n\n", "completion": " uuid: 11655736993 The pipeline has to adjust to new ways of storing data and it ensures that data is ingested at any given moment.\n"}
{"prompt": "What is the process for managing resources and ensuring cost visibility? \n\n###\n\n", "completion": " uuid: 11655736993 Tags are assigned to each resource, and a cost reporting system ensures that costs can be seen and monitored for the last week.\n"}
{"prompt": "What tools are used for monitoring and tracking performance metrics? \n\n###\n\n", "completion": " uuid: 11655736993 Software engineering uses Graphana and Prometheus for monitoring and tracking performance metrics.\n"}
{"prompt": "What tools are used for deployment, and what programming languages are used? \n\n###\n\n", "completion": " uuid: 11655736993 Python deployment is done with Flask or BentoML, and complex models are done in Scala and PMML. The KPM Columbia framework is also sometimes used for open source models.\n"}
{"prompt": "What is Soma's background and what has she been doing for the past few years? \n\n###\n\n", "completion": " uuid: 12044330588 Soma's background is in engineering and statistics. For the past few years, she has been working in the field of AI for social impact. Currently, she works at the Urban Institute for AI for Social Impact, where they work on various problems concerning public health, education, and agriculture.\n"}
{"prompt": "What is the structure of the organization and how do they fund their projects? \n\n###\n\n", "completion": " uuid: 12044330588 The organization is project-specific and works with government machinery and partner organizations rather than direct stakeholders like farmers. They write grant proposals and receive funding from large funding agencies like the Google for India grant, the Melinda Gates Foundation, and the US funding arm. They have subject matter experts like physicians, doctors, and technical experts as well as a team of about 120+ personnel.\n"}
{"prompt": "What are some of the overarching objectives for their work on ML platforms? \n\n###\n\n", "completion": " uuid: 12044330588 One of the overarching objectives is to open up their innovation process and allow undergraduate students to pick up problems that they have already worked on to make improvements in every aspect of the ML cycle. They also want to have an absolute decoupling from platforms and have an open source, open sync model that anyone can contribute to, subject to data governance and privacy concerns.\n"}
{"prompt": "What is the DevOps practice followed by the company? \n\n###\n\n", "completion": " uuid: 10238582319 The company follows the DevOps practice of having four environments, sometimes five dev testing, performance, UAT or RC, basically release candidate and the final production for their products.\n"}
{"prompt": "Can you explain the testing and performance testing involved for products with AI models? \n\n###\n\n", "completion": " uuid: 10238582319 Manual testing is involved in the testing phase and then the performance testing is done with scripts that put a lot of load on the system to check the throughput and other factors. There are also test cases for each module which measure code coverage.\n"}
{"prompt": "What external tools are used for internal monitoring? \n\n###\n\n", "completion": " uuid: 10238582319 For internal monitoring, Grafana is used to catch all the logs of Kubernetes Pods and to give a view of memory utilization, CPU utilization and more.\n"}
{"prompt": "What information is provided to customers on the admin dashboard? \n\n###\n\n", "completion": " uuid: 10238582319 The admin dashboard talks about the usage, not the infra level metrics of how the system looks like. It provides information like number of API calls, how much they have burned versus how much they had quota for and so on.\n"}
{"prompt": "Are there any external tools used for ML model monitoring, data monitoring, and experiment tracking? \n\n###\n\n", "completion": " uuid: 10238582319 The company uses ML Flow for their machine learning workloads. However, for data monitoring and experiment tracking, it's all custom-built and stored in databases for later retrieval.\n"}
{"prompt": "What is the company's approach to solving problems around data resiliency, reproducibility, scalability, and data privacy and security? \n\n###\n\n", "completion": " uuid: 10238582319 The company solves problems by controlling the system configurations and allowing for one-click deployment to upscale infra as needed. However, they are still working on making their platform completely scale down to zero when no traffic is present, and making it model agnostic.\n"}
{"prompt": "What mode of engagement does the company use with customers? \n\n###\n\n", "completion": " uuid: 10238582319 The company works in a design partner mode, where they pick up one or two problems that are pressing and work with the customer to build out that feature that can be used by the customer's team. They work together with the customer in a weekly meeting or as needed to understand requirements and timelines.\n"}
{"prompt": "What are the next steps in the engagement process with the company? \n\n###\n\n", "completion": " uuid: 10238582319 The next step is for the customer to view a demo of the company's platform. From there, they will identify synergies and discuss potential NDA agreements before moving forward with any partnership.\n"}
{"prompt": "Why do companies have a multi-cloud environment? \n\n###\n\n", "completion": " uuid: 12361625175 It takes several years to migrate everything and sometimes it's easier to keep a 50-50 split on both clouds.\n"}
{"prompt": "Was this the case at Ross? \n\n###\n\n", "completion": " uuid: 12361625175 The speaker has seen this in at least three big companies, one of which is Roche.\n"}
{"prompt": "How is Roche's approach different from Novartis'? \n\n###\n\n", "completion": " uuid: 12361625175 In Novartis, there is a tool set to be followed, while in Roche, every project has a different tool set.\n"}
{"prompt": "Why was Sage Maker chosen over other tools? \n\n###\n\n", "completion": " uuid: 12361625175 Someone decided to use it three years ago and now people don't want to migrate everything. Additionally, using only one tool helps avoid the need to maintain different tools.\n"}
{"prompt": "Who is the decision maker when it comes to choosing tools? \n\n###\n\n", "completion": " uuid: 12361625175 The speaker does not know and usually people in big companies attribute these decisions to others.\n"}
{"prompt": "Do multi-cloud systems have any benefits for compliance or security? \n\n###\n\n", "completion": " uuid: 12361625175 From a security perspective, it may be difficult to handle, but the speaker is not a security expert.\n"}
{"prompt": "Who is the target user for Proof Only? \n\n###\n\n", "completion": " uuid: 12361625175 ML Ops people, but the speaker suggests targeting data scientists as their user pool is much larger.\n"}
{"prompt": "How can data scientists use Proof Only without deploying anything? \n\n###\n\n", "completion": " uuid: 12361625175 They can use the UI and request deployment without touching AWS as an aspirational option.\n"}
{"prompt": "Can Peter try out Proof Only offline? \n\n###\n\n", "completion": " uuid: 12361625175 Yes, the speaker is willing to try it on his private machine and provide feedback.\n"}
{"prompt": "What is the main concern in regards to having a loss? \n\n###\n\n", "completion": " uuid: 12362155036 The manual work involved in maintaining models, metadata, and everything.\n"}
{"prompt": "What is the desired solution to the concern over manual work? \n\n###\n\n", "completion": " uuid: 12362155036 Having a tool that can automate the maintenance of models, metadata, and everything.\n"}
{"prompt": "What kind of tool is needed to automate maintenance of models? \n\n###\n\n", "completion": " uuid: 12362155036 Any tool that can automate the maintenance of models, metadata, and everything.\n"}
{"prompt": "What are some examples of tools that have already helped in the maintenance of models? \n\n###\n\n", "completion": " uuid: 12362155036 Docker, OCD pipelines.\n"}
{"prompt": "What is the process of building and deploying models in the Merlin team? \n\n###\n\n", "completion": " uuid: 12362155036 Extract data > Build models > Demo models to product manager > Develop API > Input Java integration link > Predictions go back to Java layer > Displayed on UI.\n"}
{"prompt": "How is the Merlin team structure organized? \n\n###\n\n", "completion": " uuid: 12362155036 Based on use cases, AI expertise is not relevant. There are DevOps teams for all five AI teams and they have the same process.\n"}
{"prompt": "What is the process for introducing new technologies in the Merlin team? \n\n###\n\n", "completion": " uuid: 12362155036 Experimentation within the AI team followed by the involvement of DevOps consultants for implementation.\n"}
{"prompt": "Who is responsible for driving engagement with consultants when introducing new technology in the Merlin team? \n\n###\n\n", "completion": " uuid: 12362155036 The DevOps leads.\n"}
{"prompt": "Is the move to Kubernetes only for the ML team or for the entire company? \n\n###\n\n", "completion": " uuid: 12362155036 The move to Kubernetes is for the entire company.\n"}
{"prompt": "What is the typical approach for development? \n\n###\n\n", "completion": " uuid: 12249630284 Start with notebooks and then move forward with different use cases such as microservices, exploratory data analysis, and model training.\n"}
{"prompt": "How do developers handle microservices use cases? \n\n###\n\n", "completion": " uuid: 12249630284 They handle it differently, and don't needed to document it. They rely on exploratory phase perspective.\n"}
{"prompt": "What tools do they use for distributed processing? \n\n###\n\n", "completion": " uuid: 12249630284 They use Spark for distributed processing, and EKS or something like that.\n"}
{"prompt": "How do they store and query data for microservices? \n\n###\n\n", "completion": " uuid: 12249630284 They store data in structured format in Snowflake, so they don't need to write a job as the data is in their data lake. They use a data pipeline for faster and specific data query.\n"}
{"prompt": "What is the usage of notebooks today? \n\n###\n\n", "completion": " uuid: 12249630284 Notebooks are mostly used for training purposes.\n"}
{"prompt": "Are notebooks running over Kubernetes cluster? \n\n###\n\n", "completion": " uuid: 12249630284 Yes, they are running over a Kubernetes cluster.\n"}
{"prompt": "What are the two things that caught their attention? \n\n###\n\n", "completion": " uuid: 12249630284 Jupyter notebook thing and Airflow adoption.\n"}
{"prompt": "How do developers conduct tests on trained models? \n\n###\n\n", "completion": " uuid: 12249630284 Developers use a shadow model approach where they flip the switch when new model performs better. They also use Prometheus and Grafana open source tool for publishing metrics.\n"}
{"prompt": "How do they handle cost perspective with developers using a lot of notebooks? \n\n###\n\n", "completion": " uuid: 12249630284 DevOps team control resource allocation to developers to restrict their memory and CPU usage. Resources are limited by the underlying node and new resources are allocated only when required.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 10038142068 It is primarily to understand the machine learning problems that the company is trying to solve and to get feedback on what they are building at True Foundry.\n"}
{"prompt": "What is One Concern's business model? \n\n###\n\n", "completion": " uuid: 10038142068 One Concern sells the data which they generate from their models at scale to various customers who pay for it through some subscription of the data.\n"}
{"prompt": "What is Truefoundry's focus area? \n\n###\n\n", "completion": " uuid: 10038142068 Truefoundry's focus area is post model pipeline, which is essentially deploying models to production while following best engineering practices like logging, monitoring, and alerting. They also focus on developer experience to meet data scientists in their own toolchain.\n"}
{"prompt": "What are the main concerns that Truefoundry is trying to solve? \n\n###\n\n", "completion": " uuid: 10038142068 They are currently focused on productivity and repeatability of pipelines to ensure they can provide updated data to their customers quickly.\n"}
{"prompt": "Have they explored existing tools in the market for their model and data registry? \n\n###\n\n", "completion": " uuid: 10038142068 They are still in the development phase and have not made a decision yet but may end up using existing tools like ML Flow or build a similar custom solution.\n"}
{"prompt": "What are the systems in place for reverting to a previous version of the model and reproducing results? \n\n###\n\n", "completion": " uuid: 11773896093 Back population systems are in place to facilitate these tasks if necessary.\n"}
{"prompt": "What is the platform that will be overviewed and demonstrated? \n\n###\n\n", "completion": " uuid: 11773896093 The platform is not explicitly named.\n"}
{"prompt": "What is the speaker's job title and what was their previous experience? \n\n###\n\n", "completion": " uuid: 11773896093 The speaker is a machine learning engineer. They previously led a conversational AI team at Facebook where they worked on building machine learning models using that platform at the learner. Their work mostly dealt with NLP, NLU, and ASR.\n"}
{"prompt": "What are the three primary areas when it comes to deployments on the platform? \n\n###\n\n", "completion": " uuid: 11773896093 The three primary areas are services, jobs, and models.\n"}
{"prompt": "What are services in the context of deployment? \n\n###\n\n", "completion": " uuid: 11773896093 Services are long-running API endpoints that can be deployed on the platform.\n"}
{"prompt": "In what ways can the services be deployed? \n\n###\n\n", "completion": " uuid: 11773896093 Services can be deployed as a model API endpoint or as any arbitrary Python code.\n"}
{"prompt": "What are the jobs on the platform? \n\n###\n\n", "completion": " uuid: 11773896093 Jobs are batch inference or model training jobs that run once.\n"}
{"prompt": "How does the platform handle version control for deployments? \n\n###\n\n", "completion": " uuid: 11773896093 All deployments done through the UI are translated to a format that is tracked on a user's GitHub repository. Each deployment version is also associated with that specific deployment.\n"}
{"prompt": "What are some ways that the platform allows for experiments to be tracked and compared? \n\n###\n\n", "completion": " uuid: 11773896093 Experiments can be tracked as tables which include information on metrics and hyperparameters. They can also be compared by checking against each other as well as against older versions.\n"}
{"prompt": "What is the purpose of the model registry? \n\n###\n\n", "completion": " uuid: 11773896093 The model registry holds all the different versions of a model, including metrics and usage with the ability to see schemas and metadata for each.\n"}
{"prompt": "What are some of the differences between the platform and ML Flow's features? \n\n###\n\n", "completion": " uuid: 11773896093 The platform goes beyond what ML Flow can offer, allowing for deploying models directly through an integrated UI, logging plots as artifacts and interactive plots, and real-time model monitoring hierarchically from model summary to raw data.\n"}
{"prompt": "What is an area of interest for the listener that they would like to discuss in a future call? \n\n###\n\n", "completion": " uuid: 11773896093 Monitoring is an area of interest for the listener.\n"}
{"prompt": "What other capabilities does the speaker mention the platform offers besides the primary areas of deployment? \n\n###\n\n", "completion": " uuid: 11773896093 The platform offers an infra allocation layer and compatibility with existing tools.\n"}
{"prompt": "How is Nikonj doing? \n\n###\n\n", "completion": " uuid: 10277539714 Nikonj is doing great.\n"}
{"prompt": "What time is it for Nishan? \n\n###\n\n", "completion": " uuid: 10277539714 It's 10:17 a.m. for Nishan.\n"}
{"prompt": "What is Truefoundry building? \n\n###\n\n", "completion": " uuid: 10277539714 Truefoundry is building an ML platform similar to Facebook's fi learner.\n"}
{"prompt": "What is Branch and what is their primary business? \n\n###\n\n", "completion": " uuid: 10277539714 Branch is a micro lending app-based company primarily operating in African countries and India.\n"}
{"prompt": "What is the role of machine learning in Branch? \n\n###\n\n", "completion": " uuid: 10277539714 Machine learning models are used for loan evaluation, credit scores, and generating offers.\n"}
{"prompt": "Does Branch have a separate data science team? \n\n###\n\n", "completion": " uuid: 10277539714 No, the machine learning team at Branch is responsible for end-to-end work and includes feature creation and analysis.\n"}
{"prompt": "How many models are currently in production at Branch? \n\n###\n\n", "completion": " uuid: 10277539714 At any given time, Branch has roughly 10-12 models in production for different borrower types in four countries.\n"}
{"prompt": "What is the workflow for training and deployment at Branch? \n\n###\n\n", "completion": " uuid: 10277539714 Training happens on Sage Maker and each model is a repository where each branch is a version of the model. Deployment happens on Tactile's clusters, which have endpoint endpoints for different use cases.\n"}
{"prompt": "How does the Truefoundry platform help companies deploy their machine learning models to production? \n\n###\n\n", "completion": " uuid: 11655736739 The Truefoundry platform helps companies quickly deploy their machine learning models to production by building a platform for that purpose. It also helps companies build a developer platform where they can ship their software engineering services quickly to production on top of either multi-cloud environments or so on.\n"}
{"prompt": "What is the structure of Truefoundry's Kubernetes cluster and how is it managed? \n\n###\n\n", "completion": " uuid: 11655736739 Truefoundry's Kubernetes cluster structure consists of creating small units of clusters called namespaces within one cluster, which can also have multiple workspaces. These workspaces can be allocated to different groups of developers, with admins granting user permissions to deploy applications. The cluster is managed by Truefoundry's DevOps team and can also be managed from the UI or CLI.\n"}
{"prompt": "How does Truefoundry handle authentication and credential management for their cloud platforms and docker registries? \n\n###\n\n", "completion": " uuid: 11655736739 Truefoundry uses an internal authentication system for credential management for their cloud platforms and docker registries. Users can connect AWS, ECR, Google Container Registry or whatever is required, and can also connect their git repositories and secret stores like Google Cloud's parameter store.\n"}
{"prompt": "How many clusters and workspaces does Truefoundry currently have, and how much cost is associated with each one? \n\n###\n\n", "completion": " uuid: 11655736739 Truefoundry currently has one cluster which has multiple workspaces within it. The number of workspaces and associated costs for each one will depend on the resources allocated to it. The cost of each workspace is based on the resources being used, such as memory and storage, and will be shown in the UI for each application.\n"}
{"prompt": "Who has permission to deploy applications in Truefoundry's workspaces, and what are the limits on resource allocation? \n\n###\n\n", "completion": " uuid: 11655736739 Permissions to deploy applications are granted by admins who can assign users as editors or viewers depending on their level of access. Resource allocation limits can also be set for each workspace, so users cannot exceed the defined limits. This helps limit costs and prevents users from exceeding the resources available.\n"}
{"prompt": "What can we do if a feature is missing from the platform? \n\n###\n\n", "completion": " uuid: 11942347136 You can let us know and we can actually build it because most of these things will have to build.\n"}
{"prompt": "How does the platform enable quick deployments? \n\n###\n\n", "completion": " uuid: 11942347136 With a code or even with a docker image or anything, you can easily deploy it to a corresponding environment of your choice.\n"}
{"prompt": "What kind of libraries are provided for making it easy to learn? \n\n###\n\n", "completion": " uuid: 11942347136 Python libraries or Python SDKs are provided, generally understood by data scientists, ML engineers, everyone.\n"}
{"prompt": "Are best practices followed automatically by the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Yes, the platform automatically ensures best practices from a security standpoint are taken care of.\n"}
{"prompt": "What sits on top of the team's workflow? \n\n###\n\n", "completion": " uuid: 11942347136 The platform sits on top of whatever your actual team's workflow, whatever your team might be using at IP, if your use currency AWS use currency without creating a separate pipeline.\n"}
{"prompt": "What are the three major parts of the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Connecting to infrastructure, deployment, and resource allocation are the three major parts of the platform.\n"}
{"prompt": "How is deployment done on the platform? \n\n###\n\n", "completion": " uuid: 11942347136 You just click like whatever you want to deploy from a source code, like if you were using Azure, or if you have a docker image, you can directly upload your docker image.\n"}
{"prompt": "What happens when something goes wrong with the system? \n\n###\n\n", "completion": " uuid: 11942347136 Our team will be available, we create like a slack channel or anything that is convenient to you, and all times our team will be available.\n"}
{"prompt": "How is data protected while using the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Only the source limits are stored, no client data, nothing flows to us. Lecture will not have access because it's installed on your cloud, so all data will flow through your cloud. So we don't even have access to it.\n"}
{"prompt": "Can you provide a demonstration of the platform? \n\n###\n\n", "completion": " uuid: 11942347136 Yes, a demo can be scheduled either later this week or early next week, for a detailed understanding.\n"}
{"prompt": "What question does Emily ask about model performance during candidate deployment? \n\n###\n\n", "completion": " uuid: 12336402979 Do you have you you still use the airflow UI for like visualizing let's say they want to know a few metrics regarding the model?\n"}
{"prompt": "How are the metrics regarding models monitored according to Emily? \n\n###\n\n", "completion": " uuid: 12336402979 All the metrics are right to some. Time series database and mostly more online survey monitoring are done through the GRAFANA\n"}
{"prompt": "What is the reason some traditional organizations do not prefer a multi-cloud approach? \n\n###\n\n", "completion": " uuid: 12336402979 Because for all the cloud, if you try to get the bytes data out, you need to pay actual price. This has turned out to be very significant.\n"}
{"prompt": "What is the purpose of the intra management layer according to the speaker? \n\n###\n\n", "completion": " uuid: 12336402979 To abstract away, not only Kubernetes but also any details related to any infrastructure, pretty much from the developer\n"}
{"prompt": "What happens when a developer connects a cluster to the platform? \n\n###\n\n", "completion": " uuid: 12336402979 When they do that, they can provide us the cloud provider. Okay. That okay, I'm running an AWS cluster. Yeah or GCP Azure cluster, anything right?\n"}
{"prompt": "What are the challenges related to supporting existing clusters as per the speaker? \n\n###\n\n", "completion": " uuid: 12336402979 I think that those are some of the barriers that we are currently facing. And that's why we right now say that okay, we will have our own separate cluster\n"}
{"prompt": "What is the ratio of platform developers to ML developers at Quora according to the speaker? \n\n###\n\n", "completion": " uuid: 12336402979 Less than 10 platform developers and about three to four times the platform developers are the ML developers.\n"}
{"prompt": "How is Angel doing? \n\n###\n\n", "completion": " uuid: 12361625221 Good.\n"}
{"prompt": "What is the purpose of the meeting? \n\n###\n\n", "completion": " uuid: 12361625221 To summarize their understanding and walk through the major components needed for the solution.\n"}
{"prompt": "What are the major components needed for the solution? \n\n###\n\n", "completion": " uuid: 12361625221 Architecture perspective, platform design, and APIs that can be used to expose the solution to customers.\n"}
{"prompt": "What is Resolve.ai providing? \n\n###\n\n", "completion": " uuid: 12361625221 Support in their platform that they provide to their SaaS companies.\n"}
{"prompt": "What is the use case provided for Resolve.ai's platform? \n\n###\n\n", "completion": " uuid: 12361625221 For example, a client called Modi uploads their knowledge bases and specific information related to their policies and ticketing system. AI will respond to the queries and if unable to, it goes to an agent.\n"}
{"prompt": "How is the model retrained when a customer uploads their data? \n\n###\n\n", "completion": " uuid: 12361625221 The platform retrain the model and expose it as an endpoint to the customer's data.\n"}
{"prompt": "How is the model loaded and deployed on the platform? \n\n###\n\n", "completion": " uuid: 12361625221 Using Python for serialization and mlFlow to save the models to ONNX format. It is then pushed to the model registry and can be deployed using the provided SDKs.\n"}
{"prompt": "How can a data scientist log in their models? \n\n###\n\n", "completion": " uuid: 12361625221 They can use the provided model registry and SDKs to deploy their models and log parameters as well as datasets.\n"}
{"prompt": "How can a data scientist run their training job? \n\n###\n\n", "completion": " uuid: 12361625221 They can use the provided API and SDKs to run the training job on the cluster.\n"}
{"prompt": "How does the platform handle GPU-based loads? \n\n###\n\n", "completion": " uuid: 12361625221 The cluster administrator must first add a node pool with GPU. The platform uses dynamic node auto-provisioning in AWS and GKE, while pre-adding a node pool with the minimum size set to zero in Azure.\n"}
{"prompt": "What cloud platforms does the company currently support? \n\n###\n\n", "completion": " uuid: 11354403948 AWS, GCP, and Azure.\n"}
{"prompt": "Is on-premises an option for the company? \n\n###\n\n", "completion": " uuid: 11354403948 Yes, they are looking into supporting on-premises due to client demand for air gap environments.\n"}
{"prompt": "What is the company's plan for cloud support? \n\n###\n\n", "completion": " uuid: 11354403948 They want to provide a similar web experience for launching training infrastructure and are considering a no-code experience in the future.\n"}
{"prompt": "What programming environment does the company's cloud support? \n\n###\n\n", "completion": " uuid: 11354403948 Python Jupiter environment hosted on any of the Cloud platforms.\n"}
{"prompt": "What does the company plan to do in terms of deployment space for models? \n\n###\n\n", "completion": " uuid: 11354403948 After focusing on training, they plan to start worrying about the deployment space. They are considering Kubeflow and other solutions.\n"}
{"prompt": "How big is the team currently working on creating the platform? \n\n###\n\n", "completion": " uuid: 11354403948 The engineering team has about ten people.\n"}
{"prompt": "Does the company have any full-time data scientists on their team? \n\n###\n\n", "completion": " uuid: 11354403948 No, the data scientists are more on the customer solution team and collaborate closely together to build tools for support.\n"}
{"prompt": "What is the company's vision for their platform? \n\n###\n\n", "completion": " uuid: 11354403948 They want to simplify the experience for data scientists, developers, and clients by abstracting the complexities that a data scientist is usually not familiar with and providing a one-stop solution for everything post-model training till deployment.\n"}
{"prompt": "What does the company want to offer for model deployment? \n\n###\n\n", "completion": " uuid: 11354403948 The company wants to offer support for serving models through model servers, creating fast API endpoints, and creating Cron jobs or dual jobs for it.\n"}
{"prompt": "Is the company open to collaboration with the Truefoundry team? \n\n###\n\n", "completion": " uuid: 11354403948 Yes, they are open to collaborating with the Truefoundry team and would love to schedule a demo to discuss further.\n"}
{"prompt": "What link are they referring to? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What is the name of the dock that they are discussing? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What is the thing they just put on WhatsApp? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "When will they put their five minutes back? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What report did they find? \n\n###\n\n", "completion": " uuid: 12249630284 Multicloud report\n"}
{"prompt": "Who did they thank for tips on Telegram? \n\n###\n\n", "completion": " uuid: 12249630284 Muthu\n"}
{"prompt": "What did the tips on Telegram help the person achieve? \n\n###\n\n", "completion": " uuid: 12249630284 Visa for Singapore\n"}
{"prompt": "What was the advice that people gave the person about applying for a visa in Singapore? \n\n###\n\n", "completion": " uuid: 12249630284 Not to risk it as they were going to India anyway\n"}
{"prompt": "What did the person do instead of going to Singapore for a visa? \n\n###\n\n", "completion": " uuid: 12249630284 Applied through Telegram groups and got slots in 2023\n"}
{"prompt": "Where is the person currently located? \n\n###\n\n", "completion": " uuid: 12249630284 Bay Area\n"}
{"prompt": "Who welcomed Muthu on board and to what? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "What hypothesis are they trying to learn about? \n\n###\n\n", "completion": " uuid: 12249630284 Whether their platform can serve the needs of companies deploying across multiple clouds\n"}
{"prompt": "What specific domain is Balbix in? \n\n###\n\n", "completion": " uuid: 12249630284 Cybersecurity quantification domain\n"}
{"prompt": "What are the targets for companies that Balbix is interested in? \n\n###\n\n", "completion": " uuid: 12249630284 Companies with a minimum requirement of 15,000 devices\n"}
{"prompt": "What ML platform does Truefoundry deal with? \n\n###\n\n", "completion": " uuid: 12249630284 Unknown\n"}
{"prompt": "How many clouds is Truefoundry serving currently? \n\n###\n\n", "completion": " uuid: 12249630284 Three clouds\n"}
{"prompt": "What was the focus of the team in the last year? \n\n###\n\n", "completion": " uuid: 12249630284 Data platform and operationalization of machine learning\n"}
{"prompt": "What is the current process of deployment for training? \n\n###\n\n", "completion": " uuid: 12249630284 Train models in GPU node and store in the history packets\n"}
{"prompt": "What was Airflow used for? \n\n###\n\n", "completion": " uuid: 12249630284 Jobs and orchestration of work\n"}
{"prompt": "What graph database are they using? \n\n###\n\n", "completion": " uuid: 12249630284 Neo4J\n"}
{"prompt": "What is next on their list for deployment? \n\n###\n\n", "completion": " uuid: 12249630284 Jupyter Hub\n"}
{"prompt": "How do developers currently run notebooks? \n\n###\n\n", "completion": " uuid: 12249630284 Through GPU node and access from local host\n"}
{"prompt": "Do developers submit jobs as scripts or through notebooks? \n\n###\n\n", "completion": " uuid: 12249630284 Both\n"}
{"prompt": "What was the trigger for starting True Foundry? \n\n###\n\n", "completion": " uuid: 11942346630 They realized that operationalization of machine learning models was hard and they saw the state-of-the-art system at Facebook.\n"}
{"prompt": "How does True Foundry see itself in relation to platform teams within large companies? \n\n###\n\n", "completion": " uuid: 11942346630 True Foundry sees itself as an ally to platform teams within large companies.\n"}
{"prompt": "What are the different stakeholders that a platform team typically deals with, and what are their requirements? \n\n###\n\n", "completion": " uuid: 11942346630 A platform team typically deals with data scientists, machine learning engineers, and business decision makers, and their requirements differ depending on their technical maturity.\n"}
{"prompt": "What is True Foundry's solution to the challenges that platform teams face? \n\n###\n\n", "completion": " uuid: 11942346630 True Foundry is building a platform on top of which other platform teams can build, with layers that interface with their own stakeholders and handle under the hood plumbing.\n"}
{"prompt": "What is the specific problem that True Foundry is trying to solve? \n\n###\n\n", "completion": " uuid: 11942346630 True Foundry is trying to solve the problem of building a platform that is generic enough to serve all stakeholders of a platform team, without requiring them to build everything from scratch.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12150845733 The purpose of the call is to learn from the experience of CBS and understand the state of machine learning at their company.\n"}
{"prompt": "What is Crew Foundry? \n\n###\n\n", "completion": " uuid: 12150845733 Crew Foundry is a startup founded by Rag, Abhishek, and Bibik with the goal of building a machine learning platform to simplify the process of model deployment and monitoring.\n"}
{"prompt": "What type of models is the CVS team building? \n\n###\n\n", "completion": " uuid: 12150845733 The CVS team is focusing on automating claim processing for their healthcare insurance unit using computer vision and NLP.\n"}
{"prompt": "Does the CVS team use outside vendors for document processing? \n\n###\n\n", "completion": " uuid: 12150845733 Yes, the CVS team uses a vendor called Conduent to handle the manual processing of documents received through physical mail.\n"}
{"prompt": "What is the differentiation of Crew Foundry's platform compared to what is already available, such as Azure or GCP? \n\n###\n\n", "completion": " uuid: 12150845733 Crew Foundry differentiates itself through potential customization for companies and working on supporting current use cases. They are also focusing on monitoring and surveillance of models once deployed.\n"}
{"prompt": "What types of models is the CVS team building? \n\n###\n\n", "completion": " uuid: 12150845733 The CVS team is focusing on automating claim processing for their healthcare insurance unit using computer vision and NLP.\n"}
{"prompt": "What is the team structure for machine learning at CBS? \n\n###\n\n", "completion": " uuid: 12150845733 There is a central SVP who manages both the Data Science and Data Engineering team, which serves the entire company. Data Science builds the models while Data Engineering supports deployment and maintenance of the models.\n"}
{"prompt": "What is the primary focus of the models being built by the CVS team? \n\n###\n\n", "completion": " uuid: 12150845733 The primary focus is on optimizing operations and cost savings through automating claim processing.\n"}
{"prompt": "Does the CVS team use A/B testing for real-time models as well as batch models? \n\n###\n\n", "completion": " uuid: 12150845733 Yes, the CVS team uses A/B testing for both real-time and batch models in order to create control groups and monitor model performance.\n"}
{"prompt": "What has changed in the dynamic between data scientists and ML engineers over time? \n\n###\n\n", "completion": " uuid: 11487646267 Data scientists needed less and less help from ML engineers as they became more mature\n"}
{"prompt": "What was the hard part of putting data jobs into production? \n\n###\n\n", "completion": " uuid: 11487646267 Serving layer, API changes, and ensuring platform resources could support the model\n"}
{"prompt": "What specific task did data scientists need to verify before putting models into production? \n\n###\n\n", "completion": " uuid: 11487646267 Ensuring the real time production features were the same as the features used to train the model\n"}
{"prompt": "What framework does the team use for TensorFlow models? \n\n###\n\n", "completion": " uuid: 11487646267 They use the TensorFlow serving framework\n"}
{"prompt": "How many people are on the platform team? \n\n###\n\n", "completion": " uuid: 11487646267 Roughly 6 people are on the platform team\n"}
{"prompt": "What is a key challenge the team is facing with onboarding data scientists? \n\n###\n\n", "completion": " uuid: 11487646267 Making it easy to onboard data scientists onto the platform and reducing the need for MLE involvement\n"}
{"prompt": "Is the team currently using any monitoring for models in production? \n\n###\n\n", "completion": " uuid: 11487646267 They have some qualitative monitoring available but it's not fully matured as a standard platform feature\n"}
{"prompt": "What experience does Avishek bring to Truefoundry? \n\n###\n\n", "completion": " uuid: 11655736677 Avishek led the software engineering and infrastructure side of things at Facebook for almost six years.\n"}
{"prompt": "What was the author's previous work experience? \n\n###\n\n", "completion": " uuid: 11655736677 The author used to work with a hedge fund called World Fund, doing a lot of algorithmic trading and investment across different asset classes.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 11655736677 The goal of Truefoundry is to enable every company to be an ML led company by providing a platform that speeds up the deployment of machine learning models.\n"}
{"prompt": "What challenges does Truefoundry solve for data science teams? \n\n###\n\n", "completion": " uuid: 11655736677 Truefoundry solves the challenges of democratizing the development of machine learning models along with testing, speeding up developer workflows, and providing flexibility through Python, SDKs, and other libraries.\n"}
{"prompt": "What does Truefoundry's platform provide for data science teams? \n\n###\n\n", "completion": " uuid: 11655736677 The platform provides independence and flexibility through Python, SDKs, and other libraries, full security and control for the infrastructure, and monitoring for model performance and debugging.\n"}
{"prompt": "What is the value of Truefoundry's platform for big tech companies? \n\n###\n\n", "completion": " uuid: 11655736677 Big tech companies can see improvement in their overall process efficiency by 30% to 40% and additional revenues being generated in the range of 10% by investing in internal platform teams that accelerate the time to value of ML projects.\n"}
{"prompt": "What is the purpose of the follow-up with the team? \n\n###\n\n", "completion": " uuid: 11655736677 The purpose of the follow-up is to understand the team's use cases and workflow and present potential useful features of Truefoundry's platform as well as potentially do a small pilot to add value to the team.\n"}
{"prompt": "What does the author hope to achieve through an investment in Truefoundry? \n\n###\n\n", "completion": " uuid: 11655736677 The author hopes to have good leaders who can be a part of their journey and take help of their network and guidance to build a really good global SaaS platform.\n"}
{"prompt": "What is the major difference between lenders like Credibly versus lenders like Chad or MX? \n\n###\n\n", "completion": " uuid: 10128442512 Lenders like Credibly target subprime customers who cannot get loans from banks and charge higher interest rates whereas banks are highly selective and cater to mostly prime customers with lower interest rates.\n"}
{"prompt": "What is Credibly's business model? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly is a fintech company in the commercial lending space and provides loans and MCAs to small medium owners digitally.\n"}
{"prompt": "How does Credibly acquire customers? \n\n###\n\n", "completion": " uuid: 10128442512 Credibly acquires customers through external agents or brokers who bring in subprime customers that the banks cannot cater to.\n"}
{"prompt": "What is the challenge in customer acquisition for lenders like Credibly? \n\n###\n\n", "completion": " uuid: 10128442512 The challenge is that subprime customers generally do not have a good web presence and conventional marketing channels like email, physical emails, and phone calls need to be utilized.\n"}
{"prompt": "What is hybrid underwriting process for Credibly? \n\n###\n\n", "completion": " uuid: 10128442512 It is a combination of automation using robots and manual underwriting or human decision making.\n"}
{"prompt": "What kind of data parsing is required in the underwriting process for commercial loans? \n\n###\n\n", "completion": " uuid: 10128442512 Parsing of application data, external sources such as credit bureau, web data, social media data, and public report data from the Secretary of the State, and financial information such as bank statements and tax returns.\n"}
{"prompt": "What kind of signals are picked up from the bank statement data in the underwriting process for commercial loans? \n\n###\n\n", "completion": " uuid: 10128442512 Consistency in revenue generation, any bad signals such as negative days or overdraft fees, and changes in deposits.\n"}
{"prompt": "What kind of signals can be picked up from social media data in the underwriting process for commercial loans? \n\n###\n\n", "completion": " uuid: 10128442512 It varies depending on the industry, but for example, good social media presence may be important for restaurants or other consumer-facing businesses that rely on customer reviews and ratings.\n"}
{"prompt": "What is the goal of the ML developers platform? \n\n###\n\n", "completion": " uuid: 11655737135 To provide a value add to the business team and make ML developers faster while saving on the cost of building and maintaining.\n"}
{"prompt": "What are the main differentiators of the platform from existing solutions? \n\n###\n\n", "completion": " uuid: 11655737135 The platform is built deeply for the developers, with multiple interfaces for deployment depending on the developer's comfort level, and aims to unify the machine learning deployment process with software deployment process, following the same principles that are followed in software engineering. In addition, the platform aims to make custom plugins building simple and easy.\n"}
{"prompt": "Who is the target customer of the platform? \n\n###\n\n", "completion": " uuid: 11655737135 The platform targets both data scientists and machine learning engineers, as the platform is built to meet the skill sets of both and the belief that both will likely use the platform for production use cases.\n"}
{"prompt": "What are the three parts of the ML platform? \n\n###\n\n", "completion": " uuid: 11655737135 The platform has an intra-team interface for creating a secure environment, a developer-exposed interface for deploying services and jobs, a monitoring interface to track performance and detect issues.\n"}
{"prompt": "What are the three types of deployments you can do on the platform? \n\n###\n\n", "completion": " uuid: 11655737135 You can deploy a model, a service, or a job on the platform.\n"}
{"prompt": "What is the metrics visualization process for performance monitoring? \n\n###\n\n", "completion": " uuid: 11655737135 The metrics visualization process in the performance monitoring dashboard includes a hierarchical overview of model performance, with the ability to compare metrics across different time windows and track subsets of data with different log losses to debug model performance issues.\n"}
{"prompt": "How are you? \n\n###\n\n", "completion": " uuid: 10097841502 I'm good, how are you doing?\n"}
{"prompt": "May I record this? \n\n###\n\n", "completion": " uuid: 10097841502 Yeah, please.\n"}
{"prompt": "What is the goal of talking to companies in the machine learning domain? \n\n###\n\n", "completion": " uuid: 10097841502 To try and see what the use cases are and what kind of challenges they have been facing.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 10097841502 To make machine learning productionization simple and easy for companies to deploy ML models.\n"}
{"prompt": "What does Simpler do? \n\n###\n\n", "completion": " uuid: 10097841502 Simpler is an employee experience company that facilitates communication within organizations and provides insights to leadership based upon employees' conversations.\n"}
{"prompt": "What channels is Simpler connected to? \n\n###\n\n", "completion": " uuid: 10097841502 Simpler is connected to Slack, Confluence, Jira, Atlassian products, Microsoft Teams, and Google Drive.\n"}
{"prompt": "Where does the AI team get all the data? \n\n###\n\n", "completion": " uuid: 10097841502 The AI team gets all the data on Salesforce and then the data is aggregated onto Snowflake for experimentation and building model stuff.\n"}
{"prompt": "What kind of infrastructure does Simpler use for training the models? \n\n###\n\n", "completion": " uuid: 10097841502 Simpler uses AWS instances and GPUs for training the models.\n"}
{"prompt": "Do you use any models server to run your models? \n\n###\n\n", "completion": " uuid: 10097841502 No, we are exploring triton but we haven't adopted it at scale. Most of our models are consumed by APIs that are deployed on EKS, so Kubernetes, and we have Auto scaling enabled.\n"}
{"prompt": "What is the biggest challenge that Simpler's AI team is facing? \n\n###\n\n", "completion": " uuid: 10097841502 The biggest challenge is the combination of scalability and monitoring, specifically how to deploy 400 models, monitor the quality of these models, and have alert mechanisms to tell the team where there is a need to work upon.\n"}
{"prompt": "Who is Mike Boufford? \n\n###\n\n", "completion": " uuid: 10881877574 Unknown\n"}
{"prompt": "Who is the CTO of Greenhouse? \n\n###\n\n", "completion": " uuid: 10881877574 Unknown\n"}
{"prompt": "What is the speaker's experience working with startups? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker is still working with startups.\n"}
{"prompt": "What is the speaker's view on innovation? \n\n###\n\n", "completion": " uuid: 10881877574 Innovation happens when there are different problems and the speaker needs to talk to new people to understand those problems.\n"}
{"prompt": "What is the speaker's view on the future of machine learning? \n\n###\n\n", "completion": " uuid: 10881877574 Adoption of machine learning is contingent on how easy it is and it is going to happen. It is important to make it 100x easier for mass adoption.\n"}
{"prompt": "What are some of the lessons the speaker learned from Facebook? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker learned that Facebook had different tools built out for each part of the ML development lifecycle, deployment was done seamlessly and parallel computation should be used to solve resource allocation problems.\n"}
{"prompt": "What simple tweak did Facebook do to reduce unnecessary computing costs? \n\n###\n\n", "completion": " uuid: 10881877574 Facebook showed developers the cost of each training run, which made them more conscious of their computing usage.\n"}
{"prompt": "How did the speaker and their team incorporate lessons learned from Facebook into their platform? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker and their team are trying to incorporate Facebook's lessons one by one into their platform.\n"}
{"prompt": "What kind of experience is the speaker trying to build for developers? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker is trying to build a more developer-friendly experience.\n"}
{"prompt": "How did the speaker schedule a call with the person they were speaking with? \n\n###\n\n", "completion": " uuid: 10881877574 The speaker shared their calendar link and will email the person to set up a call with RC together.\n"}
{"prompt": "What was causing pain points with deploying ML models to Kubernetes? \n\n###\n\n", "completion": " uuid: 11575824756 The approach being used for other types of applications was being used to deploy ML models.\n"}
{"prompt": "What was the previous approach used to deploy ML models? \n\n###\n\n", "completion": " uuid: 11575824756 Models were packaged into Jupiter notebooks and then handed off to someone who would create a PY file and understand the code.\n"}
{"prompt": "Why was the previous approach problematic? \n\n###\n\n", "completion": " uuid: 11575824756 Assumptions were made in the notebook that were not necessarily true in the production or development environment, causing problems and requiring extensive diagnosis.\n"}
{"prompt": "What is the current approach to deploying ML models? \n\n###\n\n", "completion": " uuid: 11575824756 Using a clean API to handle preprocessing, inference, and post processing, with a library approach and a very organized and fast process.\n"}
{"prompt": "Where are the fitted model artifacts being stored? \n\n###\n\n", "completion": " uuid: 11575824756 The artifacts are being stored using the ML Flow model registry and stored on S3 backend.\n"}
{"prompt": "How often are models in production updated? \n\n###\n\n", "completion": " uuid: 11575824756 Not very frequently - the models are only updated if there is an issue and are driven by client feedback.\n"}
{"prompt": "What is the main challenge currently faced in model monitoring? \n\n###\n\n", "completion": " uuid: 11575824756 Lack of a solution for monitoring and being very reactive, not proactive, in detecting drift.\n"}
{"prompt": "What is the current strategy for monitoring model performance? \n\n###\n\n", "completion": " uuid: 11575824756 Doing batch audits every so often to track accuracy and F1 scores.\n"}
{"prompt": "What are the current top challenges being addressed? \n\n###\n\n", "completion": " uuid: 11575824756 Monitoring and deploying ML models effectively, and finding the right workflow and solutions to address these challenges.\n"}
{"prompt": "Why is Groundspeed looking for external monitoring solutions? \n\n###\n\n", "completion": " uuid: 11575824756 Assumption that there are great tools out there already, and it might not make sense to build internal tools for model monitoring.\n"}
{"prompt": "What does the speaker mention about provisioning clusters? \n\n###\n\n", "completion": " uuid: 11488124534 They provide clusters as needed.\n"}
{"prompt": "Has the team considered using AWS, Sage Maker, or Azure ML for ML operations? \n\n###\n\n", "completion": " uuid: 11488124534 Yes, they have considered using Azure ML, but primarily for training.\n"}
{"prompt": "What was the main reason to move from Azure ML to Databricks? \n\n###\n\n", "completion": " uuid: 11488124534 The requirement that the data does not leave basically a VPC as Azure required the use of a remote desktop or remote shell to hop into the VPC.\n"}
{"prompt": "Has the team evaluated Sage Maker? \n\n###\n\n", "completion": " uuid: 11488124534 No, they have not evaluated Sage Maker.\n"}
{"prompt": "Were you part of the decision-making process to deploy on Kubernetes rather than a managed ML Ops platform? \n\n###\n\n", "completion": " uuid: 11488124534 No, the decision predated the speaker's involvement.\n"}
{"prompt": "How many test cases does the team write for their models? \n\n###\n\n", "completion": " uuid: 11488124534 Probably not as many as they should.\n"}
{"prompt": "What area stands out frequently as a challenge for model monitoring? \n\n###\n\n", "completion": " uuid: 11488124534 Monitoring is an area that stands out frequently.\n"}
{"prompt": "Will Carlos be open to spending some time going through a platform demo and giving feedback? \n\n###\n\n", "completion": " uuid: 11488124534 Yes, Carlos agrees to spend some time going through the platform demo and giving feedback.\n"}
{"prompt": "Do the team members work mostly remotely or from the office? \n\n###\n\n", "completion": " uuid: 11488124534 They work mostly from home, but have scheduled office visits.\n"}
{"prompt": "Does the office remain empty throughout the year? \n\n###\n\n", "completion": " uuid: 11488124534 No, the office is reserved throughout the year, but more people are coming back.\n"}
{"prompt": "Where is the person based? \n\n###\n\n", "completion": " uuid: 12428091030 The person is based in Canada.\n"}
{"prompt": "How long have they been in Canada? \n\n###\n\n", "completion": " uuid: 12428091030 They have been in Canada for almost six years.\n"}
{"prompt": "What is the goal of the call? \n\n###\n\n", "completion": " uuid: 12428091030 The goal of the call is to understand more about the company's data science initiatives, use cases and structure, the tools they use, key priorities, and any challenges they are experiencing.\n"}
{"prompt": "Who are the co-founders of Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 The co-founders of Truefoundry are Rogue, Abishek and Nikonju.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 The goal of Truefoundry is to help companies in their journey of machine learning operationalization.\n"}
{"prompt": "What internal system did Facebook build that inspired Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 Facebook built an internal system called Bill on Earth which allowed ML developers to be quite independent and abstracted out many pieces of infrastructure.\n"}
{"prompt": "What previous experience does the speaker have? \n\n###\n\n", "completion": " uuid: 12428091030 The speaker worked for six years with a hedge fund, using data to build trading strategies and also did portfolio management for worldwide.\n"}
{"prompt": "How many people are on the ML team at Son of C? \n\n###\n\n", "completion": " uuid: 12428091030 The ML team at Son of C has grown to almost 350 people.\n"}
{"prompt": "What tool stack do they use? \n\n###\n\n", "completion": " uuid: 12428091030 They use Eks for provisioning resources, Kubernetes and Terraform for deployment, Snowflake for data storage and Selden for logging model metrics.\n"}
{"prompt": "Who is responsible for deploying the models? \n\n###\n\n", "completion": " uuid: 12428091030 The ML engineering team is responsible for deploying the models.\n"}
{"prompt": "What question did Stevetha ask first? \n\n###\n\n", "completion": " uuid: 11185249632 How are you?\n"}
{"prompt": "What did Stevetha ask next and what was the response? \n\n###\n\n", "completion": " uuid: 11185249632 Stevetha asked if Sivasa could see them and Sivasa responded that he couldn't see them yet.\n"}
{"prompt": "Who did Sivasa say was with him and what was his role? \n\n###\n\n", "completion": " uuid: 11185249632 Sivasa said Vishak was with him and he was a hands-on data scientist who was an AutoML platform's hands-on practitioner perspective also.\n"}
{"prompt": "What is the goal of Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11185249632 The goal of Truefoundry platform is to build a platform for enabling companies to test out and deploy models seamlessly.\n"}
{"prompt": "What kind of problems and use cases does Maverick deal with? \n\n###\n\n", "completion": " uuid: 11185249632 Maverick deals with problems around banking, including predicting default for loans, predicting home prices in the US, cross-sell and up-sell for customers, and marketing analytics for wealth management firms.\n"}
{"prompt": "What AutoML platform does Maverick primarily use? \n\n###\n\n", "completion": " uuid: 11185249632 Maverick primarily uses Data IQ for its AutoML platform.\n"}
{"prompt": "How does Data IQ handle preprocessing and postprocessing functions? \n\n###\n\n", "completion": " uuid: 11185249632 Data IQ has recipes for transformations and can handle preprocessing and postprocessing functions.\n"}
{"prompt": "What is the size of the ML team at Maverick? \n\n###\n\n", "completion": " uuid: 11185249632 The ML team at Maverick is about 40-45 people, including data analysts and table specialists, while the data validation team is around 150 people and the rest is made up of ETL, data engineering, and other staff.\n"}
{"prompt": "What is the revenue of Data IQ? \n\n###\n\n", "completion": " uuid: 11185249632 Data IQ is a $100 million revenue company with global customers and is the second-largest AutoML platform.\n"}
{"prompt": "What event is the speaker logging in from their mobile for? \n\n###\n\n", "completion": " uuid: 11354392663 They are logging into a search event.\n"}
{"prompt": "Why is the speaker not able to connect to the internet? \n\n###\n\n", "completion": " uuid: 11354392663 The speaker is not able to connect to the internet due to some issue.\n"}
{"prompt": "Who is the co-founder of the company that is mentioned in the conversation? \n\n###\n\n", "completion": " uuid: 11354392663 The co-founder of the company mentioned in the conversation is Anurag.\n"}
{"prompt": "What is the goal of True Foundry? \n\n###\n\n", "completion": " uuid: 11354392663 The goal of True Foundry is to make it easy for data scientists and ML engineers to take their machine learning models to production.\n"}
{"prompt": "What tools do the data scientists use for prototyping? \n\n###\n\n", "completion": " uuid: 11354392663 The data scientists use XGBoost and PyTorch for prototyping.\n"}
{"prompt": "How do they extract information from the patient chart? \n\n###\n\n", "completion": " uuid: 11354392663 They use NLT to extract specific data points from massive clinical documents.\n"}
{"prompt": "What kind of monitoring platform do they have? \n\n###\n\n", "completion": " uuid: 11354392663 They have an internal monitoring platform where they maintain a representative test set that is curated with time.\n"}
{"prompt": "What kind of models do they deploy and where? \n\n###\n\n", "completion": " uuid: 11354392663 They deploy different kinds of models and use them in production. They don't have extensive feature stores and they load the text either directly from Elastic. They deploy on EC2 machines and are currently piloting with Databricks.\n"}
{"prompt": "What type of web server generally works better? \n\n###\n\n", "completion": " uuid: 12249609647 Right border server generally work better.\n"}
{"prompt": "Have you heard of thoughts of anything along those banks? \n\n###\n\n", "completion": " uuid: 12249609647 Not at the moment, I would be very open and frank here.\n"}
{"prompt": "What are the challenges that you see with respect to this entire model frameworks? \n\n###\n\n", "completion": " uuid: 12249609647 Currently, there is some transition going on, and unfortunately, I have decided to move on. So, in that case, I think challenges and everything maybe it will be better for you guys, you know, discuss with the one who will take it over from there.\n"}
{"prompt": "Will all the problems be prioritized at the same time? \n\n###\n\n", "completion": " uuid: 12249609647 No, the ones which are priority in terms of the business outcomes will be prioritized over everything that I mentioned.\n"}
{"prompt": "Have you decided where you are going? \n\n###\n\n", "completion": " uuid: 12249609647 Some options. I still need to figure out the best possible from there.\n"}
{"prompt": "Who is going to take over your old position? \n\n###\n\n", "completion": " uuid: 12249609647 Currently, not somebody from my role for sure. It's going to be somebody within the team who is just a, you know, data science types.\n"}
{"prompt": "What does True Foundry focus on? \n\n###\n\n", "completion": " uuid: 12249609647 True Foundry comes at the model level. So, we don't deal too much with the data and feature engineering side of things. We do deal with model and beyond Basically, okay?\n"}
{"prompt": "What is the main thing that True Foundry is solving for? \n\n###\n\n", "completion": " uuid: 12249609647 The main thing that we are solving for is obstructing away infrastructure in a data science, friendly using data science.\n"}
{"prompt": "What can you do once you put a model to production using the True Foundry platform? \n\n###\n\n", "completion": " uuid: 12249609647 Once you put a model to production using the platform, you can also get very quick monitoring model monitoring and data drift dashboards as well.\n"}
{"prompt": "What is the objective of True Foundry? \n\n###\n\n", "completion": " uuid: 12249609647 The main thing that we are solving for is obstructing away infrastructure in a data science, friendly using data science, Friendly APIs essentially.\n"}
{"prompt": "Are you able to quickly deploy the model without making the data scientists deal with infrastructure? \n\n###\n\n", "completion": " uuid: 12249609647 Yes, technically a data scientist could get an API endpoint directly from the Jupiter notebook.\n"}
{"prompt": "What are some areas that True Foundry is working on? \n\n###\n\n", "completion": " uuid: 12249609647 We would love to show the product demo as well to you and get some more concrete feedback at some point. So, those are the areas that we are working on.\n"}
{"prompt": "Are you going to continue to work in data science? \n\n###\n\n", "completion": " uuid: 12249609647 Yeah, I'm into data science. Only I generally like to build products in data science data related products, basically I generally not get biased by ML only stuff.\n"}
{"prompt": "What is your mental model of True Foundry? \n\n###\n\n", "completion": " uuid: 12249609647 If you think about the data scientist journey from licking building a model, right from left to right? So they typically spend a lot of time and data and feature, engineering and then model training, hyper parameter tuning deployment of the model and monitoring of the model. So true foundry comes at the model level basically.\n"}
{"prompt": "What are the stages that TrueFoundry helps people with in relation to models? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry helps people with the training deployment and the monitoring stages of the model.\n"}
{"prompt": "What is the purpose of the platform that TrueFoundry provides? \n\n###\n\n", "completion": " uuid: 11942346630 The platform that TrueFoundry provides is a place where data scientists or an ML developer can come run experiments on which model works the best.\n"}
{"prompt": "What is TrueFoundry's approach towards deployment? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry covers a wide range in terms of deployment and pays special attention towards different types of deployment like time-sensitive and offline batch inference kind of things.\n"}
{"prompt": "What is the closing the loop part that TrueFoundry handles? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry handles the closing the loop part, which is monitoring the model so that when it starts underperforming, it can be known very quickly.\n"}
{"prompt": "What is the core differentiator of TrueFoundry compared to other platforms? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry is designed to work with existing systems, which means that it fits in well with existing components and only solves parts of the problem that are important.\n"}
{"prompt": "What is one platform that TrueFoundry works well with? \n\n###\n\n", "completion": " uuid: 11942346630 TrueFoundry works well with Databricks because Databricks focuses on the offline and batch inferencing side of things, whereas TrueFoundry's strength is on the real-time inferencing side of things.\n"}
{"prompt": "What is the time frame discussed for a follow-up demonstration of the platform? \n\n###\n\n", "completion": " uuid: 11942346630 The time frame discussed for a follow-up demonstration of the platform is mid-fab. A time will be arranged between Robbie and the other party.\n"}
{"prompt": "What does the speaker ask when they first connect with George? \n\n###\n\n", "completion": " uuid: 11942287761 Hey, can you hear me?\n"}
{"prompt": "What is the response given by George? \n\n###\n\n", "completion": " uuid: 11942287761 Yes, I can hear you.\n"}
{"prompt": "What is the purpose of the companion mode that they discuss? \n\n###\n\n", "completion": " uuid: 11942287761 To join both audio and video from the phone and laptop.\n"}
{"prompt": "What is George's background and where did he work before Soroco? \n\n###\n\n", "completion": " uuid: 11942287761 He has a PhD in Computer Science from Carnegie Mellon and previously worked at Harvard.\n"}
{"prompt": "What is Soroco's goal and how do they achieve it? \n\n###\n\n", "completion": " uuid: 11942287761 To help organizations understand how work gets done and they do it by collecting digital interactions that happen between individuals.\n"}
{"prompt": "How do Soroco's machine learning models help improve business processes? \n\n###\n\n", "completion": " uuid: 11942287761 By allowing organizations to understand where inefficiencies are in the process.\n"}
{"prompt": "What is the size of Soroco's team? \n\n###\n\n", "completion": " uuid: 11942287761 The team size is between five to ten.\n"}
{"prompt": "How does Soroco ensure consistency between their training and serving code? \n\n###\n\n", "completion": " uuid: 11942287761 They ensure the version of the product and the pipeline that basically takes the data, preprocesses, etc., is all lined up with the model that will ship in production.\n"}
{"prompt": "Do Soroco use Kubernetes? \n\n###\n\n", "completion": " uuid: 11942287761 Yes.\n"}
{"prompt": "What is the purpose of Truefoundry and how does it work? \n\n###\n\n", "completion": " uuid: 11942287761 The speaker will share an overview of what Troop Onto is doing, where they are, and what are the next steps they can decide.\n"}
{"prompt": "Can you hear me okay? \n\n###\n\n", "completion": " uuid: 11773896093 Yeah, I can hear you.\n"}
{"prompt": "Can you see me? \n\n###\n\n", "completion": " uuid: 11773896093 Yeah, I can.\n"}
{"prompt": "What happened when the video did not load? \n\n###\n\n", "completion": " uuid: 11773896093 Yusuf disconnected and rejoined to figure out the problem.\n"}
{"prompt": "What was the goal of the meeting with Yusuf? \n\n###\n\n", "completion": " uuid: 11773896093 To get feedback on his ML pipeline, challenges, use cases, and infrastructure and to get to know him better.\n"}
{"prompt": "What is Yusuf's background? \n\n###\n\n", "completion": " uuid: 11773896093 Co-founder and CEO of Truefoundry, worked at Facebook in conversational AI, was leading the ML team at a startup called Reflection, did a masters at UC Berkeley and undergrad at an IT school in India.\n"}
{"prompt": "What type of work does Yusuf do now? \n\n###\n\n", "completion": " uuid: 11773896093 Building a platform to enable other companies to build, deploy and monitor their models faster.\n"}
{"prompt": "What is Pay You and what does Yusuf lead there? \n\n###\n\n", "completion": " uuid: 11773896093 Pay You is a lending business, Yusuf leads the credit side of the business.\n"}
{"prompt": "What is the team size of Yusuf's machine learning team? \n\n###\n\n", "completion": " uuid: 11773896093 Around 40-45 people including data science team.\n"}
{"prompt": "What cloud provider does Yusuf's team use? \n\n###\n\n", "completion": " uuid: 11773896093 AWS.\n"}
{"prompt": "Does the team use Sage Maker? \n\n###\n\n", "completion": " uuid: 11773896093 Initially they did, but stopped using it.\n"}
{"prompt": "How long does it take to deploy a model? \n\n###\n\n", "completion": " uuid: 11773896093 It depends on many factors such as fintech audit approvals, feature pipelines, etc., but once all systems are in place, it should not take more than a week or two weeks.\n"}
{"prompt": "How does the team request for infrastructure/resources? \n\n###\n\n", "completion": " uuid: 11773896093 They ask DevOps and they do it for them.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 10777412370 In the context of the startup that you're building, the purpose of the call was to understand IBM spending a lot of time talking to practitioners, understanding their current workflows, how are they building and deploying models today and where do they see that there are currently some gaps that exist in the workflows.\n"}
{"prompt": "What is Shane's background? \n\n###\n\n", "completion": " uuid: 10777412370 Shane comes from a machine learning background. Prior to starting Truefoundry, he was at Facebook where he was leading one of the conversational AI efforts. Before that, he worked quite extensively in the e-commerce domain.\n"}
{"prompt": "What kind of interactions does Shane want to do directly from their desktop? \n\n###\n\n", "completion": " uuid: 10777412370 Shane wants to build their training algorithm in VS code and then fire it off and say 'run training' that goes up and specifies certain instance sizes with specific input and output locations, creating the artifacts and pushing them into s3 in one seamless way.\n"}
{"prompt": "What is productionizing? \n\n###\n\n", "completion": " uuid: 10777412370 Productionizing basically means deploying the training job somewhere, mostly for them, it will be probably AWS Airflow, which will continuously keep on training while also productionizing their inferences so that every day they take their model, package it into like a Rest API and put it into some AWS container, dockerize it, and put it into AWS container using airflow to invoke it and get output from it.\n"}
{"prompt": "What kind of models is Shane primarily using? \n\n###\n\n", "completion": " uuid: 10777412370 Shane is using a mix of both classical ML types like Xg boost psychedelarn types, and TensorFlow Python types.\n"}
{"prompt": "What kind of server is Shane not using for the inferences? \n\n###\n\n", "completion": " uuid: 10777412370 Shane is not using anything like TF server or Torch server, any zoom conference servers for the inferences.\n"}
{"prompt": "What is Shane's response to using some of those servers to speed up inferences and on? \n\n###\n\n", "completion": " uuid: 10777412370  Shane is open to using some of those servers, but doesn't have a lot of information about them and needs more information.\n"}
{"prompt": "What is the platform that IBM has built is used for? \n\n###\n\n", "completion": " uuid: 10777412370 The platform IBM has built is used for DevOps, developers can deploy their models, training jobs, or batch inference jobs on the platform\n"}
{"prompt": "What led to the realization that a platform was necessary for building machine learning models? \n\n###\n\n", "completion": " uuid: 11942287761 When the speaker was at Reflection, they had five teams building out machine learning models and ended up building a horizontal machine learning platform due to the challenges they faced with model deployment, monitoring, and other aspects.\n"}
{"prompt": "What is the focus area for Truefoundry? \n\n###\n\n", "completion": " uuid: 11942287761 Truefoundry is building a platform that focuses on the model stage of an ML development workflow, enabling easy model training, deployment and monitoring.\n"}
{"prompt": "What are the three ways in which developers interact with the Truefoundry product? \n\n###\n\n", "completion": " uuid: 11942287761 Developers can interact with the Truefoundry product through the CLI, a Python library, and a web-based GUI.\n"}
{"prompt": "What is the purpose of Truefoundry building their platform in a cloud agnostic fashion? \n\n###\n\n", "completion": " uuid: 11942287761 Building their platform in a cloud agnostic manner enables Truefoundry users to deploy models on multiple cloud providers from a single pane of management and optimize costs across clouds.\n"}
{"prompt": "What is the current stage of Truefoundry's product and what is their approach to working with enterprises? \n\n###\n\n", "completion": " uuid: 11942287761 Truefoundry have built out the core parts of their platform and are working with a handful of enterprises in design partner mode. Their goal is to handhold these enterprises for the next nine months or so and make sure that the platform meets their needs. They will eventually go for general availability once they are more mature.\n"}
{"prompt": "What are the two modes in which people use Truefoundry's platform? \n\n###\n\n", "completion": " uuid: 11942287761 People can use Truefoundry's platform through the public cloud mode, which allows immediate access to the platform and an API key, or they can take the entire platform and deploy it on their cloud which ensures none of their data leaves their cloud.\n"}
{"prompt": "What is George's reason for connecting with Truefoundry and what is his approach to implementing this product? \n\n###\n\n", "completion": " uuid: 11942287761 George wishes to introduce Truefoundry to his team and circulate its material so the team can identify its ML aspects and consolidate their efforts. He plans to bring in someone from his team who has enough visibility into building and deploying models to help determine if Truefoundry's platform can help solve their pain points early on.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11577360522 To learn from Ricashi about AI functions in healthcare and to discuss True Foundry's current ML stack, use cases, challenges, and goals for the next six months.\n"}
{"prompt": "Who is leading the call? \n\n###\n\n", "completion": " uuid: 11577360522 It's unclear who is leading the call.\n"}
{"prompt": "What is Truefoundry? \n\n###\n\n", "completion": " uuid: 11577360522 Truefoundry is a startup that helps companies move fast with data by testing out and deploying models to production, as well as monitoring them in the right way without much effort needed from developers.\n"}
{"prompt": "What is Advertiser? \n\n###\n\n", "completion": " uuid: 11577360522 Advertiser is a healthcare machine learning company that focuses on pre-operative care and revenue cycle management. They are leading the research and machine learning team and are based in Seattle, USA.\n"}
{"prompt": "What are the unique challenges associated with ML in healthcare? \n\n###\n\n", "completion": " uuid: 11577360522 The unique challenges associated with ML in healthcare include the diversity of users and the use of domain-specific parameters and codes. Clinical decision making needs to be validated beyond just using GitHub workflows and requires a deep understanding of the data.\n"}
{"prompt": "What is the main focus of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11577360522 True Foundry's platform primarily focuses on the deployment side of ML, orchestrating everything over Kubernetes, making it easy for data scientists and ML engineers to train models, deploy them in a testing environment, and move them to production environment while having complete monitoring.\n"}
{"prompt": "How does one deploy a model in a stateless model versus a model based on certain data that gets pre-processed every day? \n\n###\n\n", "completion": " uuid: 11577360522 Deploying a stateless model is relatively easy, but deploying models that use large numbers of features can be more challenging, as an IT team may be required on the other end to manage the pipeline to ensure data comes in and goes out correctly, even if the clinical user on the other end is less technically experienced.\n"}
{"prompt": "Where did the interesting career journey person work before joining SAP? \n\n###\n\n", "completion": " uuid: 11656829007 The person worked at Flipkart for four years before joining SAP.\n"}
{"prompt": "Why did the person join SAP? \n\n###\n\n", "completion": " uuid: 11656829007 There is no information provided to answer this question.\n"}
{"prompt": "What are some suggestions that Hannah made? \n\n###\n\n", "completion": " uuid: 11656829007 There is no information provided to answer this question.\n"}
{"prompt": "Are the 600 users already segmented? \n\n###\n\n", "completion": " uuid: 11656829007 Yes, the 600 users are already segmented.\n"}
{"prompt": "What are the different ways the users can be segmented? \n\n###\n\n", "completion": " uuid: 11656829007 The users can be segmented as top of funnel, bottom of funnel, very technical versus leader type of segmentation, psyche engineers, Kaggle data scientists, and high level.\n"}
{"prompt": "Can the meeting be postponed to tomorrow or day after? \n\n###\n\n", "completion": " uuid: 11656829007 Yes, the meeting can be postponed to tomorrow or day after.\n"}
{"prompt": "What does the speaker plan to do in the first week? \n\n###\n\n", "completion": " uuid: 11656829007 The speaker plans to spend the first week onboarding with the platform.\n"}
{"prompt": "What are the speaker's plans after spending a few weeks with the company? \n\n###\n\n", "completion": " uuid: 11656829007 The speaker plans to take three days off and go somewhere to enjoy before coming back to work.\n"}
{"prompt": "What team outings does the speaker plan to attend? \n\n###\n\n", "completion": " uuid: 11656829007 The speaker plans to come to the office a minimum of three days per week and attend team outings around that.\n"}
{"prompt": "What can be tracked while the job is running? \n\n###\n\n", "completion": " uuid: 10777412370 CPU memory, network usage, and logs of the job.\n"}
{"prompt": "How are different versions of the same model tracked? \n\n###\n\n", "completion": " uuid: 10777412370 All runs of the same model can be tracked through different versions and it is easy to see which version of the particular job ran when.\n"}
{"prompt": "Can previous versions of a job be redeployed? \n\n###\n\n", "completion": " uuid: 10777412370 Yes, redeploying a previous version is practically just a click away.\n"}
{"prompt": "What is the developer experience like with this platform? \n\n###\n\n", "completion": " uuid: 10777412370 Developers can run jobs from their local machine and leverage the power of the cloud. Creating a job object, providing the name of the job and command, and hitting job dot deploy can create a docker container from the training script and run the job on a remote cluster.\n"}
{"prompt": "On which cluster will the job be run? \n\n###\n\n", "completion": " uuid: 10777412370 The job will run on the Kubernetes cluster that is linked on the platform dashboard.\n"}
{"prompt": "How can infrastructure specifications be specified for a job? \n\n###\n\n", "completion": " uuid: 10777412370 The type of machines can be specified for a cluster and a workspace. You can specify the type of machines you care about and the pool of machines for your cluster will be selected from this specification.\n"}
{"prompt": "Are machines always running? \n\n###\n\n", "completion": " uuid: 10777412370 No, machines only exist as part of your cluster and are only spun up and used when a job is scheduled to run.\n"}
{"prompt": "Can performance metrics be tracked for machine learning models? \n\n###\n\n", "completion": " uuid: 10777412370 Yes, you can track a lot of metrics on the platform dashboard, such as the configuration, metrics, training graphs, and distribution of the data set.\n"}
{"prompt": "What is the histogram graph showing? \n\n###\n\n", "completion": " uuid: 10777412370 The histogram shows the distribution of a feature across the training and testing data sets. The x-axis is the range of values for a particular feature and the y-axis is the count of data points within that range.\n"}
{"prompt": "Can artifacts generated by a job be tracked on the platform? \n\n###\n\n", "completion": " uuid: 10777412370 Yes, all files and artifacts generated or used during a job can be tracked on the platform dashboard.\n"}
{"prompt": "What is Truefoundry and what is the goal for Michael on the platform? \n\n###\n\n", "completion": " uuid: 10881905316 Truefoundry is a platform for deploying and managing machine learning models. The goal for Michael is to familiarize himself with the platform by deploying a couple of jobs and services.\n"}
{"prompt": "Is it possible to pass in dependencies to the code being deployed on the platform? \n\n###\n\n", "completion": " uuid: 10881905316 Yes, it is possible to pass in dependencies such as requirements.txt or other files.\n"}
{"prompt": "What is the difference between ML Foundry and Service Foundry? \n\n###\n\n", "completion": " uuid: 10881905316 ML Foundry is used for experiment management and metric logging, while Service Foundry is used for deploying services and jobs.\n"}
{"prompt": "What is the purpose of a workspace in Truefoundry? \n\n###\n\n", "completion": " uuid: 10881905316 A workspace is a logical partition of a cluster and allows for allocation of permissions for certain resources at that level. It can also be used for dev-staging-prod environments.\n"}
{"prompt": "What does the promote feature in the UI mean? \n\n###\n\n", "completion": " uuid: 10881905316 The promote feature is used to promote changes from a lower environment to a higher environment, such as from staging to production.\n"}
{"prompt": "How do you pronounce the name? \n\n###\n\n", "completion": " uuid: 9905698123 Nikhunj\n"}
{"prompt": "Where is the speaker based? \n\n###\n\n", "completion": " uuid: 9905698123 Toronto\n"}
{"prompt": "Were you able to discuss the machine learning engineers in the company? \n\n###\n\n", "completion": " uuid: 9905698123 Yes\n"}
{"prompt": "How many machine learning engineers and data scientists are combined at the company? \n\n###\n\n", "completion": " uuid: 9905698123 Three ML engineers, five data scientists.\n"}
{"prompt": "What kind of machine learning models are currently in production at the company? \n\n###\n\n", "completion": " uuid: 9905698123 Simple regression models\n"}
{"prompt": "What library is used for machine learning, particularly for neural networks? \n\n###\n\n", "completion": " uuid: 9905698123 TensorFlow\n"}
{"prompt": "What program is used for pipeline management by the company? \n\n###\n\n", "completion": " uuid: 9905698123 Cadre\n"}
{"prompt": "What caught the speaker's attention during the demo? \n\n###\n\n", "completion": " uuid: 9905698123 The simplicity and ease of use of the platform\n"}
{"prompt": "What is the focus of the company's platform? \n\n###\n\n", "completion": " uuid: 9905698123 Optimizing machine learning development workflows for companies with one full-time ML engineer\n"}
{"prompt": "What was the challenge with adding external calls and why was it a big challenge? \n\n###\n\n", "completion": " uuid: 12362100552 Most external calls were expected by the models and adding more external calls would add more latency, making it harder to serve features online. This was a big challenge for the team.\n"}
{"prompt": "Are remote calls possible? \n\n###\n\n", "completion": " uuid: 12362100552 Yes, remote calls are possible, but making a remote call for every model call would be too expensive in terms of latency.\n"}
{"prompt": "What is the team's primary focus in terms of feature engineering and A/B testing? \n\n###\n\n", "completion": " uuid: 12362100552 The team's primary focus is feature engineering, serving, and A/B testing.\n"}
{"prompt": "What tools and platforms does the team use for training and serving? \n\n###\n\n", "completion": " uuid: 12362100552 The team uses Databricks notebooks and Spark for training, and their serving layer is built on top of Kubernetes. They are exploring using TF serving for hosting, and are developing Omega ML platform for feature transformations and workflow management.\n"}
{"prompt": "How does the team manage costs on their Databricks clusters? \n\n###\n\n", "completion": " uuid: 12362100552 The team's cost monitoring systems are limited, and they usually look at Azure's cost management tool for monitoring. They do not have any fancy solutions or real-time monitoring of costs for individual jobs.\n"}
{"prompt": "Do the team separate models by different advertisers? \n\n###\n\n", "completion": " uuid: 12362100552 The team trains all advertisers together, and do not have any major concerns about sharing data between advertisers. They are exploring having models for different advertisers.\n"}
{"prompt": "What did the person say to start the conversation? \n\n###\n\n", "completion": " uuid: 10540896567 Hello.\n"}
{"prompt": "Who did the person greet and how did they respond? \n\n###\n\n", "completion": " uuid: 10540896567 They greeted a kid and the kid responded with 'Good.'\n"}
{"prompt": "What was the misunderstanding about the call? \n\n###\n\n", "completion": " uuid: 10540896567 The person was waiting for a call, thinking it was not a Google meet.\n"}
{"prompt": "Where is the person based now and where did they recently move from? \n\n###\n\n", "completion": " uuid: 10540896567 They are based in the Bay Area now and moved from Boston.\n"}
{"prompt": "Where is the other person based and where did they recently move to? \n\n###\n\n", "completion": " uuid: 10540896567 The other person is also in San Francisco and recently moved to Dublin.\n"}
{"prompt": "What area are they looking for a house in and what specific locations are they interested in? \n\n###\n\n", "completion": " uuid: 10540896567 They are looking for a house in Dublin area, preferably in East Bay, from Mission to Danville.\n"}
{"prompt": "What did the person say about their recent decision to buy and remodel a house? \n\n###\n\n", "completion": " uuid: 10540896567 They felt it was a bad decision as construction is taking more than four months.\n"}
{"prompt": "Who else did the person want to buy a house in San Jose area? \n\n###\n\n", "completion": " uuid: 10540896567 The person asked the other person where they would buy in San Jose area.\n"}
{"prompt": "What did the person reveal about their past and how they decided to start a company? \n\n###\n\n", "completion": " uuid: 10540896567 They revealed that they and two others went to college together, and later built a company together to solve issues around machine learning models.\n"}
{"prompt": "What kind of companies are they working with and how are they approaching them? \n\n###\n\n", "completion": " uuid: 10540896567 They are working with some large companies like Synopsis as design partners, building out integrations to add business value for them.\n"}
{"prompt": "What is the focus and importance of lead scoring and what other areas are they focusing on? \n\n###\n\n", "completion": " uuid: 10540896567 The focus is on lead scoring, fraud detection, and marketing analytics, with some focus on NLP related to customer satisfaction.\n"}
{"prompt": "What is the team size and how many models are currently in production? \n\n###\n\n", "completion": " uuid: 10540896567 The team size is small, with only a handful of data scientists enterprise wide. There are only a handful of key models in production, with many more being built.\n"}
{"prompt": "What is the biggest challenge in building out personalization models and scaling up the platform? \n\n###\n\n", "completion": " uuid: 10540896567 The biggest challenge is the lack of decent structure, internal architecture, feature store, and the abilities for machine learning engineers to work together.\n"}
{"prompt": "What did the person ask at the end about the other person's interests? \n\n###\n\n", "completion": " uuid: 10540896567 The person asked if the other person is still playing cricket.\n"}
{"prompt": "What is mixed precision and how does it relate to OnX runtime? \n\n###\n\n", "completion": " uuid: 11354392885 Mixed precision is a concept that involves using FP16 support to synthetically double the amount of RAM available. OnX runtime efficiently supports mixed precision for better performance.\n"}
{"prompt": "What is the approach to managing multiple models without deploying them one over another? \n\n###\n\n", "completion": " uuid: 11354392885 The approach involves deploying the model as a function on Kserv, incrementally copying one third of it to a multimodal server with GPU backend support. XGBoost provides the inference file format supported by Triton for this purpose.\n"}
{"prompt": "What is the role of OCR model in detecting and recognizing rows and requests in gRPC? \n\n###\n\n", "completion": " uuid: 11354392885 The OCR model detects each row, rotates them if required, and subsequently recognizes the requests using gRPC. This helps in generating multi-people communication for better throughput.\n"}
{"prompt": "Which two types of jobs are used for images and what was the initial use case for Taipei and Lithuania? \n\n###\n\n", "completion": " uuid: 11354392885 The two types of jobs used for images are real-time and batch. The initial use case for Taipei and Lithuania was mostly batch-oriented, but later realized about adequate reserve for real-time use cases.\n"}
{"prompt": "How is model deployment and versioning managed, and what is the role of TensorFlow server in standardizing the inference protocol? \n\n###\n\n", "completion": " uuid: 11354392885 Models are deployed and versioned using CASER, with versions automatically stored for every model. TensorFlow server and Python service are used to standardize the inference protocol for different frameworks. The model deployment is powered by CASER, and TensorFlow server is used for every framework.\n"}
{"prompt": "What is the role of snowflake and feature store, and why was Firebase replaced with fees? \n\n###\n\n", "completion": " uuid: 11354392885 Snowflake acts as the data warehouse, which is updated at a frequency of 15 minutes. Feature store compiles static data by policy and serves load functions. Firebase was replaced with fees due to scaling limitations.\n"}
{"prompt": "What is the main reason behind not using Vertex, and how is the deployment of the system managed? \n\n###\n\n", "completion": " uuid: 11354392885 The main reason behind not using Vertex is its cost effectiveness and scalability issues. The system deployment is managed using knative, Triton, and cloud run for better performance and routing specific payloads.\n"}
{"prompt": "What is the thought process of the tech team while repurposing models for different use cases, and how is testing of the system done? \n\n###\n\n", "completion": " uuid: 11354392885 The tech team focuses on repurposing models for different use cases, and testing of the system is done by debugging the detectron model and converting it to tensor RT for better scalability and efficiency.\n"}
{"prompt": "What is the goal of the system that they are building? \n\n###\n\n", "completion": " uuid: 10611764294 To give control to the ML team and deploy models in a more systematic and optimized way with SRE practices and cost efficiency.\n"}
{"prompt": "What kind of environments can be deployed with this system? \n\n###\n\n", "completion": " uuid: 10611764294 Testing, production or staging environments.\n"}
{"prompt": "What complex use cases are supported by the system? \n\n###\n\n", "completion": " uuid: 10611764294 Traffic splitting, shadow testing for models, and auto scaling.\n"}
{"prompt": "What kind of machines can be used for different deployments? \n\n###\n\n", "completion": " uuid: 10611764294 Certain kinds of machines can be restricted or used for different deployments.\n"}
{"prompt": "How is monitoring enabled for automatic deployment? \n\n###\n\n", "completion": " uuid: 10611764294 With a few lines of code the platform automatically generates a monitoring dashboard.\n"}
{"prompt": "What helps optimize costs with this system? \n\n###\n\n", "completion": " uuid: 10611764294 The way the system is structured.\n"}
{"prompt": "What type of companies are they looking to work with? \n\n###\n\n", "completion": " uuid: 10611764294 Companies with mid level or advanced ML pipelines.\n"}
{"prompt": "What is the process for working with companies and solving their problem statements? \n\n###\n\n", "completion": " uuid: 10611764294 Working closely to understand the problem statement, doing a POC to prove value, and customizing specific things for the company.\n"}
{"prompt": "When will they schedule a meeting to discuss more in depth? \n\n###\n\n", "completion": " uuid: 10611764294 Next week, on Thursday or Friday at 04:00. An invite will be sent.\n"}
{"prompt": "What will be sent to the person to help them understand more about Two Foundation? \n\n###\n\n", "completion": " uuid: 10611764294 A small deck that will give an overview of the company and their use cases.\n"}
{"prompt": "What was the first thing the speaker said to begin the conversation? \n\n###\n\n", "completion": " uuid: 11487646267 Thank you.\n"}
{"prompt": "What did the speaker ask when they couldn't hear the other person? \n\n###\n\n", "completion": " uuid: 11487646267 Hi, can you hear me?\n"}
{"prompt": "What was the response to the speaker's question about being on the road? \n\n###\n\n", "completion": " uuid: 11487646267 Yeah.\n"}
{"prompt": "What was the reason for the call? \n\n###\n\n", "completion": " uuid: 11487646267 To learn more about the specific problems that Priyanka's team is trying to solve within Zulili.\n"}
{"prompt": "What are the three broad business cases that Zulili's platform is used for? \n\n###\n\n", "completion": " uuid: 11487646267 Personalization and recommendation, forecasting, and supply chain.\n"}
{"prompt": "What are some technologies that Zulili's platform is built on? \n\n###\n\n", "completion": " uuid: 11487646267 Fiest for feature store, Qflow for training platform, and Model DB for tracking experiments.\n"}
{"prompt": "What was the speaker's role in the previous startup with Nikonj and the two co-founders? \n\n###\n\n", "completion": " uuid: 11487646267 Part of the founder's office and worked with Nikonj and the other co-founders in the HR tech space.\n"}
{"prompt": "What is Priyanka's timezone? \n\n###\n\n", "completion": " uuid: 11487646267 US PST timezone.\n"}
{"prompt": "What university did Akshay attend for his master's degree? \n\n###\n\n", "completion": " uuid: 11487646267 UC Berkeley.\n"}
{"prompt": "What are the two clouds that Zulili uses and why were they chosen? \n\n###\n\n", "completion": " uuid: 11487646267 AWS and GCP, because GCP had good data management capabilities and AWS had good real-time production services.\n"}
{"prompt": "What tool does Zulili use to track experiments? \n\n###\n\n", "completion": " uuid: 11487646267 Model DB.\n"}
{"prompt": "What was a challenge with using Kubeflow as a training platform? \n\n###\n\n", "completion": " uuid: 11487646267 It heavily favors TensorFlow as a training platform, but there are other libraries that may do better, like for example training GBA decision trees.\n"}
{"prompt": "Who manages the Kubernetes clusters at Zulili? \n\n###\n\n", "completion": " uuid: 11487646267 The platform team.\n"}
{"prompt": "What teams work together to put models into production in Zulili's platform? \n\n###\n\n", "completion": " uuid: 11487646267 Data scientists and applied MLE teams.\n"}
{"prompt": "What is the goal of the product? \n\n###\n\n", "completion": " uuid: 10441289250 The goal is to make it easy for data scientists and ML developers to test and deploy their models into production without having to depend on ML engineers or DevOps team.\n"}
{"prompt": "Why do data scientists and ML developers need this product? \n\n###\n\n", "completion": " uuid: 10441289250 Because they often lack core engineering skill set and working with infra becomes challenging for them.\n"}
{"prompt": "What are the ways to deploy a model using this product? \n\n###\n\n", "completion": " uuid: 10441289250 You can deploy a model using Python code, YAML, or through the UI.\n"}
{"prompt": "What is the platform designed to work with? \n\n###\n\n", "completion": " uuid: 10441289250 The platform is designed to work with Kubernetes, which is cloud native and can be used on any cloud like AWS or GCP.\n"}
{"prompt": "Can you integrate your own Docker register? \n\n###\n\n", "completion": " uuid: 10441289250 Yes, you can integrate your own Docker register.\n"}
{"prompt": "What is the purpose of integrating GitHub repositories in the platform? \n\n###\n\n", "completion": " uuid: 10441289250 Integrating GitHub repositories allows you to choose options when you deploy.\n"}
{"prompt": "What is the purpose of creating a workspace in a cluster? \n\n###\n\n", "completion": " uuid: 10441289250 To give every data scientist or team a safe space to play around with, where they can do their own deployment and not exceed beyond that.\n"}
{"prompt": "What are some components of the product? \n\n###\n\n", "completion": " uuid: 10441289250 The product has components for tracking runs and metrics, data monitoring, and browsing through the raw data of the model.\n"}
{"prompt": "Will the conversation continue over email? \n\n###\n\n", "completion": " uuid: 10441289250 Yes, the conversation will continue over email.\n"}
{"prompt": "What is the primary infrastructure that the research team heavily relies on at the moment? \n\n###\n\n", "completion": " uuid: 12150828398 The research team heavily relies on Google Kubernetes engine and Cloud File store at the moment.\n"}
{"prompt": "What is the typical YAML file submitted by researchers, and what does it contain? \n\n###\n\n", "completion": " uuid: 12150828398 The typical YAML file submitted by researchers contains the image they want, the Python packages they need, and specifies the resources they want to use such as GPUs, CPUs, and memory. It may also specify persistent volumes for storing data sets and model checkpoints.\n"}
{"prompt": "How do researchers track their progress and monitor logs and metrics? \n\n###\n\n", "completion": " uuid: 12150828398 Researchers use Kubestl or GCP Console to track their progress and monitor logs and metrics.\n"}
{"prompt": "Is there a limit on how much infrastructure researchers can request? \n\n###\n\n", "completion": " uuid: 12150828398 There are no limitations on CPU and memory requests, but for GPUs there are limits.\n"}
{"prompt": "How does the request for allocation of infrastructure come to your team? \n\n###\n\n", "completion": " uuid: 12150828398 There is no need for permission to request CPU and memory resources. However, for GPUs, there are limitations and the request may need approval from the infrastructure team.\n"}
{"prompt": "What was the main reason for the speaker to move on from their India centric business? \n\n###\n\n", "completion": " uuid: 11656830826 They wanted to explore something newer.\n"}
{"prompt": "What is the objective of the speaker in reaching out to people in the industry associated with the ML Ops domain? \n\n###\n\n", "completion": " uuid: 11656830826 To get to know more about the challenges faced by users in the tools they have been using.\n"}
{"prompt": "What is the challenge that most ML engineers face after training a model? \n\n###\n\n", "completion": " uuid: 11656830826 Optimizing the model.\n"}
{"prompt": "What is quantization in machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 It means doing calculations in 16 or even 8 bits instead of Floating Point 32 bits, and helps in making the model faster.\n"}
{"prompt": "Which tool did the speaker use for deployment at Procore? \n\n###\n\n", "completion": " uuid: 11656830826 Selden Core.\n"}
{"prompt": "What was the main reason for the speaker not continuing with the support license of Selden Core? \n\n###\n\n", "completion": " uuid: 11656830826 The team at Proco was confident in their competence to fix issues, and they felt the support was not providing enough value.\n"}
{"prompt": "Why did the speaker not go for an enterprise version of Selden Core? \n\n###\n\n", "completion": " uuid: 11656830826 The manager felt building their own solution was better since the tools were not mature enough.\n"}
{"prompt": "What topics do the speaker want to dive deeper into in the next meeting? \n\n###\n\n", "completion": " uuid: 11656830826 Sage Maker, competition with Selden, and monitoring.\n"}
{"prompt": "What time and day did the speaker suggest for their next meeting? \n\n###\n\n", "completion": " uuid: 11656830826 Tuesday, the 17th of the next month, same time as the current meeting.\n"}
{"prompt": "What is Truefoundry? \n\n###\n\n", "completion": " uuid: 11189912081 Truefoundry is a platform developed for operationalizing machine learning models.\n"}
{"prompt": "How can you connect Kubernetes cluster with Truefoundry? \n\n###\n\n", "completion": " uuid: 11189912081 You can connect a Kubernetes cluster with Truefoundry dashboard.\n"}
{"prompt": "What is the purpose of installing helm charts on the Kubernetes cluster? \n\n###\n\n", "completion": " uuid: 11189912081 Installing helm charts on the Kubernetes cluster sets up the infrastructure required by Truefoundry to run machine learning models.\n"}
{"prompt": "Can Truefoundry work with any infrastructure? \n\n###\n\n", "completion": " uuid: 11189912081 Truefoundry supports working with Kubernetes and can be deployed on multiple cloud platforms, on-premise architectures, and even specific clouds, if required.\n"}
{"prompt": "What do data scientists need to do to deploy their machine learning models using Truefoundry platform? \n\n###\n\n", "completion": " uuid: 11189912081 Data scientists can deploy their machine learning models on the Truefoundry platform by installing the Truefoundry client-side library on their Jupiter notebook, invoking API's to deploy models on the remote server, and scaling the deployment system.\n"}
{"prompt": "Who is addressing whom at the beginning of the conversation? \n\n###\n\n", "completion": " uuid: 12249629853 Hey punit addressing someone\n"}
{"prompt": "What is the response to the initial greeting? \n\n###\n\n", "completion": " uuid: 12249629853 Hi is the response\n"}
{"prompt": "Who else is on the call besides the speakers? \n\n###\n\n", "completion": " uuid: 12249629853 Rog is on the call\n"}
{"prompt": "What is the speaker's response when asked how they are doing? \n\n###\n\n", "completion": " uuid: 12249629853 I'm doing well, thank you.\n"}
{"prompt": "Why is one of the speakers not able to see the other? \n\n###\n\n", "completion": " uuid: 12249629853 It seems like they are using a different platform, Teams instead of Meat.\n"}
{"prompt": "What is the speaker's question about the platform they are using? \n\n###\n\n", "completion": " uuid: 12249629853 Is it like the video?\n"}
{"prompt": "What does the speaker say about the platform being discussed? \n\n###\n\n", "completion": " uuid: 12249629853 The platform being discussed is Meat Wrapped Around Teams.\n"}
{"prompt": "What happens when someone else tries to join the call? \n\n###\n\n", "completion": " uuid: 12249629853 The speaker forwards the invite to others so they can join.\n"}
{"prompt": "What does one of the speakers suggest when someone else is unable to join the call? \n\n###\n\n", "completion": " uuid: 12249629853 Create a separate link from their enterprise account.\n"}
{"prompt": "How does one of the speakers suggest they deal with the issue of others not being able to join? \n\n###\n\n", "completion": " uuid: 12249629853 By creating a separate link and asking others to join that.\n"}
{"prompt": "Who is mentioned as possibly being the main audience for the call? \n\n###\n\n", "completion": " uuid: 12249629853 The speaker's team is mentioned.\n"}
{"prompt": "What do the speakers plan to do when someone else is ready to join the call? \n\n###\n\n", "completion": " uuid: 12249629853 They will join the link Punit creates.\n"}
{"prompt": "How does one of the speakers say they joined the call? \n\n###\n\n", "completion": " uuid: 12249629853 They joined using their mobile app instead of the laptop.\n"}
{"prompt": "What is one of the speaker's response when told others are waiting for them? \n\n###\n\n", "completion": " uuid: 12249629853 They express their willingness to wait for Punit's link to join the call.\n"}
{"prompt": "What kind of metrics does this service provide? \n\n###\n\n", "completion": " uuid: 10611765880 The service provides metrics for CPU, memory, disk usage, request stats, success rate, and live logs.\n"}
{"prompt": "What is the purpose of the FastAPI? \n\n###\n\n", "completion": " uuid: 10611765880 The FastAPI allows developers to write a Pythonic model which gets converted to JSON for deployment.\n"}
{"prompt": "What is the purpose of the Deploy.py file? \n\n###\n\n", "completion": " uuid: 10611765880 The Deploy.py file imports the SDK and defines a service, which can be customized in terms of its CPU resources, memory, and machine type.\n"}
{"prompt": "What is the function of the Workspace in the platform? \n\n###\n\n", "completion": " uuid: 10611765880 The Workspace is a collection of resources where the pods will be deployed to, and it is used to deploy a service definition.\n"}
{"prompt": "What is the main difference between deploying a job and deploying a service? \n\n###\n\n", "completion": " uuid: 10611765880 Jobs only consume resources when they are running, while services require a web app or extra code to call the model and generate predictions.\n"}
{"prompt": "What is the beta feature for model deployment? \n\n###\n\n", "completion": " uuid: 10611765880 The beta feature for model deployment allows users to take a model from a model registry and deploy it directly as a working service without having to write extra code.\n"}
{"prompt": "What is True Foundry building? \n\n###\n\n", "completion": " uuid: 11655737135 A reliable ML platform to facilitate the deployment of ML models, making it simple and enforcing best practices.\n"}
{"prompt": "What is the goal of True Foundry's platform? \n\n###\n\n", "completion": " uuid: 11655737135 To enable deployment of ML models at all stages, from running training jobs to deploying to production spaces, while enforcing best engineering and SRE principles.\n"}
{"prompt": "What is the system built on? \n\n###\n\n", "completion": " uuid: 11655737135 Kubernetes as the PaaS.\n"}
{"prompt": "What is the Python library used for? \n\n###\n\n", "completion": " uuid: 11655737135 To enable Data Scientists to deploy their models without needing knowledge of Kubernetes.\n"}
{"prompt": "What principles are enforced in the system? \n\n###\n\n", "completion": " uuid: 11655737135 Best engineering and SRE principles such as authentication, secret management, and monitoring.\n"}
{"prompt": "Who leads the ML platform team? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker is asking who leads the ML (Machine Learning) team in Hadabad.\n"}
{"prompt": "Who is the manager and who's the manager's manager? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker is seeking to know the manager and their manager's manager in the ML platform team.\n"}
{"prompt": "Are both the manager and manager's manager in Hyderabad? \n\n###\n\n", "completion": " uuid: 12339635717 Yes, both the manager and their manager's manager are in Hyderabad.\n"}
{"prompt": "What is the goal of the speaker? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker's goal is to learn what challenges companies face in building and orchestrating their machine learning models across clouds.\n"}
{"prompt": "What are some challenges in building and orchestrating machine learning models across clouds? \n\n###\n\n", "completion": " uuid: 12339635717 Some of the challenges include visibility of all the models running across clouds and the speed of execution due to the need to be cautious about many things that are typically abstracted away.\n"}
{"prompt": "What is the speaker's plan for setting up a follow-up call with Abhishek and the interviewee? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker will set up a call for 30 minutes between the three of them and would like to get the interviewee's WhatsApp number.\n"}
{"prompt": "What is the thesis of the speaker? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker's thesis is that companies that are cross cloud might face more challenges in building and orchestrating their machine learning models than companies that are on one cloud.\n"}
{"prompt": "What will the speaker do after gathering information on different companies building cross cloud solutions? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker will build out a more core thesis on what problems can be solved as a startup.\n"}
{"prompt": "What is the speaker asking for at the end of the call? \n\n###\n\n", "completion": " uuid: 12339635717 The speaker thanked the interviewee and asked to set up another call later.\n"}
{"prompt": "What is the first sentence in the context? \n\n###\n\n", "completion": " uuid: 12362100552 Are you in midst of travel?\n"}
{"prompt": "What is the issue with the voice on the call? \n\n###\n\n", "completion": " uuid: 12362100552 Hello? It's very bleak. Like the voice is breaking out.\n"}
{"prompt": "What does the speaker ask after the issue with the voice is resolved? \n\n###\n\n", "completion": " uuid: 12362100552 Is it better now?\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 12362100552 So Kalan, just to kind of I think from the email thread basically we were connected by Adithta caldro who is actually one of our advisors and angels.\n"}
{"prompt": "Who are the three co-founders of Truefoundry? \n\n###\n\n", "completion": " uuid: 12362100552 Nick Kunj, Abhishek and myself\n"}
{"prompt": "What was the first startup that the founders built in the talent space? \n\n###\n\n", "completion": " uuid: 12362100552 an Entire\n"}
{"prompt": "What did the founders discuss while building models for matching candidates and resumes? \n\n###\n\n", "completion": " uuid: 12362100552 the systems that existed at Facebook at that time and Vishik and Nicole mentioned about Epiler, which is their internal ML platform.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12362100552 to build a multi cloud system on top of Kubernetes, wherein it's very easy for data scientists and ML engineers to quickly take their models tested and then deployed in production in a reliable and cost effective manner.\n"}
{"prompt": "What is Kalyan's role in InMobi? \n\n###\n\n", "completion": " uuid: 12362100552 I look into the ML platforms in mobile over here and at the same time I also work with one of our business units, demand side platform which is heavy, and data science in general.\n"}
{"prompt": "What external capabilities and tools do they use in Inmobi? \n\n###\n\n", "completion": " uuid: 12362100552 only data bricks notebooks, that is primarily for data analysis also, any idea purposes?\n"}
{"prompt": "What internal capabilities are used in Inmobi? \n\n###\n\n", "completion": " uuid: 12362100552 the ref framework and feature store on top of Databrick feature store.\n"}
{"prompt": "What is the latency requirement for running the models in Inmobi? \n\n###\n\n", "completion": " uuid: 12362100552 We have around 20 milliseconds to run all of our models, right. In a request request path.\n"}
{"prompt": "What is the current state of the conversation? \n\n###\n\n", "completion": " uuid: 11189924245 Yogesh and Niquinh are discussing a potential call and their availability.\n"}
{"prompt": "Who is Niquinh? \n\n###\n\n", "completion": " uuid: 11189924245 Niquinh is a person who is speaking to Yogesh.\n"}
{"prompt": "Who are the target customers for Niquinh\u2019s startup? \n\n###\n\n", "completion": " uuid: 11189924245 Their target customers are large companies who need help with machine learning.\n"}
{"prompt": "How many companies is Niquinh currently working with? \n\n###\n\n", "completion": " uuid: 11189924245 Niquinh is currently working with three companies.\n"}
{"prompt": "What does Yogesh think about the sales pitch for Niquinh\u2019s startup? \n\n###\n\n", "completion": " uuid: 11189924245 Yogesh thinks that the sales pitch needs to change.\n"}
{"prompt": "What advice does Yogesh give to Niquinh about working with large companies? \n\n###\n\n", "completion": " uuid: 11189924245 Yogesh advises Niquinh to focus on relationship-building and finding a champion at the top level of the company.\n"}
{"prompt": "What is the purpose of Truefoundry? \n\n###\n\n", "completion": " uuid: 11564066567 To build a startup in the machine learning domain, helping companies build out ML platforms.\n"}
{"prompt": "What is the main problem that Truefoundry is trying to solve? \n\n###\n\n", "completion": " uuid: 11564066567 To help companies get the level of productivity without the actual internal tooling by building an ML platform.\n"}
{"prompt": "Who are the companies that Truefoundry is currently working with? \n\n###\n\n", "completion": " uuid: 11564066567 A few companies like Early Enterprises.\n"}
{"prompt": "What type of machine learning problems is Ravi looking to understand? \n\n###\n\n", "completion": " uuid: 11564066567 Machine learning problems that major companies face, what's top of mind for them from a modeling and infrastructure perspective and how do they get business outcomes from machine learning?\n"}
{"prompt": "What is the issue with ML in the fintech space? \n\n###\n\n", "completion": " uuid: 11564066567 The regulatory hold on explainability of ML models is much greater because of lending and insurance's need to have a very clear explainability.\n"}
{"prompt": "Are there use cases where regulatory hold is not that great? \n\n###\n\n", "completion": " uuid: 11564066567 Yes, in marketing there is less regulatory hold.\n"}
{"prompt": "What kind of models are typically used at Lending Club? \n\n###\n\n", "completion": " uuid: 11564066567 Risk models, which are mostly decision trees, are used.\n"}
{"prompt": "What is the role of data scientists at LC? \n\n###\n\n", "completion": " uuid: 11564066567 They build the models and the next generation six to twelve months out once they have more fresh data.\n"}
{"prompt": "What does LC do with the models after they are built? \n\n###\n\n", "completion": " uuid: 11564066567 The data engineers do the deployment, testing, launch, and maintenance. They manage the one version in production while the data scientists keep looking for more data and keep refreshing the buyer in progress.\n"}
{"prompt": "What is the broad objective of the call? \n\n###\n\n", "completion": " uuid: 10881905922 To understand the ML process and pain points while getting to know each other.\n"}
{"prompt": "What is the current location of the person on the call? \n\n###\n\n", "completion": " uuid: 10881905922 The person is currently located in Bangalore.\n"}
{"prompt": "What is the focus of the startup? \n\n###\n\n", "completion": " uuid: 10881905922 The startup's main focus is on the platform for machine learning teams and optimizing model deployment and monitoring.\n"}
{"prompt": "What is the company's stage? \n\n###\n\n", "completion": " uuid: 10881905922 The product is in pre-launch, with a seed round of funding, a small full-time team, and working with design partners.\n"}
{"prompt": "What is Freshworks' machine learning engineering charter? \n\n###\n\n", "completion": " uuid: 10881905922 They are verticalized and cover the full gamut of one particular thing, with a large part being machine learning engineering and some regular application type engineering.\n"}
{"prompt": "How does the machine learning team work at Freshworks? \n\n###\n\n", "completion": " uuid: 10881905922 They maintain their own infrastructure and have a layer that abstracts the application from the ML service. The service is stateless with different models for each account loaded from S3.\n"}
{"prompt": "Does Freshworks use Kubernetes or Sage Maker? \n\n###\n\n", "completion": " uuid: 10881905922 Freshworks does not use Sage Maker, but they do use Kubernetes for their infrastructure.\n"}
{"prompt": "What is the current stack being used by you.com? \n\n###\n\n", "completion": " uuid: 10784174762 you.com is built on azure, using data bricks for analysis, plotting and dashboarding, Kubernetes for deployment and PyTorch for machine learning. They are currently in the process of figuring out nvidia triton for model serving.\n"}
{"prompt": "Who does the deployment of models in you.com? \n\n###\n\n", "completion": " uuid: 10784174762 Deployment is mostly managed by ML Ops and DevOps people, with some back end engineers. An ML engineer may also do the deployment themselves, after having learned the pattern.\n"}
{"prompt": "Can you explain briefly what Truefoundry does? \n\n###\n\n", "completion": " uuid: 10784174762 Truefoundry is a path on top of Kubernetes designed to help ML developers deploy their models to production. It provides support for real time as well as batch case deployment of models, monitors resource utilization and costs, and allows for easy optimization of deployment for better cost efficiency.\n"}
{"prompt": "What are some features of Truefoundry that make it user-friendly? \n\n###\n\n", "completion": " uuid: 10784174762 Truefoundry enforces best practices and supports fast deployment through UI, CLI or Python. It supports traffic splitting and other complicated features by default and has a low learning curve.\n"}
{"prompt": "What are the goals of Truefoundry? \n\n###\n\n", "completion": " uuid: 10784174762 The goal of Truefoundry is to make deployment of machine learning models easy and efficient, enforce the best practices, ensure CI/CD, and enable developers to quickly deploy services through UI, CLI or Python.\n"}
{"prompt": "How is Anrag introduced on the call? \n\n###\n\n", "completion": " uuid: 11942347136 Anrag introduces himself as one of the co-founders at IIFL True Foundry.\n"}
{"prompt": "What is True Foundry's main goal? \n\n###\n\n", "completion": " uuid: 11942347136 To make it easier for data teams to get access to a better platform for testing out and deploying models in a scalable way to production with the right security, with the right authentication and with monitoring in building.\n"}
{"prompt": "Who are the co-founders of True Foundry and what is their background? \n\n###\n\n", "completion": " uuid: 11942347136 Apart from Anrag, the co-founders are Nikkunjana and Vishek who come from a Facebook background with the same educational background as Anrag.\n"}
{"prompt": "Who is Arihan and why does he reach out to Anrag? \n\n###\n\n", "completion": " uuid: 11942347136 Arihan saw the True Foundry platform and reached out to understand what kind of things the company can support in terms of data science initiatives within IIFL.\n"}
{"prompt": "What is the size of the Data Science team currently at IIFL? \n\n###\n\n", "completion": " uuid: 11942347136 They have between two to ten members but they have not been segregated between Data Science and ML.\n"}
{"prompt": "What kind of models are being used by the Data Science team in underwriting? \n\n###\n\n", "completion": " uuid: 11942347136 They are using four thought models but they have not been deployed so they are not running in a production environment.\n"}
{"prompt": "Where are the batch compute processes being done and how are they run? \n\n###\n\n", "completion": " uuid: 11942347136 They are currently using Azure but they are looking to move towards AWS. They run the processes in a patch compute manner.\n"}
{"prompt": "What is the current traffic expectation for the Fast API endpoints once the models are deployed? \n\n###\n\n", "completion": " uuid: 11942347136 Around ten to fifteen hits per minute.\n"}
{"prompt": "What are the necessary components that Anrag is looking for in a platform for deploying the models? \n\n###\n\n", "completion": " uuid: 11942347136 A deployment part, a dashboard for performance and failure monitoring, and intelligence for retraining models and model performance metrics such as population stability index, AUC k or characteristic stability index.\n"}
{"prompt": "What is True Foundry's core focus in terms of platform deployment? \n\n###\n\n", "completion": " uuid: 11942347136 To build a platform that allows for very seamless deployment with every deployment being a dockerized containerized script that can be deployed to a corresponding environment on top of a Kubernetes cluster on whatever cloud provider is being used.\n"}
{"prompt": "What is Two Foundry? \n\n###\n\n", "completion": " uuid: 11354404149 Two Foundry is a startup founded by Ansul, Abhishek, and Nikkunj with the goal of providing an ML platform for companies around the globe. The platform aims to provide ML developers the ability to quickly test out and deploy models using the best engineering practices, including monitoring, auto scaling, and the right authentication and security systems, while also allowing for flexibility for developers to build on top of it.\n"}
{"prompt": "What is the target customer of True Foundry? \n\n###\n\n", "completion": " uuid: 11354404149 The target customers of True Foundry are ML developers who build models, the DevOps or intra-engineer team in companies who want a full view of the infrastructure, and ML engineering leads or managers who want to have a faster ROI for their ML models.\n"}
{"prompt": "What are some of the challenges for on-device ML deployment? \n\n###\n\n", "completion": " uuid: 11354404149 Some of the challenges for on-device ML deployment include optimizing models for device size limitations, figuring out the right approach for SDK, TensorFlow dependencies, distillation techniques for model size reduction, and overcoming privacy concerns for models that need to stay on the device.\n"}
{"prompt": "What components of Sage Maker does Prove use the most? \n\n###\n\n", "completion": " uuid: 11354404149 Prove uses Sage Maker notebooks for easy prototyping, Sage Maker pipelines to package up code and run experiments, and Sage Maker regression for running experiments.\n"}
{"prompt": "What is the structure of the data team at Kotak? \n\n###\n\n", "completion": " uuid: 11655736677 There is a central data team which works with different business units.\n"}
{"prompt": "Do they work with external vendors for ML work? \n\n###\n\n", "completion": " uuid: 11655736677 Yes, they do work with external vendors.\n"}
{"prompt": "How do they measure the ROI from the central data team? \n\n###\n\n", "completion": " uuid: 11655736677 The structure is more of a federated structure where skills are at central level control but teams are embedded within the business functions to work closely with them on use cases and create value.\n"}
{"prompt": "What challenges do they face from a data perspective? \n\n###\n\n", "completion": " uuid: 11655736677 There are significant opportunities for them to scale up and become better, but expectations are far higher as most businesses are becoming data-led businesses.\n"}
{"prompt": "What is the size of the True Foundry team? \n\n###\n\n", "completion": " uuid: 11655736677 The True Foundry team is currently a 15 member full-time team with a few full-time contractors and interns. In total, it is a 24 member team.\n"}
{"prompt": "What is the name of the person being addressed in the conversation? \n\n###\n\n", "completion": " uuid: 10441289250 Richard/Anurag/ANU/Anna\n"}
{"prompt": "What is Richard responsible for at Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 Richard is responsible for the tooling in all ML operations at Wayve, developing better workflows for model developers and measuring improved driving quality on the vehicles.\n"}
{"prompt": "How many people are there in the ML engineering team at Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 Around 60-70 people for a company of 200.\n"}
{"prompt": "What external tooling is used by Wayve for experimentation? \n\n###\n\n", "completion": " uuid: 10441289250 Wayve uses Weights and Biases and Azure for training and experimentation workflows.\n"}
{"prompt": "What is the biggest time sink in Wayve's pipeline that they want to improve? \n\n###\n\n", "completion": " uuid: 10441289250 The biggest time sink is the feedback loop for identifying bugs and fixing issues during the deployment of models.\n"}
{"prompt": "What is the ideal solution for the problem that Richard faces? \n\n###\n\n", "completion": " uuid: 10441289250 Richard would like a way to identify bugs in the model during deployment, understand the issues that the model has during deployment and how to fix those issues.\n"}
{"prompt": "What is the mode of engagement for the company? \n\n###\n\n", "completion": " uuid: 10441289250 The company works with a few companies closely and builds a product along the way, instead of working with a lot of customers.\n"}
{"prompt": "What can the other company provide to Wayve? \n\n###\n\n", "completion": " uuid: 10441289250 The other company can provide clarity on what the product might look like based on Wayve's use case, and they can think about a co-development project if it's necessary.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11185249388 The purpose of the call was to discuss Truefoundry, a machine learning platform being developed to solve problems faced by large startups and enterprises.\n"}
{"prompt": "Where is Bobby based? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby is based in the New York City area, just a little bit north of the city.\n"}
{"prompt": "What is Bobby's background? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby comes from a machine learning background, has a master's from UC Berkeley, and has worked at startups such as Reflection and Facebook. Bobby is the current CEO of his second startup with the same set of co founders.\n"}
{"prompt": "What is the company Bobby sold? \n\n###\n\n", "completion": " uuid: 11185249388 Bobby sold the last startup to Infoyage, the parent company of Nockley.com. The startup focused on building an HR tech platform.\n"}
{"prompt": "What is Netomi's use of machine learning? \n\n###\n\n", "completion": " uuid: 11185249388 Netomi uses machine learning in its customer care platform to provide service and recommendations, such as for upsell and cross-selling.\n"}
{"prompt": "What challenges does Netomi face with machine learning operationalization? \n\n###\n\n", "completion": " uuid: 11185249388 Netomi faces challenges with real-time scoring being slower than database queries, as well as the need to score within a few seconds for their voice platform to avoid timeouts.\n"}
{"prompt": "Who is leading the call? \n\n###\n\n", "completion": " uuid: 11354403912 The person says they are happy to lead the call.\n"}
{"prompt": "What kind of approach does the leader want to take? \n\n###\n\n", "completion": " uuid: 11354403912 The leader wants to try to lead through the floor on the user flow.\n"}
{"prompt": "Who is joining the call? \n\n###\n\n", "completion": " uuid: 11354403912 Michelle is joining the call.\n"}
{"prompt": "What is Michelle's background? \n\n###\n\n", "completion": " uuid: 11354403912 Michelle was working at Times Square as the head of engineering before being acquired by Delivery Hero. Before this, she worked with startups in various engineering roles.\n"}
{"prompt": "What is Proof.Truefoundry presenting? \n\n###\n\n", "completion": " uuid: 11354403912 Proof.Truefoundry is presenting an ML platform focused on model deployment that can ease the process for enterprises.\n"}
{"prompt": "What kind of use cases does TabSquare work on? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare works with restaurants, providing an integration for their menus and helping manage online and offline orders.\n"}
{"prompt": "What is the team size for TabSquare? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare has around 15 people on their data science team and around 120 people on their product engineering team.\n"}
{"prompt": "Where is TabSquare's data stored? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare's data is stored in GCP, including their analytics database and ML models.\n"}
{"prompt": "What tool is TabSquare using for monitoring? \n\n###\n\n", "completion": " uuid: 11354403912 TabSquare is using Data Dog for monitoring.\n"}
{"prompt": "Who writes the YAML configuration for TabSquare's infrastructure? \n\n###\n\n", "completion": " uuid: 11354403912 The DevOps team writes the YAML configuration, but the engineering team writes the Docker files for their services.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11354404209 To gather information about Pegasystems' current ML pipeline.\n"}
{"prompt": "What is Pegasystems' primary use case for AI? \n\n###\n\n", "completion": " uuid: 11354404209 Pegasystems' primary use case for AI is marketing, and they are a gartner leader in real time interaction management.\n"}
{"prompt": "What is the latency requirement for Pega's ML infrastructure? \n\n###\n\n", "completion": " uuid: 11354404209 The latency requirement for Pega's ML infrastructure is 7 milliseconds.\n"}
{"prompt": "What does Pegasystems specialize in for business process automation? \n\n###\n\n", "completion": " uuid: 11354404209 Pegasystems specializes in process AI, which is optimizing processes.\n"}
{"prompt": "Does Pegasystems have a data science team? \n\n###\n\n", "completion": " uuid: 11354404209 Yes, Pegasystems has a data science team of around 50 people.\n"}
{"prompt": "What is the main reason for the call? \n\n###\n\n", "completion": " uuid: 12428091307 Introducing themselves and discussing the company's product line and use cases.\n"}
{"prompt": "What is Jimmy's background? \n\n###\n\n", "completion": " uuid: 12428091307 Jimmy worked as a management consultant at McKinsey before joining his current company where he works mostly on product and customer development and sales. He has a degree in machine learning and is mostly interested in NLP.\n"}
{"prompt": "What is the company's approach to data science? \n\n###\n\n", "completion": " uuid: 12428091307 The company's approach to data science is business-driven rather than centralized. They identify use cases that are associated with various business units and have separate engineering teams associated with each of them.\n"}
{"prompt": "What are the main products that the company is working on? \n\n###\n\n", "completion": " uuid: 12428091307 The company is working on two main products, one of which is a document processing system that automates the manual tasks users might have of gathering data from multiple files and combining them into one file. The other is a process discovery system that identifies the exact process that users are performing and generates a report of these processes automatically.\n"}
{"prompt": "What is Truefoundry's core competency? \n\n###\n\n", "completion": " uuid: 12428091307 Truefoundry's core competency is model deployment and everything after that, including scaling, EB testing, concept drift tracking, and monitoring with data drift tracking. They provide a unified framework to deploy models across clouds.\n"}
{"prompt": "Do you have any clients who are not comfortable sharing data back to the company? \n\n###\n\n", "completion": " uuid: 12428091307 Yes, the company has clients who do not want to share their data back, so in those cases, the company provides them with a locally deployed version of their system.\n"}
{"prompt": "What is the company's approach to ML training and research? \n\n###\n\n", "completion": " uuid: 12428091307 The company's approach to ML training and research is mostly on generated data, and they do not do continuous training or ML work using client data. They continue to update their software and release new versions for clients who are interested.\n"}
{"prompt": "How do developers do training on the company's system? \n\n###\n\n", "completion": " uuid: 12428091307 Developers can submit a training job to Vertex AI, build an image, and then use VMs to conduct the training.\n"}
{"prompt": "Who is joining the call? \n\n###\n\n", "completion": " uuid: 11354392885 Abhishek and Sabnesh\n"}
{"prompt": "What is Abhishek's background? \n\n###\n\n", "completion": " uuid: 11354392885 Abhishek graduated from IT in 2013 with a degree in Computer Science and worked at Facebook for around 5 and a half years. During his time at Facebook, he worked on different teams like the Distributed Caching System team, leading a mobile performance team, and eventually leading the business organization there.\n"}
{"prompt": "What does Trip Foundry focus on? \n\n###\n\n", "completion": " uuid: 11354392885 Trip Foundry is focused on solving the ML deployment platform.\n"}
{"prompt": "What is the main infrastructure used in the company? \n\n###\n\n", "completion": " uuid: 11354392885 The main infrastructure used in the company is GKE-based.\n"}
{"prompt": "What is used for the feature store? \n\n###\n\n", "completion": " uuid: 11354392885 Feast is used for the feature store.\n"}
{"prompt": "What is used for scale-to-zero things? \n\n###\n\n", "completion": " uuid: 11354392885 CSI driver is used for scale-to-zero things.\n"}
{"prompt": "What is used for monitoring? \n\n###\n\n", "completion": " uuid: 11354392885 Google's internal monitoring tool is used for monitoring.\n"}
{"prompt": "What is the purpose of Pub Sub Enabled Cloud Function? \n\n###\n\n", "completion": " uuid: 11354392885 The Pub Sub Enabled Cloud Function is used to send requests to cases and provides throughput control so that it does not choke like Kubernetes chokes.\n"}
{"prompt": "What is the name of the multimodel server used? \n\n###\n\n", "completion": " uuid: 11354392885 The name of the multimodel server used is Triton.\n"}
{"prompt": "What is the purpose of OCR model? \n\n###\n\n", "completion": " uuid: 11354392885 The purpose of the OCR model is to efficiently deploy it on the infrastructure without incurring additional GPU costs.\n"}
{"prompt": "What is the purpose of using Secret Manager? \n\n###\n\n", "completion": " uuid: 11354392885 The purpose of using Secret Manager is to store the secrets permanently and securely, and not rely on Kubernetes to store the secrets.\n"}
{"prompt": "What are some of the challenges that Ankit and his team at locus are facing? \n\n###\n\n", "completion": " uuid: 12249609647 Some of the challenges that Ankit and his team at locus are facing include improving geocoding as a problem, addressing transaction time at the door prediction, figuring out the premium pricing for the prime delivery slot, and possibly identifying the value-based pricing\n"}
{"prompt": "What is the data lake that Ankit and his team are using? \n\n###\n\n", "completion": " uuid: 12249609647 Ankit mentioned that they currently use file storage S3 for the data lake since their load is currently not large enough, but they may explore other options like Snowflake in the future\n"}
{"prompt": "What is the team structure like at locus? \n\n###\n\n", "completion": " uuid: 12249609647 Ankit has a team of roughly 7 data scientists, one or two data engineers, one data analyst, and a DevOps. The team collectively works on structure and non-structured data and leverages pre-trained models and libraries like PyTorch for development and experimentation.\n"}
{"prompt": "What type of models is the team at locus currently experimenting with? \n\n###\n\n", "completion": " uuid: 12249609647 The team at locus is currently experimenting with several machine learning models for different use cases, including optimization, geocoding, addressing transaction times and premium pricing for prime slots for delivery, but nothing has been put into production yet.\n"}
{"prompt": "What do the experiments the team at Locus have in addressing the address problem? \n\n###\n\n", "completion": " uuid: 12249609647 The Locus team has experimented with different approaches to NLP that specifically support address problems, either to train from scratch or to use pre-trained embeddings. They concluded that character-based embeddings tend to perform better than token-based embeddings because they preserve the punctuation and other significant characters in addresses.\n"}
{"prompt": "What is the business model of Health IQ? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ acts as a middleman between insurance carriers and customers with a focus on healthy lifestyles, offering discounted rates to customers who are likely to use insurance less. They generate leads and engage with customers to sell policies. The company is currently focused on Precision Medicare, which uses health data to recommend the best plans for individual customers.\n"}
{"prompt": "What kind of ML problems do they solve at Health IQ? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ works on lead scoring, identifying additional features for leads, and augmenting demographic data from third-party vendors. They use AWS, including Sage Maker and Sage Maker Studio, for model deployment and batch inferencing. All work on ML is done in-house by a team of engineers, without a formal differentiation between data scientists and machine learning engineers.\n"}
{"prompt": "What are the three broad areas of Health IQ's business? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ's business can be broadly divided into marketing and lead generation; sales and dialing leads; and the back-end process of getting paperwork together, sending it to carriers for approval, and getting policies in effect. ML is used to identify the best features, score leads, and augment demographic data.\n"}
{"prompt": "How does the company prepare for AP (annual enrollment period)? \n\n###\n\n", "completion": " uuid: 10346094649 AP is a 55-day period during which insurance companies do 70-80% of their annual business. During this time, companies focus on selling policies and do not engage in extra work or code development that could potentially break anything or slow down the business.\n"}
{"prompt": "How does Health IQ use data to recommend the best plans for individual customers? \n\n###\n\n", "completion": " uuid: 10346094649 Health IQ uses health data from electronic health records, lab tests, doctors and pharmacy visits, and drug history to build models that predict a person's needs and recommend the best plans. They are currently focused on Precision Medicare, which is a multi-level, multi-classification problem for each of 150 diseases, and requires identifying which plans are active and which are most suitable for individual customers.\n"}
{"prompt": "Where is Beville located? \n\n###\n\n", "completion": " uuid: 11656830826 Beville's location is not mentioned in the context.\n"}
{"prompt": "What is the issue with Beville's Chrome? \n\n###\n\n", "completion": " uuid: 11656830826 Beville cannot connect to their camera on their Chrome.\n"}
{"prompt": "Where is Brampton located? \n\n###\n\n", "completion": " uuid: 11656830826 Brampton is located close to Toronto in Canada.\n"}
{"prompt": "What is the weather like in Brampton? \n\n###\n\n", "completion": " uuid: 11656830826 During December to March, the weather in Brampton is very snowy. However, it is currently not a lot of snow.\n"}
{"prompt": "Where is the speaker, Nikki, based currently? \n\n###\n\n", "completion": " uuid: 11656830826 Nikki is currently traveling in India and may take a bus soon. However, Nikki is based out of SF.\n"}
{"prompt": "What is Truefoundry's primary focus? \n\n###\n\n", "completion": " uuid: 11656830826 Truefoundry focuses on deployment and monitoring of machine learning models.\n"}
{"prompt": "What cloud does Procore use? \n\n###\n\n", "completion": " uuid: 11656830826 Procore primarily uses AWS.\n"}
{"prompt": "Where do they primarily do their machine learning? \n\n###\n\n", "completion": " uuid: 11656830826 98% of machine learning work is performed on AWS.\n"}
{"prompt": "Does Procore use Sage Makers? \n\n###\n\n", "completion": " uuid: 11656830826 They used to use Sage Makers, but they now prefer their own solutions.\n"}
{"prompt": "Does Procore use Kubernetes? \n\n###\n\n", "completion": " uuid: 11656830826 Yes, Procore primarily uses Kubernetes for their machine learning.\n"}
{"prompt": "What is the reason for the call? \n\n###\n\n", "completion": " uuid: 12339635717 The caller is working on a thesis and is trying to validate by talking to practitioners.\n"}
{"prompt": "What is the caller's background? \n\n###\n\n", "completion": " uuid: 12339635717 The caller comes from a machine learning background, worked at Facebook and a startup, and has a master's degree from UC Berkeley and a bachelor's from IIT Kharagpur.\n"}
{"prompt": "What is Chandram's background? \n\n###\n\n", "completion": " uuid: 12339635717 Chandram has a CD in Computer Science and Engineering from KIAT University and is currently working as a software engineer related to machine learning operations and previously worked as a data scientist.\n"}
{"prompt": "What cloud providers does High Radius use? \n\n###\n\n", "completion": " uuid: 12339635717 High Radius uses AWS, Google Cloud Platform, and on-premises for their cloud environments.\n"}
{"prompt": "What is the biggest challenge faced in orchestrating cross cloud models and architecture environments? \n\n###\n\n", "completion": " uuid: 12339635717 Performance-related issues such as memory leakages in inference endpoints and use cases that require loading and returning of predictions for huge model file sizes.\n"}
{"prompt": "How many people are on the MLS platform team and data scientist team? \n\n###\n\n", "completion": " uuid: 12339635717 The MLS platform team has 15 people, and the data scientist team has over 100 people.\n"}
{"prompt": "How are the code and dependencies across multiple cloud providers managed and abstracted? \n\n###\n\n", "completion": " uuid: 12339635717 Cloud-native utilities are written, and a naming convention is used for files paths that denote which cloud environment is used. The code is written in a way that all cloud environments are abstracted by a single function that knows from the file path which cloud environment to fetch the file from.\n"}
{"prompt": "What was the goal of the call? \n\n###\n\n", "completion": " uuid: 12428091030 To understand more about the company's data science initiatives, use cases, structure, tools, key priorities, and challenges.\n"}
{"prompt": "Who are the co-founders of Truefoundry and what is their background? \n\n###\n\n", "completion": " uuid: 12428091030 The co-founders of Truefoundry are Aman Raj and his teammates Abishek and Nikunj. Abishek and Nikunj used to be at Facebook where they saw a really good system called Bill on Earth that allowed ML developers to be independent.\n"}
{"prompt": "What is the goal of Truefoundry? \n\n###\n\n", "completion": " uuid: 12428091030 The goal of Truefoundry is to help companies in their journey of machine learning operationalization, by providing infrastructure for training, testing, and deploying models to a broader environment with the right cost effectiveness and engineering practices.\n"}
{"prompt": "What is One AI? \n\n###\n\n", "completion": " uuid: 12428091030 One AI is an internal platform that helps data scientists spin up their own small workbench to work on, based on a microservices platform. It also has built-in support for Jupyter notebooks and VS Code.\n"}
{"prompt": "What data storage system is used for storing experimentation data? \n\n###\n\n", "completion": " uuid: 12428091030 Snowflake is used for storing experimentation data.\n"}
{"prompt": "What metrics platforms are used by the data science team? \n\n###\n\n", "completion": " uuid: 12428091030 The data science team uses MLflow and Seldon for logging model metrics.\n"}
{"prompt": "Who is responsible for deploying the models created by the data scientists? \n\n###\n\n", "completion": " uuid: 12428091030 The ML engineering team is responsible for deploying the models created by the data scientists.\n"}
{"prompt": "Do you use GPU instances for deployment? \n\n###\n\n", "completion": " uuid: 12428091030 No, only CPU instances are used for deployment.\n"}
{"prompt": "Do you maintain separate namespaces or projects within Kubernetes? \n\n###\n\n", "completion": " uuid: 12428091030 Yes, namespaces are used to maintain access control and are sometimes based on projects, but not necessarily.\n"}
{"prompt": "What is the purpose of the call? \n\n###\n\n", "completion": " uuid: 11942287761 To understand more about Soroco and Truefoundry and see how they can potentially help each other.\n"}
{"prompt": "What does George mention about the companion mode? \n\n###\n\n", "completion": " uuid: 11942287761 George mentions that he just learned about it and that his audio is always better through his phone.\n"}
{"prompt": "What is Soroco's goal? \n\n###\n\n", "completion": " uuid: 11942287761 Soroco aims to help organizations understand how work gets done globally through collecting data points and analyzing patterns in the data.\n"}
{"prompt": "What is an example of a real use case of Soroco's analysis? \n\n###\n\n", "completion": " uuid: 11942287761 A real use case is when Soroco worked with a large supply chain customer to improve their purchasing process.\n"}
{"prompt": "How does Soroco deploy their models? \n\n###\n\n", "completion": " uuid: 11942287761 Soroco puts the model into a Blob store location and when the product gets deployed, they are fetched by the product and then loaded locally.\n"}
{"prompt": "What cloud platforms does Soroco use? \n\n###\n\n", "completion": " uuid: 11942287761 Soroco uses Azure and AWS.\n"}
{"prompt": "Does Soroco plan to migrate to GCP soon? \n\n###\n\n", "completion": " uuid: 11942287761 No, Soroco does not see any current customers on GCP.\n"}
{"prompt": "Does Soroco use Kubernetes? \n\n###\n\n", "completion": " uuid: 11942287761 Yes, Soroco does use Kubernetes.\n"}
{"prompt": "What are the three broad business cases that Zulily is trying to solve? \n\n###\n\n", "completion": " uuid: 11487646267 The three broad business cases that Zulily is trying to solve are \u2014 personalization and recommendation, forecasting the sales of a product, and supply chain optimization.\n"}
{"prompt": "What kind of models is Zulily using for recommendations? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses a mix of decision tree-based models and deep learning models for recommendations.\n"}
{"prompt": "What cloud platforms is Zulily using? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses both AWS and GCP as their cloud platforms.\n"}
{"prompt": "What is the tech stack used by Zulily for deploying models? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses Kubernetes for deploying models, and everything is containerized using Docker.\n"}
{"prompt": "Why did Zulily choose to live in two clouds? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily chose to live in two clouds to leverage the best of both worlds. Google BigQuery and data management across Google Cloud and productionizing models for real-time customer services on AWS.\n"}
{"prompt": "What ML training platform is Zulily using? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily is using Kubeflow as their ML training platform to manage and deploy ML pipelines and custom components.\n"}
{"prompt": "What is the in-house tool used by Zulily to track experiments? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily uses Model DB instead of ML Flow to track experiments.\n"}
{"prompt": "How is Zulily's team structured? \n\n###\n\n", "completion": " uuid: 11487646267 Zulily's platform team manages the infrastructure and Kubernetes clusters. Data scientists build the models and there are applied ML engineers who bridge the gap between the platform and the models to put them into production.\n"}
{"prompt": "What is the interface between data scientists and ML engineers at Zulily? \n\n###\n\n", "completion": " uuid: 11487646267 ML engineers work closely with data scientists to bridge the gap between their work and putting the models in production.\n"}
